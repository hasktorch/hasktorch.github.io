<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd"><html xmlns="http://www.w3.org/1999/xhtml"><head><link rel="stylesheet" type="text/css" href="style.css" /><script type="text/javascript" src="highlight.js"></script></head><body><pre><span class="hs-pragma">{-# LANGUAGE ConstraintKinds #-}</span><span>
</span><span id="line-2"></span><span class="hs-pragma">{-# LANGUAGE DataKinds #-}</span><span>
</span><span id="line-3"></span><span class="hs-pragma">{-# LANGUAGE FlexibleContexts #-}</span><span>
</span><span id="line-4"></span><span class="hs-pragma">{-# LANGUAGE FlexibleInstances #-}</span><span>
</span><span id="line-5"></span><span class="hs-pragma">{-# LANGUAGE GADTs #-}</span><span>
</span><span id="line-6"></span><span class="hs-pragma">{-# LANGUAGE MultiParamTypeClasses #-}</span><span>
</span><span id="line-7"></span><span class="hs-pragma">{-# LANGUAGE PartialTypeSignatures #-}</span><span>
</span><span id="line-8"></span><span class="hs-pragma">{-# LANGUAGE PatternSynonyms #-}</span><span>
</span><span id="line-9"></span><span class="hs-pragma">{-# LANGUAGE RecordWildCards #-}</span><span>
</span><span id="line-10"></span><span class="hs-pragma">{-# LANGUAGE ScopedTypeVariables #-}</span><span>
</span><span id="line-11"></span><span class="hs-pragma">{-# LANGUAGE TypeApplications #-}</span><span>
</span><span id="line-12"></span><span class="hs-pragma">{-# LANGUAGE TypeFamilies #-}</span><span>
</span><span id="line-13"></span><span class="hs-pragma">{-# LANGUAGE TypeOperators #-}</span><span>
</span><span id="line-14"></span><span class="hs-pragma">{-# LANGUAGE UndecidableInstances #-}</span><span>
</span><span id="line-15"></span><span class="hs-pragma">{-# OPTIONS_GHC -fplugin TypeLevel.Rewrite
                -fplugin-opt=TypeLevel.Rewrite:Torch.GraduallyTyped.Unify.UnifyRightAssociativeL
                -fplugin-opt=TypeLevel.Rewrite:Torch.GraduallyTyped.Unify.OrRightAssociativeL #-}</span><span>
</span><span id="line-18"></span><span class="hs-pragma">{-# OPTIONS_GHC -v2 -Wall #-}</span><span>
</span><span id="line-19"></span><span>
</span><span id="line-20"></span><span class="hs-keyword">module</span><span> </span><span class="hs-identifier">Torch.GraduallyTyped.NN.Transformer.Encoder</span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-21"></span><span>
</span><span id="line-22"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-identifier">Control.Monad.Indexed</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator">(&gt;&gt;&gt;=)</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-23"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="../file:///nix/store/8vjaffqxij7bih93d9mlzmc7ksanlw0i-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier">Control.Monad.Indexed.State</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="../file:///nix/store/8vjaffqxij7bih93d9mlzmc7ksanlw0i-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier">IxState</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="../file:///nix/store/8vjaffqxij7bih93d9mlzmc7ksanlw0i-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier">IxStateT</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-24"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-identifier">Control.Monad.Indexed.Trans</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-identifier">IxMonadTrans</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-identifier">ilift</span></a></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-25"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-identifier">Data.Functor.Indexed</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-identifier">IxPointed</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-identifier">ireturn</span></a></span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator">(&lt;&lt;$&gt;&gt;)</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator">(&lt;&lt;*&gt;&gt;)</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-26"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><span class="hs-identifier">Data.Kind</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="hs-identifier">Type</span></span><span class="hs-special">)</span><span>
</span><span id="line-27"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier">Data.Singletons</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier">SingI</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-28"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier">Data.Singletons.Prelude.List</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier">SList</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier">SNil</span></a></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-29"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier">Data.Singletons.Prelude.Maybe</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier">SMaybe</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier">SNothing</span></a></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-30"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier">Data.Singletons.TypeLits</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier">SNat</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-31"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><span class="hs-identifier">GHC.TypeLits</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="hs-identifier">Nat</span></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="hs-identifier">Symbol</span></span><span class="hs-special">)</span><span>
</span><span id="line-32"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html"><span class="hs-identifier">Torch.GraduallyTyped.DType</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#DType"><span class="hs-identifier">DType</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#DataType"><span class="hs-identifier">DataType</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#SDType"><span class="hs-identifier">SDType</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#SDataType"><span class="hs-identifier">SDataType</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-33"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Device.html"><span class="hs-identifier">Torch.GraduallyTyped.Device</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#Device"><span class="hs-identifier">Device</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#DeviceType"><span class="hs-identifier">DeviceType</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#SDevice"><span class="hs-identifier">SDevice</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#SDeviceType"><span class="hs-identifier">SDeviceType</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-34"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html"><span class="hs-identifier">Torch.GraduallyTyped.Layout</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#Layout"><span class="hs-identifier">Layout</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#LayoutType"><span class="hs-identifier">LayoutType</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#SLayout"><span class="hs-identifier">SLayout</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#SLayoutType"><span class="hs-identifier">SLayoutType</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-35"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html"><span class="hs-identifier">Torch.GraduallyTyped.NN.Class</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasForward"><span class="hs-identifier">HasForward</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasInitialize"><span class="hs-identifier">HasInitialize</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasStateDict"><span class="hs-identifier">HasStateDict</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#ModelSpec"><span class="hs-identifier">ModelSpec</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-36"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Dropout.html"><span class="hs-identifier">Torch.GraduallyTyped.NN.Dropout</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Dropout.html#Dropout"><span class="hs-identifier">Dropout</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-37"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Functional.Sparse.html"><span class="hs-identifier">Torch.GraduallyTyped.NN.Functional.Sparse</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Functional.Sparse.html#EmbeddingF"><span class="hs-identifier">EmbeddingF</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-38"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Normalization.html"><span class="hs-identifier">Torch.GraduallyTyped.NN.Normalization</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Normalization.html#LayerNorm"><span class="hs-identifier">LayerNorm</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Normalization.html#LayerNormSpec"><span class="hs-identifier">LayerNormSpec</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-39"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Sparse.html"><span class="hs-identifier">Torch.GraduallyTyped.NN.Sparse</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Sparse.html#Embedding"><span class="hs-identifier">Embedding</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Sparse.html#EmbeddingSpec"><span class="hs-identifier">EmbeddingSpec</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-40"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Stack.html"><span class="hs-identifier">Torch.GraduallyTyped.NN.Transformer.Stack</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Stack.html#TransformerStack"><span class="hs-identifier">TransformerStack</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Stack.html#TransformerStackSpec"><span class="hs-identifier">TransformerStackSpec</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-41"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html"><span class="hs-identifier">Torch.GraduallyTyped.NN.Transformer.Type</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#STransformerStyle"><span class="hs-identifier">STransformerStyle</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#TransformerStyle"><span class="hs-identifier">TransformerStyle</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-42"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Type.html"><span class="hs-identifier">Torch.GraduallyTyped.NN.Type</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Type.html#HasBias"><span class="hs-identifier">HasBias</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Type.html#SHasBias"><span class="hs-identifier">SHasBias</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Type.html#SWithBias"><span class="hs-identifier">SWithBias</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Type.html#SWithoutBias"><span class="hs-identifier">SWithoutBias</span></a></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-43"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Prelude.html"><span class="hs-identifier">Torch.GraduallyTyped.Prelude</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Prelude.html#Seq"><span class="hs-identifier">Seq</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-44"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Random.html"><span class="hs-identifier">Torch.GraduallyTyped.Random</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Random.html#sGeneratorToDevice"><span class="hs-identifier">sGeneratorToDevice</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Random.html#sMkGenerator"><span class="hs-identifier">sMkGenerator</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-45"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html"><span class="hs-identifier">Torch.GraduallyTyped.RequiresGradient</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#Gradient"><span class="hs-identifier">Gradient</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#RequiresGradient"><span class="hs-identifier">RequiresGradient</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#SGradient"><span class="hs-identifier">SGradient</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#SRequiresGradient"><span class="hs-identifier">SRequiresGradient</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-46"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Class.html"><span class="hs-identifier">Torch.GraduallyTyped.Shape.Class</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Class.html#BroadcastShapesF"><span class="hs-identifier">BroadcastShapesF</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-47"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html"><span class="hs-identifier">Torch.GraduallyTyped.Shape.Type</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#By"><span class="hs-identifier">By</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier">Name</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SDim"><span class="hs-identifier">SDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SName"><span class="hs-identifier">SName</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SShape"><span class="hs-identifier">SShape</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SSize"><span class="hs-identifier">SSize</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SelectDim"><span class="hs-identifier">SelectDim</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Shape"><span class="hs-identifier">Shape</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier">Size</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="hs-keyword">pattern</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%26%3A"><span class="hs-operator">(:&amp;:)</span></a></span><span class="hs-special">,</span><span> </span><span class="hs-keyword">pattern</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%7C%3A"><span class="hs-operator">(:|:)</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-48"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Creation.html"><span class="hs-identifier">Torch.GraduallyTyped.Tensor.Creation</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Creation.html#sOnes"><span class="hs-identifier">sOnes</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-49"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.IndexingSlicingJoining.html"><span class="hs-identifier">Torch.GraduallyTyped.Tensor.IndexingSlicingJoining</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.IndexingSlicingJoining.html#TransposeF"><span class="hs-identifier">TransposeF</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.IndexingSlicingJoining.html#UnsqueezeF"><span class="hs-identifier">UnsqueezeF</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.IndexingSlicingJoining.html#transpose"><span class="hs-identifier">transpose</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.IndexingSlicingJoining.html#unsqueeze"><span class="hs-identifier">unsqueeze</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-50"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html"><span class="hs-identifier">Torch.GraduallyTyped.Tensor.MathOperations.Pointwise</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#add"><span class="hs-identifier">add</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-51"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html"><span class="hs-identifier">Torch.GraduallyTyped.Tensor.Type</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier">Tensor</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#TensorSpec"><span class="hs-identifier">TensorSpec</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-52"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html"><span class="hs-identifier">Torch.GraduallyTyped.Unify</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-keyword">type</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator">(&lt;+&gt;)</span></a></span><span class="hs-special">,</span><span> </span><span class="hs-keyword">type</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%7C%3E"><span class="hs-operator">(&lt;|&gt;)</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-53"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><span class="hs-identifier">Debug.Trace</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="hs-identifier">traceShowId</span></span><span class="hs-special">)</span><span>
</span><span id="line-54"></span><span>
</span><span id="line-55"></span><span class="hs-comment">-- | Generic transformer encoder.</span><span>
</span><span id="line-56"></span><span class="hs-comment">-- Needs to be specialized to a given transformer type, e.g. 'T5'.</span><span>
</span><span id="line-57"></span><span class="hs-comment">-- See 'TransformerEncoder'.</span><span>
</span><span id="line-58"></span><span class="hs-keyword">data</span><span>
</span><span id="line-59"></span><span>  </span><span id="GTransformerEncoder"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Encoder.html#GTransformerEncoder"><span class="hs-identifier hs-var">GTransformerEncoder</span></a></span></span><span>
</span><span id="line-60"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679808965"><span class="annot"><a href="#local-6989586621679808965"><span class="hs-identifier hs-type">stack</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Type</span></span><span class="hs-special">)</span><span>
</span><span id="line-61"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679808964"><span class="annot"><a href="#local-6989586621679808964"><span class="hs-identifier hs-type">embedLayerNorm</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Type</span></span><span class="hs-special">)</span><span>
</span><span id="line-62"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679808963"><span class="annot"><a href="#local-6989586621679808963"><span class="hs-identifier hs-type">layerNorm</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Type</span></span><span class="hs-special">)</span><span>
</span><span id="line-63"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679808962"><span class="annot"><a href="#local-6989586621679808962"><span class="hs-identifier hs-type">dropout</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Type</span></span><span class="hs-special">)</span><span>
</span><span id="line-64"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679808961"><span class="annot"><a href="#local-6989586621679808961"><span class="hs-identifier hs-type">posEnc</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Type</span></span><span class="hs-special">)</span><span>
</span><span id="line-65"></span><span>  </span><span class="hs-keyword">where</span><span>
</span><span id="line-66"></span><span>  </span><span id="GTransformerEncoder"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Encoder.html#GTransformerEncoder"><span class="hs-identifier hs-var">GTransformerEncoder</span></a></span></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-67"></span><span>    </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679809363"><span class="annot"><a href="#local-6989586621679809363"><span class="hs-identifier hs-type">stack</span></a></span></span><span> </span><span id="local-6989586621679809362"><span class="annot"><a href="#local-6989586621679809362"><span class="hs-identifier hs-type">embedLayerNorm</span></a></span></span><span> </span><span id="local-6989586621679809361"><span class="annot"><a href="#local-6989586621679809361"><span class="hs-identifier hs-type">layerNorm</span></a></span></span><span> </span><span id="local-6989586621679809360"><span class="annot"><a href="#local-6989586621679809360"><span class="hs-identifier hs-type">dropout</span></a></span></span><span> </span><span id="local-6989586621679809359"><span class="annot"><a href="#local-6989586621679809359"><span class="hs-identifier hs-type">posEnc</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-68"></span><span>    </span><span class="hs-special">{</span><span> </span><span class="hs-comment">-- | encoder layer stack</span><span>
</span><span id="line-69"></span><span>      </span><span id="teStack"><span class="annot"><span class="annottext">GTransformerEncoder stack embedLayerNorm layerNorm dropout posEnc
-&gt; stack
</span><a href="Torch.GraduallyTyped.NN.Transformer.Encoder.html#teStack"><span class="hs-identifier hs-var hs-var">teStack</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="#local-6989586621679809363"><span class="hs-identifier hs-type">stack</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-70"></span><span>      </span><span class="hs-comment">-- | encoder embedding layer norm</span><span>
</span><span id="line-71"></span><span>      </span><span id="teEmbedLayerNorm"><span class="annot"><span class="annottext">GTransformerEncoder stack embedLayerNorm layerNorm dropout posEnc
-&gt; embedLayerNorm
</span><a href="Torch.GraduallyTyped.NN.Transformer.Encoder.html#teEmbedLayerNorm"><span class="hs-identifier hs-var hs-var">teEmbedLayerNorm</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="#local-6989586621679809362"><span class="hs-identifier hs-type">embedLayerNorm</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-72"></span><span>      </span><span class="hs-comment">-- | encoder layer norm</span><span>
</span><span id="line-73"></span><span>      </span><span id="teLayerNorm"><span class="annot"><span class="annottext">GTransformerEncoder stack embedLayerNorm layerNorm dropout posEnc
-&gt; layerNorm
</span><a href="Torch.GraduallyTyped.NN.Transformer.Encoder.html#teLayerNorm"><span class="hs-identifier hs-var hs-var">teLayerNorm</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="#local-6989586621679809361"><span class="hs-identifier hs-type">layerNorm</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-74"></span><span>      </span><span class="hs-comment">-- | encoder dropout</span><span>
</span><span id="line-75"></span><span>      </span><span id="teDropout"><span class="annot"><span class="annottext">GTransformerEncoder stack embedLayerNorm layerNorm dropout posEnc
-&gt; dropout
</span><a href="Torch.GraduallyTyped.NN.Transformer.Encoder.html#teDropout"><span class="hs-identifier hs-var hs-var">teDropout</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="#local-6989586621679809360"><span class="hs-identifier hs-type">dropout</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-76"></span><span>      </span><span class="hs-comment">-- | positional encoding</span><span>
</span><span id="line-77"></span><span>      </span><span id="tePosEnc"><span class="annot"><span class="annottext">GTransformerEncoder stack embedLayerNorm layerNorm dropout posEnc
-&gt; posEnc
</span><a href="Torch.GraduallyTyped.NN.Transformer.Encoder.html#tePosEnc"><span class="hs-identifier hs-var hs-var">tePosEnc</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="#local-6989586621679809359"><span class="hs-identifier hs-type">posEnc</span></a></span><span>
</span><span id="line-78"></span><span>    </span><span class="hs-special">}</span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-79"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Encoder.html#GTransformerEncoder"><span class="hs-identifier hs-type">GTransformerEncoder</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679809363"><span class="hs-identifier hs-type">stack</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679809362"><span class="hs-identifier hs-type">embedLayerNorm</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679809361"><span class="hs-identifier hs-type">layerNorm</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679809360"><span class="hs-identifier hs-type">dropout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679809359"><span class="hs-identifier hs-type">posEnc</span></a></span><span>
</span><span id="line-80"></span><span>
</span><span id="line-81"></span><span class="hs-comment">-- | Transformer encoder.</span><span>
</span><span id="line-82"></span><span class="hs-keyword">newtype</span><span>
</span><span id="line-83"></span><span>  </span><span id="TransformerEncoder"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Encoder.html#TransformerEncoder"><span class="hs-identifier hs-var">TransformerEncoder</span></a></span></span><span>
</span><span id="line-84"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679808954"><span class="annot"><a href="#local-6989586621679808954"><span class="hs-identifier hs-type">style</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#TransformerStyle"><span class="hs-identifier hs-type">TransformerStyle</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-85"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679808953"><span class="annot"><a href="#local-6989586621679808953"><span class="hs-identifier hs-type">numLayers</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span>
</span><span id="line-86"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679808952"><span class="annot"><a href="#local-6989586621679808952"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#Gradient"><span class="hs-identifier hs-type">Gradient</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#RequiresGradient"><span class="hs-identifier hs-type">RequiresGradient</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-87"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679808951"><span class="annot"><a href="#local-6989586621679808951"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#Device"><span class="hs-identifier hs-type">Device</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#DeviceType"><span class="hs-identifier hs-type">DeviceType</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-88"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679808950"><span class="annot"><a href="#local-6989586621679808950"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#DataType"><span class="hs-identifier hs-type">DataType</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#DType"><span class="hs-identifier hs-type">DType</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-89"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679808949"><span class="annot"><a href="#local-6989586621679808949"><span class="hs-identifier hs-type">headDim</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Symbol</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-90"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679808948"><span class="annot"><a href="#local-6989586621679808948"><span class="hs-identifier hs-type">headEmbedDim</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Symbol</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-91"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679808947"><span class="annot"><a href="#local-6989586621679808947"><span class="hs-identifier hs-type">embedDim</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Symbol</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-92"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679808946"><span class="annot"><a href="#local-6989586621679808946"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Symbol</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-93"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679808945"><span class="annot"><a href="#local-6989586621679808945"><span class="hs-identifier hs-type">ffnDim</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Symbol</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-94"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679808944"><span class="annot"><a href="#local-6989586621679808944"><span class="hs-identifier hs-type">posEncDim</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Symbol</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-95"></span><span>  </span><span class="hs-keyword">where</span><span>
</span><span id="line-96"></span><span>  </span><span id="TransformerEncoder"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Encoder.html#TransformerEncoder"><span class="hs-identifier hs-var">TransformerEncoder</span></a></span></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-97"></span><span>    </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679809325"><span class="annot"><a href="#local-6989586621679809325"><span class="hs-identifier hs-type">style</span></a></span></span><span> </span><span id="local-6989586621679809324"><span class="annot"><a href="#local-6989586621679809324"><span class="hs-identifier hs-type">numLayers</span></a></span></span><span> </span><span id="local-6989586621679809323"><span class="annot"><a href="#local-6989586621679809323"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679809322"><span class="annot"><a href="#local-6989586621679809322"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679809321"><span class="annot"><a href="#local-6989586621679809321"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679809320"><span class="annot"><a href="#local-6989586621679809320"><span class="hs-identifier hs-type">headDim</span></a></span></span><span> </span><span id="local-6989586621679809319"><span class="annot"><a href="#local-6989586621679809319"><span class="hs-identifier hs-type">headEmbedDim</span></a></span></span><span> </span><span id="local-6989586621679809318"><span class="annot"><a href="#local-6989586621679809318"><span class="hs-identifier hs-type">embedDim</span></a></span></span><span> </span><span id="local-6989586621679809317"><span class="annot"><a href="#local-6989586621679809317"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span></span><span> </span><span id="local-6989586621679809316"><span class="annot"><a href="#local-6989586621679809316"><span class="hs-identifier hs-type">ffnDim</span></a></span></span><span> </span><span id="local-6989586621679809315"><span class="annot"><a href="#local-6989586621679809315"><span class="hs-identifier hs-type">posEncDim</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-98"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Encoder.html#GTransformerEncoder"><span class="hs-identifier hs-type">GTransformerEncoder</span></a></span><span>
</span><span id="line-99"></span><span>      </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Encoder.html#TEStackF"><span class="hs-identifier hs-type">TEStackF</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679809325"><span class="hs-identifier hs-type">style</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679809324"><span class="hs-identifier hs-type">numLayers</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679809323"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679809322"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679809321"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679809320"><span class="hs-identifier hs-type">headDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679809319"><span class="hs-identifier hs-type">headEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679809318"><span class="hs-identifier hs-type">embedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679809317"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679809316"><span class="hs-identifier hs-type">ffnDim</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-100"></span><span>      </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Encoder.html#TEEmbedLayerNormF"><span class="hs-identifier hs-type">TEEmbedLayerNormF</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679809325"><span class="hs-identifier hs-type">style</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679809323"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679809322"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679809321"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679809317"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-101"></span><span>      </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Encoder.html#TELayerNormF"><span class="hs-identifier hs-type">TELayerNormF</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679809325"><span class="hs-identifier hs-type">style</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679809323"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679809322"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679809321"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679809317"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-102"></span><span>      </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Encoder.html#TEDropoutF"><span class="hs-identifier hs-type">TEDropoutF</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679809325"><span class="hs-identifier hs-type">style</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-103"></span><span>      </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Encoder.html#TEPosEncF"><span class="hs-identifier hs-type">TEPosEncF</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679809325"><span class="hs-identifier hs-type">style</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679809323"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679809322"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679809321"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679809320"><span class="hs-identifier hs-type">headDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679809317"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679809315"><span class="hs-identifier hs-type">posEncDim</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-104"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Encoder.html#TransformerEncoder"><span class="hs-identifier hs-type">TransformerEncoder</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679809325"><span class="hs-identifier hs-type">style</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679809324"><span class="hs-identifier hs-type">numLayers</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679809323"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679809322"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679809321"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679809320"><span class="hs-identifier hs-type">headDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679809319"><span class="hs-identifier hs-type">headEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679809318"><span class="hs-identifier hs-type">embedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679809317"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679809316"><span class="hs-identifier hs-type">ffnDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679809315"><span class="hs-identifier hs-type">posEncDim</span></a></span><span>
</span><span id="line-105"></span><span>
</span><span id="line-106"></span><span class="hs-keyword">data</span><span>
</span><span id="line-107"></span><span>  </span><span id="TransformerEncoderSpec"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Encoder.html#TransformerEncoderSpec"><span class="hs-identifier hs-var">TransformerEncoderSpec</span></a></span></span><span>
</span><span id="line-108"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679808942"><span class="annot"><a href="#local-6989586621679808942"><span class="hs-identifier hs-type">style</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#TransformerStyle"><span class="hs-identifier hs-type">TransformerStyle</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-109"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679808941"><span class="annot"><a href="#local-6989586621679808941"><span class="hs-identifier hs-type">numLayers</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span>
</span><span id="line-110"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679808940"><span class="annot"><a href="#local-6989586621679808940"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#Gradient"><span class="hs-identifier hs-type">Gradient</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#RequiresGradient"><span class="hs-identifier hs-type">RequiresGradient</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-111"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679808939"><span class="annot"><a href="#local-6989586621679808939"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#Device"><span class="hs-identifier hs-type">Device</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#DeviceType"><span class="hs-identifier hs-type">DeviceType</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-112"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679808938"><span class="annot"><a href="#local-6989586621679808938"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#DataType"><span class="hs-identifier hs-type">DataType</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#DType"><span class="hs-identifier hs-type">DType</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-113"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679808937"><span class="annot"><a href="#local-6989586621679808937"><span class="hs-identifier hs-type">headDim</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Symbol</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-114"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679808936"><span class="annot"><a href="#local-6989586621679808936"><span class="hs-identifier hs-type">headEmbedDim</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Symbol</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-115"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679808935"><span class="annot"><a href="#local-6989586621679808935"><span class="hs-identifier hs-type">embedDim</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Symbol</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-116"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679808934"><span class="annot"><a href="#local-6989586621679808934"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Symbol</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-117"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679808933"><span class="annot"><a href="#local-6989586621679808933"><span class="hs-identifier hs-type">ffnDim</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Symbol</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-118"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679808932"><span class="annot"><a href="#local-6989586621679808932"><span class="hs-identifier hs-type">posEncDim</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Symbol</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-119"></span><span>  </span><span class="hs-keyword">where</span><span>
</span><span id="line-120"></span><span>  </span><span id="TransformerEncoderSpec"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Encoder.html#TransformerEncoderSpec"><span class="hs-identifier hs-var">TransformerEncoderSpec</span></a></span></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-121"></span><span>    </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679809169"><span class="annot"><a href="#local-6989586621679809169"><span class="hs-identifier hs-type">style</span></a></span></span><span> </span><span id="local-6989586621679809168"><span class="annot"><a href="#local-6989586621679809168"><span class="hs-identifier hs-type">numLayers</span></a></span></span><span> </span><span id="local-6989586621679809167"><span class="annot"><a href="#local-6989586621679809167"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679809166"><span class="annot"><a href="#local-6989586621679809166"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679809165"><span class="annot"><a href="#local-6989586621679809165"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679809164"><span class="annot"><a href="#local-6989586621679809164"><span class="hs-identifier hs-type">headDim</span></a></span></span><span> </span><span id="local-6989586621679809163"><span class="annot"><a href="#local-6989586621679809163"><span class="hs-identifier hs-type">headEmbedDim</span></a></span></span><span> </span><span id="local-6989586621679809162"><span class="annot"><a href="#local-6989586621679809162"><span class="hs-identifier hs-type">embedDim</span></a></span></span><span> </span><span id="local-6989586621679809161"><span class="annot"><a href="#local-6989586621679809161"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span></span><span> </span><span id="local-6989586621679809160"><span class="annot"><a href="#local-6989586621679809160"><span class="hs-identifier hs-type">ffnDim</span></a></span></span><span> </span><span id="local-6989586621679809159"><span class="annot"><a href="#local-6989586621679809159"><span class="hs-identifier hs-type">posEncDim</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-122"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#STransformerStyle"><span class="hs-identifier hs-type">STransformerStyle</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679809169"><span class="hs-identifier hs-type">style</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-123"></span><span>    </span><span class="annot"><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-type">SNat</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679809168"><span class="hs-identifier hs-type">numLayers</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-124"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#SGradient"><span class="hs-identifier hs-type">SGradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679809167"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-125"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#SDevice"><span class="hs-identifier hs-type">SDevice</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679809166"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-126"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#SDataType"><span class="hs-identifier hs-type">SDataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679809165"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-127"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SDim"><span class="hs-identifier hs-type">SDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679809164"><span class="hs-identifier hs-type">headDim</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-128"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SDim"><span class="hs-identifier hs-type">SDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679809163"><span class="hs-identifier hs-type">headEmbedDim</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-129"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SDim"><span class="hs-identifier hs-type">SDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679809162"><span class="hs-identifier hs-type">embedDim</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-130"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SDim"><span class="hs-identifier hs-type">SDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679809161"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-131"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SDim"><span class="hs-identifier hs-type">SDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679809160"><span class="hs-identifier hs-type">ffnDim</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-132"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SDim"><span class="hs-identifier hs-type">SDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679809159"><span class="hs-identifier hs-type">posEncDim</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-133"></span><span>    </span><span class="annot"><span class="hs-identifier hs-type">Double</span></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-134"></span><span>    </span><span class="annot"><span class="hs-identifier hs-type">Double</span></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-135"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Encoder.html#TransformerEncoderSpec"><span class="hs-identifier hs-type">TransformerEncoderSpec</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679809169"><span class="hs-identifier hs-type">style</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679809168"><span class="hs-identifier hs-type">numLayers</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679809167"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679809166"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679809165"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679809164"><span class="hs-identifier hs-type">headDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679809163"><span class="hs-identifier hs-type">headEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679809162"><span class="hs-identifier hs-type">embedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679809161"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679809160"><span class="hs-identifier hs-type">ffnDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679809159"><span class="hs-identifier hs-type">posEncDim</span></a></span><span>
</span><span id="line-136"></span><span>
</span><span id="line-137"></span><span class="hs-keyword">type</span><span> </span><span class="hs-keyword">instance</span><span> </span><span id="ModelSpec"><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#ModelSpec"><span class="hs-identifier hs-var">ModelSpec</span></a></span></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Encoder.html#TransformerEncoder"><span class="hs-identifier hs-type">TransformerEncoder</span></a></span><span> </span><span id="local-6989586621679808930"><span class="annot"><a href="#local-6989586621679808930"><span class="hs-identifier hs-type hs-type">style</span></a></span></span><span> </span><span id="local-6989586621679808929"><span class="annot"><a href="#local-6989586621679808929"><span class="hs-identifier hs-type hs-type">numLayers</span></a></span></span><span> </span><span id="local-6989586621679808928"><span class="annot"><a href="#local-6989586621679808928"><span class="hs-identifier hs-type hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679808927"><span class="annot"><a href="#local-6989586621679808927"><span class="hs-identifier hs-type hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679808926"><span class="annot"><a href="#local-6989586621679808926"><span class="hs-identifier hs-type hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679808925"><span class="annot"><a href="#local-6989586621679808925"><span class="hs-identifier hs-type hs-type">headDim</span></a></span></span><span> </span><span id="local-6989586621679808924"><span class="annot"><a href="#local-6989586621679808924"><span class="hs-identifier hs-type hs-type">headEmbedDim</span></a></span></span><span> </span><span id="local-6989586621679808923"><span class="annot"><a href="#local-6989586621679808923"><span class="hs-identifier hs-type hs-type">embedDim</span></a></span></span><span> </span><span id="local-6989586621679808922"><span class="annot"><a href="#local-6989586621679808922"><span class="hs-identifier hs-type hs-type">inputEmbedDim</span></a></span></span><span> </span><span id="local-6989586621679808921"><span class="annot"><a href="#local-6989586621679808921"><span class="hs-identifier hs-type hs-type">ffnDim</span></a></span></span><span> </span><span id="local-6989586621679808920"><span class="annot"><a href="#local-6989586621679808920"><span class="hs-identifier hs-type hs-type">posEncDim</span></a></span></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Encoder.html#TransformerEncoderSpec"><span class="hs-identifier hs-type">TransformerEncoderSpec</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808930"><span class="hs-identifier hs-type">style</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808929"><span class="hs-identifier hs-type">numLayers</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808928"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808927"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808926"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808925"><span class="hs-identifier hs-type">headDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808924"><span class="hs-identifier hs-type">headEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808923"><span class="hs-identifier hs-type">embedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808922"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808921"><span class="hs-identifier hs-type">ffnDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808920"><span class="hs-identifier hs-type">posEncDim</span></a></span><span>
</span><span id="line-138"></span><span>
</span><span id="line-139"></span><span class="hs-keyword">type</span><span> </span><span class="hs-keyword">family</span><span>
</span><span id="line-140"></span><span>  </span><span id="TEStackF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Encoder.html#TEStackF"><span class="hs-identifier hs-var">TEStackF</span></a></span></span><span>
</span><span id="line-141"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679808919"><span class="annot"><a href="#local-6989586621679808919"><span class="hs-identifier hs-type">style</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#TransformerStyle"><span class="hs-identifier hs-type">TransformerStyle</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-142"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679808918"><span class="annot"><a href="#local-6989586621679808918"><span class="hs-identifier hs-type">numLayers</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span>
</span><span id="line-143"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679808917"><span class="annot"><a href="#local-6989586621679808917"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#Gradient"><span class="hs-identifier hs-type">Gradient</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#RequiresGradient"><span class="hs-identifier hs-type">RequiresGradient</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-144"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679808916"><span class="annot"><a href="#local-6989586621679808916"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#Device"><span class="hs-identifier hs-type">Device</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#DeviceType"><span class="hs-identifier hs-type">DeviceType</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-145"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679808915"><span class="annot"><a href="#local-6989586621679808915"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#DataType"><span class="hs-identifier hs-type">DataType</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#DType"><span class="hs-identifier hs-type">DType</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-146"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679808914"><span class="annot"><a href="#local-6989586621679808914"><span class="hs-identifier hs-type">headDim</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Symbol</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-147"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679808913"><span class="annot"><a href="#local-6989586621679808913"><span class="hs-identifier hs-type">headEmbedDim</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Symbol</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-148"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679808912"><span class="annot"><a href="#local-6989586621679808912"><span class="hs-identifier hs-type">embedDim</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Symbol</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-149"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679808911"><span class="annot"><a href="#local-6989586621679808911"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Symbol</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-150"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679808910"><span class="annot"><a href="#local-6989586621679808910"><span class="hs-identifier hs-type">ffnDim</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Symbol</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-151"></span><span>    </span><span class="annot"><span class="hs-identifier hs-type">Type</span></span><span>
</span><span id="line-152"></span><span>  </span><span class="hs-keyword">where</span><span>
</span><span id="line-153"></span><span>  </span><span id="TEStackF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Encoder.html#TEStackF"><span class="hs-identifier hs-var">TEStackF</span></a></span></span><span> </span><span id="local-6989586621679808909"><span class="annot"><a href="#local-6989586621679808909"><span class="hs-identifier hs-type hs-type">style</span></a></span></span><span> </span><span id="local-6989586621679808908"><span class="annot"><a href="#local-6989586621679808908"><span class="hs-identifier hs-type hs-type">numLayers</span></a></span></span><span> </span><span id="local-6989586621679808907"><span class="annot"><a href="#local-6989586621679808907"><span class="hs-identifier hs-type hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679808906"><span class="annot"><a href="#local-6989586621679808906"><span class="hs-identifier hs-type hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679808905"><span class="annot"><a href="#local-6989586621679808905"><span class="hs-identifier hs-type hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679808904"><span class="annot"><a href="#local-6989586621679808904"><span class="hs-identifier hs-type hs-type">headDim</span></a></span></span><span> </span><span id="local-6989586621679808903"><span class="annot"><a href="#local-6989586621679808903"><span class="hs-identifier hs-type hs-type">headEmbedDim</span></a></span></span><span> </span><span id="local-6989586621679808902"><span class="annot"><a href="#local-6989586621679808902"><span class="hs-identifier hs-type hs-type">embedDim</span></a></span></span><span> </span><span id="local-6989586621679808901"><span class="annot"><a href="#local-6989586621679808901"><span class="hs-identifier hs-type hs-type">inputEmbedDim</span></a></span></span><span> </span><span id="local-6989586621679808900"><span class="annot"><a href="#local-6989586621679808900"><span class="hs-identifier hs-type hs-type">ffnDim</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-154"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Stack.html#TransformerStack"><span class="hs-identifier hs-type">TransformerStack</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808909"><span class="hs-identifier hs-type">style</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808908"><span class="hs-identifier hs-type">numLayers</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808907"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808906"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808905"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808904"><span class="hs-identifier hs-type">headDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808903"><span class="hs-identifier hs-type">headEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808902"><span class="hs-identifier hs-type">embedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808901"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808900"><span class="hs-identifier hs-type">ffnDim</span></a></span><span>
</span><span id="line-155"></span><span>
</span><span id="line-156"></span><span class="hs-keyword">type</span><span> </span><span class="hs-keyword">family</span><span>
</span><span id="line-157"></span><span>  </span><span id="TEEmbedLayerNormF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Encoder.html#TEEmbedLayerNormF"><span class="hs-identifier hs-var">TEEmbedLayerNormF</span></a></span></span><span>
</span><span id="line-158"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679808899"><span class="annot"><a href="#local-6989586621679808899"><span class="hs-identifier hs-type">style</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#TransformerStyle"><span class="hs-identifier hs-type">TransformerStyle</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-159"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679808898"><span class="annot"><a href="#local-6989586621679808898"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#Gradient"><span class="hs-identifier hs-type">Gradient</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#RequiresGradient"><span class="hs-identifier hs-type">RequiresGradient</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-160"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679808897"><span class="annot"><a href="#local-6989586621679808897"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#Device"><span class="hs-identifier hs-type">Device</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#DeviceType"><span class="hs-identifier hs-type">DeviceType</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-161"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679808896"><span class="annot"><a href="#local-6989586621679808896"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#DataType"><span class="hs-identifier hs-type">DataType</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#DType"><span class="hs-identifier hs-type">DType</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-162"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679808895"><span class="annot"><a href="#local-6989586621679808895"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Symbol</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-163"></span><span>    </span><span class="annot"><span class="hs-identifier hs-type">Type</span></span><span>
</span><span id="line-164"></span><span>  </span><span class="hs-keyword">where</span><span>
</span><span id="line-165"></span><span>  </span><span id="TEEmbedLayerNormF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Encoder.html#TEEmbedLayerNormF"><span class="hs-identifier hs-var">TEEmbedLayerNormF</span></a></span></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#T5"><span class="hs-identifier hs-type">T5</span></a></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="hs-special">(</span><span class="hs-special">)</span><span>
</span><span id="line-166"></span><span>  </span><span id="TEEmbedLayerNormF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Encoder.html#TEEmbedLayerNormF"><span class="hs-identifier hs-var">TEEmbedLayerNormF</span></a></span></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#ByT5"><span class="hs-identifier hs-type">ByT5</span></a></span><span> </span><span id="local-6989586621679808894"><span class="annot"><a href="#local-6989586621679808894"><span class="hs-identifier hs-type hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679808893"><span class="annot"><a href="#local-6989586621679808893"><span class="hs-identifier hs-type hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679808892"><span class="annot"><a href="#local-6989586621679808892"><span class="hs-identifier hs-type hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679808891"><span class="annot"><a href="#local-6989586621679808891"><span class="hs-identifier hs-type hs-type">inputEmbedDim</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Encoder.html#TEEmbedLayerNormF"><span class="hs-identifier hs-type">TEEmbedLayerNormF</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#T5"><span class="hs-identifier hs-type">T5</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808894"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808893"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808892"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808891"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span><span>
</span><span id="line-167"></span><span>  </span><span id="TEEmbedLayerNormF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Encoder.html#TEEmbedLayerNormF"><span class="hs-identifier hs-var">TEEmbedLayerNormF</span></a></span></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#BART"><span class="hs-identifier hs-type">BART</span></a></span><span> </span><span id="local-6989586621679808890"><span class="annot"><a href="#local-6989586621679808890"><span class="hs-identifier hs-type hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679808889"><span class="annot"><a href="#local-6989586621679808889"><span class="hs-identifier hs-type hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679808888"><span class="annot"><a href="#local-6989586621679808888"><span class="hs-identifier hs-type hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679808887"><span class="annot"><a href="#local-6989586621679808887"><span class="hs-identifier hs-type hs-type">inputEmbedDim</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Normalization.html#LayerNorm"><span class="hs-identifier hs-type">LayerNorm</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Type.html#WithBias"><span class="hs-identifier hs-type">WithBias</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808890"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808889"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808888"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Shape"><span class="hs-identifier hs-type">Shape</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="annot"><a href="#local-6989586621679808887"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span><span class="hs-special">]</span><span class="hs-special">)</span><span>
</span><span id="line-168"></span><span>  </span><span id="TEEmbedLayerNormF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Encoder.html#TEEmbedLayerNormF"><span class="hs-identifier hs-var">TEEmbedLayerNormF</span></a></span></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#MBART"><span class="hs-identifier hs-type">MBART</span></a></span><span> </span><span id="local-6989586621679808886"><span class="annot"><a href="#local-6989586621679808886"><span class="hs-identifier hs-type hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679808885"><span class="annot"><a href="#local-6989586621679808885"><span class="hs-identifier hs-type hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679808884"><span class="annot"><a href="#local-6989586621679808884"><span class="hs-identifier hs-type hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679808883"><span class="annot"><a href="#local-6989586621679808883"><span class="hs-identifier hs-type hs-type">inputEmbedDim</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Encoder.html#TEEmbedLayerNormF"><span class="hs-identifier hs-type">TEEmbedLayerNormF</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#BART"><span class="hs-identifier hs-type">BART</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808886"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808885"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808884"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808883"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span><span>
</span><span id="line-169"></span><span>  </span><span id="TEEmbedLayerNormF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Encoder.html#TEEmbedLayerNormF"><span class="hs-identifier hs-var">TEEmbedLayerNormF</span></a></span></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#Pegasus"><span class="hs-identifier hs-type">Pegasus</span></a></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="hs-special">(</span><span class="hs-special">)</span><span>
</span><span id="line-170"></span><span>  </span><span id="TEEmbedLayerNormF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Encoder.html#TEEmbedLayerNormF"><span class="hs-identifier hs-var">TEEmbedLayerNormF</span></a></span></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#BERT"><span class="hs-identifier hs-type">BERT</span></a></span><span> </span><span id="local-6989586621679808882"><span class="annot"><a href="#local-6989586621679808882"><span class="hs-identifier hs-type hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679808881"><span class="annot"><a href="#local-6989586621679808881"><span class="hs-identifier hs-type hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679808880"><span class="annot"><a href="#local-6989586621679808880"><span class="hs-identifier hs-type hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679808879"><span class="annot"><a href="#local-6989586621679808879"><span class="hs-identifier hs-type hs-type">inputEmbedDim</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Normalization.html#LayerNorm"><span class="hs-identifier hs-type">LayerNorm</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Type.html#WithBias"><span class="hs-identifier hs-type">WithBias</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808882"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808881"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808880"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Shape"><span class="hs-identifier hs-type">Shape</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="annot"><a href="#local-6989586621679808879"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span><span class="hs-special">]</span><span class="hs-special">)</span><span>
</span><span id="line-171"></span><span>  </span><span id="TEEmbedLayerNormF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Encoder.html#TEEmbedLayerNormF"><span class="hs-identifier hs-var">TEEmbedLayerNormF</span></a></span></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#RoBERTa"><span class="hs-identifier hs-type">RoBERTa</span></a></span><span> </span><span id="local-6989586621679808878"><span class="annot"><a href="#local-6989586621679808878"><span class="hs-identifier hs-type hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679808877"><span class="annot"><a href="#local-6989586621679808877"><span class="hs-identifier hs-type hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679808876"><span class="annot"><a href="#local-6989586621679808876"><span class="hs-identifier hs-type hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679808875"><span class="annot"><a href="#local-6989586621679808875"><span class="hs-identifier hs-type hs-type">inputEmbedDim</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Encoder.html#TEEmbedLayerNormF"><span class="hs-identifier hs-type">TEEmbedLayerNormF</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#BERT"><span class="hs-identifier hs-type">BERT</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808878"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808877"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808876"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808875"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span><span>
</span><span id="line-172"></span><span>
</span><span id="line-173"></span><span class="hs-keyword">type</span><span> </span><span class="hs-keyword">family</span><span>
</span><span id="line-174"></span><span>  </span><span id="TELayerNormF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Encoder.html#TELayerNormF"><span class="hs-identifier hs-var">TELayerNormF</span></a></span></span><span>
</span><span id="line-175"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679808874"><span class="annot"><a href="#local-6989586621679808874"><span class="hs-identifier hs-type">style</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#TransformerStyle"><span class="hs-identifier hs-type">TransformerStyle</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-176"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679808873"><span class="annot"><a href="#local-6989586621679808873"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#Gradient"><span class="hs-identifier hs-type">Gradient</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#RequiresGradient"><span class="hs-identifier hs-type">RequiresGradient</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-177"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679808872"><span class="annot"><a href="#local-6989586621679808872"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#Device"><span class="hs-identifier hs-type">Device</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#DeviceType"><span class="hs-identifier hs-type">DeviceType</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-178"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679808871"><span class="annot"><a href="#local-6989586621679808871"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#DataType"><span class="hs-identifier hs-type">DataType</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#DType"><span class="hs-identifier hs-type">DType</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-179"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679808870"><span class="annot"><a href="#local-6989586621679808870"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Symbol</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-180"></span><span>    </span><span class="annot"><span class="hs-identifier hs-type">Type</span></span><span>
</span><span id="line-181"></span><span>  </span><span class="hs-keyword">where</span><span>
</span><span id="line-182"></span><span>  </span><span id="TELayerNormF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Encoder.html#TELayerNormF"><span class="hs-identifier hs-var">TELayerNormF</span></a></span></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#T5"><span class="hs-identifier hs-type">T5</span></a></span><span> </span><span id="local-6989586621679808869"><span class="annot"><a href="#local-6989586621679808869"><span class="hs-identifier hs-type hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679808868"><span class="annot"><a href="#local-6989586621679808868"><span class="hs-identifier hs-type hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679808867"><span class="annot"><a href="#local-6989586621679808867"><span class="hs-identifier hs-type hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679808866"><span class="annot"><a href="#local-6989586621679808866"><span class="hs-identifier hs-type hs-type">inputEmbedDim</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Normalization.html#LayerNorm"><span class="hs-identifier hs-type">LayerNorm</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Type.html#WithoutBias"><span class="hs-identifier hs-type">WithoutBias</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808869"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808868"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808867"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Shape"><span class="hs-identifier hs-type">Shape</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="annot"><a href="#local-6989586621679808866"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span><span class="hs-special">]</span><span class="hs-special">)</span><span>
</span><span id="line-183"></span><span>  </span><span id="TELayerNormF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Encoder.html#TELayerNormF"><span class="hs-identifier hs-var">TELayerNormF</span></a></span></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#ByT5"><span class="hs-identifier hs-type">ByT5</span></a></span><span> </span><span id="local-6989586621679808865"><span class="annot"><a href="#local-6989586621679808865"><span class="hs-identifier hs-type hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679808864"><span class="annot"><a href="#local-6989586621679808864"><span class="hs-identifier hs-type hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679808863"><span class="annot"><a href="#local-6989586621679808863"><span class="hs-identifier hs-type hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679808862"><span class="annot"><a href="#local-6989586621679808862"><span class="hs-identifier hs-type hs-type">inputEmbedDim</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Encoder.html#TELayerNormF"><span class="hs-identifier hs-type">TELayerNormF</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#T5"><span class="hs-identifier hs-type">T5</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808865"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808864"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808863"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808862"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span><span>
</span><span id="line-184"></span><span>  </span><span id="TELayerNormF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Encoder.html#TELayerNormF"><span class="hs-identifier hs-var">TELayerNormF</span></a></span></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#BART"><span class="hs-identifier hs-type">BART</span></a></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="hs-special">(</span><span class="hs-special">)</span><span>
</span><span id="line-185"></span><span>  </span><span id="TELayerNormF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Encoder.html#TELayerNormF"><span class="hs-identifier hs-var">TELayerNormF</span></a></span></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#MBART"><span class="hs-identifier hs-type">MBART</span></a></span><span> </span><span id="local-6989586621679808861"><span class="annot"><a href="#local-6989586621679808861"><span class="hs-identifier hs-type hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679808860"><span class="annot"><a href="#local-6989586621679808860"><span class="hs-identifier hs-type hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679808859"><span class="annot"><a href="#local-6989586621679808859"><span class="hs-identifier hs-type hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679808858"><span class="annot"><a href="#local-6989586621679808858"><span class="hs-identifier hs-type hs-type">inputEmbedDim</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Encoder.html#TELayerNormF"><span class="hs-identifier hs-type">TELayerNormF</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#BART"><span class="hs-identifier hs-type">BART</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808861"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808860"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808859"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808858"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span><span>
</span><span id="line-186"></span><span>  </span><span id="TELayerNormF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Encoder.html#TELayerNormF"><span class="hs-identifier hs-var">TELayerNormF</span></a></span></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#Pegasus"><span class="hs-identifier hs-type">Pegasus</span></a></span><span> </span><span id="local-6989586621679808857"><span class="annot"><a href="#local-6989586621679808857"><span class="hs-identifier hs-type hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679808856"><span class="annot"><a href="#local-6989586621679808856"><span class="hs-identifier hs-type hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679808855"><span class="annot"><a href="#local-6989586621679808855"><span class="hs-identifier hs-type hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679808854"><span class="annot"><a href="#local-6989586621679808854"><span class="hs-identifier hs-type hs-type">inputEmbedDim</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Normalization.html#LayerNorm"><span class="hs-identifier hs-type">LayerNorm</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Type.html#WithBias"><span class="hs-identifier hs-type">WithBias</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808857"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808856"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808855"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Shape"><span class="hs-identifier hs-type">Shape</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="annot"><a href="#local-6989586621679808854"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span><span class="hs-special">]</span><span class="hs-special">)</span><span>
</span><span id="line-187"></span><span>  </span><span id="TELayerNormF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Encoder.html#TELayerNormF"><span class="hs-identifier hs-var">TELayerNormF</span></a></span></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#BERT"><span class="hs-identifier hs-type">BERT</span></a></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="hs-special">(</span><span class="hs-special">)</span><span>
</span><span id="line-188"></span><span>  </span><span id="TELayerNormF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Encoder.html#TELayerNormF"><span class="hs-identifier hs-var">TELayerNormF</span></a></span></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#RoBERTa"><span class="hs-identifier hs-type">RoBERTa</span></a></span><span> </span><span id="local-6989586621679808853"><span class="annot"><a href="#local-6989586621679808853"><span class="hs-identifier hs-type hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679808852"><span class="annot"><a href="#local-6989586621679808852"><span class="hs-identifier hs-type hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679808851"><span class="annot"><a href="#local-6989586621679808851"><span class="hs-identifier hs-type hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679808850"><span class="annot"><a href="#local-6989586621679808850"><span class="hs-identifier hs-type hs-type">inputEmbedDim</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Encoder.html#TELayerNormF"><span class="hs-identifier hs-type">TELayerNormF</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#BERT"><span class="hs-identifier hs-type">BERT</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808853"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808852"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808851"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808850"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span><span>
</span><span id="line-189"></span><span>
</span><span id="line-190"></span><span class="hs-keyword">type</span><span> </span><span class="hs-keyword">family</span><span>
</span><span id="line-191"></span><span>  </span><span id="TEDropoutF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Encoder.html#TEDropoutF"><span class="hs-identifier hs-var">TEDropoutF</span></a></span></span><span>
</span><span id="line-192"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679808849"><span class="annot"><a href="#local-6989586621679808849"><span class="hs-identifier hs-type">style</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#TransformerStyle"><span class="hs-identifier hs-type">TransformerStyle</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-193"></span><span>    </span><span class="annot"><span class="hs-identifier hs-type">Type</span></span><span>
</span><span id="line-194"></span><span>  </span><span class="hs-keyword">where</span><span>
</span><span id="line-195"></span><span>  </span><span id="TEDropoutF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Encoder.html#TEDropoutF"><span class="hs-identifier hs-var">TEDropoutF</span></a></span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Dropout.html#Dropout"><span class="hs-identifier hs-type">Dropout</span></a></span><span>
</span><span id="line-196"></span><span>
</span><span id="line-197"></span><span class="hs-keyword">type</span><span> </span><span class="hs-keyword">family</span><span>
</span><span id="line-198"></span><span>  </span><span id="TEPosEncF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Encoder.html#TEPosEncF"><span class="hs-identifier hs-var">TEPosEncF</span></a></span></span><span>
</span><span id="line-199"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679808848"><span class="annot"><a href="#local-6989586621679808848"><span class="hs-identifier hs-type">style</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#TransformerStyle"><span class="hs-identifier hs-type">TransformerStyle</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-200"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679808847"><span class="annot"><a href="#local-6989586621679808847"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#Gradient"><span class="hs-identifier hs-type">Gradient</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#RequiresGradient"><span class="hs-identifier hs-type">RequiresGradient</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-201"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679808846"><span class="annot"><a href="#local-6989586621679808846"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#Device"><span class="hs-identifier hs-type">Device</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#DeviceType"><span class="hs-identifier hs-type">DeviceType</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-202"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679808845"><span class="annot"><a href="#local-6989586621679808845"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#DataType"><span class="hs-identifier hs-type">DataType</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#DType"><span class="hs-identifier hs-type">DType</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-203"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679808844"><span class="annot"><a href="#local-6989586621679808844"><span class="hs-identifier hs-type">headDim</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Symbol</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-204"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679808843"><span class="annot"><a href="#local-6989586621679808843"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Symbol</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-205"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679808842"><span class="annot"><a href="#local-6989586621679808842"><span class="hs-identifier hs-type">posEncDim</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Symbol</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-206"></span><span>    </span><span class="annot"><span class="hs-identifier hs-type">Type</span></span><span>
</span><span id="line-207"></span><span>  </span><span class="hs-keyword">where</span><span>
</span><span id="line-208"></span><span>  </span><span id="TEPosEncF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Encoder.html#TEPosEncF"><span class="hs-identifier hs-var">TEPosEncF</span></a></span></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#T5"><span class="hs-identifier hs-type">T5</span></a></span><span> </span><span id="local-6989586621679808841"><span class="annot"><a href="#local-6989586621679808841"><span class="hs-identifier hs-type hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679808840"><span class="annot"><a href="#local-6989586621679808840"><span class="hs-identifier hs-type hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679808839"><span class="annot"><a href="#local-6989586621679808839"><span class="hs-identifier hs-type hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679808838"><span class="annot"><a href="#local-6989586621679808838"><span class="hs-identifier hs-type hs-type">headDim</span></a></span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span id="local-6989586621679808837"><span class="annot"><a href="#local-6989586621679808837"><span class="hs-identifier hs-type hs-type">posEncDim</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Sparse.html#Embedding"><span class="hs-identifier hs-type">Embedding</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808841"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#Layout"><span class="hs-identifier hs-type">Layout</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#Dense"><span class="hs-identifier hs-type">Dense</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679808840"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808839"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808837"><span class="hs-identifier hs-type">posEncDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808838"><span class="hs-identifier hs-type">headDim</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><span class="hs-identifier hs-type">Nothing</span></span><span>
</span><span id="line-209"></span><span>  </span><span id="TEPosEncF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Encoder.html#TEPosEncF"><span class="hs-identifier hs-var">TEPosEncF</span></a></span></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#ByT5"><span class="hs-identifier hs-type">ByT5</span></a></span><span> </span><span id="local-6989586621679808836"><span class="annot"><a href="#local-6989586621679808836"><span class="hs-identifier hs-type hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679808835"><span class="annot"><a href="#local-6989586621679808835"><span class="hs-identifier hs-type hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679808834"><span class="annot"><a href="#local-6989586621679808834"><span class="hs-identifier hs-type hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679808833"><span class="annot"><a href="#local-6989586621679808833"><span class="hs-identifier hs-type hs-type">headDim</span></a></span></span><span> </span><span id="local-6989586621679808832"><span class="annot"><a href="#local-6989586621679808832"><span class="hs-identifier hs-type hs-type">inputEmbedDim</span></a></span></span><span> </span><span id="local-6989586621679808831"><span class="annot"><a href="#local-6989586621679808831"><span class="hs-identifier hs-type hs-type">posEncDim</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Encoder.html#TEPosEncF"><span class="hs-identifier hs-type">TEPosEncF</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#T5"><span class="hs-identifier hs-type">T5</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808836"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808835"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808834"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808833"><span class="hs-identifier hs-type">headDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808832"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808831"><span class="hs-identifier hs-type">posEncDim</span></a></span><span>
</span><span id="line-210"></span><span>  </span><span id="TEPosEncF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Encoder.html#TEPosEncF"><span class="hs-identifier hs-var">TEPosEncF</span></a></span></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#BART"><span class="hs-identifier hs-type">BART</span></a></span><span> </span><span id="local-6989586621679808830"><span class="annot"><a href="#local-6989586621679808830"><span class="hs-identifier hs-type hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679808829"><span class="annot"><a href="#local-6989586621679808829"><span class="hs-identifier hs-type hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679808828"><span class="annot"><a href="#local-6989586621679808828"><span class="hs-identifier hs-type hs-type">dataType</span></a></span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span id="local-6989586621679808827"><span class="annot"><a href="#local-6989586621679808827"><span class="hs-identifier hs-type hs-type">inputEmbedDim</span></a></span></span><span> </span><span id="local-6989586621679808826"><span class="annot"><a href="#local-6989586621679808826"><span class="hs-identifier hs-type hs-type">posEncDim</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Sparse.html#Embedding"><span class="hs-identifier hs-type">Embedding</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808830"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#Layout"><span class="hs-identifier hs-type">Layout</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#Dense"><span class="hs-identifier hs-type">Dense</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679808829"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808828"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808826"><span class="hs-identifier hs-type">posEncDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808827"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><span class="hs-identifier hs-type">Nothing</span></span><span>
</span><span id="line-211"></span><span>  </span><span id="TEPosEncF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Encoder.html#TEPosEncF"><span class="hs-identifier hs-var">TEPosEncF</span></a></span></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#MBART"><span class="hs-identifier hs-type">MBART</span></a></span><span> </span><span id="local-6989586621679808825"><span class="annot"><a href="#local-6989586621679808825"><span class="hs-identifier hs-type hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679808824"><span class="annot"><a href="#local-6989586621679808824"><span class="hs-identifier hs-type hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679808823"><span class="annot"><a href="#local-6989586621679808823"><span class="hs-identifier hs-type hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679808822"><span class="annot"><a href="#local-6989586621679808822"><span class="hs-identifier hs-type hs-type">headDim</span></a></span></span><span> </span><span id="local-6989586621679808821"><span class="annot"><a href="#local-6989586621679808821"><span class="hs-identifier hs-type hs-type">inputEmbedDim</span></a></span></span><span> </span><span id="local-6989586621679808820"><span class="annot"><a href="#local-6989586621679808820"><span class="hs-identifier hs-type hs-type">posEncDim</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Encoder.html#TEPosEncF"><span class="hs-identifier hs-type">TEPosEncF</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#BART"><span class="hs-identifier hs-type">BART</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808825"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808824"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808823"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808822"><span class="hs-identifier hs-type">headDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808821"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808820"><span class="hs-identifier hs-type">posEncDim</span></a></span><span>
</span><span id="line-212"></span><span>  </span><span id="TEPosEncF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Encoder.html#TEPosEncF"><span class="hs-identifier hs-var">TEPosEncF</span></a></span></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#Pegasus"><span class="hs-identifier hs-type">Pegasus</span></a></span><span> </span><span id="local-6989586621679808819"><span class="annot"><a href="#local-6989586621679808819"><span class="hs-identifier hs-type hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679808818"><span class="annot"><a href="#local-6989586621679808818"><span class="hs-identifier hs-type hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679808817"><span class="annot"><a href="#local-6989586621679808817"><span class="hs-identifier hs-type hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679808816"><span class="annot"><a href="#local-6989586621679808816"><span class="hs-identifier hs-type hs-type">headDim</span></a></span></span><span> </span><span id="local-6989586621679808815"><span class="annot"><a href="#local-6989586621679808815"><span class="hs-identifier hs-type hs-type">inputEmbedDim</span></a></span></span><span> </span><span id="local-6989586621679808814"><span class="annot"><a href="#local-6989586621679808814"><span class="hs-identifier hs-type hs-type">posEncDim</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Encoder.html#TEPosEncF"><span class="hs-identifier hs-type">TEPosEncF</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#BART"><span class="hs-identifier hs-type">BART</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808819"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808818"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808817"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808816"><span class="hs-identifier hs-type">headDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808815"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808814"><span class="hs-identifier hs-type">posEncDim</span></a></span><span>
</span><span id="line-213"></span><span>  </span><span id="TEPosEncF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Encoder.html#TEPosEncF"><span class="hs-identifier hs-var">TEPosEncF</span></a></span></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#BERT"><span class="hs-identifier hs-type">BERT</span></a></span><span> </span><span id="local-6989586621679808813"><span class="annot"><a href="#local-6989586621679808813"><span class="hs-identifier hs-type hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679808812"><span class="annot"><a href="#local-6989586621679808812"><span class="hs-identifier hs-type hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679808811"><span class="annot"><a href="#local-6989586621679808811"><span class="hs-identifier hs-type hs-type">dataType</span></a></span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span id="local-6989586621679808810"><span class="annot"><a href="#local-6989586621679808810"><span class="hs-identifier hs-type hs-type">inputEmbedDim</span></a></span></span><span> </span><span id="local-6989586621679808809"><span class="annot"><a href="#local-6989586621679808809"><span class="hs-identifier hs-type hs-type">posEncDim</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Sparse.html#Embedding"><span class="hs-identifier hs-type">Embedding</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808813"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#Layout"><span class="hs-identifier hs-type">Layout</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#Dense"><span class="hs-identifier hs-type">Dense</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679808812"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808811"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808809"><span class="hs-identifier hs-type">posEncDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808810"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><span class="hs-identifier hs-type">Nothing</span></span><span>
</span><span id="line-214"></span><span>  </span><span id="TEPosEncF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Encoder.html#TEPosEncF"><span class="hs-identifier hs-var">TEPosEncF</span></a></span></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#RoBERTa"><span class="hs-identifier hs-type">RoBERTa</span></a></span><span> </span><span id="local-6989586621679808808"><span class="annot"><a href="#local-6989586621679808808"><span class="hs-identifier hs-type hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679808807"><span class="annot"><a href="#local-6989586621679808807"><span class="hs-identifier hs-type hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679808806"><span class="annot"><a href="#local-6989586621679808806"><span class="hs-identifier hs-type hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679808805"><span class="annot"><a href="#local-6989586621679808805"><span class="hs-identifier hs-type hs-type">headDim</span></a></span></span><span> </span><span id="local-6989586621679808804"><span class="annot"><a href="#local-6989586621679808804"><span class="hs-identifier hs-type hs-type">inputEmbedDim</span></a></span></span><span> </span><span id="local-6989586621679808803"><span class="annot"><a href="#local-6989586621679808803"><span class="hs-identifier hs-type hs-type">posEncDim</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Encoder.html#TEPosEncF"><span class="hs-identifier hs-type">TEPosEncF</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#BERT"><span class="hs-identifier hs-type">BERT</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808808"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808807"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808806"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808805"><span class="hs-identifier hs-type">headDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808804"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808803"><span class="hs-identifier hs-type">posEncDim</span></a></span><span>
</span><span id="line-215"></span><span>
</span><span id="line-216"></span><span id="local-6989586621679808786"><span id="local-6989586621679808787"><span id="local-6989586621679808788"><span id="local-6989586621679808789"><span id="local-6989586621679808790"><span id="local-6989586621679808791"><span id="local-6989586621679808792"><span id="local-6989586621679808793"><span id="local-6989586621679808794"><span id="local-6989586621679808795"><span id="local-6989586621679808796"><span id="local-6989586621679808797"><span id="local-6989586621679808798"><span id="local-6989586621679808799"><span id="local-6989586621679808800"><span id="local-6989586621679808801"><span id="local-6989586621679808802"><span class="hs-keyword">instance</span><span>
</span><span id="line-217"></span><span>  </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-type">SingI</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808802"><span class="hs-identifier hs-type">style</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-218"></span><span>    </span><span class="annot"><a href="#local-6989586621679808801"><span class="hs-identifier hs-type">stack</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Encoder.html#TEStackF"><span class="hs-identifier hs-type">TEStackF</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808802"><span class="hs-identifier hs-type">style</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808800"><span class="hs-identifier hs-type">numLayers</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808799"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808798"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808797"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808796"><span class="hs-identifier hs-type">headDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808795"><span class="hs-identifier hs-type">headEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808794"><span class="hs-identifier hs-type">embedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808793"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808792"><span class="hs-identifier hs-type">ffnDim</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-219"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasInitialize"><span class="hs-identifier hs-type">HasInitialize</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808801"><span class="hs-identifier hs-type">stack</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808798"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808801"><span class="hs-identifier hs-type">stack</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808798"><span class="hs-identifier hs-type">device</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-220"></span><span>    </span><span class="annot"><a href="#local-6989586621679808791"><span class="hs-identifier hs-type">embedLayerNorm</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Encoder.html#TEEmbedLayerNormF"><span class="hs-identifier hs-type">TEEmbedLayerNormF</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808802"><span class="hs-identifier hs-type">style</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808799"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808798"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808797"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808793"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-221"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasInitialize"><span class="hs-identifier hs-type">HasInitialize</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808791"><span class="hs-identifier hs-type">embedLayerNorm</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808798"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808791"><span class="hs-identifier hs-type">embedLayerNorm</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808798"><span class="hs-identifier hs-type">device</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-222"></span><span>    </span><span class="annot"><a href="#local-6989586621679808790"><span class="hs-identifier hs-type">layerNorm</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Encoder.html#TELayerNormF"><span class="hs-identifier hs-type">TELayerNormF</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808802"><span class="hs-identifier hs-type">style</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808799"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808798"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808797"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808793"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-223"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasInitialize"><span class="hs-identifier hs-type">HasInitialize</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808790"><span class="hs-identifier hs-type">layerNorm</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808798"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808790"><span class="hs-identifier hs-type">layerNorm</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808798"><span class="hs-identifier hs-type">device</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-224"></span><span>    </span><span class="annot"><a href="#local-6989586621679808789"><span class="hs-identifier hs-type">dropout</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Encoder.html#TEDropoutF"><span class="hs-identifier hs-type">TEDropoutF</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808802"><span class="hs-identifier hs-type">style</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-225"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasInitialize"><span class="hs-identifier hs-type">HasInitialize</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808789"><span class="hs-identifier hs-type">dropout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808798"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808789"><span class="hs-identifier hs-type">dropout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808798"><span class="hs-identifier hs-type">device</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-226"></span><span>    </span><span class="annot"><a href="#local-6989586621679808788"><span class="hs-identifier hs-type">posEnc</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Encoder.html#TEPosEncF"><span class="hs-identifier hs-type">TEPosEncF</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808802"><span class="hs-identifier hs-type">style</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808799"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808798"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808797"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808796"><span class="hs-identifier hs-type">headDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808793"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808787"><span class="hs-identifier hs-type">posEncDim</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-227"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasInitialize"><span class="hs-identifier hs-type">HasInitialize</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808788"><span class="hs-identifier hs-type">posEnc</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808798"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808788"><span class="hs-identifier hs-type">posEnc</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808798"><span class="hs-identifier hs-type">device</span></a></span><span>
</span><span id="line-228"></span><span>  </span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-229"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasInitialize"><span class="hs-identifier hs-type">HasInitialize</span></a></span><span>
</span><span id="line-230"></span><span>    </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Encoder.html#TransformerEncoder"><span class="hs-identifier hs-type">TransformerEncoder</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808802"><span class="hs-identifier hs-type">style</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808800"><span class="hs-identifier hs-type">numLayers</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808799"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808798"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808797"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808796"><span class="hs-identifier hs-type">headDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808795"><span class="hs-identifier hs-type">headEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808794"><span class="hs-identifier hs-type">embedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808793"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808792"><span class="hs-identifier hs-type">ffnDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808787"><span class="hs-identifier hs-type">posEncDim</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-231"></span><span>    </span><span class="annot"><a href="#local-6989586621679808786"><span class="hs-identifier hs-type">generatorDevice</span></a></span><span>
</span><span id="line-232"></span><span>    </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Encoder.html#TransformerEncoder"><span class="hs-identifier hs-type">TransformerEncoder</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808802"><span class="hs-identifier hs-type">style</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808800"><span class="hs-identifier hs-type">numLayers</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808799"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808798"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808797"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808796"><span class="hs-identifier hs-type">headDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808795"><span class="hs-identifier hs-type">headEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808794"><span class="hs-identifier hs-type">embedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808793"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808792"><span class="hs-identifier hs-type">ffnDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808787"><span class="hs-identifier hs-type">posEncDim</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-233"></span><span>    </span><span class="annot"><a href="#local-6989586621679808798"><span class="hs-identifier hs-type">device</span></a></span><span>
</span><span id="line-234"></span><span>  </span><span class="hs-keyword">where</span><span>
</span><span id="line-235"></span><span>  </span><span id="local-6989586621679808783"><span class="annot"><span class="annottext">initialize :: ModelSpec
  (TransformerEncoder
     style
     numLayers
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     inputEmbedDim
     ffnDim
     posEncDim)
-&gt; Generator generatorDevice
-&gt; m (TransformerEncoder
        style
        numLayers
        gradient
        device
        dataType
        headDim
        headEmbedDim
        embedDim
        inputEmbedDim
        ffnDim
        posEncDim,
      Generator device)
</span><a href="Torch.GraduallyTyped.NN.Class.html#initialize"><span class="hs-identifier hs-var hs-var hs-var hs-var">initialize</span></a></span></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Encoder.html#TransformerEncoderSpec"><span class="hs-identifier hs-type">TransformerEncoderSpec</span></a></span><span> </span><span id="local-6989586621679808781"><span class="annot"><a href="#local-6989586621679808781"><span class="hs-identifier hs-var">style</span></a></span></span><span> </span><span id="local-6989586621679808780"><span class="annot"><a href="#local-6989586621679808780"><span class="hs-identifier hs-var">numLayers</span></a></span></span><span> </span><span id="local-6989586621679808779"><span class="annot"><a href="#local-6989586621679808779"><span class="hs-identifier hs-var">gradient</span></a></span></span><span> </span><span id="local-6989586621679808778"><span class="annot"><a href="#local-6989586621679808778"><span class="hs-identifier hs-var">device</span></a></span></span><span> </span><span id="local-6989586621679808777"><span class="annot"><a href="#local-6989586621679808777"><span class="hs-identifier hs-var">dataType</span></a></span></span><span> </span><span id="local-6989586621679808776"><span class="annot"><a href="#local-6989586621679808776"><span class="hs-identifier hs-var">headDim</span></a></span></span><span> </span><span id="local-6989586621679808775"><span class="annot"><a href="#local-6989586621679808775"><span class="hs-identifier hs-var">headEmbedDim</span></a></span></span><span> </span><span id="local-6989586621679808774"><span class="annot"><a href="#local-6989586621679808774"><span class="hs-identifier hs-var">embedDim</span></a></span></span><span> </span><span id="local-6989586621679808773"><span class="annot"><a href="#local-6989586621679808773"><span class="hs-identifier hs-var">inputEmbedDim</span></a></span></span><span> </span><span id="local-6989586621679808772"><span class="annot"><a href="#local-6989586621679808772"><span class="hs-identifier hs-var">ffnDim</span></a></span></span><span> </span><span id="local-6989586621679808771"><span class="annot"><a href="#local-6989586621679808771"><span class="hs-identifier hs-var">posEncDim</span></a></span></span><span> </span><span id="local-6989586621679808770"><span class="annot"><a href="#local-6989586621679808770"><span class="hs-identifier hs-var">dropoutP</span></a></span></span><span> </span><span id="local-6989586621679808769"><span class="annot"><a href="#local-6989586621679808769"><span class="hs-identifier hs-var">eps</span></a></span></span><span class="hs-special">)</span><span> </span><span id="local-6989586621679808768"><span class="annot"><span class="annottext">Generator generatorDevice
</span><a href="#local-6989586621679808768"><span class="hs-identifier hs-var">generator</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-236"></span><span>    </span><span class="hs-keyword">let</span><span> </span><span id="local-6989586621679808767"><span class="annot"><span class="annottext">generator' :: Generator device
</span><a href="#local-6989586621679808767"><span class="hs-identifier hs-var hs-var">generator'</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">SDevice device -&gt; Generator generatorDevice -&gt; Generator device
forall (generatorDevice' :: Device (DeviceType Nat))
       (generatorDevice :: Device (DeviceType Nat)).
SDevice generatorDevice'
-&gt; Generator generatorDevice -&gt; Generator generatorDevice'
</span><a href="Torch.GraduallyTyped.Random.html#sGeneratorToDevice"><span class="hs-identifier hs-var">sGeneratorToDevice</span></a></span><span> </span><span class="annot"><span class="annottext">SDevice device
</span><a href="#local-6989586621679808778"><span class="hs-identifier hs-var">device</span></a></span><span> </span><span class="annot"><span class="annottext">Generator generatorDevice
</span><a href="#local-6989586621679808768"><span class="hs-identifier hs-var">generator</span></a></span><span>
</span><span id="line-237"></span><span>        </span><span id="local-6989586621679808766"><span class="annot"><span class="annottext">stack :: IxStateT
  m
  (Generator device)
  (Generator device)
  (TransformerStack
     style
     numLayers
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     inputEmbedDim
     ffnDim)
</span><a href="#local-6989586621679808766"><span class="hs-identifier hs-var hs-var">stack</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">(Generator device
 -&gt; m (TransformerStack
         style
         numLayers
         gradient
         device
         dataType
         headDim
         headEmbedDim
         embedDim
         inputEmbedDim
         ffnDim,
       Generator device))
-&gt; IxStateT
     m
     (Generator device)
     (Generator device)
     (TransformerStack
        style
        numLayers
        gradient
        device
        dataType
        headDim
        headEmbedDim
        embedDim
        inputEmbedDim
        ffnDim)
forall (m :: * -&gt; *) i j a. (i -&gt; m (a, j)) -&gt; IxStateT m i j a
</span><a href="../file:///nix/store/8vjaffqxij7bih93d9mlzmc7ksanlw0i-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier hs-var">IxStateT</span></a></span><span> </span><span class="annot"><span class="annottext">((Generator device
  -&gt; m (TransformerStack
          style
          numLayers
          gradient
          device
          dataType
          headDim
          headEmbedDim
          embedDim
          inputEmbedDim
          ffnDim,
        Generator device))
 -&gt; IxStateT
      m
      (Generator device)
      (Generator device)
      (TransformerStack
         style
         numLayers
         gradient
         device
         dataType
         headDim
         headEmbedDim
         embedDim
         inputEmbedDim
         ffnDim))
-&gt; (TransformerStackSpec
      style
      numLayers
      gradient
      device
      dataType
      headDim
      headEmbedDim
      embedDim
      inputEmbedDim
      ffnDim
    -&gt; Generator device
    -&gt; m (TransformerStack
            style
            numLayers
            gradient
            device
            dataType
            headDim
            headEmbedDim
            embedDim
            inputEmbedDim
            ffnDim,
          Generator device))
-&gt; TransformerStackSpec
     style
     numLayers
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     inputEmbedDim
     ffnDim
-&gt; IxStateT
     m
     (Generator device)
     (Generator device)
     (TransformerStack
        style
        numLayers
        gradient
        device
        dataType
        headDim
        headEmbedDim
        embedDim
        inputEmbedDim
        ffnDim)
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">forall model (generatorDevice :: Device (DeviceType Nat)) output
       (generatorOutputDevice :: Device (DeviceType Nat)) (m :: * -&gt; *).
(HasInitialize model generatorDevice output generatorOutputDevice,
 MonadThrow m) =&gt;
ModelSpec model
-&gt; Generator generatorDevice
-&gt; m (output, Generator generatorOutputDevice)
forall (generatorDevice :: Device (DeviceType Nat)) output
       (generatorOutputDevice :: Device (DeviceType Nat)) (m :: * -&gt; *).
(HasInitialize stack generatorDevice output generatorOutputDevice,
 MonadThrow m) =&gt;
ModelSpec stack
-&gt; Generator generatorDevice
-&gt; m (output, Generator generatorOutputDevice)
</span><a href="Torch.GraduallyTyped.NN.Class.html#initialize"><span class="hs-identifier hs-var">initialize</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679808801"><span class="hs-identifier hs-type">stack</span></a></span><span> </span><span class="annot"><span class="annottext">(TransformerStackSpec
   style
   numLayers
   gradient
   device
   dataType
   headDim
   headEmbedDim
   embedDim
   inputEmbedDim
   ffnDim
 -&gt; IxStateT
      m
      (Generator device)
      (Generator device)
      (TransformerStack
         style
         numLayers
         gradient
         device
         dataType
         headDim
         headEmbedDim
         embedDim
         inputEmbedDim
         ffnDim))
-&gt; TransformerStackSpec
     style
     numLayers
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     inputEmbedDim
     ffnDim
-&gt; IxStateT
     m
     (Generator device)
     (Generator device)
     (TransformerStack
        style
        numLayers
        gradient
        device
        dataType
        headDim
        headEmbedDim
        embedDim
        inputEmbedDim
        ffnDim)
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
-&gt; SNat numLayers
-&gt; SGradient gradient
-&gt; SDevice device
-&gt; SDataType dataType
-&gt; SDim headDim
-&gt; SDim headEmbedDim
-&gt; SDim embedDim
-&gt; SDim inputEmbedDim
-&gt; SDim ffnDim
-&gt; Double
-&gt; Double
-&gt; TransformerStackSpec
     style
     numLayers
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     inputEmbedDim
     ffnDim
forall (style :: TransformerStyle) (numLayers :: Nat)
       (gradient :: Gradient RequiresGradient)
       (device :: Device (DeviceType Nat)) (dataType :: DataType DType)
       (headDim :: Dim (Name Symbol) (Size Nat))
       (headEmbedDim :: Dim (Name Symbol) (Size Nat))
       (embedDim :: Dim (Name Symbol) (Size Nat))
       (queryEmbedDim :: Dim (Name Symbol) (Size Nat))
       (ffnDim :: Dim (Name Symbol) (Size Nat)).
STransformerStyle style
-&gt; SNat numLayers
-&gt; SGradient gradient
-&gt; SDevice device
-&gt; SDataType dataType
-&gt; SDim headDim
-&gt; SDim headEmbedDim
-&gt; SDim embedDim
-&gt; SDim queryEmbedDim
-&gt; SDim ffnDim
-&gt; Double
-&gt; Double
-&gt; TransformerStackSpec
     style
     numLayers
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     queryEmbedDim
     ffnDim
</span><a href="Torch.GraduallyTyped.NN.Transformer.Stack.html#TransformerStackSpec"><span class="hs-identifier hs-var">TransformerStackSpec</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="#local-6989586621679808781"><span class="hs-identifier hs-var">style</span></a></span><span> </span><span class="annot"><span class="annottext">SNat numLayers
</span><a href="#local-6989586621679808780"><span class="hs-identifier hs-var">numLayers</span></a></span><span> </span><span class="annot"><span class="annottext">SGradient gradient
</span><a href="#local-6989586621679808779"><span class="hs-identifier hs-var">gradient</span></a></span><span> </span><span class="annot"><span class="annottext">SDevice device
</span><a href="#local-6989586621679808778"><span class="hs-identifier hs-var">device</span></a></span><span> </span><span class="annot"><span class="annottext">SDataType dataType
</span><a href="#local-6989586621679808777"><span class="hs-identifier hs-var">dataType</span></a></span><span> </span><span class="annot"><span class="annottext">SDim headDim
</span><a href="#local-6989586621679808776"><span class="hs-identifier hs-var">headDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim headEmbedDim
</span><a href="#local-6989586621679808775"><span class="hs-identifier hs-var">headEmbedDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim embedDim
</span><a href="#local-6989586621679808774"><span class="hs-identifier hs-var">embedDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim inputEmbedDim
</span><a href="#local-6989586621679808773"><span class="hs-identifier hs-var">inputEmbedDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim ffnDim
</span><a href="#local-6989586621679808772"><span class="hs-identifier hs-var">ffnDim</span></a></span><span> </span><span class="annot"><span class="annottext">Double
</span><a href="#local-6989586621679808770"><span class="hs-identifier hs-var">dropoutP</span></a></span><span> </span><span class="annot"><span class="annottext">Double
</span><a href="#local-6989586621679808769"><span class="hs-identifier hs-var">eps</span></a></span><span>
</span><span id="line-238"></span><span>        </span><span id="local-6989586621679808762"><span class="annot"><span class="annottext">embedLayerNormSpec :: LayerNormSpec
  'WithBias gradient device dataType ('Shape '[inputEmbedDim])
</span><a href="#local-6989586621679808762"><span class="hs-identifier hs-var hs-var">embedLayerNormSpec</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">SHasBias 'WithBias
-&gt; SGradient gradient
-&gt; SDevice device
-&gt; SDataType dataType
-&gt; SShape ('Shape '[inputEmbedDim])
-&gt; Double
-&gt; LayerNormSpec
     'WithBias gradient device dataType ('Shape '[inputEmbedDim])
forall (hasBias :: HasBias) (gradient :: Gradient RequiresGradient)
       (device :: Device (DeviceType Nat)) (dataType :: DataType DType)
       (normalizedShape :: Shape [Dim (Name Symbol) (Size Nat)]).
SHasBias hasBias
-&gt; SGradient gradient
-&gt; SDevice device
-&gt; SDataType dataType
-&gt; SShape normalizedShape
-&gt; Double
-&gt; LayerNormSpec hasBias gradient device dataType normalizedShape
</span><a href="Torch.GraduallyTyped.NN.Normalization.html#LayerNormSpec"><span class="hs-identifier hs-var">LayerNormSpec</span></a></span><span> </span><span class="annot"><span class="annottext">SHasBias 'WithBias
</span><a href="Torch.GraduallyTyped.NN.Type.html#SWithBias"><span class="hs-identifier hs-var">SWithBias</span></a></span><span> </span><span class="annot"><span class="annottext">SGradient gradient
</span><a href="#local-6989586621679808779"><span class="hs-identifier hs-var">gradient</span></a></span><span> </span><span class="annot"><span class="annottext">SDevice device
</span><a href="#local-6989586621679808778"><span class="hs-identifier hs-var">device</span></a></span><span> </span><span class="annot"><span class="annottext">SDataType dataType
</span><a href="#local-6989586621679808777"><span class="hs-identifier hs-var">dataType</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SList '[inputEmbedDim] -&gt; SShape ('Shape '[inputEmbedDim])
forall (dims :: [Dim (Name Symbol) (Size Nat)]).
SList dims -&gt; SShape ('Shape dims)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SShape"><span class="hs-identifier hs-var">SShape</span></a></span><span> </span><span class="annot"><span class="annottext">(SList '[inputEmbedDim] -&gt; SShape ('Shape '[inputEmbedDim]))
-&gt; SList '[inputEmbedDim] -&gt; SShape ('Shape '[inputEmbedDim])
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">SDim inputEmbedDim
</span><a href="#local-6989586621679808773"><span class="hs-identifier hs-var">inputEmbedDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim inputEmbedDim -&gt; SList '[] -&gt; SList '[inputEmbedDim]
forall (dim :: Dim (Name Symbol) (Size Nat))
       (dims :: [Dim (Name Symbol) (Size Nat)]).
SDim dim -&gt; SList dims -&gt; SList (dim : dims)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%7C%3A"><span class="hs-operator hs-var">:|:</span></a></span><span> </span><span class="annot"><span class="annottext">SList '[]
forall a. SList '[]
</span><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-var">SNil</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">Double
</span><a href="#local-6989586621679808769"><span class="hs-identifier hs-var">eps</span></a></span><span>
</span><span id="line-239"></span><span>        </span><span id="local-6989586621679808759"><span class="annot"><span class="annottext">embedLayerNorm :: IxStateT m (Generator device) (Generator device) embedLayerNorm
</span><a href="#local-6989586621679808759"><span class="hs-identifier hs-var hs-var">embedLayerNorm</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">(Generator device -&gt; m (embedLayerNorm, Generator device))
-&gt; IxStateT m (Generator device) (Generator device) embedLayerNorm
forall (m :: * -&gt; *) i j a. (i -&gt; m (a, j)) -&gt; IxStateT m i j a
</span><a href="../file:///nix/store/8vjaffqxij7bih93d9mlzmc7ksanlw0i-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier hs-var">IxStateT</span></a></span><span> </span><span class="annot"><span class="annottext">((Generator device -&gt; m (embedLayerNorm, Generator device))
 -&gt; IxStateT m (Generator device) (Generator device) embedLayerNorm)
-&gt; (ModelSpec embedLayerNorm
    -&gt; Generator device -&gt; m (embedLayerNorm, Generator device))
-&gt; ModelSpec embedLayerNorm
-&gt; IxStateT m (Generator device) (Generator device) embedLayerNorm
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">forall model (generatorDevice :: Device (DeviceType Nat)) output
       (generatorOutputDevice :: Device (DeviceType Nat)) (m :: * -&gt; *).
(HasInitialize model generatorDevice output generatorOutputDevice,
 MonadThrow m) =&gt;
ModelSpec model
-&gt; Generator generatorDevice
-&gt; m (output, Generator generatorOutputDevice)
forall (generatorDevice :: Device (DeviceType Nat)) output
       (generatorOutputDevice :: Device (DeviceType Nat)) (m :: * -&gt; *).
(HasInitialize
   embedLayerNorm generatorDevice output generatorOutputDevice,
 MonadThrow m) =&gt;
ModelSpec embedLayerNorm
-&gt; Generator generatorDevice
-&gt; m (output, Generator generatorOutputDevice)
</span><a href="Torch.GraduallyTyped.NN.Class.html#initialize"><span class="hs-identifier hs-var">initialize</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679808791"><span class="hs-identifier hs-type">embedLayerNorm</span></a></span><span> </span><span class="annot"><span class="annottext">(ModelSpec embedLayerNorm
 -&gt; IxStateT m (Generator device) (Generator device) embedLayerNorm)
-&gt; ModelSpec embedLayerNorm
-&gt; IxStateT m (Generator device) (Generator device) embedLayerNorm
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="hs-keyword">case</span><span> </span><span class="annot"><span class="annottext">SingI style =&gt; Sing style
forall k (a :: k). SingI a =&gt; Sing a
</span><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-var">sing</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679808802"><span class="hs-identifier hs-type">style</span></a></span><span> </span><span class="hs-keyword">of</span><span>
</span><span id="line-240"></span><span>          </span><span class="annot"><span class="annottext">Sing style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#ST5"><span class="hs-identifier hs-var">ST5</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="hs-special">(</span><span class="hs-special">)</span><span>
</span><span id="line-241"></span><span>          </span><span class="annot"><span class="annottext">Sing style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SByT5"><span class="hs-identifier hs-var">SByT5</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="hs-special">(</span><span class="hs-special">)</span><span>
</span><span id="line-242"></span><span>          </span><span class="annot"><span class="annottext">Sing style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SBART"><span class="hs-identifier hs-var">SBART</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><span class="annottext">ModelSpec embedLayerNorm
LayerNormSpec
  'WithBias gradient device dataType ('Shape '[inputEmbedDim])
</span><a href="#local-6989586621679808762"><span class="hs-identifier hs-var">embedLayerNormSpec</span></a></span><span>
</span><span id="line-243"></span><span>          </span><span class="annot"><span class="annottext">Sing style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SMBART"><span class="hs-identifier hs-var">SMBART</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><span class="annottext">ModelSpec embedLayerNorm
LayerNormSpec
  'WithBias gradient device dataType ('Shape '[inputEmbedDim])
</span><a href="#local-6989586621679808762"><span class="hs-identifier hs-var">embedLayerNormSpec</span></a></span><span>
</span><span id="line-244"></span><span>          </span><span class="annot"><span class="annottext">Sing style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SPegasus"><span class="hs-identifier hs-var">SPegasus</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="hs-special">(</span><span class="hs-special">)</span><span>
</span><span id="line-245"></span><span>          </span><span class="annot"><span class="annottext">Sing style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SBERT"><span class="hs-identifier hs-var">SBERT</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><span class="annottext">ModelSpec embedLayerNorm
LayerNormSpec
  'WithBias gradient device dataType ('Shape '[inputEmbedDim])
</span><a href="#local-6989586621679808762"><span class="hs-identifier hs-var">embedLayerNormSpec</span></a></span><span>
</span><span id="line-246"></span><span>          </span><span class="annot"><span class="annottext">Sing style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SRoBERTa"><span class="hs-identifier hs-var">SRoBERTa</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><span class="annottext">ModelSpec embedLayerNorm
LayerNormSpec
  'WithBias gradient device dataType ('Shape '[inputEmbedDim])
</span><a href="#local-6989586621679808762"><span class="hs-identifier hs-var">embedLayerNormSpec</span></a></span><span>
</span><span id="line-247"></span><span>          </span><span class="annot"><span class="annottext">Sing style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SGPT2"><span class="hs-identifier hs-var">SGPT2</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><span class="annottext">ModelSpec embedLayerNorm
forall a. HasCallStack =&gt; a
</span><span class="hs-identifier hs-var">undefined</span></span><span>
</span><span id="line-248"></span><span>        </span><span id="local-6989586621679808748"><span class="annot"><span class="annottext">layerNormWithoutBiasSpec :: LayerNormSpec
  'WithoutBias gradient device dataType ('Shape '[inputEmbedDim])
</span><a href="#local-6989586621679808748"><span class="hs-identifier hs-var hs-var">layerNormWithoutBiasSpec</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">SHasBias 'WithoutBias
-&gt; SGradient gradient
-&gt; SDevice device
-&gt; SDataType dataType
-&gt; SShape ('Shape '[inputEmbedDim])
-&gt; Double
-&gt; LayerNormSpec
     'WithoutBias gradient device dataType ('Shape '[inputEmbedDim])
forall (hasBias :: HasBias) (gradient :: Gradient RequiresGradient)
       (device :: Device (DeviceType Nat)) (dataType :: DataType DType)
       (normalizedShape :: Shape [Dim (Name Symbol) (Size Nat)]).
SHasBias hasBias
-&gt; SGradient gradient
-&gt; SDevice device
-&gt; SDataType dataType
-&gt; SShape normalizedShape
-&gt; Double
-&gt; LayerNormSpec hasBias gradient device dataType normalizedShape
</span><a href="Torch.GraduallyTyped.NN.Normalization.html#LayerNormSpec"><span class="hs-identifier hs-var">LayerNormSpec</span></a></span><span> </span><span class="annot"><span class="annottext">SHasBias 'WithoutBias
</span><a href="Torch.GraduallyTyped.NN.Type.html#SWithoutBias"><span class="hs-identifier hs-var">SWithoutBias</span></a></span><span> </span><span class="annot"><span class="annottext">SGradient gradient
</span><a href="#local-6989586621679808779"><span class="hs-identifier hs-var">gradient</span></a></span><span> </span><span class="annot"><span class="annottext">SDevice device
</span><a href="#local-6989586621679808778"><span class="hs-identifier hs-var">device</span></a></span><span> </span><span class="annot"><span class="annottext">SDataType dataType
</span><a href="#local-6989586621679808777"><span class="hs-identifier hs-var">dataType</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SList '[inputEmbedDim] -&gt; SShape ('Shape '[inputEmbedDim])
forall (dims :: [Dim (Name Symbol) (Size Nat)]).
SList dims -&gt; SShape ('Shape dims)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SShape"><span class="hs-identifier hs-var">SShape</span></a></span><span> </span><span class="annot"><span class="annottext">(SList '[inputEmbedDim] -&gt; SShape ('Shape '[inputEmbedDim]))
-&gt; SList '[inputEmbedDim] -&gt; SShape ('Shape '[inputEmbedDim])
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">SDim inputEmbedDim
</span><a href="#local-6989586621679808773"><span class="hs-identifier hs-var">inputEmbedDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim inputEmbedDim -&gt; SList '[] -&gt; SList '[inputEmbedDim]
forall (dim :: Dim (Name Symbol) (Size Nat))
       (dims :: [Dim (Name Symbol) (Size Nat)]).
SDim dim -&gt; SList dims -&gt; SList (dim : dims)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%7C%3A"><span class="hs-operator hs-var">:|:</span></a></span><span> </span><span class="annot"><span class="annottext">SList '[]
forall a. SList '[]
</span><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-var">SNil</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">Double
</span><a href="#local-6989586621679808769"><span class="hs-identifier hs-var">eps</span></a></span><span>
</span><span id="line-249"></span><span>        </span><span id="local-6989586621679808747"><span class="annot"><span class="annottext">layerNormWithBiasSpec :: LayerNormSpec
  'WithBias gradient device dataType ('Shape '[inputEmbedDim])
</span><a href="#local-6989586621679808747"><span class="hs-identifier hs-var hs-var">layerNormWithBiasSpec</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">SHasBias 'WithBias
-&gt; SGradient gradient
-&gt; SDevice device
-&gt; SDataType dataType
-&gt; SShape ('Shape '[inputEmbedDim])
-&gt; Double
-&gt; LayerNormSpec
     'WithBias gradient device dataType ('Shape '[inputEmbedDim])
forall (hasBias :: HasBias) (gradient :: Gradient RequiresGradient)
       (device :: Device (DeviceType Nat)) (dataType :: DataType DType)
       (normalizedShape :: Shape [Dim (Name Symbol) (Size Nat)]).
SHasBias hasBias
-&gt; SGradient gradient
-&gt; SDevice device
-&gt; SDataType dataType
-&gt; SShape normalizedShape
-&gt; Double
-&gt; LayerNormSpec hasBias gradient device dataType normalizedShape
</span><a href="Torch.GraduallyTyped.NN.Normalization.html#LayerNormSpec"><span class="hs-identifier hs-var">LayerNormSpec</span></a></span><span> </span><span class="annot"><span class="annottext">SHasBias 'WithBias
</span><a href="Torch.GraduallyTyped.NN.Type.html#SWithBias"><span class="hs-identifier hs-var">SWithBias</span></a></span><span> </span><span class="annot"><span class="annottext">SGradient gradient
</span><a href="#local-6989586621679808779"><span class="hs-identifier hs-var">gradient</span></a></span><span> </span><span class="annot"><span class="annottext">SDevice device
</span><a href="#local-6989586621679808778"><span class="hs-identifier hs-var">device</span></a></span><span> </span><span class="annot"><span class="annottext">SDataType dataType
</span><a href="#local-6989586621679808777"><span class="hs-identifier hs-var">dataType</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SList '[inputEmbedDim] -&gt; SShape ('Shape '[inputEmbedDim])
forall (dims :: [Dim (Name Symbol) (Size Nat)]).
SList dims -&gt; SShape ('Shape dims)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SShape"><span class="hs-identifier hs-var">SShape</span></a></span><span> </span><span class="annot"><span class="annottext">(SList '[inputEmbedDim] -&gt; SShape ('Shape '[inputEmbedDim]))
-&gt; SList '[inputEmbedDim] -&gt; SShape ('Shape '[inputEmbedDim])
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">SDim inputEmbedDim
</span><a href="#local-6989586621679808773"><span class="hs-identifier hs-var">inputEmbedDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim inputEmbedDim -&gt; SList '[] -&gt; SList '[inputEmbedDim]
forall (dim :: Dim (Name Symbol) (Size Nat))
       (dims :: [Dim (Name Symbol) (Size Nat)]).
SDim dim -&gt; SList dims -&gt; SList (dim : dims)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%7C%3A"><span class="hs-operator hs-var">:|:</span></a></span><span> </span><span class="annot"><span class="annottext">SList '[]
forall a. SList '[]
</span><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-var">SNil</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">Double
</span><a href="#local-6989586621679808769"><span class="hs-identifier hs-var">eps</span></a></span><span>
</span><span id="line-250"></span><span>        </span><span id="local-6989586621679808746"><span class="annot"><span class="annottext">layerNorm :: IxStateT m (Generator device) (Generator device) layerNorm
</span><a href="#local-6989586621679808746"><span class="hs-identifier hs-var hs-var">layerNorm</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">(Generator device -&gt; m (layerNorm, Generator device))
-&gt; IxStateT m (Generator device) (Generator device) layerNorm
forall (m :: * -&gt; *) i j a. (i -&gt; m (a, j)) -&gt; IxStateT m i j a
</span><a href="../file:///nix/store/8vjaffqxij7bih93d9mlzmc7ksanlw0i-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier hs-var">IxStateT</span></a></span><span> </span><span class="annot"><span class="annottext">((Generator device -&gt; m (layerNorm, Generator device))
 -&gt; IxStateT m (Generator device) (Generator device) layerNorm)
-&gt; (ModelSpec layerNorm
    -&gt; Generator device -&gt; m (layerNorm, Generator device))
-&gt; ModelSpec layerNorm
-&gt; IxStateT m (Generator device) (Generator device) layerNorm
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">forall model (generatorDevice :: Device (DeviceType Nat)) output
       (generatorOutputDevice :: Device (DeviceType Nat)) (m :: * -&gt; *).
(HasInitialize model generatorDevice output generatorOutputDevice,
 MonadThrow m) =&gt;
ModelSpec model
-&gt; Generator generatorDevice
-&gt; m (output, Generator generatorOutputDevice)
forall (generatorDevice :: Device (DeviceType Nat)) output
       (generatorOutputDevice :: Device (DeviceType Nat)) (m :: * -&gt; *).
(HasInitialize
   layerNorm generatorDevice output generatorOutputDevice,
 MonadThrow m) =&gt;
ModelSpec layerNorm
-&gt; Generator generatorDevice
-&gt; m (output, Generator generatorOutputDevice)
</span><a href="Torch.GraduallyTyped.NN.Class.html#initialize"><span class="hs-identifier hs-var">initialize</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679808790"><span class="hs-identifier hs-type">layerNorm</span></a></span><span> </span><span class="annot"><span class="annottext">(ModelSpec layerNorm
 -&gt; IxStateT m (Generator device) (Generator device) layerNorm)
-&gt; ModelSpec layerNorm
-&gt; IxStateT m (Generator device) (Generator device) layerNorm
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="hs-keyword">case</span><span> </span><span class="annot"><span class="annottext">SingI style =&gt; Sing style
forall k (a :: k). SingI a =&gt; Sing a
</span><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-var">sing</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679808802"><span class="hs-identifier hs-type">style</span></a></span><span> </span><span class="hs-keyword">of</span><span>
</span><span id="line-251"></span><span>          </span><span class="annot"><span class="annottext">Sing style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#ST5"><span class="hs-identifier hs-var">ST5</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><span class="annottext">ModelSpec layerNorm
LayerNormSpec
  'WithoutBias gradient device dataType ('Shape '[inputEmbedDim])
</span><a href="#local-6989586621679808748"><span class="hs-identifier hs-var">layerNormWithoutBiasSpec</span></a></span><span>
</span><span id="line-252"></span><span>          </span><span class="annot"><span class="annottext">Sing style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SByT5"><span class="hs-identifier hs-var">SByT5</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><span class="annottext">ModelSpec layerNorm
LayerNormSpec
  'WithoutBias gradient device dataType ('Shape '[inputEmbedDim])
</span><a href="#local-6989586621679808748"><span class="hs-identifier hs-var">layerNormWithoutBiasSpec</span></a></span><span>
</span><span id="line-253"></span><span>          </span><span class="annot"><span class="annottext">Sing style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SBART"><span class="hs-identifier hs-var">SBART</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="hs-special">(</span><span class="hs-special">)</span><span>
</span><span id="line-254"></span><span>          </span><span class="annot"><span class="annottext">Sing style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SMBART"><span class="hs-identifier hs-var">SMBART</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="hs-special">(</span><span class="hs-special">)</span><span>
</span><span id="line-255"></span><span>          </span><span class="annot"><span class="annottext">Sing style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SPegasus"><span class="hs-identifier hs-var">SPegasus</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><span class="annottext">ModelSpec layerNorm
LayerNormSpec
  'WithBias gradient device dataType ('Shape '[inputEmbedDim])
</span><a href="#local-6989586621679808747"><span class="hs-identifier hs-var">layerNormWithBiasSpec</span></a></span><span>
</span><span id="line-256"></span><span>          </span><span class="annot"><span class="annottext">Sing style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SBERT"><span class="hs-identifier hs-var">SBERT</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="hs-special">(</span><span class="hs-special">)</span><span>
</span><span id="line-257"></span><span>          </span><span class="annot"><span class="annottext">Sing style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SRoBERTa"><span class="hs-identifier hs-var">SRoBERTa</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="hs-special">(</span><span class="hs-special">)</span><span>
</span><span id="line-258"></span><span>          </span><span class="annot"><span class="annottext">Sing style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SGPT2"><span class="hs-identifier hs-var">SGPT2</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><span class="annottext">ModelSpec layerNorm
forall a. HasCallStack =&gt; a
</span><span class="hs-identifier hs-var">undefined</span></span><span>
</span><span id="line-259"></span><span>        </span><span id="local-6989586621679808745"><span class="annot"><span class="annottext">dropout :: IxStateT m (Generator device) (Generator device) Dropout
</span><a href="#local-6989586621679808745"><span class="hs-identifier hs-var hs-var">dropout</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">(Generator device -&gt; m (Dropout, Generator device))
-&gt; IxStateT m (Generator device) (Generator device) Dropout
forall (m :: * -&gt; *) i j a. (i -&gt; m (a, j)) -&gt; IxStateT m i j a
</span><a href="../file:///nix/store/8vjaffqxij7bih93d9mlzmc7ksanlw0i-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier hs-var">IxStateT</span></a></span><span> </span><span class="annot"><span class="annottext">((Generator device -&gt; m (Dropout, Generator device))
 -&gt; IxStateT m (Generator device) (Generator device) Dropout)
-&gt; (Dropout -&gt; Generator device -&gt; m (Dropout, Generator device))
-&gt; Dropout
-&gt; IxStateT m (Generator device) (Generator device) Dropout
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">forall model (generatorDevice :: Device (DeviceType Nat)) output
       (generatorOutputDevice :: Device (DeviceType Nat)) (m :: * -&gt; *).
(HasInitialize model generatorDevice output generatorOutputDevice,
 MonadThrow m) =&gt;
ModelSpec model
-&gt; Generator generatorDevice
-&gt; m (output, Generator generatorOutputDevice)
forall (generatorDevice :: Device (DeviceType Nat)) output
       (generatorOutputDevice :: Device (DeviceType Nat)) (m :: * -&gt; *).
(HasInitialize
   dropout generatorDevice output generatorOutputDevice,
 MonadThrow m) =&gt;
ModelSpec dropout
-&gt; Generator generatorDevice
-&gt; m (output, Generator generatorOutputDevice)
</span><a href="Torch.GraduallyTyped.NN.Class.html#initialize"><span class="hs-identifier hs-var">initialize</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679808789"><span class="hs-identifier hs-type">dropout</span></a></span><span> </span><span class="annot"><span class="annottext">(Dropout
 -&gt; IxStateT m (Generator device) (Generator device) Dropout)
-&gt; Dropout
-&gt; IxStateT m (Generator device) (Generator device) Dropout
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">Double -&gt; Dropout
</span><a href="Torch.GraduallyTyped.NN.Dropout.html#Dropout"><span class="hs-identifier hs-var">Dropout</span></a></span><span> </span><span class="annot"><span class="annottext">Double
</span><a href="#local-6989586621679808770"><span class="hs-identifier hs-var">dropoutP</span></a></span><span>
</span><span id="line-260"></span><span>        </span><span id="local-6989586621679808743"><span class="annot"><span class="annottext">relPosEncSpec :: EmbeddingSpec
  gradient
  ('Layout 'Dense)
  device
  dataType
  posEncDim
  headDim
  'Nothing
</span><a href="#local-6989586621679808743"><span class="hs-identifier hs-var hs-var">relPosEncSpec</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">SGradient gradient
-&gt; SLayout ('Layout 'Dense)
-&gt; SDevice device
-&gt; SDataType dataType
-&gt; SDim posEncDim
-&gt; SDim headDim
-&gt; SMaybe 'Nothing
-&gt; EmbeddingSpec
     gradient
     ('Layout 'Dense)
     device
     dataType
     posEncDim
     headDim
     'Nothing
forall (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (embedNumDim :: Dim (Name Symbol) (Size Nat))
       (embedDim :: Dim (Name Symbol) (Size Nat))
       (paddingIdx :: Maybe Nat).
SGradient gradient
-&gt; SLayout layout
-&gt; SDevice device
-&gt; SDataType dataType
-&gt; SDim embedNumDim
-&gt; SDim embedDim
-&gt; SMaybe paddingIdx
-&gt; EmbeddingSpec
     gradient layout device dataType embedNumDim embedDim paddingIdx
</span><a href="Torch.GraduallyTyped.NN.Sparse.html#EmbeddingSpec"><span class="hs-identifier hs-var">EmbeddingSpec</span></a></span><span> </span><span class="annot"><span class="annottext">SGradient gradient
</span><a href="#local-6989586621679808779"><span class="hs-identifier hs-var">gradient</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SLayoutType 'Dense -&gt; SLayout ('Layout 'Dense)
forall (layoutType :: LayoutType).
SLayoutType layoutType -&gt; SLayout ('Layout layoutType)
</span><a href="Torch.GraduallyTyped.Layout.html#SLayout"><span class="hs-identifier hs-var">SLayout</span></a></span><span> </span><span class="annot"><span class="annottext">SLayoutType 'Dense
</span><a href="Torch.GraduallyTyped.Layout.html#SDense"><span class="hs-identifier hs-var">SDense</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">SDevice device
</span><a href="#local-6989586621679808778"><span class="hs-identifier hs-var">device</span></a></span><span> </span><span class="annot"><span class="annottext">SDataType dataType
</span><a href="#local-6989586621679808777"><span class="hs-identifier hs-var">dataType</span></a></span><span> </span><span class="annot"><span class="annottext">SDim posEncDim
</span><a href="#local-6989586621679808771"><span class="hs-identifier hs-var">posEncDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim headDim
</span><a href="#local-6989586621679808776"><span class="hs-identifier hs-var">headDim</span></a></span><span> </span><span class="annot"><span class="annottext">SMaybe 'Nothing
forall a. SMaybe 'Nothing
</span><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-var">SNothing</span></a></span><span>
</span><span id="line-261"></span><span>        </span><span id="local-6989586621679808739"><span class="annot"><span class="annottext">posEncSpec :: EmbeddingSpec
  gradient
  ('Layout 'Dense)
  device
  dataType
  posEncDim
  inputEmbedDim
  'Nothing
</span><a href="#local-6989586621679808739"><span class="hs-identifier hs-var hs-var">posEncSpec</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">SGradient gradient
-&gt; SLayout ('Layout 'Dense)
-&gt; SDevice device
-&gt; SDataType dataType
-&gt; SDim posEncDim
-&gt; SDim inputEmbedDim
-&gt; SMaybe 'Nothing
-&gt; EmbeddingSpec
     gradient
     ('Layout 'Dense)
     device
     dataType
     posEncDim
     inputEmbedDim
     'Nothing
forall (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (embedNumDim :: Dim (Name Symbol) (Size Nat))
       (embedDim :: Dim (Name Symbol) (Size Nat))
       (paddingIdx :: Maybe Nat).
SGradient gradient
-&gt; SLayout layout
-&gt; SDevice device
-&gt; SDataType dataType
-&gt; SDim embedNumDim
-&gt; SDim embedDim
-&gt; SMaybe paddingIdx
-&gt; EmbeddingSpec
     gradient layout device dataType embedNumDim embedDim paddingIdx
</span><a href="Torch.GraduallyTyped.NN.Sparse.html#EmbeddingSpec"><span class="hs-identifier hs-var">EmbeddingSpec</span></a></span><span> </span><span class="annot"><span class="annottext">SGradient gradient
</span><a href="#local-6989586621679808779"><span class="hs-identifier hs-var">gradient</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SLayoutType 'Dense -&gt; SLayout ('Layout 'Dense)
forall (layoutType :: LayoutType).
SLayoutType layoutType -&gt; SLayout ('Layout layoutType)
</span><a href="Torch.GraduallyTyped.Layout.html#SLayout"><span class="hs-identifier hs-var">SLayout</span></a></span><span> </span><span class="annot"><span class="annottext">SLayoutType 'Dense
</span><a href="Torch.GraduallyTyped.Layout.html#SDense"><span class="hs-identifier hs-var">SDense</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">SDevice device
</span><a href="#local-6989586621679808778"><span class="hs-identifier hs-var">device</span></a></span><span> </span><span class="annot"><span class="annottext">SDataType dataType
</span><a href="#local-6989586621679808777"><span class="hs-identifier hs-var">dataType</span></a></span><span> </span><span class="annot"><span class="annottext">SDim posEncDim
</span><a href="#local-6989586621679808771"><span class="hs-identifier hs-var">posEncDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim inputEmbedDim
</span><a href="#local-6989586621679808773"><span class="hs-identifier hs-var">inputEmbedDim</span></a></span><span> </span><span class="annot"><span class="annottext">SMaybe 'Nothing
forall a. SMaybe 'Nothing
</span><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-var">SNothing</span></a></span><span>
</span><span id="line-262"></span><span>        </span><span id="local-6989586621679808738"><span class="annot"><span class="annottext">posEnc :: IxStateT m (Generator device) (Generator device) posEnc
</span><a href="#local-6989586621679808738"><span class="hs-identifier hs-var hs-var">posEnc</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">(Generator device -&gt; m (posEnc, Generator device))
-&gt; IxStateT m (Generator device) (Generator device) posEnc
forall (m :: * -&gt; *) i j a. (i -&gt; m (a, j)) -&gt; IxStateT m i j a
</span><a href="../file:///nix/store/8vjaffqxij7bih93d9mlzmc7ksanlw0i-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier hs-var">IxStateT</span></a></span><span> </span><span class="annot"><span class="annottext">((Generator device -&gt; m (posEnc, Generator device))
 -&gt; IxStateT m (Generator device) (Generator device) posEnc)
-&gt; (ModelSpec posEnc
    -&gt; Generator device -&gt; m (posEnc, Generator device))
-&gt; ModelSpec posEnc
-&gt; IxStateT m (Generator device) (Generator device) posEnc
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">forall model (generatorDevice :: Device (DeviceType Nat)) output
       (generatorOutputDevice :: Device (DeviceType Nat)) (m :: * -&gt; *).
(HasInitialize model generatorDevice output generatorOutputDevice,
 MonadThrow m) =&gt;
ModelSpec model
-&gt; Generator generatorDevice
-&gt; m (output, Generator generatorOutputDevice)
forall (generatorDevice :: Device (DeviceType Nat)) output
       (generatorOutputDevice :: Device (DeviceType Nat)) (m :: * -&gt; *).
(HasInitialize posEnc generatorDevice output generatorOutputDevice,
 MonadThrow m) =&gt;
ModelSpec posEnc
-&gt; Generator generatorDevice
-&gt; m (output, Generator generatorOutputDevice)
</span><a href="Torch.GraduallyTyped.NN.Class.html#initialize"><span class="hs-identifier hs-var">initialize</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679808788"><span class="hs-identifier hs-type">posEnc</span></a></span><span> </span><span class="annot"><span class="annottext">(ModelSpec posEnc
 -&gt; IxStateT m (Generator device) (Generator device) posEnc)
-&gt; ModelSpec posEnc
-&gt; IxStateT m (Generator device) (Generator device) posEnc
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="hs-keyword">case</span><span> </span><span class="annot"><span class="annottext">SingI style =&gt; Sing style
forall k (a :: k). SingI a =&gt; Sing a
</span><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-var">sing</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679808802"><span class="hs-identifier hs-type">style</span></a></span><span> </span><span class="hs-keyword">of</span><span>
</span><span id="line-263"></span><span>          </span><span class="annot"><span class="annottext">Sing style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#ST5"><span class="hs-identifier hs-var">ST5</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><span class="annottext">ModelSpec posEnc
EmbeddingSpec
  gradient
  ('Layout 'Dense)
  device
  dataType
  posEncDim
  headDim
  'Nothing
</span><a href="#local-6989586621679808743"><span class="hs-identifier hs-var">relPosEncSpec</span></a></span><span>
</span><span id="line-264"></span><span>          </span><span class="annot"><span class="annottext">Sing style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SByT5"><span class="hs-identifier hs-var">SByT5</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><span class="annottext">ModelSpec posEnc
EmbeddingSpec
  gradient
  ('Layout 'Dense)
  device
  dataType
  posEncDim
  headDim
  'Nothing
</span><a href="#local-6989586621679808743"><span class="hs-identifier hs-var">relPosEncSpec</span></a></span><span>
</span><span id="line-265"></span><span>          </span><span class="annot"><span class="annottext">Sing style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SBART"><span class="hs-identifier hs-var">SBART</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><span class="annottext">ModelSpec posEnc
EmbeddingSpec
  gradient
  ('Layout 'Dense)
  device
  dataType
  posEncDim
  inputEmbedDim
  'Nothing
</span><a href="#local-6989586621679808739"><span class="hs-identifier hs-var">posEncSpec</span></a></span><span>
</span><span id="line-266"></span><span>          </span><span class="annot"><span class="annottext">Sing style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SMBART"><span class="hs-identifier hs-var">SMBART</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><span class="annottext">ModelSpec posEnc
EmbeddingSpec
  gradient
  ('Layout 'Dense)
  device
  dataType
  posEncDim
  inputEmbedDim
  'Nothing
</span><a href="#local-6989586621679808739"><span class="hs-identifier hs-var">posEncSpec</span></a></span><span>
</span><span id="line-267"></span><span>          </span><span class="annot"><span class="annottext">Sing style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SPegasus"><span class="hs-identifier hs-var">SPegasus</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><span class="annottext">ModelSpec posEnc
EmbeddingSpec
  gradient
  ('Layout 'Dense)
  device
  dataType
  posEncDim
  inputEmbedDim
  'Nothing
</span><a href="#local-6989586621679808739"><span class="hs-identifier hs-var">posEncSpec</span></a></span><span>
</span><span id="line-268"></span><span>          </span><span class="annot"><span class="annottext">Sing style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SBERT"><span class="hs-identifier hs-var">SBERT</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><span class="annottext">ModelSpec posEnc
EmbeddingSpec
  gradient
  ('Layout 'Dense)
  device
  dataType
  posEncDim
  inputEmbedDim
  'Nothing
</span><a href="#local-6989586621679808739"><span class="hs-identifier hs-var">posEncSpec</span></a></span><span>
</span><span id="line-269"></span><span>          </span><span class="annot"><span class="annottext">Sing style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SRoBERTa"><span class="hs-identifier hs-var">SRoBERTa</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><span class="annottext">ModelSpec posEnc
EmbeddingSpec
  gradient
  ('Layout 'Dense)
  device
  dataType
  posEncDim
  inputEmbedDim
  'Nothing
</span><a href="#local-6989586621679808739"><span class="hs-identifier hs-var">posEncSpec</span></a></span><span>
</span><span id="line-270"></span><span>          </span><span class="annot"><span class="annottext">Sing style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SGPT2"><span class="hs-identifier hs-var">SGPT2</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><span class="annottext">ModelSpec posEnc
forall a. HasCallStack =&gt; a
</span><span class="hs-identifier hs-var">undefined</span></span><span>
</span><span id="line-271"></span><span>        </span><span id="local-6989586621679808737"><span class="annot"><span class="annottext">gte :: IxStateT
  m
  (Generator device)
  (Generator device)
  (GTransformerEncoder
     (TransformerStack
        style
        numLayers
        gradient
        device
        dataType
        headDim
        headEmbedDim
        embedDim
        inputEmbedDim
        ffnDim)
     embedLayerNorm
     layerNorm
     Dropout
     posEnc)
</span><a href="#local-6989586621679808737"><span class="hs-identifier hs-var hs-var">gte</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-272"></span><span>          </span><span class="annot"><span class="annottext">TransformerStack
  style
  numLayers
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  inputEmbedDim
  ffnDim
-&gt; embedLayerNorm
-&gt; layerNorm
-&gt; Dropout
-&gt; posEnc
-&gt; GTransformerEncoder
     (TransformerStack
        style
        numLayers
        gradient
        device
        dataType
        headDim
        headEmbedDim
        embedDim
        inputEmbedDim
        ffnDim)
     embedLayerNorm
     layerNorm
     Dropout
     posEnc
forall stack embedLayerNorm layerNorm dropout posEnc.
stack
-&gt; embedLayerNorm
-&gt; layerNorm
-&gt; dropout
-&gt; posEnc
-&gt; GTransformerEncoder
     stack embedLayerNorm layerNorm dropout posEnc
</span><a href="Torch.GraduallyTyped.NN.Transformer.Encoder.html#GTransformerEncoder"><span class="hs-identifier hs-var">GTransformerEncoder</span></a></span><span>
</span><span id="line-273"></span><span>            </span><span class="annot"><span class="annottext">(TransformerStack
   style
   numLayers
   gradient
   device
   dataType
   headDim
   headEmbedDim
   embedDim
   inputEmbedDim
   ffnDim
 -&gt; embedLayerNorm
 -&gt; layerNorm
 -&gt; Dropout
 -&gt; posEnc
 -&gt; GTransformerEncoder
      (TransformerStack
         style
         numLayers
         gradient
         device
         dataType
         headDim
         headEmbedDim
         embedDim
         inputEmbedDim
         ffnDim)
      embedLayerNorm
      layerNorm
      Dropout
      posEnc)
-&gt; IxStateT
     m
     (Generator device)
     (Generator device)
     (TransformerStack
        style
        numLayers
        gradient
        device
        dataType
        headDim
        headEmbedDim
        embedDim
        inputEmbedDim
        ffnDim)
-&gt; IxStateT
     m
     (Generator device)
     (Generator device)
     (embedLayerNorm
      -&gt; layerNorm
      -&gt; Dropout
      -&gt; posEnc
      -&gt; GTransformerEncoder
           (TransformerStack
              style
              numLayers
              gradient
              device
              dataType
              headDim
              headEmbedDim
              embedDim
              inputEmbedDim
              ffnDim)
           embedLayerNorm
           layerNorm
           Dropout
           posEnc)
forall k1 k2 (f :: k1 -&gt; k2 -&gt; * -&gt; *) a b (j :: k1) (k3 :: k2).
IxFunctor f =&gt;
(a -&gt; b) -&gt; f j k3 a -&gt; f j k3 b
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&lt;&lt;$&gt;&gt;</span></a></span><span> </span><span class="annot"><span class="annottext">IxStateT
  m
  (Generator device)
  (Generator device)
  (TransformerStack
     style
     numLayers
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     inputEmbedDim
     ffnDim)
</span><a href="#local-6989586621679808766"><span class="hs-identifier hs-var">stack</span></a></span><span>
</span><span id="line-274"></span><span>            </span><span class="annot"><span class="annottext">IxStateT
  m
  (Generator device)
  (Generator device)
  (embedLayerNorm
   -&gt; layerNorm
   -&gt; Dropout
   -&gt; posEnc
   -&gt; GTransformerEncoder
        (TransformerStack
           style
           numLayers
           gradient
           device
           dataType
           headDim
           headEmbedDim
           embedDim
           inputEmbedDim
           ffnDim)
        embedLayerNorm
        layerNorm
        Dropout
        posEnc)
-&gt; IxStateT m (Generator device) (Generator device) embedLayerNorm
-&gt; IxStateT
     m
     (Generator device)
     (Generator device)
     (layerNorm
      -&gt; Dropout
      -&gt; posEnc
      -&gt; GTransformerEncoder
           (TransformerStack
              style
              numLayers
              gradient
              device
              dataType
              headDim
              headEmbedDim
              embedDim
              inputEmbedDim
              ffnDim)
           embedLayerNorm
           layerNorm
           Dropout
           posEnc)
forall k1 (f :: k1 -&gt; k1 -&gt; * -&gt; *) (i :: k1) (j :: k1) a b
       (k2 :: k1).
IxApplicative f =&gt;
f i j (a -&gt; b) -&gt; f j k2 a -&gt; f i k2 b
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&lt;&lt;*&gt;&gt;</span></a></span><span> </span><span class="annot"><span class="annottext">IxStateT m (Generator device) (Generator device) embedLayerNorm
</span><a href="#local-6989586621679808759"><span class="hs-identifier hs-var">embedLayerNorm</span></a></span><span>
</span><span id="line-275"></span><span>            </span><span class="annot"><span class="annottext">IxStateT
  m
  (Generator device)
  (Generator device)
  (layerNorm
   -&gt; Dropout
   -&gt; posEnc
   -&gt; GTransformerEncoder
        (TransformerStack
           style
           numLayers
           gradient
           device
           dataType
           headDim
           headEmbedDim
           embedDim
           inputEmbedDim
           ffnDim)
        embedLayerNorm
        layerNorm
        Dropout
        posEnc)
-&gt; IxStateT m (Generator device) (Generator device) layerNorm
-&gt; IxStateT
     m
     (Generator device)
     (Generator device)
     (Dropout
      -&gt; posEnc
      -&gt; GTransformerEncoder
           (TransformerStack
              style
              numLayers
              gradient
              device
              dataType
              headDim
              headEmbedDim
              embedDim
              inputEmbedDim
              ffnDim)
           embedLayerNorm
           layerNorm
           Dropout
           posEnc)
forall k1 (f :: k1 -&gt; k1 -&gt; * -&gt; *) (i :: k1) (j :: k1) a b
       (k2 :: k1).
IxApplicative f =&gt;
f i j (a -&gt; b) -&gt; f j k2 a -&gt; f i k2 b
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&lt;&lt;*&gt;&gt;</span></a></span><span> </span><span class="annot"><span class="annottext">IxStateT m (Generator device) (Generator device) layerNorm
</span><a href="#local-6989586621679808746"><span class="hs-identifier hs-var">layerNorm</span></a></span><span>
</span><span id="line-276"></span><span>            </span><span class="annot"><span class="annottext">IxStateT
  m
  (Generator device)
  (Generator device)
  (Dropout
   -&gt; posEnc
   -&gt; GTransformerEncoder
        (TransformerStack
           style
           numLayers
           gradient
           device
           dataType
           headDim
           headEmbedDim
           embedDim
           inputEmbedDim
           ffnDim)
        embedLayerNorm
        layerNorm
        Dropout
        posEnc)
-&gt; IxStateT m (Generator device) (Generator device) Dropout
-&gt; IxStateT
     m
     (Generator device)
     (Generator device)
     (posEnc
      -&gt; GTransformerEncoder
           (TransformerStack
              style
              numLayers
              gradient
              device
              dataType
              headDim
              headEmbedDim
              embedDim
              inputEmbedDim
              ffnDim)
           embedLayerNorm
           layerNorm
           Dropout
           posEnc)
forall k1 (f :: k1 -&gt; k1 -&gt; * -&gt; *) (i :: k1) (j :: k1) a b
       (k2 :: k1).
IxApplicative f =&gt;
f i j (a -&gt; b) -&gt; f j k2 a -&gt; f i k2 b
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&lt;&lt;*&gt;&gt;</span></a></span><span> </span><span class="annot"><span class="annottext">IxStateT m (Generator device) (Generator device) Dropout
</span><a href="#local-6989586621679808745"><span class="hs-identifier hs-var">dropout</span></a></span><span>
</span><span id="line-277"></span><span>            </span><span class="annot"><span class="annottext">IxStateT
  m
  (Generator device)
  (Generator device)
  (posEnc
   -&gt; GTransformerEncoder
        (TransformerStack
           style
           numLayers
           gradient
           device
           dataType
           headDim
           headEmbedDim
           embedDim
           inputEmbedDim
           ffnDim)
        embedLayerNorm
        layerNorm
        Dropout
        posEnc)
-&gt; IxStateT m (Generator device) (Generator device) posEnc
-&gt; IxStateT
     m
     (Generator device)
     (Generator device)
     (GTransformerEncoder
        (TransformerStack
           style
           numLayers
           gradient
           device
           dataType
           headDim
           headEmbedDim
           embedDim
           inputEmbedDim
           ffnDim)
        embedLayerNorm
        layerNorm
        Dropout
        posEnc)
forall k1 (f :: k1 -&gt; k1 -&gt; * -&gt; *) (i :: k1) (j :: k1) a b
       (k2 :: k1).
IxApplicative f =&gt;
f i j (a -&gt; b) -&gt; f j k2 a -&gt; f i k2 b
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&lt;&lt;*&gt;&gt;</span></a></span><span> </span><span class="annot"><span class="annottext">IxStateT m (Generator device) (Generator device) posEnc
</span><a href="#local-6989586621679808738"><span class="hs-identifier hs-var">posEnc</span></a></span><span>
</span><span id="line-278"></span><span>     </span><span class="hs-keyword">in</span><span> </span><span class="annot"><span class="annottext">IxStateT
  m
  (Generator device)
  (Generator device)
  (TransformerEncoder
     style
     numLayers
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     inputEmbedDim
     ffnDim
     posEncDim)
-&gt; Generator device
-&gt; m (TransformerEncoder
        style
        numLayers
        gradient
        device
        dataType
        headDim
        headEmbedDim
        embedDim
        inputEmbedDim
        ffnDim
        posEncDim,
      Generator device)
forall (m :: * -&gt; *) i j a. IxStateT m i j a -&gt; i -&gt; m (a, j)
</span><a href="../file:///nix/store/8vjaffqxij7bih93d9mlzmc7ksanlw0i-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier hs-var hs-var">runIxStateT</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">IxStateT
  m
  (Generator device)
  (Generator device)
  (GTransformerEncoder
     (TransformerStack
        style
        numLayers
        gradient
        device
        dataType
        headDim
        headEmbedDim
        embedDim
        inputEmbedDim
        ffnDim)
     embedLayerNorm
     layerNorm
     Dropout
     posEnc)
</span><a href="#local-6989586621679808737"><span class="hs-identifier hs-var">gte</span></a></span><span> </span><span class="annot"><span class="annottext">IxStateT
  m
  (Generator device)
  (Generator device)
  (GTransformerEncoder
     (TransformerStack
        style
        numLayers
        gradient
        device
        dataType
        headDim
        headEmbedDim
        embedDim
        inputEmbedDim
        ffnDim)
     embedLayerNorm
     layerNorm
     Dropout
     posEnc)
-&gt; (GTransformerEncoder
      (TransformerStack
         style
         numLayers
         gradient
         device
         dataType
         headDim
         headEmbedDim
         embedDim
         inputEmbedDim
         ffnDim)
      embedLayerNorm
      layerNorm
      Dropout
      posEnc
    -&gt; IxStateT
         m
         (Generator device)
         (Generator device)
         (TransformerEncoder
            style
            numLayers
            gradient
            device
            dataType
            headDim
            headEmbedDim
            embedDim
            inputEmbedDim
            ffnDim
            posEncDim))
-&gt; IxStateT
     m
     (Generator device)
     (Generator device)
     (TransformerEncoder
        style
        numLayers
        gradient
        device
        dataType
        headDim
        headEmbedDim
        embedDim
        inputEmbedDim
        ffnDim
        posEncDim)
forall k1 (m :: k1 -&gt; k1 -&gt; * -&gt; *) (i :: k1) (j :: k1) a
       (k2 :: k1) b.
IxMonad m =&gt;
m i j a -&gt; (a -&gt; m j k2 b) -&gt; m i k2 b
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&gt;&gt;&gt;=</span></a></span><span> </span><span class="annot"><span class="annottext">TransformerEncoder
  style
  numLayers
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  inputEmbedDim
  ffnDim
  posEncDim
-&gt; IxStateT
     m
     (Generator device)
     (Generator device)
     (TransformerEncoder
        style
        numLayers
        gradient
        device
        dataType
        headDim
        headEmbedDim
        embedDim
        inputEmbedDim
        ffnDim
        posEncDim)
forall k (m :: k -&gt; k -&gt; * -&gt; *) a (i :: k).
IxPointed m =&gt;
a -&gt; m i i a
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-identifier hs-var">ireturn</span></a></span><span> </span><span class="annot"><span class="annottext">(TransformerEncoder
   style
   numLayers
   gradient
   device
   dataType
   headDim
   headEmbedDim
   embedDim
   inputEmbedDim
   ffnDim
   posEncDim
 -&gt; IxStateT
      m
      (Generator device)
      (Generator device)
      (TransformerEncoder
         style
         numLayers
         gradient
         device
         dataType
         headDim
         headEmbedDim
         embedDim
         inputEmbedDim
         ffnDim
         posEncDim))
-&gt; (GTransformerEncoder
      (TransformerStack
         style
         numLayers
         gradient
         device
         dataType
         headDim
         headEmbedDim
         embedDim
         inputEmbedDim
         ffnDim)
      embedLayerNorm
      layerNorm
      Dropout
      posEnc
    -&gt; TransformerEncoder
         style
         numLayers
         gradient
         device
         dataType
         headDim
         headEmbedDim
         embedDim
         inputEmbedDim
         ffnDim
         posEncDim)
-&gt; GTransformerEncoder
     (TransformerStack
        style
        numLayers
        gradient
        device
        dataType
        headDim
        headEmbedDim
        embedDim
        inputEmbedDim
        ffnDim)
     embedLayerNorm
     layerNorm
     Dropout
     posEnc
-&gt; IxStateT
     m
     (Generator device)
     (Generator device)
     (TransformerEncoder
        style
        numLayers
        gradient
        device
        dataType
        headDim
        headEmbedDim
        embedDim
        inputEmbedDim
        ffnDim
        posEncDim)
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">GTransformerEncoder
  (TransformerStack
     style
     numLayers
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     inputEmbedDim
     ffnDim)
  embedLayerNorm
  layerNorm
  Dropout
  posEnc
-&gt; TransformerEncoder
     style
     numLayers
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     inputEmbedDim
     ffnDim
     posEncDim
forall (style :: TransformerStyle) (numLayers :: Nat)
       (gradient :: Gradient RequiresGradient)
       (device :: Device (DeviceType Nat)) (dataType :: DataType DType)
       (headDim :: Dim (Name Symbol) (Size Nat))
       (headEmbedDim :: Dim (Name Symbol) (Size Nat))
       (embedDim :: Dim (Name Symbol) (Size Nat))
       (inputEmbedDim :: Dim (Name Symbol) (Size Nat))
       (ffnDim :: Dim (Name Symbol) (Size Nat))
       (posEncDim :: Dim (Name Symbol) (Size Nat)).
GTransformerEncoder
  (TEStackF
     style
     numLayers
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     inputEmbedDim
     ffnDim)
  (TEEmbedLayerNormF style gradient device dataType inputEmbedDim)
  (TELayerNormF style gradient device dataType inputEmbedDim)
  (TEDropoutF style)
  (TEPosEncF
     style gradient device dataType headDim inputEmbedDim posEncDim)
-&gt; TransformerEncoder
     style
     numLayers
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     inputEmbedDim
     ffnDim
     posEncDim
</span><a href="Torch.GraduallyTyped.NN.Transformer.Encoder.html#TransformerEncoder"><span class="hs-identifier hs-var">TransformerEncoder</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">Generator device
</span><a href="#local-6989586621679808767"><span class="hs-identifier hs-var">generator'</span></a></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span><span>
</span><span id="line-279"></span><span>
</span><span id="line-280"></span><span id="local-6989586621679808725"><span id="local-6989586621679808726"><span id="local-6989586621679808727"><span id="local-6989586621679808728"><span id="local-6989586621679808729"><span id="local-6989586621679808730"><span id="local-6989586621679808731"><span id="local-6989586621679808732"><span id="local-6989586621679808733"><span id="local-6989586621679808734"><span id="local-6989586621679808735"><span class="hs-keyword">instance</span><span>
</span><span id="line-281"></span><span>  </span><span class="annot"><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-type">SingI</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808735"><span class="hs-identifier hs-type">style</span></a></span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-282"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasStateDict"><span class="hs-identifier hs-type">HasStateDict</span></a></span><span>
</span><span id="line-283"></span><span>    </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Encoder.html#TransformerEncoder"><span class="hs-identifier hs-type">TransformerEncoder</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808735"><span class="hs-identifier hs-type">style</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808734"><span class="hs-identifier hs-type">numLayers</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808733"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808732"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808731"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808730"><span class="hs-identifier hs-type">headDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808729"><span class="hs-identifier hs-type">headEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808728"><span class="hs-identifier hs-type">embedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808727"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808726"><span class="hs-identifier hs-type">ffnDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808725"><span class="hs-identifier hs-type">posEncDim</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-284"></span><span>  </span><span class="hs-keyword">where</span><span>
</span><span id="line-285"></span><span>  </span><span id="local-6989586621679808721"><span class="annot"><span class="annottext">fromStateDict :: ModelSpec
  (TransformerEncoder
     style
     numLayers
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     inputEmbedDim
     ffnDim
     posEncDim)
-&gt; StateDictKey
-&gt; m (TransformerEncoder
        style
        numLayers
        gradient
        device
        dataType
        headDim
        headEmbedDim
        embedDim
        inputEmbedDim
        ffnDim
        posEncDim)
</span><a href="Torch.GraduallyTyped.NN.Class.html#fromStateDict"><span class="hs-identifier hs-var hs-var hs-var hs-var">fromStateDict</span></a></span></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Encoder.html#TransformerEncoderSpec"><span class="hs-identifier hs-type">TransformerEncoderSpec</span></a></span><span> </span><span id="local-6989586621679808719"><span class="annot"><a href="#local-6989586621679808719"><span class="hs-identifier hs-var">style</span></a></span></span><span> </span><span id="local-6989586621679808718"><span class="annot"><a href="#local-6989586621679808718"><span class="hs-identifier hs-var">numLayers</span></a></span></span><span> </span><span id="local-6989586621679808717"><span class="annot"><a href="#local-6989586621679808717"><span class="hs-identifier hs-var">gradient</span></a></span></span><span> </span><span id="local-6989586621679808716"><span class="annot"><a href="#local-6989586621679808716"><span class="hs-identifier hs-var">device</span></a></span></span><span> </span><span id="local-6989586621679808715"><span class="annot"><a href="#local-6989586621679808715"><span class="hs-identifier hs-var">dataType</span></a></span></span><span> </span><span id="local-6989586621679808714"><span class="annot"><a href="#local-6989586621679808714"><span class="hs-identifier hs-var">headDim</span></a></span></span><span> </span><span id="local-6989586621679808713"><span class="annot"><a href="#local-6989586621679808713"><span class="hs-identifier hs-var">headEmbedDim</span></a></span></span><span> </span><span id="local-6989586621679808712"><span class="annot"><a href="#local-6989586621679808712"><span class="hs-identifier hs-var">embedDim</span></a></span></span><span> </span><span id="local-6989586621679808711"><span class="annot"><a href="#local-6989586621679808711"><span class="hs-identifier hs-var">inputEmbedDim</span></a></span></span><span> </span><span id="local-6989586621679808710"><span class="annot"><a href="#local-6989586621679808710"><span class="hs-identifier hs-var">ffnDim</span></a></span></span><span> </span><span id="local-6989586621679808709"><span class="annot"><a href="#local-6989586621679808709"><span class="hs-identifier hs-var">posEncDim</span></a></span></span><span> </span><span id="local-6989586621679808708"><span class="annot"><a href="#local-6989586621679808708"><span class="hs-identifier hs-var">dropoutP</span></a></span></span><span> </span><span id="local-6989586621679808707"><span class="annot"><a href="#local-6989586621679808707"><span class="hs-identifier hs-var">eps</span></a></span></span><span class="hs-special">)</span><span> </span><span id="local-6989586621679808706"><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679808706"><span class="hs-identifier hs-var">k</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-286"></span><span>    </span><span class="hs-keyword">let</span><span> </span><span id="local-6989586621679808705"><span class="annot"><span class="annottext">stackSpec :: TransformerStackSpec
  style
  numLayers
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  inputEmbedDim
  ffnDim
</span><a href="#local-6989586621679808705"><span class="hs-identifier hs-var hs-var">stackSpec</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
-&gt; SNat numLayers
-&gt; SGradient gradient
-&gt; SDevice device
-&gt; SDataType dataType
-&gt; SDim headDim
-&gt; SDim headEmbedDim
-&gt; SDim embedDim
-&gt; SDim inputEmbedDim
-&gt; SDim ffnDim
-&gt; Double
-&gt; Double
-&gt; TransformerStackSpec
     style
     numLayers
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     inputEmbedDim
     ffnDim
forall (style :: TransformerStyle) (numLayers :: Nat)
       (gradient :: Gradient RequiresGradient)
       (device :: Device (DeviceType Nat)) (dataType :: DataType DType)
       (headDim :: Dim (Name Symbol) (Size Nat))
       (headEmbedDim :: Dim (Name Symbol) (Size Nat))
       (embedDim :: Dim (Name Symbol) (Size Nat))
       (queryEmbedDim :: Dim (Name Symbol) (Size Nat))
       (ffnDim :: Dim (Name Symbol) (Size Nat)).
STransformerStyle style
-&gt; SNat numLayers
-&gt; SGradient gradient
-&gt; SDevice device
-&gt; SDataType dataType
-&gt; SDim headDim
-&gt; SDim headEmbedDim
-&gt; SDim embedDim
-&gt; SDim queryEmbedDim
-&gt; SDim ffnDim
-&gt; Double
-&gt; Double
-&gt; TransformerStackSpec
     style
     numLayers
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     queryEmbedDim
     ffnDim
</span><a href="Torch.GraduallyTyped.NN.Transformer.Stack.html#TransformerStackSpec"><span class="hs-identifier hs-var">TransformerStackSpec</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="#local-6989586621679808719"><span class="hs-identifier hs-var">style</span></a></span><span> </span><span class="annot"><span class="annottext">SNat numLayers
</span><a href="#local-6989586621679808718"><span class="hs-identifier hs-var">numLayers</span></a></span><span> </span><span class="annot"><span class="annottext">SGradient gradient
</span><a href="#local-6989586621679808717"><span class="hs-identifier hs-var">gradient</span></a></span><span> </span><span class="annot"><span class="annottext">SDevice device
</span><a href="#local-6989586621679808716"><span class="hs-identifier hs-var">device</span></a></span><span> </span><span class="annot"><span class="annottext">SDataType dataType
</span><a href="#local-6989586621679808715"><span class="hs-identifier hs-var">dataType</span></a></span><span> </span><span class="annot"><span class="annottext">SDim headDim
</span><a href="#local-6989586621679808714"><span class="hs-identifier hs-var">headDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim headEmbedDim
</span><a href="#local-6989586621679808713"><span class="hs-identifier hs-var">headEmbedDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim embedDim
</span><a href="#local-6989586621679808712"><span class="hs-identifier hs-var">embedDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim inputEmbedDim
</span><a href="#local-6989586621679808711"><span class="hs-identifier hs-var">inputEmbedDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim ffnDim
</span><a href="#local-6989586621679808710"><span class="hs-identifier hs-var">ffnDim</span></a></span><span> </span><span class="annot"><span class="annottext">Double
</span><a href="#local-6989586621679808708"><span class="hs-identifier hs-var">dropoutP</span></a></span><span> </span><span class="annot"><span class="annottext">Double
</span><a href="#local-6989586621679808707"><span class="hs-identifier hs-var">eps</span></a></span><span>
</span><span id="line-287"></span><span>        </span><span id="local-6989586621679808704"><span class="annot"><span class="annottext">stack :: STransformerStyle style
-&gt; m (TransformerStack
        style
        numLayers
        gradient
        device
        dataType
        headDim
        headEmbedDim
        embedDim
        inputEmbedDim
        ffnDim)
</span><a href="#local-6989586621679808704"><span class="hs-identifier hs-var hs-var">stack</span></a></span></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#ST5"><span class="hs-identifier hs-var">ST5</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">ModelSpec
  (TransformerStack
     'T5
     numLayers
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     inputEmbedDim
     ffnDim)
-&gt; StateDictKey
-&gt; m (TransformerStack
        'T5
        numLayers
        gradient
        device
        dataType
        headDim
        headEmbedDim
        embedDim
        inputEmbedDim
        ffnDim)
forall model (m :: * -&gt; *).
(HasStateDict model, MonadThrow m, MonadState StateDict m) =&gt;
ModelSpec model -&gt; StateDictKey -&gt; m model
</span><a href="Torch.GraduallyTyped.NN.Class.html#fromStateDict"><span class="hs-identifier hs-var">fromStateDict</span></a></span><span> </span><span class="annot"><span class="annottext">ModelSpec
  (TransformerStack
     'T5
     numLayers
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     inputEmbedDim
     ffnDim)
TransformerStackSpec
  style
  numLayers
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  inputEmbedDim
  ffnDim
</span><a href="#local-6989586621679808705"><span class="hs-identifier hs-var">stackSpec</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679808706"><span class="hs-identifier hs-var">k</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey -&gt; StateDictKey -&gt; StateDictKey
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;block.&quot;</span></span><span class="hs-special">)</span><span>
</span><span id="line-288"></span><span>        </span><span class="annot"><a href="#local-6989586621679808704"><span class="hs-identifier hs-var">stack</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SByT5"><span class="hs-identifier hs-var">SByT5</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">ModelSpec
  (TransformerStack
     'ByT5
     numLayers
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     inputEmbedDim
     ffnDim)
-&gt; StateDictKey
-&gt; m (TransformerStack
        'ByT5
        numLayers
        gradient
        device
        dataType
        headDim
        headEmbedDim
        embedDim
        inputEmbedDim
        ffnDim)
forall model (m :: * -&gt; *).
(HasStateDict model, MonadThrow m, MonadState StateDict m) =&gt;
ModelSpec model -&gt; StateDictKey -&gt; m model
</span><a href="Torch.GraduallyTyped.NN.Class.html#fromStateDict"><span class="hs-identifier hs-var">fromStateDict</span></a></span><span> </span><span class="annot"><span class="annottext">ModelSpec
  (TransformerStack
     'ByT5
     numLayers
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     inputEmbedDim
     ffnDim)
TransformerStackSpec
  style
  numLayers
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  inputEmbedDim
  ffnDim
</span><a href="#local-6989586621679808705"><span class="hs-identifier hs-var">stackSpec</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679808706"><span class="hs-identifier hs-var">k</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey -&gt; StateDictKey -&gt; StateDictKey
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;block.&quot;</span></span><span class="hs-special">)</span><span>
</span><span id="line-289"></span><span>        </span><span class="annot"><a href="#local-6989586621679808704"><span class="hs-identifier hs-var">stack</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SBART"><span class="hs-identifier hs-var">SBART</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">ModelSpec
  (TransformerStack
     'BART
     numLayers
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     inputEmbedDim
     ffnDim)
-&gt; StateDictKey
-&gt; m (TransformerStack
        'BART
        numLayers
        gradient
        device
        dataType
        headDim
        headEmbedDim
        embedDim
        inputEmbedDim
        ffnDim)
forall model (m :: * -&gt; *).
(HasStateDict model, MonadThrow m, MonadState StateDict m) =&gt;
ModelSpec model -&gt; StateDictKey -&gt; m model
</span><a href="Torch.GraduallyTyped.NN.Class.html#fromStateDict"><span class="hs-identifier hs-var">fromStateDict</span></a></span><span> </span><span class="annot"><span class="annottext">ModelSpec
  (TransformerStack
     'BART
     numLayers
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     inputEmbedDim
     ffnDim)
TransformerStackSpec
  style
  numLayers
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  inputEmbedDim
  ffnDim
</span><a href="#local-6989586621679808705"><span class="hs-identifier hs-var">stackSpec</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679808706"><span class="hs-identifier hs-var">k</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey -&gt; StateDictKey -&gt; StateDictKey
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;layers.&quot;</span></span><span class="hs-special">)</span><span>
</span><span id="line-290"></span><span>        </span><span class="annot"><a href="#local-6989586621679808704"><span class="hs-identifier hs-var">stack</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SMBART"><span class="hs-identifier hs-var">SMBART</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">ModelSpec
  (TransformerStack
     'MBART
     numLayers
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     inputEmbedDim
     ffnDim)
-&gt; StateDictKey
-&gt; m (TransformerStack
        'MBART
        numLayers
        gradient
        device
        dataType
        headDim
        headEmbedDim
        embedDim
        inputEmbedDim
        ffnDim)
forall model (m :: * -&gt; *).
(HasStateDict model, MonadThrow m, MonadState StateDict m) =&gt;
ModelSpec model -&gt; StateDictKey -&gt; m model
</span><a href="Torch.GraduallyTyped.NN.Class.html#fromStateDict"><span class="hs-identifier hs-var">fromStateDict</span></a></span><span> </span><span class="annot"><span class="annottext">ModelSpec
  (TransformerStack
     'MBART
     numLayers
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     inputEmbedDim
     ffnDim)
TransformerStackSpec
  style
  numLayers
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  inputEmbedDim
  ffnDim
</span><a href="#local-6989586621679808705"><span class="hs-identifier hs-var">stackSpec</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679808706"><span class="hs-identifier hs-var">k</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey -&gt; StateDictKey -&gt; StateDictKey
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;layers.&quot;</span></span><span class="hs-special">)</span><span>
</span><span id="line-291"></span><span>        </span><span class="annot"><a href="#local-6989586621679808704"><span class="hs-identifier hs-var">stack</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SPegasus"><span class="hs-identifier hs-var">SPegasus</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">ModelSpec
  (TransformerStack
     'Pegasus
     numLayers
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     inputEmbedDim
     ffnDim)
-&gt; StateDictKey
-&gt; m (TransformerStack
        'Pegasus
        numLayers
        gradient
        device
        dataType
        headDim
        headEmbedDim
        embedDim
        inputEmbedDim
        ffnDim)
forall model (m :: * -&gt; *).
(HasStateDict model, MonadThrow m, MonadState StateDict m) =&gt;
ModelSpec model -&gt; StateDictKey -&gt; m model
</span><a href="Torch.GraduallyTyped.NN.Class.html#fromStateDict"><span class="hs-identifier hs-var">fromStateDict</span></a></span><span> </span><span class="annot"><span class="annottext">ModelSpec
  (TransformerStack
     'Pegasus
     numLayers
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     inputEmbedDim
     ffnDim)
TransformerStackSpec
  style
  numLayers
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  inputEmbedDim
  ffnDim
</span><a href="#local-6989586621679808705"><span class="hs-identifier hs-var">stackSpec</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679808706"><span class="hs-identifier hs-var">k</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey -&gt; StateDictKey -&gt; StateDictKey
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;layers.&quot;</span></span><span class="hs-special">)</span><span>
</span><span id="line-292"></span><span>        </span><span class="annot"><a href="#local-6989586621679808704"><span class="hs-identifier hs-var">stack</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SBERT"><span class="hs-identifier hs-var">SBERT</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">ModelSpec
  (TransformerStack
     'BERT
     numLayers
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     inputEmbedDim
     ffnDim)
-&gt; StateDictKey
-&gt; m (TransformerStack
        'BERT
        numLayers
        gradient
        device
        dataType
        headDim
        headEmbedDim
        embedDim
        inputEmbedDim
        ffnDim)
forall model (m :: * -&gt; *).
(HasStateDict model, MonadThrow m, MonadState StateDict m) =&gt;
ModelSpec model -&gt; StateDictKey -&gt; m model
</span><a href="Torch.GraduallyTyped.NN.Class.html#fromStateDict"><span class="hs-identifier hs-var">fromStateDict</span></a></span><span> </span><span class="annot"><span class="annottext">ModelSpec
  (TransformerStack
     'BERT
     numLayers
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     inputEmbedDim
     ffnDim)
TransformerStackSpec
  style
  numLayers
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  inputEmbedDim
  ffnDim
</span><a href="#local-6989586621679808705"><span class="hs-identifier hs-var">stackSpec</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679808706"><span class="hs-identifier hs-var">k</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey -&gt; StateDictKey -&gt; StateDictKey
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;encoder.layer.&quot;</span></span><span class="hs-special">)</span><span>
</span><span id="line-293"></span><span>        </span><span class="annot"><a href="#local-6989586621679808704"><span class="hs-identifier hs-var">stack</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SRoBERTa"><span class="hs-identifier hs-var">SRoBERTa</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">ModelSpec
  (TransformerStack
     'RoBERTa
     numLayers
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     inputEmbedDim
     ffnDim)
-&gt; StateDictKey
-&gt; m (TransformerStack
        'RoBERTa
        numLayers
        gradient
        device
        dataType
        headDim
        headEmbedDim
        embedDim
        inputEmbedDim
        ffnDim)
forall model (m :: * -&gt; *).
(HasStateDict model, MonadThrow m, MonadState StateDict m) =&gt;
ModelSpec model -&gt; StateDictKey -&gt; m model
</span><a href="Torch.GraduallyTyped.NN.Class.html#fromStateDict"><span class="hs-identifier hs-var">fromStateDict</span></a></span><span> </span><span class="annot"><span class="annottext">ModelSpec
  (TransformerStack
     'RoBERTa
     numLayers
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     inputEmbedDim
     ffnDim)
TransformerStackSpec
  style
  numLayers
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  inputEmbedDim
  ffnDim
</span><a href="#local-6989586621679808705"><span class="hs-identifier hs-var">stackSpec</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679808706"><span class="hs-identifier hs-var">k</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey -&gt; StateDictKey -&gt; StateDictKey
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;encoder.layer.&quot;</span></span><span class="hs-special">)</span><span>
</span><span id="line-294"></span><span>        </span><span class="annot"><a href="#local-6989586621679808704"><span class="hs-identifier hs-var">stack</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SGPT2"><span class="hs-identifier hs-var">SGPT2</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">m (TransformerStack
     style
     numLayers
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     inputEmbedDim
     ffnDim)
forall a. HasCallStack =&gt; a
</span><span class="hs-identifier hs-var">undefined</span></span><span>
</span><span id="line-295"></span><span>        </span><span id="local-6989586621679808703"><span class="annot"><span class="annottext">embedLayerNormSpec :: LayerNormSpec
  'WithBias gradient device dataType ('Shape '[inputEmbedDim])
</span><a href="#local-6989586621679808703"><span class="hs-identifier hs-var hs-var">embedLayerNormSpec</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">SHasBias 'WithBias
-&gt; SGradient gradient
-&gt; SDevice device
-&gt; SDataType dataType
-&gt; SShape ('Shape '[inputEmbedDim])
-&gt; Double
-&gt; LayerNormSpec
     'WithBias gradient device dataType ('Shape '[inputEmbedDim])
forall (hasBias :: HasBias) (gradient :: Gradient RequiresGradient)
       (device :: Device (DeviceType Nat)) (dataType :: DataType DType)
       (normalizedShape :: Shape [Dim (Name Symbol) (Size Nat)]).
SHasBias hasBias
-&gt; SGradient gradient
-&gt; SDevice device
-&gt; SDataType dataType
-&gt; SShape normalizedShape
-&gt; Double
-&gt; LayerNormSpec hasBias gradient device dataType normalizedShape
</span><a href="Torch.GraduallyTyped.NN.Normalization.html#LayerNormSpec"><span class="hs-identifier hs-var">LayerNormSpec</span></a></span><span> </span><span class="annot"><span class="annottext">SHasBias 'WithBias
</span><a href="Torch.GraduallyTyped.NN.Type.html#SWithBias"><span class="hs-identifier hs-var">SWithBias</span></a></span><span> </span><span class="annot"><span class="annottext">SGradient gradient
</span><a href="#local-6989586621679808717"><span class="hs-identifier hs-var">gradient</span></a></span><span> </span><span class="annot"><span class="annottext">SDevice device
</span><a href="#local-6989586621679808716"><span class="hs-identifier hs-var">device</span></a></span><span> </span><span class="annot"><span class="annottext">SDataType dataType
</span><a href="#local-6989586621679808715"><span class="hs-identifier hs-var">dataType</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SList '[inputEmbedDim] -&gt; SShape ('Shape '[inputEmbedDim])
forall (dims :: [Dim (Name Symbol) (Size Nat)]).
SList dims -&gt; SShape ('Shape dims)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SShape"><span class="hs-identifier hs-var">SShape</span></a></span><span> </span><span class="annot"><span class="annottext">(SList '[inputEmbedDim] -&gt; SShape ('Shape '[inputEmbedDim]))
-&gt; SList '[inputEmbedDim] -&gt; SShape ('Shape '[inputEmbedDim])
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">SDim inputEmbedDim
</span><a href="#local-6989586621679808711"><span class="hs-identifier hs-var">inputEmbedDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim inputEmbedDim -&gt; SList '[] -&gt; SList '[inputEmbedDim]
forall (dim :: Dim (Name Symbol) (Size Nat))
       (dims :: [Dim (Name Symbol) (Size Nat)]).
SDim dim -&gt; SList dims -&gt; SList (dim : dims)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%7C%3A"><span class="hs-operator hs-var">:|:</span></a></span><span> </span><span class="annot"><span class="annottext">SList '[]
forall a. SList '[]
</span><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-var">SNil</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">Double
</span><a href="#local-6989586621679808707"><span class="hs-identifier hs-var">eps</span></a></span><span>
</span><span id="line-296"></span><span>        </span><span id="local-6989586621679808702"><span class="annot"><span class="annottext">embedLayerNorm :: STransformerStyle style
-&gt; m (TEEmbedLayerNormF
        style gradient device dataType inputEmbedDim)
</span><a href="#local-6989586621679808702"><span class="hs-identifier hs-var hs-var">embedLayerNorm</span></a></span></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#ST5"><span class="hs-identifier hs-var">ST5</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">ModelSpec () -&gt; StateDictKey -&gt; m ()
forall model (m :: * -&gt; *).
(HasStateDict model, MonadThrow m, MonadState StateDict m) =&gt;
ModelSpec model -&gt; StateDictKey -&gt; m model
</span><a href="Torch.GraduallyTyped.NN.Class.html#fromStateDict"><span class="hs-identifier hs-var">fromStateDict</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679808706"><span class="hs-identifier hs-var">k</span></a></span><span>
</span><span id="line-297"></span><span>        </span><span class="annot"><a href="#local-6989586621679808702"><span class="hs-identifier hs-var">embedLayerNorm</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SByT5"><span class="hs-identifier hs-var">SByT5</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">ModelSpec () -&gt; StateDictKey -&gt; m ()
forall model (m :: * -&gt; *).
(HasStateDict model, MonadThrow m, MonadState StateDict m) =&gt;
ModelSpec model -&gt; StateDictKey -&gt; m model
</span><a href="Torch.GraduallyTyped.NN.Class.html#fromStateDict"><span class="hs-identifier hs-var">fromStateDict</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679808706"><span class="hs-identifier hs-var">k</span></a></span><span>
</span><span id="line-298"></span><span>        </span><span class="annot"><a href="#local-6989586621679808702"><span class="hs-identifier hs-var">embedLayerNorm</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SBART"><span class="hs-identifier hs-var">SBART</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">ModelSpec
  (LayerNorm
     'WithBias gradient device dataType ('Shape '[inputEmbedDim]))
-&gt; StateDictKey
-&gt; m (LayerNorm
        'WithBias gradient device dataType ('Shape '[inputEmbedDim]))
forall model (m :: * -&gt; *).
(HasStateDict model, MonadThrow m, MonadState StateDict m) =&gt;
ModelSpec model -&gt; StateDictKey -&gt; m model
</span><a href="Torch.GraduallyTyped.NN.Class.html#fromStateDict"><span class="hs-identifier hs-var">fromStateDict</span></a></span><span> </span><span class="annot"><span class="annottext">ModelSpec
  (LayerNorm
     'WithBias gradient device dataType ('Shape '[inputEmbedDim]))
LayerNormSpec
  'WithBias gradient device dataType ('Shape '[inputEmbedDim])
</span><a href="#local-6989586621679808703"><span class="hs-identifier hs-var">embedLayerNormSpec</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679808706"><span class="hs-identifier hs-var">k</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey -&gt; StateDictKey -&gt; StateDictKey
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;layernorm_embedding.&quot;</span></span><span class="hs-special">)</span><span>
</span><span id="line-299"></span><span>        </span><span class="annot"><a href="#local-6989586621679808702"><span class="hs-identifier hs-var">embedLayerNorm</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SMBART"><span class="hs-identifier hs-var">SMBART</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">ModelSpec
  (LayerNorm
     'WithBias gradient device dataType ('Shape '[inputEmbedDim]))
-&gt; StateDictKey
-&gt; m (LayerNorm
        'WithBias gradient device dataType ('Shape '[inputEmbedDim]))
forall model (m :: * -&gt; *).
(HasStateDict model, MonadThrow m, MonadState StateDict m) =&gt;
ModelSpec model -&gt; StateDictKey -&gt; m model
</span><a href="Torch.GraduallyTyped.NN.Class.html#fromStateDict"><span class="hs-identifier hs-var">fromStateDict</span></a></span><span> </span><span class="annot"><span class="annottext">ModelSpec
  (LayerNorm
     'WithBias gradient device dataType ('Shape '[inputEmbedDim]))
LayerNormSpec
  'WithBias gradient device dataType ('Shape '[inputEmbedDim])
</span><a href="#local-6989586621679808703"><span class="hs-identifier hs-var">embedLayerNormSpec</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679808706"><span class="hs-identifier hs-var">k</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey -&gt; StateDictKey -&gt; StateDictKey
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;layernorm_embedding.&quot;</span></span><span class="hs-special">)</span><span>
</span><span id="line-300"></span><span>        </span><span class="annot"><a href="#local-6989586621679808702"><span class="hs-identifier hs-var">embedLayerNorm</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SPegasus"><span class="hs-identifier hs-var">SPegasus</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">ModelSpec () -&gt; StateDictKey -&gt; m ()
forall model (m :: * -&gt; *).
(HasStateDict model, MonadThrow m, MonadState StateDict m) =&gt;
ModelSpec model -&gt; StateDictKey -&gt; m model
</span><a href="Torch.GraduallyTyped.NN.Class.html#fromStateDict"><span class="hs-identifier hs-var">fromStateDict</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679808706"><span class="hs-identifier hs-var">k</span></a></span><span>
</span><span id="line-301"></span><span>        </span><span class="annot"><a href="#local-6989586621679808702"><span class="hs-identifier hs-var">embedLayerNorm</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SBERT"><span class="hs-identifier hs-var">SBERT</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">ModelSpec
  (LayerNorm
     'WithBias gradient device dataType ('Shape '[inputEmbedDim]))
-&gt; StateDictKey
-&gt; m (LayerNorm
        'WithBias gradient device dataType ('Shape '[inputEmbedDim]))
forall model (m :: * -&gt; *).
(HasStateDict model, MonadThrow m, MonadState StateDict m) =&gt;
ModelSpec model -&gt; StateDictKey -&gt; m model
</span><a href="Torch.GraduallyTyped.NN.Class.html#fromStateDict"><span class="hs-identifier hs-var">fromStateDict</span></a></span><span> </span><span class="annot"><span class="annottext">ModelSpec
  (LayerNorm
     'WithBias gradient device dataType ('Shape '[inputEmbedDim]))
LayerNormSpec
  'WithBias gradient device dataType ('Shape '[inputEmbedDim])
</span><a href="#local-6989586621679808703"><span class="hs-identifier hs-var">embedLayerNormSpec</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679808706"><span class="hs-identifier hs-var">k</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey -&gt; StateDictKey -&gt; StateDictKey
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;embeddings.LayerNorm.&quot;</span></span><span class="hs-special">)</span><span>
</span><span id="line-302"></span><span>        </span><span class="annot"><a href="#local-6989586621679808702"><span class="hs-identifier hs-var">embedLayerNorm</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SRoBERTa"><span class="hs-identifier hs-var">SRoBERTa</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">ModelSpec
  (LayerNorm
     'WithBias gradient device dataType ('Shape '[inputEmbedDim]))
-&gt; StateDictKey
-&gt; m (LayerNorm
        'WithBias gradient device dataType ('Shape '[inputEmbedDim]))
forall model (m :: * -&gt; *).
(HasStateDict model, MonadThrow m, MonadState StateDict m) =&gt;
ModelSpec model -&gt; StateDictKey -&gt; m model
</span><a href="Torch.GraduallyTyped.NN.Class.html#fromStateDict"><span class="hs-identifier hs-var">fromStateDict</span></a></span><span> </span><span class="annot"><span class="annottext">ModelSpec
  (LayerNorm
     'WithBias gradient device dataType ('Shape '[inputEmbedDim]))
LayerNormSpec
  'WithBias gradient device dataType ('Shape '[inputEmbedDim])
</span><a href="#local-6989586621679808703"><span class="hs-identifier hs-var">embedLayerNormSpec</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679808706"><span class="hs-identifier hs-var">k</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey -&gt; StateDictKey -&gt; StateDictKey
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;embeddings.LayerNorm.&quot;</span></span><span class="hs-special">)</span><span>
</span><span id="line-303"></span><span>        </span><span class="annot"><a href="#local-6989586621679808702"><span class="hs-identifier hs-var">embedLayerNorm</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SGPT2"><span class="hs-identifier hs-var">SGPT2</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">m (TEEmbedLayerNormF style gradient device dataType inputEmbedDim)
forall a. HasCallStack =&gt; a
</span><span class="hs-identifier hs-var">undefined</span></span><span>
</span><span id="line-304"></span><span>        </span><span id="local-6989586621679808701"><span class="annot"><span class="annottext">layerNormWithoutBiasSpec :: LayerNormSpec
  'WithoutBias gradient device dataType ('Shape '[inputEmbedDim])
</span><a href="#local-6989586621679808701"><span class="hs-identifier hs-var hs-var">layerNormWithoutBiasSpec</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">SHasBias 'WithoutBias
-&gt; SGradient gradient
-&gt; SDevice device
-&gt; SDataType dataType
-&gt; SShape ('Shape '[inputEmbedDim])
-&gt; Double
-&gt; LayerNormSpec
     'WithoutBias gradient device dataType ('Shape '[inputEmbedDim])
forall (hasBias :: HasBias) (gradient :: Gradient RequiresGradient)
       (device :: Device (DeviceType Nat)) (dataType :: DataType DType)
       (normalizedShape :: Shape [Dim (Name Symbol) (Size Nat)]).
SHasBias hasBias
-&gt; SGradient gradient
-&gt; SDevice device
-&gt; SDataType dataType
-&gt; SShape normalizedShape
-&gt; Double
-&gt; LayerNormSpec hasBias gradient device dataType normalizedShape
</span><a href="Torch.GraduallyTyped.NN.Normalization.html#LayerNormSpec"><span class="hs-identifier hs-var">LayerNormSpec</span></a></span><span> </span><span class="annot"><span class="annottext">SHasBias 'WithoutBias
</span><a href="Torch.GraduallyTyped.NN.Type.html#SWithoutBias"><span class="hs-identifier hs-var">SWithoutBias</span></a></span><span> </span><span class="annot"><span class="annottext">SGradient gradient
</span><a href="#local-6989586621679808717"><span class="hs-identifier hs-var">gradient</span></a></span><span> </span><span class="annot"><span class="annottext">SDevice device
</span><a href="#local-6989586621679808716"><span class="hs-identifier hs-var">device</span></a></span><span> </span><span class="annot"><span class="annottext">SDataType dataType
</span><a href="#local-6989586621679808715"><span class="hs-identifier hs-var">dataType</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SList '[inputEmbedDim] -&gt; SShape ('Shape '[inputEmbedDim])
forall (dims :: [Dim (Name Symbol) (Size Nat)]).
SList dims -&gt; SShape ('Shape dims)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SShape"><span class="hs-identifier hs-var">SShape</span></a></span><span> </span><span class="annot"><span class="annottext">(SList '[inputEmbedDim] -&gt; SShape ('Shape '[inputEmbedDim]))
-&gt; SList '[inputEmbedDim] -&gt; SShape ('Shape '[inputEmbedDim])
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">SDim inputEmbedDim
</span><a href="#local-6989586621679808711"><span class="hs-identifier hs-var">inputEmbedDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim inputEmbedDim -&gt; SList '[] -&gt; SList '[inputEmbedDim]
forall (dim :: Dim (Name Symbol) (Size Nat))
       (dims :: [Dim (Name Symbol) (Size Nat)]).
SDim dim -&gt; SList dims -&gt; SList (dim : dims)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%7C%3A"><span class="hs-operator hs-var">:|:</span></a></span><span> </span><span class="annot"><span class="annottext">SList '[]
forall a. SList '[]
</span><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-var">SNil</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">Double
</span><a href="#local-6989586621679808707"><span class="hs-identifier hs-var">eps</span></a></span><span>
</span><span id="line-305"></span><span>        </span><span id="local-6989586621679808700"><span class="annot"><span class="annottext">layerNormWithBiasSpec :: LayerNormSpec
  'WithBias gradient device dataType ('Shape '[inputEmbedDim])
</span><a href="#local-6989586621679808700"><span class="hs-identifier hs-var hs-var">layerNormWithBiasSpec</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">SHasBias 'WithBias
-&gt; SGradient gradient
-&gt; SDevice device
-&gt; SDataType dataType
-&gt; SShape ('Shape '[inputEmbedDim])
-&gt; Double
-&gt; LayerNormSpec
     'WithBias gradient device dataType ('Shape '[inputEmbedDim])
forall (hasBias :: HasBias) (gradient :: Gradient RequiresGradient)
       (device :: Device (DeviceType Nat)) (dataType :: DataType DType)
       (normalizedShape :: Shape [Dim (Name Symbol) (Size Nat)]).
SHasBias hasBias
-&gt; SGradient gradient
-&gt; SDevice device
-&gt; SDataType dataType
-&gt; SShape normalizedShape
-&gt; Double
-&gt; LayerNormSpec hasBias gradient device dataType normalizedShape
</span><a href="Torch.GraduallyTyped.NN.Normalization.html#LayerNormSpec"><span class="hs-identifier hs-var">LayerNormSpec</span></a></span><span> </span><span class="annot"><span class="annottext">SHasBias 'WithBias
</span><a href="Torch.GraduallyTyped.NN.Type.html#SWithBias"><span class="hs-identifier hs-var">SWithBias</span></a></span><span> </span><span class="annot"><span class="annottext">SGradient gradient
</span><a href="#local-6989586621679808717"><span class="hs-identifier hs-var">gradient</span></a></span><span> </span><span class="annot"><span class="annottext">SDevice device
</span><a href="#local-6989586621679808716"><span class="hs-identifier hs-var">device</span></a></span><span> </span><span class="annot"><span class="annottext">SDataType dataType
</span><a href="#local-6989586621679808715"><span class="hs-identifier hs-var">dataType</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SList '[inputEmbedDim] -&gt; SShape ('Shape '[inputEmbedDim])
forall (dims :: [Dim (Name Symbol) (Size Nat)]).
SList dims -&gt; SShape ('Shape dims)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SShape"><span class="hs-identifier hs-var">SShape</span></a></span><span> </span><span class="annot"><span class="annottext">(SList '[inputEmbedDim] -&gt; SShape ('Shape '[inputEmbedDim]))
-&gt; SList '[inputEmbedDim] -&gt; SShape ('Shape '[inputEmbedDim])
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">SDim inputEmbedDim
</span><a href="#local-6989586621679808711"><span class="hs-identifier hs-var">inputEmbedDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim inputEmbedDim -&gt; SList '[] -&gt; SList '[inputEmbedDim]
forall (dim :: Dim (Name Symbol) (Size Nat))
       (dims :: [Dim (Name Symbol) (Size Nat)]).
SDim dim -&gt; SList dims -&gt; SList (dim : dims)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%7C%3A"><span class="hs-operator hs-var">:|:</span></a></span><span> </span><span class="annot"><span class="annottext">SList '[]
forall a. SList '[]
</span><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-var">SNil</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">Double
</span><a href="#local-6989586621679808707"><span class="hs-identifier hs-var">eps</span></a></span><span>
</span><span id="line-306"></span><span>        </span><span id="local-6989586621679808699"><span class="annot"><span class="annottext">layerNorm :: STransformerStyle style
-&gt; m (TELayerNormF style gradient device dataType inputEmbedDim)
</span><a href="#local-6989586621679808699"><span class="hs-identifier hs-var hs-var">layerNorm</span></a></span></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#ST5"><span class="hs-identifier hs-var">ST5</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">ModelSpec
  (LayerNorm
     'WithoutBias gradient device dataType ('Shape '[inputEmbedDim]))
-&gt; StateDictKey
-&gt; m (LayerNorm
        'WithoutBias gradient device dataType ('Shape '[inputEmbedDim]))
forall model (m :: * -&gt; *).
(HasStateDict model, MonadThrow m, MonadState StateDict m) =&gt;
ModelSpec model -&gt; StateDictKey -&gt; m model
</span><a href="Torch.GraduallyTyped.NN.Class.html#fromStateDict"><span class="hs-identifier hs-var">fromStateDict</span></a></span><span> </span><span class="annot"><span class="annottext">ModelSpec
  (LayerNorm
     'WithoutBias gradient device dataType ('Shape '[inputEmbedDim]))
LayerNormSpec
  'WithoutBias gradient device dataType ('Shape '[inputEmbedDim])
</span><a href="#local-6989586621679808701"><span class="hs-identifier hs-var">layerNormWithoutBiasSpec</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679808706"><span class="hs-identifier hs-var">k</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey -&gt; StateDictKey -&gt; StateDictKey
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;final_layer_norm.&quot;</span></span><span class="hs-special">)</span><span>
</span><span id="line-307"></span><span>        </span><span class="annot"><a href="#local-6989586621679808699"><span class="hs-identifier hs-var">layerNorm</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SByT5"><span class="hs-identifier hs-var">SByT5</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">ModelSpec
  (LayerNorm
     'WithoutBias gradient device dataType ('Shape '[inputEmbedDim]))
-&gt; StateDictKey
-&gt; m (LayerNorm
        'WithoutBias gradient device dataType ('Shape '[inputEmbedDim]))
forall model (m :: * -&gt; *).
(HasStateDict model, MonadThrow m, MonadState StateDict m) =&gt;
ModelSpec model -&gt; StateDictKey -&gt; m model
</span><a href="Torch.GraduallyTyped.NN.Class.html#fromStateDict"><span class="hs-identifier hs-var">fromStateDict</span></a></span><span> </span><span class="annot"><span class="annottext">ModelSpec
  (LayerNorm
     'WithoutBias gradient device dataType ('Shape '[inputEmbedDim]))
LayerNormSpec
  'WithoutBias gradient device dataType ('Shape '[inputEmbedDim])
</span><a href="#local-6989586621679808701"><span class="hs-identifier hs-var">layerNormWithoutBiasSpec</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679808706"><span class="hs-identifier hs-var">k</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey -&gt; StateDictKey -&gt; StateDictKey
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;final_layer_norm.&quot;</span></span><span class="hs-special">)</span><span>
</span><span id="line-308"></span><span>        </span><span class="annot"><a href="#local-6989586621679808699"><span class="hs-identifier hs-var">layerNorm</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SBART"><span class="hs-identifier hs-var">SBART</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">ModelSpec () -&gt; StateDictKey -&gt; m ()
forall model (m :: * -&gt; *).
(HasStateDict model, MonadThrow m, MonadState StateDict m) =&gt;
ModelSpec model -&gt; StateDictKey -&gt; m model
</span><a href="Torch.GraduallyTyped.NN.Class.html#fromStateDict"><span class="hs-identifier hs-var">fromStateDict</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679808706"><span class="hs-identifier hs-var">k</span></a></span><span>
</span><span id="line-309"></span><span>        </span><span class="annot"><a href="#local-6989586621679808699"><span class="hs-identifier hs-var">layerNorm</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SMBART"><span class="hs-identifier hs-var">SMBART</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">ModelSpec () -&gt; StateDictKey -&gt; m ()
forall model (m :: * -&gt; *).
(HasStateDict model, MonadThrow m, MonadState StateDict m) =&gt;
ModelSpec model -&gt; StateDictKey -&gt; m model
</span><a href="Torch.GraduallyTyped.NN.Class.html#fromStateDict"><span class="hs-identifier hs-var">fromStateDict</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679808706"><span class="hs-identifier hs-var">k</span></a></span><span>
</span><span id="line-310"></span><span>        </span><span class="annot"><a href="#local-6989586621679808699"><span class="hs-identifier hs-var">layerNorm</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SPegasus"><span class="hs-identifier hs-var">SPegasus</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">ModelSpec
  (LayerNorm
     'WithBias gradient device dataType ('Shape '[inputEmbedDim]))
-&gt; StateDictKey
-&gt; m (LayerNorm
        'WithBias gradient device dataType ('Shape '[inputEmbedDim]))
forall model (m :: * -&gt; *).
(HasStateDict model, MonadThrow m, MonadState StateDict m) =&gt;
ModelSpec model -&gt; StateDictKey -&gt; m model
</span><a href="Torch.GraduallyTyped.NN.Class.html#fromStateDict"><span class="hs-identifier hs-var">fromStateDict</span></a></span><span> </span><span class="annot"><span class="annottext">ModelSpec
  (LayerNorm
     'WithBias gradient device dataType ('Shape '[inputEmbedDim]))
LayerNormSpec
  'WithBias gradient device dataType ('Shape '[inputEmbedDim])
</span><a href="#local-6989586621679808700"><span class="hs-identifier hs-var">layerNormWithBiasSpec</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679808706"><span class="hs-identifier hs-var">k</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey -&gt; StateDictKey -&gt; StateDictKey
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;layer_norm.&quot;</span></span><span class="hs-special">)</span><span>
</span><span id="line-311"></span><span>        </span><span class="annot"><a href="#local-6989586621679808699"><span class="hs-identifier hs-var">layerNorm</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SBERT"><span class="hs-identifier hs-var">SBERT</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">ModelSpec () -&gt; StateDictKey -&gt; m ()
forall model (m :: * -&gt; *).
(HasStateDict model, MonadThrow m, MonadState StateDict m) =&gt;
ModelSpec model -&gt; StateDictKey -&gt; m model
</span><a href="Torch.GraduallyTyped.NN.Class.html#fromStateDict"><span class="hs-identifier hs-var">fromStateDict</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679808706"><span class="hs-identifier hs-var">k</span></a></span><span>
</span><span id="line-312"></span><span>        </span><span class="annot"><a href="#local-6989586621679808699"><span class="hs-identifier hs-var">layerNorm</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SRoBERTa"><span class="hs-identifier hs-var">SRoBERTa</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">ModelSpec () -&gt; StateDictKey -&gt; m ()
forall model (m :: * -&gt; *).
(HasStateDict model, MonadThrow m, MonadState StateDict m) =&gt;
ModelSpec model -&gt; StateDictKey -&gt; m model
</span><a href="Torch.GraduallyTyped.NN.Class.html#fromStateDict"><span class="hs-identifier hs-var">fromStateDict</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679808706"><span class="hs-identifier hs-var">k</span></a></span><span>
</span><span id="line-313"></span><span>        </span><span class="annot"><a href="#local-6989586621679808699"><span class="hs-identifier hs-var">layerNorm</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SGPT2"><span class="hs-identifier hs-var">SGPT2</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">m (TELayerNormF style gradient device dataType inputEmbedDim)
forall a. HasCallStack =&gt; a
</span><span class="hs-identifier hs-var">undefined</span></span><span>
</span><span id="line-314"></span><span>        </span><span id="local-6989586621679808698"><span class="annot"><span class="annottext">dropout :: STransformerStyle style -&gt; m Dropout
</span><a href="#local-6989586621679808698"><span class="hs-identifier hs-var hs-var">dropout</span></a></span></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><span class="hs-identifier">_</span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">ModelSpec Dropout -&gt; StateDictKey -&gt; m Dropout
forall model (m :: * -&gt; *).
(HasStateDict model, MonadThrow m, MonadState StateDict m) =&gt;
ModelSpec model -&gt; StateDictKey -&gt; m model
</span><a href="Torch.GraduallyTyped.NN.Class.html#fromStateDict"><span class="hs-identifier hs-var">fromStateDict</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">Double -&gt; Dropout
</span><a href="Torch.GraduallyTyped.NN.Dropout.html#Dropout"><span class="hs-identifier hs-var">Dropout</span></a></span><span> </span><span class="annot"><span class="annottext">Double
</span><a href="#local-6989586621679808708"><span class="hs-identifier hs-var">dropoutP</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679808706"><span class="hs-identifier hs-var">k</span></a></span><span>
</span><span id="line-315"></span><span>        </span><span id="local-6989586621679808697"><span class="annot"><span class="annottext">relPosEncSpec :: EmbeddingSpec
  gradient
  ('Layout 'Dense)
  device
  dataType
  posEncDim
  headDim
  'Nothing
</span><a href="#local-6989586621679808697"><span class="hs-identifier hs-var hs-var">relPosEncSpec</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">SGradient gradient
-&gt; SLayout ('Layout 'Dense)
-&gt; SDevice device
-&gt; SDataType dataType
-&gt; SDim posEncDim
-&gt; SDim headDim
-&gt; SMaybe 'Nothing
-&gt; EmbeddingSpec
     gradient
     ('Layout 'Dense)
     device
     dataType
     posEncDim
     headDim
     'Nothing
forall (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (embedNumDim :: Dim (Name Symbol) (Size Nat))
       (embedDim :: Dim (Name Symbol) (Size Nat))
       (paddingIdx :: Maybe Nat).
SGradient gradient
-&gt; SLayout layout
-&gt; SDevice device
-&gt; SDataType dataType
-&gt; SDim embedNumDim
-&gt; SDim embedDim
-&gt; SMaybe paddingIdx
-&gt; EmbeddingSpec
     gradient layout device dataType embedNumDim embedDim paddingIdx
</span><a href="Torch.GraduallyTyped.NN.Sparse.html#EmbeddingSpec"><span class="hs-identifier hs-var">EmbeddingSpec</span></a></span><span> </span><span class="annot"><span class="annottext">SGradient gradient
</span><a href="#local-6989586621679808717"><span class="hs-identifier hs-var">gradient</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SLayoutType 'Dense -&gt; SLayout ('Layout 'Dense)
forall (layoutType :: LayoutType).
SLayoutType layoutType -&gt; SLayout ('Layout layoutType)
</span><a href="Torch.GraduallyTyped.Layout.html#SLayout"><span class="hs-identifier hs-var">SLayout</span></a></span><span> </span><span class="annot"><span class="annottext">SLayoutType 'Dense
</span><a href="Torch.GraduallyTyped.Layout.html#SDense"><span class="hs-identifier hs-var">SDense</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">SDevice device
</span><a href="#local-6989586621679808716"><span class="hs-identifier hs-var">device</span></a></span><span> </span><span class="annot"><span class="annottext">SDataType dataType
</span><a href="#local-6989586621679808715"><span class="hs-identifier hs-var">dataType</span></a></span><span> </span><span class="annot"><span class="annottext">SDim posEncDim
</span><a href="#local-6989586621679808709"><span class="hs-identifier hs-var">posEncDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim headDim
</span><a href="#local-6989586621679808714"><span class="hs-identifier hs-var">headDim</span></a></span><span> </span><span class="annot"><span class="annottext">SMaybe 'Nothing
forall a. SMaybe 'Nothing
</span><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-var">SNothing</span></a></span><span>
</span><span id="line-316"></span><span>        </span><span id="local-6989586621679808696"><span class="annot"><span class="annottext">posEncSpec :: EmbeddingSpec
  gradient
  ('Layout 'Dense)
  device
  dataType
  posEncDim
  inputEmbedDim
  'Nothing
</span><a href="#local-6989586621679808696"><span class="hs-identifier hs-var hs-var">posEncSpec</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">SGradient gradient
-&gt; SLayout ('Layout 'Dense)
-&gt; SDevice device
-&gt; SDataType dataType
-&gt; SDim posEncDim
-&gt; SDim inputEmbedDim
-&gt; SMaybe 'Nothing
-&gt; EmbeddingSpec
     gradient
     ('Layout 'Dense)
     device
     dataType
     posEncDim
     inputEmbedDim
     'Nothing
forall (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (embedNumDim :: Dim (Name Symbol) (Size Nat))
       (embedDim :: Dim (Name Symbol) (Size Nat))
       (paddingIdx :: Maybe Nat).
SGradient gradient
-&gt; SLayout layout
-&gt; SDevice device
-&gt; SDataType dataType
-&gt; SDim embedNumDim
-&gt; SDim embedDim
-&gt; SMaybe paddingIdx
-&gt; EmbeddingSpec
     gradient layout device dataType embedNumDim embedDim paddingIdx
</span><a href="Torch.GraduallyTyped.NN.Sparse.html#EmbeddingSpec"><span class="hs-identifier hs-var">EmbeddingSpec</span></a></span><span> </span><span class="annot"><span class="annottext">SGradient gradient
</span><a href="#local-6989586621679808717"><span class="hs-identifier hs-var">gradient</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SLayoutType 'Dense -&gt; SLayout ('Layout 'Dense)
forall (layoutType :: LayoutType).
SLayoutType layoutType -&gt; SLayout ('Layout layoutType)
</span><a href="Torch.GraduallyTyped.Layout.html#SLayout"><span class="hs-identifier hs-var">SLayout</span></a></span><span> </span><span class="annot"><span class="annottext">SLayoutType 'Dense
</span><a href="Torch.GraduallyTyped.Layout.html#SDense"><span class="hs-identifier hs-var">SDense</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">SDevice device
</span><a href="#local-6989586621679808716"><span class="hs-identifier hs-var">device</span></a></span><span> </span><span class="annot"><span class="annottext">SDataType dataType
</span><a href="#local-6989586621679808715"><span class="hs-identifier hs-var">dataType</span></a></span><span> </span><span class="annot"><span class="annottext">SDim posEncDim
</span><a href="#local-6989586621679808709"><span class="hs-identifier hs-var">posEncDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim inputEmbedDim
</span><a href="#local-6989586621679808711"><span class="hs-identifier hs-var">inputEmbedDim</span></a></span><span> </span><span class="annot"><span class="annottext">SMaybe 'Nothing
forall a. SMaybe 'Nothing
</span><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-var">SNothing</span></a></span><span>
</span><span id="line-317"></span><span>        </span><span id="local-6989586621679808695"><span class="annot"><span class="annottext">posEnc :: STransformerStyle style
-&gt; m (TEPosEncF
        style gradient device dataType headDim inputEmbedDim posEncDim)
</span><a href="#local-6989586621679808695"><span class="hs-identifier hs-var hs-var">posEnc</span></a></span></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#ST5"><span class="hs-identifier hs-var">ST5</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">ModelSpec
  (Embedding
     gradient
     ('Layout 'Dense)
     device
     dataType
     posEncDim
     headDim
     'Nothing)
-&gt; StateDictKey
-&gt; m (Embedding
        gradient
        ('Layout 'Dense)
        device
        dataType
        posEncDim
        headDim
        'Nothing)
forall model (m :: * -&gt; *).
(HasStateDict model, MonadThrow m, MonadState StateDict m) =&gt;
ModelSpec model -&gt; StateDictKey -&gt; m model
</span><a href="Torch.GraduallyTyped.NN.Class.html#fromStateDict"><span class="hs-identifier hs-var">fromStateDict</span></a></span><span> </span><span class="annot"><span class="annottext">ModelSpec
  (Embedding
     gradient
     ('Layout 'Dense)
     device
     dataType
     posEncDim
     headDim
     'Nothing)
EmbeddingSpec
  gradient
  ('Layout 'Dense)
  device
  dataType
  posEncDim
  headDim
  'Nothing
</span><a href="#local-6989586621679808697"><span class="hs-identifier hs-var">relPosEncSpec</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679808706"><span class="hs-identifier hs-var">k</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey -&gt; StateDictKey -&gt; StateDictKey
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;block.0.layer.0.SelfAttention.relative_attention_bias.&quot;</span></span><span class="hs-special">)</span><span>
</span><span id="line-318"></span><span>        </span><span class="annot"><a href="#local-6989586621679808695"><span class="hs-identifier hs-var">posEnc</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SByT5"><span class="hs-identifier hs-var">SByT5</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">ModelSpec
  (Embedding
     gradient
     ('Layout 'Dense)
     device
     dataType
     posEncDim
     headDim
     'Nothing)
-&gt; StateDictKey
-&gt; m (Embedding
        gradient
        ('Layout 'Dense)
        device
        dataType
        posEncDim
        headDim
        'Nothing)
forall model (m :: * -&gt; *).
(HasStateDict model, MonadThrow m, MonadState StateDict m) =&gt;
ModelSpec model -&gt; StateDictKey -&gt; m model
</span><a href="Torch.GraduallyTyped.NN.Class.html#fromStateDict"><span class="hs-identifier hs-var">fromStateDict</span></a></span><span> </span><span class="annot"><span class="annottext">ModelSpec
  (Embedding
     gradient
     ('Layout 'Dense)
     device
     dataType
     posEncDim
     headDim
     'Nothing)
EmbeddingSpec
  gradient
  ('Layout 'Dense)
  device
  dataType
  posEncDim
  headDim
  'Nothing
</span><a href="#local-6989586621679808697"><span class="hs-identifier hs-var">relPosEncSpec</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679808706"><span class="hs-identifier hs-var">k</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey -&gt; StateDictKey -&gt; StateDictKey
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;block.0.layer.0.SelfAttention.relative_attention_bias.&quot;</span></span><span class="hs-special">)</span><span>
</span><span id="line-319"></span><span>        </span><span class="annot"><a href="#local-6989586621679808695"><span class="hs-identifier hs-var">posEnc</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SBART"><span class="hs-identifier hs-var">SBART</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">ModelSpec
  (Embedding
     gradient
     ('Layout 'Dense)
     device
     dataType
     posEncDim
     inputEmbedDim
     'Nothing)
-&gt; StateDictKey
-&gt; m (Embedding
        gradient
        ('Layout 'Dense)
        device
        dataType
        posEncDim
        inputEmbedDim
        'Nothing)
forall model (m :: * -&gt; *).
(HasStateDict model, MonadThrow m, MonadState StateDict m) =&gt;
ModelSpec model -&gt; StateDictKey -&gt; m model
</span><a href="Torch.GraduallyTyped.NN.Class.html#fromStateDict"><span class="hs-identifier hs-var">fromStateDict</span></a></span><span> </span><span class="annot"><span class="annottext">ModelSpec
  (Embedding
     gradient
     ('Layout 'Dense)
     device
     dataType
     posEncDim
     inputEmbedDim
     'Nothing)
EmbeddingSpec
  gradient
  ('Layout 'Dense)
  device
  dataType
  posEncDim
  inputEmbedDim
  'Nothing
</span><a href="#local-6989586621679808696"><span class="hs-identifier hs-var">posEncSpec</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679808706"><span class="hs-identifier hs-var">k</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey -&gt; StateDictKey -&gt; StateDictKey
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;embed_positions.&quot;</span></span><span class="hs-special">)</span><span>
</span><span id="line-320"></span><span>        </span><span class="annot"><a href="#local-6989586621679808695"><span class="hs-identifier hs-var">posEnc</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SMBART"><span class="hs-identifier hs-var">SMBART</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">ModelSpec
  (Embedding
     gradient
     ('Layout 'Dense)
     device
     dataType
     posEncDim
     inputEmbedDim
     'Nothing)
-&gt; StateDictKey
-&gt; m (Embedding
        gradient
        ('Layout 'Dense)
        device
        dataType
        posEncDim
        inputEmbedDim
        'Nothing)
forall model (m :: * -&gt; *).
(HasStateDict model, MonadThrow m, MonadState StateDict m) =&gt;
ModelSpec model -&gt; StateDictKey -&gt; m model
</span><a href="Torch.GraduallyTyped.NN.Class.html#fromStateDict"><span class="hs-identifier hs-var">fromStateDict</span></a></span><span> </span><span class="annot"><span class="annottext">ModelSpec
  (Embedding
     gradient
     ('Layout 'Dense)
     device
     dataType
     posEncDim
     inputEmbedDim
     'Nothing)
EmbeddingSpec
  gradient
  ('Layout 'Dense)
  device
  dataType
  posEncDim
  inputEmbedDim
  'Nothing
</span><a href="#local-6989586621679808696"><span class="hs-identifier hs-var">posEncSpec</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679808706"><span class="hs-identifier hs-var">k</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey -&gt; StateDictKey -&gt; StateDictKey
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;embed_positions.&quot;</span></span><span class="hs-special">)</span><span>
</span><span id="line-321"></span><span>        </span><span class="annot"><a href="#local-6989586621679808695"><span class="hs-identifier hs-var">posEnc</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SPegasus"><span class="hs-identifier hs-var">SPegasus</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">ModelSpec
  (Embedding
     gradient
     ('Layout 'Dense)
     device
     dataType
     posEncDim
     inputEmbedDim
     'Nothing)
-&gt; StateDictKey
-&gt; m (Embedding
        gradient
        ('Layout 'Dense)
        device
        dataType
        posEncDim
        inputEmbedDim
        'Nothing)
forall model (m :: * -&gt; *).
(HasStateDict model, MonadThrow m, MonadState StateDict m) =&gt;
ModelSpec model -&gt; StateDictKey -&gt; m model
</span><a href="Torch.GraduallyTyped.NN.Class.html#fromStateDict"><span class="hs-identifier hs-var">fromStateDict</span></a></span><span> </span><span class="annot"><span class="annottext">ModelSpec
  (Embedding
     gradient
     ('Layout 'Dense)
     device
     dataType
     posEncDim
     inputEmbedDim
     'Nothing)
EmbeddingSpec
  gradient
  ('Layout 'Dense)
  device
  dataType
  posEncDim
  inputEmbedDim
  'Nothing
</span><a href="#local-6989586621679808696"><span class="hs-identifier hs-var">posEncSpec</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679808706"><span class="hs-identifier hs-var">k</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey -&gt; StateDictKey -&gt; StateDictKey
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;embed_positions.&quot;</span></span><span class="hs-special">)</span><span>
</span><span id="line-322"></span><span>        </span><span class="annot"><a href="#local-6989586621679808695"><span class="hs-identifier hs-var">posEnc</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SBERT"><span class="hs-identifier hs-var">SBERT</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">ModelSpec
  (Embedding
     gradient
     ('Layout 'Dense)
     device
     dataType
     posEncDim
     inputEmbedDim
     'Nothing)
-&gt; StateDictKey
-&gt; m (Embedding
        gradient
        ('Layout 'Dense)
        device
        dataType
        posEncDim
        inputEmbedDim
        'Nothing)
forall model (m :: * -&gt; *).
(HasStateDict model, MonadThrow m, MonadState StateDict m) =&gt;
ModelSpec model -&gt; StateDictKey -&gt; m model
</span><a href="Torch.GraduallyTyped.NN.Class.html#fromStateDict"><span class="hs-identifier hs-var">fromStateDict</span></a></span><span> </span><span class="annot"><span class="annottext">ModelSpec
  (Embedding
     gradient
     ('Layout 'Dense)
     device
     dataType
     posEncDim
     inputEmbedDim
     'Nothing)
EmbeddingSpec
  gradient
  ('Layout 'Dense)
  device
  dataType
  posEncDim
  inputEmbedDim
  'Nothing
</span><a href="#local-6989586621679808696"><span class="hs-identifier hs-var">posEncSpec</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679808706"><span class="hs-identifier hs-var">k</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey -&gt; StateDictKey -&gt; StateDictKey
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;embeddings.position_embeddings.&quot;</span></span><span class="hs-special">)</span><span>
</span><span id="line-323"></span><span>        </span><span class="annot"><a href="#local-6989586621679808695"><span class="hs-identifier hs-var">posEnc</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SRoBERTa"><span class="hs-identifier hs-var">SRoBERTa</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">ModelSpec
  (Embedding
     gradient
     ('Layout 'Dense)
     device
     dataType
     posEncDim
     inputEmbedDim
     'Nothing)
-&gt; StateDictKey
-&gt; m (Embedding
        gradient
        ('Layout 'Dense)
        device
        dataType
        posEncDim
        inputEmbedDim
        'Nothing)
forall model (m :: * -&gt; *).
(HasStateDict model, MonadThrow m, MonadState StateDict m) =&gt;
ModelSpec model -&gt; StateDictKey -&gt; m model
</span><a href="Torch.GraduallyTyped.NN.Class.html#fromStateDict"><span class="hs-identifier hs-var">fromStateDict</span></a></span><span> </span><span class="annot"><span class="annottext">ModelSpec
  (Embedding
     gradient
     ('Layout 'Dense)
     device
     dataType
     posEncDim
     inputEmbedDim
     'Nothing)
EmbeddingSpec
  gradient
  ('Layout 'Dense)
  device
  dataType
  posEncDim
  inputEmbedDim
  'Nothing
</span><a href="#local-6989586621679808696"><span class="hs-identifier hs-var">posEncSpec</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679808706"><span class="hs-identifier hs-var">k</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey -&gt; StateDictKey -&gt; StateDictKey
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;embeddings.position_embeddings.&quot;</span></span><span class="hs-special">)</span><span>
</span><span id="line-324"></span><span>        </span><span class="annot"><a href="#local-6989586621679808695"><span class="hs-identifier hs-var">posEnc</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SGPT2"><span class="hs-identifier hs-var">SGPT2</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">m (TEPosEncF
     style gradient device dataType headDim inputEmbedDim posEncDim)
forall a. HasCallStack =&gt; a
</span><span class="hs-identifier hs-var">undefined</span></span><span>
</span><span id="line-325"></span><span>     </span><span class="hs-keyword">in</span><span> </span><span class="annot"><span class="annottext">GTransformerEncoder
  (TransformerStack
     style
     numLayers
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     inputEmbedDim
     ffnDim)
  (TEEmbedLayerNormF style gradient device dataType inputEmbedDim)
  (TELayerNormF style gradient device dataType inputEmbedDim)
  Dropout
  (TEPosEncF
     style gradient device dataType headDim inputEmbedDim posEncDim)
-&gt; TransformerEncoder
     style
     numLayers
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     inputEmbedDim
     ffnDim
     posEncDim
forall (style :: TransformerStyle) (numLayers :: Nat)
       (gradient :: Gradient RequiresGradient)
       (device :: Device (DeviceType Nat)) (dataType :: DataType DType)
       (headDim :: Dim (Name Symbol) (Size Nat))
       (headEmbedDim :: Dim (Name Symbol) (Size Nat))
       (embedDim :: Dim (Name Symbol) (Size Nat))
       (inputEmbedDim :: Dim (Name Symbol) (Size Nat))
       (ffnDim :: Dim (Name Symbol) (Size Nat))
       (posEncDim :: Dim (Name Symbol) (Size Nat)).
GTransformerEncoder
  (TEStackF
     style
     numLayers
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     inputEmbedDim
     ffnDim)
  (TEEmbedLayerNormF style gradient device dataType inputEmbedDim)
  (TELayerNormF style gradient device dataType inputEmbedDim)
  (TEDropoutF style)
  (TEPosEncF
     style gradient device dataType headDim inputEmbedDim posEncDim)
-&gt; TransformerEncoder
     style
     numLayers
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     inputEmbedDim
     ffnDim
     posEncDim
</span><a href="Torch.GraduallyTyped.NN.Transformer.Encoder.html#TransformerEncoder"><span class="hs-identifier hs-var">TransformerEncoder</span></a></span><span>
</span><span id="line-326"></span><span>          </span><span class="annot"><span class="annottext">(GTransformerEncoder
   (TransformerStack
      style
      numLayers
      gradient
      device
      dataType
      headDim
      headEmbedDim
      embedDim
      inputEmbedDim
      ffnDim)
   (TEEmbedLayerNormF style gradient device dataType inputEmbedDim)
   (TELayerNormF style gradient device dataType inputEmbedDim)
   Dropout
   (TEPosEncF
      style gradient device dataType headDim inputEmbedDim posEncDim)
 -&gt; TransformerEncoder
      style
      numLayers
      gradient
      device
      dataType
      headDim
      headEmbedDim
      embedDim
      inputEmbedDim
      ffnDim
      posEncDim)
-&gt; m (GTransformerEncoder
        (TransformerStack
           style
           numLayers
           gradient
           device
           dataType
           headDim
           headEmbedDim
           embedDim
           inputEmbedDim
           ffnDim)
        (TEEmbedLayerNormF style gradient device dataType inputEmbedDim)
        (TELayerNormF style gradient device dataType inputEmbedDim)
        Dropout
        (TEPosEncF
           style gradient device dataType headDim inputEmbedDim posEncDim))
-&gt; m (TransformerEncoder
        style
        numLayers
        gradient
        device
        dataType
        headDim
        headEmbedDim
        embedDim
        inputEmbedDim
        ffnDim
        posEncDim)
forall (f :: * -&gt; *) a b. Functor f =&gt; (a -&gt; b) -&gt; f a -&gt; f b
</span><span class="hs-operator hs-var">&lt;$&gt;</span></span><span> </span><span class="hs-special">(</span><span> </span><span class="annot"><span class="annottext">TransformerStack
  style
  numLayers
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  inputEmbedDim
  ffnDim
-&gt; TEEmbedLayerNormF style gradient device dataType inputEmbedDim
-&gt; TELayerNormF style gradient device dataType inputEmbedDim
-&gt; Dropout
-&gt; TEPosEncF
     style gradient device dataType headDim inputEmbedDim posEncDim
-&gt; GTransformerEncoder
     (TransformerStack
        style
        numLayers
        gradient
        device
        dataType
        headDim
        headEmbedDim
        embedDim
        inputEmbedDim
        ffnDim)
     (TEEmbedLayerNormF style gradient device dataType inputEmbedDim)
     (TELayerNormF style gradient device dataType inputEmbedDim)
     Dropout
     (TEPosEncF
        style gradient device dataType headDim inputEmbedDim posEncDim)
forall stack embedLayerNorm layerNorm dropout posEnc.
stack
-&gt; embedLayerNorm
-&gt; layerNorm
-&gt; dropout
-&gt; posEnc
-&gt; GTransformerEncoder
     stack embedLayerNorm layerNorm dropout posEnc
</span><a href="Torch.GraduallyTyped.NN.Transformer.Encoder.html#GTransformerEncoder"><span class="hs-identifier hs-var">GTransformerEncoder</span></a></span><span>
</span><span id="line-327"></span><span>                  </span><span class="annot"><span class="annottext">(TransformerStack
   style
   numLayers
   gradient
   device
   dataType
   headDim
   headEmbedDim
   embedDim
   inputEmbedDim
   ffnDim
 -&gt; TEEmbedLayerNormF style gradient device dataType inputEmbedDim
 -&gt; TELayerNormF style gradient device dataType inputEmbedDim
 -&gt; Dropout
 -&gt; TEPosEncF
      style gradient device dataType headDim inputEmbedDim posEncDim
 -&gt; GTransformerEncoder
      (TransformerStack
         style
         numLayers
         gradient
         device
         dataType
         headDim
         headEmbedDim
         embedDim
         inputEmbedDim
         ffnDim)
      (TEEmbedLayerNormF style gradient device dataType inputEmbedDim)
      (TELayerNormF style gradient device dataType inputEmbedDim)
      Dropout
      (TEPosEncF
         style gradient device dataType headDim inputEmbedDim posEncDim))
-&gt; m (TransformerStack
        style
        numLayers
        gradient
        device
        dataType
        headDim
        headEmbedDim
        embedDim
        inputEmbedDim
        ffnDim)
-&gt; m (TEEmbedLayerNormF
        style gradient device dataType inputEmbedDim
      -&gt; TELayerNormF style gradient device dataType inputEmbedDim
      -&gt; Dropout
      -&gt; TEPosEncF
           style gradient device dataType headDim inputEmbedDim posEncDim
      -&gt; GTransformerEncoder
           (TransformerStack
              style
              numLayers
              gradient
              device
              dataType
              headDim
              headEmbedDim
              embedDim
              inputEmbedDim
              ffnDim)
           (TEEmbedLayerNormF style gradient device dataType inputEmbedDim)
           (TELayerNormF style gradient device dataType inputEmbedDim)
           Dropout
           (TEPosEncF
              style gradient device dataType headDim inputEmbedDim posEncDim))
forall (f :: * -&gt; *) a b. Functor f =&gt; (a -&gt; b) -&gt; f a -&gt; f b
</span><span class="hs-operator hs-var">&lt;$&gt;</span></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
-&gt; m (TransformerStack
        style
        numLayers
        gradient
        device
        dataType
        headDim
        headEmbedDim
        embedDim
        inputEmbedDim
        ffnDim)
</span><a href="#local-6989586621679808704"><span class="hs-identifier hs-var">stack</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SingI style =&gt; Sing style
forall k (a :: k). SingI a =&gt; Sing a
</span><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-var">sing</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679808735"><span class="hs-identifier hs-type">style</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-328"></span><span>                  </span><span class="annot"><span class="annottext">m (TEEmbedLayerNormF style gradient device dataType inputEmbedDim
   -&gt; TELayerNormF style gradient device dataType inputEmbedDim
   -&gt; Dropout
   -&gt; TEPosEncF
        style gradient device dataType headDim inputEmbedDim posEncDim
   -&gt; GTransformerEncoder
        (TransformerStack
           style
           numLayers
           gradient
           device
           dataType
           headDim
           headEmbedDim
           embedDim
           inputEmbedDim
           ffnDim)
        (TEEmbedLayerNormF style gradient device dataType inputEmbedDim)
        (TELayerNormF style gradient device dataType inputEmbedDim)
        Dropout
        (TEPosEncF
           style gradient device dataType headDim inputEmbedDim posEncDim))
-&gt; m (TEEmbedLayerNormF
        style gradient device dataType inputEmbedDim)
-&gt; m (TELayerNormF style gradient device dataType inputEmbedDim
      -&gt; Dropout
      -&gt; TEPosEncF
           style gradient device dataType headDim inputEmbedDim posEncDim
      -&gt; GTransformerEncoder
           (TransformerStack
              style
              numLayers
              gradient
              device
              dataType
              headDim
              headEmbedDim
              embedDim
              inputEmbedDim
              ffnDim)
           (TEEmbedLayerNormF style gradient device dataType inputEmbedDim)
           (TELayerNormF style gradient device dataType inputEmbedDim)
           Dropout
           (TEPosEncF
              style gradient device dataType headDim inputEmbedDim posEncDim))
forall (f :: * -&gt; *) a b. Applicative f =&gt; f (a -&gt; b) -&gt; f a -&gt; f b
</span><span class="hs-operator hs-var">&lt;*&gt;</span></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
-&gt; m (TEEmbedLayerNormF
        style gradient device dataType inputEmbedDim)
</span><a href="#local-6989586621679808702"><span class="hs-identifier hs-var">embedLayerNorm</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SingI style =&gt; Sing style
forall k (a :: k). SingI a =&gt; Sing a
</span><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-var">sing</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679808735"><span class="hs-identifier hs-type">style</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-329"></span><span>                  </span><span class="annot"><span class="annottext">m (TELayerNormF style gradient device dataType inputEmbedDim
   -&gt; Dropout
   -&gt; TEPosEncF
        style gradient device dataType headDim inputEmbedDim posEncDim
   -&gt; GTransformerEncoder
        (TransformerStack
           style
           numLayers
           gradient
           device
           dataType
           headDim
           headEmbedDim
           embedDim
           inputEmbedDim
           ffnDim)
        (TEEmbedLayerNormF style gradient device dataType inputEmbedDim)
        (TELayerNormF style gradient device dataType inputEmbedDim)
        Dropout
        (TEPosEncF
           style gradient device dataType headDim inputEmbedDim posEncDim))
-&gt; m (TELayerNormF style gradient device dataType inputEmbedDim)
-&gt; m (Dropout
      -&gt; TEPosEncF
           style gradient device dataType headDim inputEmbedDim posEncDim
      -&gt; GTransformerEncoder
           (TransformerStack
              style
              numLayers
              gradient
              device
              dataType
              headDim
              headEmbedDim
              embedDim
              inputEmbedDim
              ffnDim)
           (TEEmbedLayerNormF style gradient device dataType inputEmbedDim)
           (TELayerNormF style gradient device dataType inputEmbedDim)
           Dropout
           (TEPosEncF
              style gradient device dataType headDim inputEmbedDim posEncDim))
forall (f :: * -&gt; *) a b. Applicative f =&gt; f (a -&gt; b) -&gt; f a -&gt; f b
</span><span class="hs-operator hs-var">&lt;*&gt;</span></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
-&gt; m (TELayerNormF style gradient device dataType inputEmbedDim)
</span><a href="#local-6989586621679808699"><span class="hs-identifier hs-var">layerNorm</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SingI style =&gt; Sing style
forall k (a :: k). SingI a =&gt; Sing a
</span><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-var">sing</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679808735"><span class="hs-identifier hs-type">style</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-330"></span><span>                  </span><span class="annot"><span class="annottext">m (Dropout
   -&gt; TEPosEncF
        style gradient device dataType headDim inputEmbedDim posEncDim
   -&gt; GTransformerEncoder
        (TransformerStack
           style
           numLayers
           gradient
           device
           dataType
           headDim
           headEmbedDim
           embedDim
           inputEmbedDim
           ffnDim)
        (TEEmbedLayerNormF style gradient device dataType inputEmbedDim)
        (TELayerNormF style gradient device dataType inputEmbedDim)
        Dropout
        (TEPosEncF
           style gradient device dataType headDim inputEmbedDim posEncDim))
-&gt; m Dropout
-&gt; m (TEPosEncF
        style gradient device dataType headDim inputEmbedDim posEncDim
      -&gt; GTransformerEncoder
           (TransformerStack
              style
              numLayers
              gradient
              device
              dataType
              headDim
              headEmbedDim
              embedDim
              inputEmbedDim
              ffnDim)
           (TEEmbedLayerNormF style gradient device dataType inputEmbedDim)
           (TELayerNormF style gradient device dataType inputEmbedDim)
           Dropout
           (TEPosEncF
              style gradient device dataType headDim inputEmbedDim posEncDim))
forall (f :: * -&gt; *) a b. Applicative f =&gt; f (a -&gt; b) -&gt; f a -&gt; f b
</span><span class="hs-operator hs-var">&lt;*&gt;</span></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style -&gt; m Dropout
</span><a href="#local-6989586621679808698"><span class="hs-identifier hs-var">dropout</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SingI style =&gt; Sing style
forall k (a :: k). SingI a =&gt; Sing a
</span><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-var">sing</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679808735"><span class="hs-identifier hs-type">style</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-331"></span><span>                  </span><span class="annot"><span class="annottext">m (TEPosEncF
     style gradient device dataType headDim inputEmbedDim posEncDim
   -&gt; GTransformerEncoder
        (TransformerStack
           style
           numLayers
           gradient
           device
           dataType
           headDim
           headEmbedDim
           embedDim
           inputEmbedDim
           ffnDim)
        (TEEmbedLayerNormF style gradient device dataType inputEmbedDim)
        (TELayerNormF style gradient device dataType inputEmbedDim)
        Dropout
        (TEPosEncF
           style gradient device dataType headDim inputEmbedDim posEncDim))
-&gt; m (TEPosEncF
        style gradient device dataType headDim inputEmbedDim posEncDim)
-&gt; m (GTransformerEncoder
        (TransformerStack
           style
           numLayers
           gradient
           device
           dataType
           headDim
           headEmbedDim
           embedDim
           inputEmbedDim
           ffnDim)
        (TEEmbedLayerNormF style gradient device dataType inputEmbedDim)
        (TELayerNormF style gradient device dataType inputEmbedDim)
        Dropout
        (TEPosEncF
           style gradient device dataType headDim inputEmbedDim posEncDim))
forall (f :: * -&gt; *) a b. Applicative f =&gt; f (a -&gt; b) -&gt; f a -&gt; f b
</span><span class="hs-operator hs-var">&lt;*&gt;</span></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
-&gt; m (TEPosEncF
        style gradient device dataType headDim inputEmbedDim posEncDim)
</span><a href="#local-6989586621679808695"><span class="hs-identifier hs-var">posEnc</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SingI style =&gt; Sing style
forall k (a :: k). SingI a =&gt; Sing a
</span><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-var">sing</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679808735"><span class="hs-identifier hs-type">style</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-332"></span><span>              </span><span class="hs-special">)</span><span>
</span><span id="line-333"></span><span>  </span><span id="local-6989586621679808693"><span class="annot"><span class="annottext">toStateDict :: StateDictKey
-&gt; TransformerEncoder
     style
     numLayers
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     inputEmbedDim
     ffnDim
     posEncDim
-&gt; m ()
</span><a href="Torch.GraduallyTyped.NN.Class.html#toStateDict"><span class="hs-identifier hs-var hs-var hs-var hs-var">toStateDict</span></a></span></span><span> </span><span id="local-6989586621679808691"><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679808691"><span class="hs-identifier hs-var">k</span></a></span></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Encoder.html#TransformerEncoder"><span class="hs-identifier hs-type">TransformerEncoder</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Encoder.html#GTransformerEncoder"><span class="hs-identifier hs-type">GTransformerEncoder</span></a></span><span> </span><span class="hs-special">{</span><span id="local-6989586621679808686"><span id="local-6989586621679808687"><span id="local-6989586621679808688"><span id="local-6989586621679808689"><span id="local-6989586621679808690"><span class="annot"><span class="annottext">TEPosEncF
  style gradient device dataType headDim inputEmbedDim posEncDim
TEDropoutF style
TELayerNormF style gradient device dataType inputEmbedDim
TEEmbedLayerNormF style gradient device dataType inputEmbedDim
TEStackF
  style
  numLayers
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  inputEmbedDim
  ffnDim
tePosEnc :: TEPosEncF
  style gradient device dataType headDim inputEmbedDim posEncDim
teDropout :: TEDropoutF style
teLayerNorm :: TELayerNormF style gradient device dataType inputEmbedDim
teEmbedLayerNorm :: TEEmbedLayerNormF style gradient device dataType inputEmbedDim
teStack :: TEStackF
  style
  numLayers
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  inputEmbedDim
  ffnDim
tePosEnc :: forall stack embedLayerNorm layerNorm dropout posEnc.
GTransformerEncoder stack embedLayerNorm layerNorm dropout posEnc
-&gt; posEnc
teDropout :: forall stack embedLayerNorm layerNorm dropout posEnc.
GTransformerEncoder stack embedLayerNorm layerNorm dropout posEnc
-&gt; dropout
teLayerNorm :: forall stack embedLayerNorm layerNorm dropout posEnc.
GTransformerEncoder stack embedLayerNorm layerNorm dropout posEnc
-&gt; layerNorm
teEmbedLayerNorm :: forall stack embedLayerNorm layerNorm dropout posEnc.
GTransformerEncoder stack embedLayerNorm layerNorm dropout posEnc
-&gt; embedLayerNorm
teStack :: forall stack embedLayerNorm layerNorm dropout posEnc.
GTransformerEncoder stack embedLayerNorm layerNorm dropout posEnc
-&gt; stack
</span><a href="#local-6989586621679808686"><span class="hs-glyph hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var">..</span></a></span></span></span></span></span></span><span class="hs-special">}</span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-334"></span><span>    </span><span class="hs-keyword">let</span><span> </span><span id="local-6989586621679808685"><span class="annot"><span class="annottext">stack :: STransformerStyle style
-&gt; TransformerStack
     style
     numLayers
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     inputEmbedDim
     ffnDim
-&gt; m ()
</span><a href="#local-6989586621679808685"><span class="hs-identifier hs-var hs-var">stack</span></a></span></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#ST5"><span class="hs-identifier hs-var">ST5</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">StateDictKey
-&gt; TransformerStack
     'T5
     numLayers
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     inputEmbedDim
     ffnDim
-&gt; m ()
forall model (m :: * -&gt; *).
(HasStateDict model, MonadThrow m, MonadState StateDict m) =&gt;
StateDictKey -&gt; model -&gt; m ()
</span><a href="Torch.GraduallyTyped.NN.Class.html#toStateDict"><span class="hs-identifier hs-var">toStateDict</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679808691"><span class="hs-identifier hs-var">k</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey -&gt; StateDictKey -&gt; StateDictKey
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;block.&quot;</span></span><span class="hs-special">)</span><span>
</span><span id="line-335"></span><span>        </span><span class="annot"><a href="#local-6989586621679808685"><span class="hs-identifier hs-var">stack</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SByT5"><span class="hs-identifier hs-var">SByT5</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">StateDictKey
-&gt; TransformerStack
     'ByT5
     numLayers
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     inputEmbedDim
     ffnDim
-&gt; m ()
forall model (m :: * -&gt; *).
(HasStateDict model, MonadThrow m, MonadState StateDict m) =&gt;
StateDictKey -&gt; model -&gt; m ()
</span><a href="Torch.GraduallyTyped.NN.Class.html#toStateDict"><span class="hs-identifier hs-var">toStateDict</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679808691"><span class="hs-identifier hs-var">k</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey -&gt; StateDictKey -&gt; StateDictKey
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;block.&quot;</span></span><span class="hs-special">)</span><span>
</span><span id="line-336"></span><span>        </span><span class="annot"><a href="#local-6989586621679808685"><span class="hs-identifier hs-var">stack</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SBART"><span class="hs-identifier hs-var">SBART</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">StateDictKey
-&gt; TransformerStack
     'BART
     numLayers
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     inputEmbedDim
     ffnDim
-&gt; m ()
forall model (m :: * -&gt; *).
(HasStateDict model, MonadThrow m, MonadState StateDict m) =&gt;
StateDictKey -&gt; model -&gt; m ()
</span><a href="Torch.GraduallyTyped.NN.Class.html#toStateDict"><span class="hs-identifier hs-var">toStateDict</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679808691"><span class="hs-identifier hs-var">k</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey -&gt; StateDictKey -&gt; StateDictKey
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;layers.&quot;</span></span><span class="hs-special">)</span><span>
</span><span id="line-337"></span><span>        </span><span class="annot"><a href="#local-6989586621679808685"><span class="hs-identifier hs-var">stack</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SMBART"><span class="hs-identifier hs-var">SMBART</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">StateDictKey
-&gt; TransformerStack
     'MBART
     numLayers
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     inputEmbedDim
     ffnDim
-&gt; m ()
forall model (m :: * -&gt; *).
(HasStateDict model, MonadThrow m, MonadState StateDict m) =&gt;
StateDictKey -&gt; model -&gt; m ()
</span><a href="Torch.GraduallyTyped.NN.Class.html#toStateDict"><span class="hs-identifier hs-var">toStateDict</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679808691"><span class="hs-identifier hs-var">k</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey -&gt; StateDictKey -&gt; StateDictKey
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;layers.&quot;</span></span><span class="hs-special">)</span><span>
</span><span id="line-338"></span><span>        </span><span class="annot"><a href="#local-6989586621679808685"><span class="hs-identifier hs-var">stack</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SPegasus"><span class="hs-identifier hs-var">SPegasus</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">StateDictKey
-&gt; TransformerStack
     'Pegasus
     numLayers
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     inputEmbedDim
     ffnDim
-&gt; m ()
forall model (m :: * -&gt; *).
(HasStateDict model, MonadThrow m, MonadState StateDict m) =&gt;
StateDictKey -&gt; model -&gt; m ()
</span><a href="Torch.GraduallyTyped.NN.Class.html#toStateDict"><span class="hs-identifier hs-var">toStateDict</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679808691"><span class="hs-identifier hs-var">k</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey -&gt; StateDictKey -&gt; StateDictKey
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;layers.&quot;</span></span><span class="hs-special">)</span><span>
</span><span id="line-339"></span><span>        </span><span class="annot"><a href="#local-6989586621679808685"><span class="hs-identifier hs-var">stack</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SBERT"><span class="hs-identifier hs-var">SBERT</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">StateDictKey
-&gt; TransformerStack
     'BERT
     numLayers
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     inputEmbedDim
     ffnDim
-&gt; m ()
forall model (m :: * -&gt; *).
(HasStateDict model, MonadThrow m, MonadState StateDict m) =&gt;
StateDictKey -&gt; model -&gt; m ()
</span><a href="Torch.GraduallyTyped.NN.Class.html#toStateDict"><span class="hs-identifier hs-var">toStateDict</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679808691"><span class="hs-identifier hs-var">k</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey -&gt; StateDictKey -&gt; StateDictKey
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;encoder.layer.&quot;</span></span><span class="hs-special">)</span><span>
</span><span id="line-340"></span><span>        </span><span class="annot"><a href="#local-6989586621679808685"><span class="hs-identifier hs-var">stack</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SRoBERTa"><span class="hs-identifier hs-var">SRoBERTa</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">StateDictKey
-&gt; TransformerStack
     'RoBERTa
     numLayers
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     inputEmbedDim
     ffnDim
-&gt; m ()
forall model (m :: * -&gt; *).
(HasStateDict model, MonadThrow m, MonadState StateDict m) =&gt;
StateDictKey -&gt; model -&gt; m ()
</span><a href="Torch.GraduallyTyped.NN.Class.html#toStateDict"><span class="hs-identifier hs-var">toStateDict</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679808691"><span class="hs-identifier hs-var">k</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey -&gt; StateDictKey -&gt; StateDictKey
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;encoder.layer.&quot;</span></span><span class="hs-special">)</span><span>
</span><span id="line-341"></span><span>        </span><span class="annot"><a href="#local-6989586621679808685"><span class="hs-identifier hs-var">stack</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SGPT2"><span class="hs-identifier hs-var">SGPT2</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">TransformerStack
  style
  numLayers
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  inputEmbedDim
  ffnDim
-&gt; m ()
forall a. HasCallStack =&gt; a
</span><span class="hs-identifier hs-var">undefined</span></span><span>
</span><span id="line-342"></span><span>        </span><span id="local-6989586621679808684"><span class="annot"><span class="annottext">embedLayerNorm :: STransformerStyle style
-&gt; TEEmbedLayerNormF style gradient device dataType inputEmbedDim
-&gt; m ()
</span><a href="#local-6989586621679808684"><span class="hs-identifier hs-var hs-var">embedLayerNorm</span></a></span></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#ST5"><span class="hs-identifier hs-var">ST5</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">StateDictKey -&gt; () -&gt; m ()
forall model (m :: * -&gt; *).
(HasStateDict model, MonadThrow m, MonadState StateDict m) =&gt;
StateDictKey -&gt; model -&gt; m ()
</span><a href="Torch.GraduallyTyped.NN.Class.html#toStateDict"><span class="hs-identifier hs-var">toStateDict</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679808691"><span class="hs-identifier hs-var">k</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey -&gt; StateDictKey -&gt; StateDictKey
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;layernorm_embedding.&quot;</span></span><span class="hs-special">)</span><span>
</span><span id="line-343"></span><span>        </span><span class="annot"><a href="#local-6989586621679808684"><span class="hs-identifier hs-var">embedLayerNorm</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SByT5"><span class="hs-identifier hs-var">SByT5</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">StateDictKey -&gt; () -&gt; m ()
forall model (m :: * -&gt; *).
(HasStateDict model, MonadThrow m, MonadState StateDict m) =&gt;
StateDictKey -&gt; model -&gt; m ()
</span><a href="Torch.GraduallyTyped.NN.Class.html#toStateDict"><span class="hs-identifier hs-var">toStateDict</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679808691"><span class="hs-identifier hs-var">k</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey -&gt; StateDictKey -&gt; StateDictKey
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;layernorm_embedding.&quot;</span></span><span class="hs-special">)</span><span>
</span><span id="line-344"></span><span>        </span><span class="annot"><a href="#local-6989586621679808684"><span class="hs-identifier hs-var">embedLayerNorm</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SBART"><span class="hs-identifier hs-var">SBART</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">StateDictKey
-&gt; LayerNorm
     'WithBias gradient device dataType ('Shape '[inputEmbedDim])
-&gt; m ()
forall model (m :: * -&gt; *).
(HasStateDict model, MonadThrow m, MonadState StateDict m) =&gt;
StateDictKey -&gt; model -&gt; m ()
</span><a href="Torch.GraduallyTyped.NN.Class.html#toStateDict"><span class="hs-identifier hs-var">toStateDict</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679808691"><span class="hs-identifier hs-var">k</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey -&gt; StateDictKey -&gt; StateDictKey
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;layernorm_embedding.&quot;</span></span><span class="hs-special">)</span><span>
</span><span id="line-345"></span><span>        </span><span class="annot"><a href="#local-6989586621679808684"><span class="hs-identifier hs-var">embedLayerNorm</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SMBART"><span class="hs-identifier hs-var">SMBART</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">StateDictKey
-&gt; LayerNorm
     'WithBias gradient device dataType ('Shape '[inputEmbedDim])
-&gt; m ()
forall model (m :: * -&gt; *).
(HasStateDict model, MonadThrow m, MonadState StateDict m) =&gt;
StateDictKey -&gt; model -&gt; m ()
</span><a href="Torch.GraduallyTyped.NN.Class.html#toStateDict"><span class="hs-identifier hs-var">toStateDict</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679808691"><span class="hs-identifier hs-var">k</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey -&gt; StateDictKey -&gt; StateDictKey
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;layernorm_embedding.&quot;</span></span><span class="hs-special">)</span><span>
</span><span id="line-346"></span><span>        </span><span class="annot"><a href="#local-6989586621679808684"><span class="hs-identifier hs-var">embedLayerNorm</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SPegasus"><span class="hs-identifier hs-var">SPegasus</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">StateDictKey -&gt; () -&gt; m ()
forall model (m :: * -&gt; *).
(HasStateDict model, MonadThrow m, MonadState StateDict m) =&gt;
StateDictKey -&gt; model -&gt; m ()
</span><a href="Torch.GraduallyTyped.NN.Class.html#toStateDict"><span class="hs-identifier hs-var">toStateDict</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679808691"><span class="hs-identifier hs-var">k</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey -&gt; StateDictKey -&gt; StateDictKey
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;layernorm_embedding.&quot;</span></span><span class="hs-special">)</span><span>
</span><span id="line-347"></span><span>        </span><span class="annot"><a href="#local-6989586621679808684"><span class="hs-identifier hs-var">embedLayerNorm</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SBERT"><span class="hs-identifier hs-var">SBERT</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">StateDictKey
-&gt; LayerNorm
     'WithBias gradient device dataType ('Shape '[inputEmbedDim])
-&gt; m ()
forall model (m :: * -&gt; *).
(HasStateDict model, MonadThrow m, MonadState StateDict m) =&gt;
StateDictKey -&gt; model -&gt; m ()
</span><a href="Torch.GraduallyTyped.NN.Class.html#toStateDict"><span class="hs-identifier hs-var">toStateDict</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679808691"><span class="hs-identifier hs-var">k</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey -&gt; StateDictKey -&gt; StateDictKey
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;embeddings.LayerNorm.&quot;</span></span><span class="hs-special">)</span><span>
</span><span id="line-348"></span><span>        </span><span class="annot"><a href="#local-6989586621679808684"><span class="hs-identifier hs-var">embedLayerNorm</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SRoBERTa"><span class="hs-identifier hs-var">SRoBERTa</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">StateDictKey
-&gt; LayerNorm
     'WithBias gradient device dataType ('Shape '[inputEmbedDim])
-&gt; m ()
forall model (m :: * -&gt; *).
(HasStateDict model, MonadThrow m, MonadState StateDict m) =&gt;
StateDictKey -&gt; model -&gt; m ()
</span><a href="Torch.GraduallyTyped.NN.Class.html#toStateDict"><span class="hs-identifier hs-var">toStateDict</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679808691"><span class="hs-identifier hs-var">k</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey -&gt; StateDictKey -&gt; StateDictKey
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;embeddings.LayerNorm.&quot;</span></span><span class="hs-special">)</span><span>
</span><span id="line-349"></span><span>        </span><span class="annot"><a href="#local-6989586621679808684"><span class="hs-identifier hs-var">embedLayerNorm</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SGPT2"><span class="hs-identifier hs-var">SGPT2</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">TEEmbedLayerNormF style gradient device dataType inputEmbedDim
-&gt; m ()
forall a. HasCallStack =&gt; a
</span><span class="hs-identifier hs-var">undefined</span></span><span>
</span><span id="line-350"></span><span>        </span><span id="local-6989586621679808683"><span class="annot"><span class="annottext">layerNorm :: STransformerStyle style
-&gt; TELayerNormF style gradient device dataType inputEmbedDim
-&gt; m ()
</span><a href="#local-6989586621679808683"><span class="hs-identifier hs-var hs-var">layerNorm</span></a></span></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#ST5"><span class="hs-identifier hs-var">ST5</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">StateDictKey
-&gt; LayerNorm
     'WithoutBias gradient device dataType ('Shape '[inputEmbedDim])
-&gt; m ()
forall model (m :: * -&gt; *).
(HasStateDict model, MonadThrow m, MonadState StateDict m) =&gt;
StateDictKey -&gt; model -&gt; m ()
</span><a href="Torch.GraduallyTyped.NN.Class.html#toStateDict"><span class="hs-identifier hs-var">toStateDict</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679808691"><span class="hs-identifier hs-var">k</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey -&gt; StateDictKey -&gt; StateDictKey
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;final_layer_norm.&quot;</span></span><span class="hs-special">)</span><span>
</span><span id="line-351"></span><span>        </span><span class="annot"><a href="#local-6989586621679808683"><span class="hs-identifier hs-var">layerNorm</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SByT5"><span class="hs-identifier hs-var">SByT5</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">StateDictKey
-&gt; LayerNorm
     'WithoutBias gradient device dataType ('Shape '[inputEmbedDim])
-&gt; m ()
forall model (m :: * -&gt; *).
(HasStateDict model, MonadThrow m, MonadState StateDict m) =&gt;
StateDictKey -&gt; model -&gt; m ()
</span><a href="Torch.GraduallyTyped.NN.Class.html#toStateDict"><span class="hs-identifier hs-var">toStateDict</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679808691"><span class="hs-identifier hs-var">k</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey -&gt; StateDictKey -&gt; StateDictKey
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;final_layer_norm.&quot;</span></span><span class="hs-special">)</span><span>
</span><span id="line-352"></span><span>        </span><span class="annot"><a href="#local-6989586621679808683"><span class="hs-identifier hs-var">layerNorm</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SBART"><span class="hs-identifier hs-var">SBART</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">StateDictKey -&gt; () -&gt; m ()
forall model (m :: * -&gt; *).
(HasStateDict model, MonadThrow m, MonadState StateDict m) =&gt;
StateDictKey -&gt; model -&gt; m ()
</span><a href="Torch.GraduallyTyped.NN.Class.html#toStateDict"><span class="hs-identifier hs-var">toStateDict</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679808691"><span class="hs-identifier hs-var">k</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey -&gt; StateDictKey -&gt; StateDictKey
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;final_layer_norm.&quot;</span></span><span class="hs-special">)</span><span>
</span><span id="line-353"></span><span>        </span><span class="annot"><a href="#local-6989586621679808683"><span class="hs-identifier hs-var">layerNorm</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SMBART"><span class="hs-identifier hs-var">SMBART</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">StateDictKey -&gt; () -&gt; m ()
forall model (m :: * -&gt; *).
(HasStateDict model, MonadThrow m, MonadState StateDict m) =&gt;
StateDictKey -&gt; model -&gt; m ()
</span><a href="Torch.GraduallyTyped.NN.Class.html#toStateDict"><span class="hs-identifier hs-var">toStateDict</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679808691"><span class="hs-identifier hs-var">k</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey -&gt; StateDictKey -&gt; StateDictKey
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;final_layer_norm.&quot;</span></span><span class="hs-special">)</span><span>
</span><span id="line-354"></span><span>        </span><span class="annot"><a href="#local-6989586621679808683"><span class="hs-identifier hs-var">layerNorm</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SPegasus"><span class="hs-identifier hs-var">SPegasus</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">StateDictKey
-&gt; LayerNorm
     'WithBias gradient device dataType ('Shape '[inputEmbedDim])
-&gt; m ()
forall model (m :: * -&gt; *).
(HasStateDict model, MonadThrow m, MonadState StateDict m) =&gt;
StateDictKey -&gt; model -&gt; m ()
</span><a href="Torch.GraduallyTyped.NN.Class.html#toStateDict"><span class="hs-identifier hs-var">toStateDict</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679808691"><span class="hs-identifier hs-var">k</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey -&gt; StateDictKey -&gt; StateDictKey
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;layernorm_embedding.&quot;</span></span><span class="hs-special">)</span><span>
</span><span id="line-355"></span><span>        </span><span class="annot"><a href="#local-6989586621679808683"><span class="hs-identifier hs-var">layerNorm</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SBERT"><span class="hs-identifier hs-var">SBERT</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">StateDictKey -&gt; () -&gt; m ()
forall model (m :: * -&gt; *).
(HasStateDict model, MonadThrow m, MonadState StateDict m) =&gt;
StateDictKey -&gt; model -&gt; m ()
</span><a href="Torch.GraduallyTyped.NN.Class.html#toStateDict"><span class="hs-identifier hs-var">toStateDict</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679808691"><span class="hs-identifier hs-var">k</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey -&gt; StateDictKey -&gt; StateDictKey
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;layernorm_embedding.&quot;</span></span><span class="hs-special">)</span><span>
</span><span id="line-356"></span><span>        </span><span class="annot"><a href="#local-6989586621679808683"><span class="hs-identifier hs-var">layerNorm</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SRoBERTa"><span class="hs-identifier hs-var">SRoBERTa</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">StateDictKey -&gt; () -&gt; m ()
forall model (m :: * -&gt; *).
(HasStateDict model, MonadThrow m, MonadState StateDict m) =&gt;
StateDictKey -&gt; model -&gt; m ()
</span><a href="Torch.GraduallyTyped.NN.Class.html#toStateDict"><span class="hs-identifier hs-var">toStateDict</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679808691"><span class="hs-identifier hs-var">k</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey -&gt; StateDictKey -&gt; StateDictKey
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;layernorm_embedding.&quot;</span></span><span class="hs-special">)</span><span>
</span><span id="line-357"></span><span>        </span><span class="annot"><a href="#local-6989586621679808683"><span class="hs-identifier hs-var">layerNorm</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SGPT2"><span class="hs-identifier hs-var">SGPT2</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">TELayerNormF style gradient device dataType inputEmbedDim -&gt; m ()
forall a. HasCallStack =&gt; a
</span><span class="hs-identifier hs-var">undefined</span></span><span>
</span><span id="line-358"></span><span>        </span><span id="local-6989586621679808682"><span class="annot"><span class="annottext">dropout :: STransformerStyle style -&gt; Dropout -&gt; m ()
</span><a href="#local-6989586621679808682"><span class="hs-identifier hs-var hs-var">dropout</span></a></span></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><span class="hs-identifier">_</span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">StateDictKey -&gt; Dropout -&gt; m ()
forall model (m :: * -&gt; *).
(HasStateDict model, MonadThrow m, MonadState StateDict m) =&gt;
StateDictKey -&gt; model -&gt; m ()
</span><a href="Torch.GraduallyTyped.NN.Class.html#toStateDict"><span class="hs-identifier hs-var">toStateDict</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679808691"><span class="hs-identifier hs-var">k</span></a></span><span>
</span><span id="line-359"></span><span>        </span><span id="local-6989586621679808681"><span class="annot"><span class="annottext">posEnc :: STransformerStyle style
-&gt; TEPosEncF
     style gradient device dataType headDim inputEmbedDim posEncDim
-&gt; m ()
</span><a href="#local-6989586621679808681"><span class="hs-identifier hs-var hs-var">posEnc</span></a></span></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#ST5"><span class="hs-identifier hs-var">ST5</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">StateDictKey
-&gt; Embedding
     gradient
     ('Layout 'Dense)
     device
     dataType
     posEncDim
     headDim
     'Nothing
-&gt; m ()
forall model (m :: * -&gt; *).
(HasStateDict model, MonadThrow m, MonadState StateDict m) =&gt;
StateDictKey -&gt; model -&gt; m ()
</span><a href="Torch.GraduallyTyped.NN.Class.html#toStateDict"><span class="hs-identifier hs-var">toStateDict</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679808691"><span class="hs-identifier hs-var">k</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey -&gt; StateDictKey -&gt; StateDictKey
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;block.0.layer.0.SelfAttention.relative_attention_bias.&quot;</span></span><span class="hs-special">)</span><span>
</span><span id="line-360"></span><span>        </span><span class="annot"><a href="#local-6989586621679808681"><span class="hs-identifier hs-var">posEnc</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SByT5"><span class="hs-identifier hs-var">SByT5</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">StateDictKey
-&gt; Embedding
     gradient
     ('Layout 'Dense)
     device
     dataType
     posEncDim
     headDim
     'Nothing
-&gt; m ()
forall model (m :: * -&gt; *).
(HasStateDict model, MonadThrow m, MonadState StateDict m) =&gt;
StateDictKey -&gt; model -&gt; m ()
</span><a href="Torch.GraduallyTyped.NN.Class.html#toStateDict"><span class="hs-identifier hs-var">toStateDict</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679808691"><span class="hs-identifier hs-var">k</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey -&gt; StateDictKey -&gt; StateDictKey
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;block.0.layer.0.SelfAttention.relative_attention_bias.&quot;</span></span><span class="hs-special">)</span><span>
</span><span id="line-361"></span><span>        </span><span class="annot"><a href="#local-6989586621679808681"><span class="hs-identifier hs-var">posEnc</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SBART"><span class="hs-identifier hs-var">SBART</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">StateDictKey
-&gt; Embedding
     gradient
     ('Layout 'Dense)
     device
     dataType
     posEncDim
     inputEmbedDim
     'Nothing
-&gt; m ()
forall model (m :: * -&gt; *).
(HasStateDict model, MonadThrow m, MonadState StateDict m) =&gt;
StateDictKey -&gt; model -&gt; m ()
</span><a href="Torch.GraduallyTyped.NN.Class.html#toStateDict"><span class="hs-identifier hs-var">toStateDict</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679808691"><span class="hs-identifier hs-var">k</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey -&gt; StateDictKey -&gt; StateDictKey
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;embed_positions.&quot;</span></span><span class="hs-special">)</span><span>
</span><span id="line-362"></span><span>        </span><span class="annot"><a href="#local-6989586621679808681"><span class="hs-identifier hs-var">posEnc</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SMBART"><span class="hs-identifier hs-var">SMBART</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">StateDictKey
-&gt; Embedding
     gradient
     ('Layout 'Dense)
     device
     dataType
     posEncDim
     inputEmbedDim
     'Nothing
-&gt; m ()
forall model (m :: * -&gt; *).
(HasStateDict model, MonadThrow m, MonadState StateDict m) =&gt;
StateDictKey -&gt; model -&gt; m ()
</span><a href="Torch.GraduallyTyped.NN.Class.html#toStateDict"><span class="hs-identifier hs-var">toStateDict</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679808691"><span class="hs-identifier hs-var">k</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey -&gt; StateDictKey -&gt; StateDictKey
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;embed_positions.&quot;</span></span><span class="hs-special">)</span><span>
</span><span id="line-363"></span><span>        </span><span class="annot"><a href="#local-6989586621679808681"><span class="hs-identifier hs-var">posEnc</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SPegasus"><span class="hs-identifier hs-var">SPegasus</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">StateDictKey
-&gt; Embedding
     gradient
     ('Layout 'Dense)
     device
     dataType
     posEncDim
     inputEmbedDim
     'Nothing
-&gt; m ()
forall model (m :: * -&gt; *).
(HasStateDict model, MonadThrow m, MonadState StateDict m) =&gt;
StateDictKey -&gt; model -&gt; m ()
</span><a href="Torch.GraduallyTyped.NN.Class.html#toStateDict"><span class="hs-identifier hs-var">toStateDict</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679808691"><span class="hs-identifier hs-var">k</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey -&gt; StateDictKey -&gt; StateDictKey
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;embed_positions.&quot;</span></span><span class="hs-special">)</span><span>
</span><span id="line-364"></span><span>        </span><span class="annot"><a href="#local-6989586621679808681"><span class="hs-identifier hs-var">posEnc</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SBERT"><span class="hs-identifier hs-var">SBERT</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">StateDictKey
-&gt; Embedding
     gradient
     ('Layout 'Dense)
     device
     dataType
     posEncDim
     inputEmbedDim
     'Nothing
-&gt; m ()
forall model (m :: * -&gt; *).
(HasStateDict model, MonadThrow m, MonadState StateDict m) =&gt;
StateDictKey -&gt; model -&gt; m ()
</span><a href="Torch.GraduallyTyped.NN.Class.html#toStateDict"><span class="hs-identifier hs-var">toStateDict</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679808691"><span class="hs-identifier hs-var">k</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey -&gt; StateDictKey -&gt; StateDictKey
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;embeddings.position_embeddings.&quot;</span></span><span class="hs-special">)</span><span>
</span><span id="line-365"></span><span>        </span><span class="annot"><a href="#local-6989586621679808681"><span class="hs-identifier hs-var">posEnc</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SRoBERTa"><span class="hs-identifier hs-var">SRoBERTa</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">StateDictKey
-&gt; Embedding
     gradient
     ('Layout 'Dense)
     device
     dataType
     posEncDim
     inputEmbedDim
     'Nothing
-&gt; m ()
forall model (m :: * -&gt; *).
(HasStateDict model, MonadThrow m, MonadState StateDict m) =&gt;
StateDictKey -&gt; model -&gt; m ()
</span><a href="Torch.GraduallyTyped.NN.Class.html#toStateDict"><span class="hs-identifier hs-var">toStateDict</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679808691"><span class="hs-identifier hs-var">k</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey -&gt; StateDictKey -&gt; StateDictKey
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;embeddings.position_embeddings.&quot;</span></span><span class="hs-special">)</span><span>
</span><span id="line-366"></span><span>        </span><span class="annot"><a href="#local-6989586621679808681"><span class="hs-identifier hs-var">posEnc</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SGPT2"><span class="hs-identifier hs-var">SGPT2</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">TEPosEncF
  style gradient device dataType headDim inputEmbedDim posEncDim
-&gt; m ()
forall a. HasCallStack =&gt; a
</span><span class="hs-identifier hs-var">undefined</span></span><span>
</span><span id="line-367"></span><span>     </span><span class="hs-keyword">in</span><span> </span><span class="hs-keyword">do</span><span>
</span><span id="line-368"></span><span>          </span><span class="hs-special">(</span><span class="hs-special">)</span><span> </span><span class="hs-glyph">&lt;-</span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
-&gt; TransformerStack
     style
     numLayers
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     inputEmbedDim
     ffnDim
-&gt; m ()
</span><a href="#local-6989586621679808685"><span class="hs-identifier hs-var">stack</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SingI style =&gt; Sing style
forall k (a :: k). SingI a =&gt; Sing a
</span><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-var">sing</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679808735"><span class="hs-identifier hs-type">style</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">TransformerStack
  style
  numLayers
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  inputEmbedDim
  ffnDim
TEStackF
  style
  numLayers
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  inputEmbedDim
  ffnDim
</span><a href="#local-6989586621679808690"><span class="hs-identifier hs-var">teStack</span></a></span><span>
</span><span id="line-369"></span><span>          </span><span class="hs-special">(</span><span class="hs-special">)</span><span> </span><span class="hs-glyph">&lt;-</span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
-&gt; TEEmbedLayerNormF style gradient device dataType inputEmbedDim
-&gt; m ()
</span><a href="#local-6989586621679808684"><span class="hs-identifier hs-var">embedLayerNorm</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SingI style =&gt; Sing style
forall k (a :: k). SingI a =&gt; Sing a
</span><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-var">sing</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679808735"><span class="hs-identifier hs-type">style</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">TEEmbedLayerNormF style gradient device dataType inputEmbedDim
</span><a href="#local-6989586621679808689"><span class="hs-identifier hs-var">teEmbedLayerNorm</span></a></span><span>
</span><span id="line-370"></span><span>          </span><span class="hs-special">(</span><span class="hs-special">)</span><span> </span><span class="hs-glyph">&lt;-</span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
-&gt; TELayerNormF style gradient device dataType inputEmbedDim
-&gt; m ()
</span><a href="#local-6989586621679808683"><span class="hs-identifier hs-var">layerNorm</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SingI style =&gt; Sing style
forall k (a :: k). SingI a =&gt; Sing a
</span><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-var">sing</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679808735"><span class="hs-identifier hs-type">style</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">TELayerNormF style gradient device dataType inputEmbedDim
</span><a href="#local-6989586621679808688"><span class="hs-identifier hs-var">teLayerNorm</span></a></span><span>
</span><span id="line-371"></span><span>          </span><span class="hs-special">(</span><span class="hs-special">)</span><span> </span><span class="hs-glyph">&lt;-</span><span> </span><span class="annot"><span class="annottext">STransformerStyle style -&gt; Dropout -&gt; m ()
</span><a href="#local-6989586621679808682"><span class="hs-identifier hs-var">dropout</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SingI style =&gt; Sing style
forall k (a :: k). SingI a =&gt; Sing a
</span><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-var">sing</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679808735"><span class="hs-identifier hs-type">style</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">Dropout
TEDropoutF style
</span><a href="#local-6989586621679808687"><span class="hs-identifier hs-var">teDropout</span></a></span><span>
</span><span id="line-372"></span><span>          </span><span class="hs-special">(</span><span class="hs-special">)</span><span> </span><span class="hs-glyph">&lt;-</span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
-&gt; TEPosEncF
     style gradient device dataType headDim inputEmbedDim posEncDim
-&gt; m ()
</span><a href="#local-6989586621679808681"><span class="hs-identifier hs-var">posEnc</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SingI style =&gt; Sing style
forall k (a :: k). SingI a =&gt; Sing a
</span><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-var">sing</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679808735"><span class="hs-identifier hs-type">style</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">TEPosEncF
  style gradient device dataType headDim inputEmbedDim posEncDim
</span><a href="#local-6989586621679808686"><span class="hs-identifier hs-var">tePosEnc</span></a></span><span>
</span><span id="line-373"></span><span>          </span><span class="annot"><span class="annottext">() -&gt; m ()
forall (f :: * -&gt; *) a. Applicative f =&gt; a -&gt; f a
</span><span class="hs-identifier hs-var">pure</span></span><span> </span><span class="hs-special">(</span><span class="hs-special">)</span></span></span></span></span></span></span></span></span></span></span></span><span>
</span><span id="line-374"></span><span>
</span><span id="line-375"></span><span class="hs-comment">-- | 'HasForward' instance for @TransformerEncoder numLayers 'T5@.</span><span>
</span><span id="line-376"></span><span class="hs-comment">--</span><span>
</span><span id="line-377"></span><span class="hs-comment">-- @</span><span>
</span><span id="line-378"></span><span class="hs-comment">--  &#9484;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9488;  &#9484;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9488;  &#9484;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9488;</span><span>
</span><span id="line-379"></span><span class="hs-comment">--  &#9474; input &#9474;  &#9474; relPos &#9474;  &#9474; attentionMask &#9474;</span><span>
</span><span id="line-380"></span><span class="hs-comment">--  &#9492;&#9472;&#9472;&#9472;&#9516;&#9472;&#9472;&#9472;&#9496;  &#9492;&#9472;&#9472;&#9472;&#9516;&#9472;&#9472;&#9472;&#9472;&#9496;  &#9492;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9516;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9496;</span><span>
</span><span id="line-381"></span><span class="hs-comment">--      &#9474;          &#9474;               &#9474;</span><span>
</span><span id="line-382"></span><span class="hs-comment">--      &#9474;          &#9660;               &#9474;</span><span>
</span><span id="line-383"></span><span class="hs-comment">--      &#9474;      tePosEnc            &#9474;</span><span>
</span><span id="line-384"></span><span class="hs-comment">--      &#9474;          &#9660;               &#9474;</span><span>
</span><span id="line-385"></span><span class="hs-comment">--      &#9474;      transpose           &#9474;</span><span>
</span><span id="line-386"></span><span class="hs-comment">--      &#9474;          &#9660;               &#9660;</span><span>
</span><span id="line-387"></span><span class="hs-comment">--      &#9474;      transpose       unsqueeze</span><span>
</span><span id="line-388"></span><span class="hs-comment">--      &#9660;          &#9474;               &#9474;</span><span>
</span><span id="line-389"></span><span class="hs-comment">--  teDropout      &#9492;&#9472;&#9472;&#9472;&#9472;&#9472;&#9658;add&#9668;&#9472;&#9472;&#9472;&#9472;&#9472;&#9496;</span><span>
</span><span id="line-390"></span><span class="hs-comment">--      &#9660;                  &#9474;</span><span>
</span><span id="line-391"></span><span class="hs-comment">--   teStack&#9668;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9496;</span><span>
</span><span id="line-392"></span><span class="hs-comment">--      &#9660;</span><span>
</span><span id="line-393"></span><span class="hs-comment">-- teLayerNorm</span><span>
</span><span id="line-394"></span><span class="hs-comment">--      &#9660;</span><span>
</span><span id="line-395"></span><span class="hs-comment">--  teDropout</span><span>
</span><span id="line-396"></span><span class="hs-comment">--      &#9474;</span><span>
</span><span id="line-397"></span><span class="hs-comment">--      &#9660;</span><span>
</span><span id="line-398"></span><span class="hs-comment">--  &#9484;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9488;</span><span>
</span><span id="line-399"></span><span class="hs-comment">--  &#9474; output &#9474;</span><span>
</span><span id="line-400"></span><span class="hs-comment">--  &#9492;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9496;</span><span>
</span><span id="line-401"></span><span class="hs-comment">-- @</span><span>
</span><span id="line-402"></span><span id="local-6989586621679808651"><span id="local-6989586621679808652"><span id="local-6989586621679808653"><span id="local-6989586621679808654"><span id="local-6989586621679808655"><span id="local-6989586621679808656"><span id="local-6989586621679808657"><span id="local-6989586621679808658"><span id="local-6989586621679808659"><span id="local-6989586621679808660"><span id="local-6989586621679808661"><span id="local-6989586621679808662"><span id="local-6989586621679808663"><span id="local-6989586621679808664"><span id="local-6989586621679808665"><span id="local-6989586621679808666"><span id="local-6989586621679808667"><span id="local-6989586621679808668"><span id="local-6989586621679808669"><span id="local-6989586621679808670"><span id="local-6989586621679808671"><span id="local-6989586621679808672"><span id="local-6989586621679808673"><span id="local-6989586621679808674"><span id="local-6989586621679808675"><span id="local-6989586621679808676"><span id="local-6989586621679808677"><span id="local-6989586621679808678"><span id="local-6989586621679808679"><span id="local-6989586621679808680"><span class="hs-keyword">instance</span><span>
</span><span id="line-403"></span><span>  </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasForward"><span class="hs-identifier hs-type">HasForward</span></a></span><span>
</span><span id="line-404"></span><span>      </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Encoder.html#TEDropoutF"><span class="hs-identifier hs-type">TEDropoutF</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#T5"><span class="hs-identifier hs-type">T5</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-405"></span><span>      </span><span class="annot"><a href="#local-6989586621679808680"><span class="hs-identifier hs-type">input</span></a></span><span>
</span><span id="line-406"></span><span>      </span><span class="annot"><a href="#local-6989586621679808679"><span class="hs-identifier hs-type">generatorDevice</span></a></span><span>
</span><span id="line-407"></span><span>      </span><span class="annot"><a href="#local-6989586621679808678"><span class="hs-identifier hs-type">dropoutOutput</span></a></span><span>
</span><span id="line-408"></span><span>      </span><span class="annot"><a href="#local-6989586621679808677"><span class="hs-identifier hs-type">dropoutGeneratorOutputDevice</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-409"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasForward"><span class="hs-identifier hs-type">HasForward</span></a></span><span>
</span><span id="line-410"></span><span>      </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Encoder.html#TEStackF"><span class="hs-identifier hs-type">TEStackF</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#T5"><span class="hs-identifier hs-type">T5</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808676"><span class="hs-identifier hs-type">numLayers</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808675"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808674"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808673"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808672"><span class="hs-identifier hs-type">headDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808671"><span class="hs-identifier hs-type">headEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808670"><span class="hs-identifier hs-type">embedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808669"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808668"><span class="hs-identifier hs-type">ffnDim</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-411"></span><span>      </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="#local-6989586621679808678"><span class="hs-identifier hs-type">dropoutOutput</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-412"></span><span>        </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span>
</span><span id="line-413"></span><span>          </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679808675"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%7C%3E"><span class="hs-operator hs-type">&lt;|&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808667"><span class="hs-identifier hs-type">relPosGradient</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%7C%3E"><span class="hs-operator hs-type">&lt;|&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808666"><span class="hs-identifier hs-type">attentionMaskGradient</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-414"></span><span>          </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#Layout"><span class="hs-identifier hs-type">Layout</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#Dense"><span class="hs-identifier hs-type">Dense</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808665"><span class="hs-identifier hs-type">relPosLayout</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808664"><span class="hs-identifier hs-type">attentionMaskLayout</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-415"></span><span>          </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679808674"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808663"><span class="hs-identifier hs-type">relPosDevice</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808662"><span class="hs-identifier hs-type">attentionMaskDevice</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-416"></span><span>          </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Prelude.html#Seq"><span class="hs-identifier hs-type">Seq</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679808661"><span class="hs-identifier hs-type">relPosDataType</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#DataType"><span class="hs-identifier hs-type">DataType</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#Int64"><span class="hs-identifier hs-type">Int64</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679808673"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808660"><span class="hs-identifier hs-type">attentionMaskDataType</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-417"></span><span>          </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Class.html#BroadcastShapesF"><span class="hs-identifier hs-type">BroadcastShapesF</span></a></span><span>
</span><span id="line-418"></span><span>              </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.IndexingSlicingJoining.html#TransposeF"><span class="hs-identifier hs-type">TransposeF</span></a></span><span>
</span><span id="line-419"></span><span>                  </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SelectDim"><span class="hs-identifier hs-type">SelectDim</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#ByIndex"><span class="hs-identifier hs-type">ByIndex</span></a></span><span> </span><span class="annot"><span class="hs-number">1</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-420"></span><span>                  </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SelectDim"><span class="hs-identifier hs-type">SelectDim</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#ByIndex"><span class="hs-identifier hs-type">ByIndex</span></a></span><span> </span><span class="annot"><span class="hs-number">2</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-421"></span><span>                  </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.IndexingSlicingJoining.html#TransposeF"><span class="hs-identifier hs-type">TransposeF</span></a></span><span>
</span><span id="line-422"></span><span>                      </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SelectDim"><span class="hs-identifier hs-type">SelectDim</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#ByIndex"><span class="hs-identifier hs-type">ByIndex</span></a></span><span> </span><span class="annot"><span class="hs-number">2</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-423"></span><span>                      </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SelectDim"><span class="hs-identifier hs-type">SelectDim</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#ByIndex"><span class="hs-identifier hs-type">ByIndex</span></a></span><span> </span><span class="annot"><span class="hs-number">3</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-424"></span><span>                      </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Functional.Sparse.html#EmbeddingF"><span class="hs-identifier hs-type">EmbeddingF</span></a></span><span>
</span><span id="line-425"></span><span>                          </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Shape"><span class="hs-identifier hs-type">Shape</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="annot"><a href="#local-6989586621679808659"><span class="hs-identifier hs-type">posEncDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679808672"><span class="hs-identifier hs-type">headDim</span></a></span><span class="hs-special">]</span><span class="hs-special">)</span><span>
</span><span id="line-426"></span><span>                          </span><span class="annot"><a href="#local-6989586621679808658"><span class="hs-identifier hs-type">relPosShape</span></a></span><span>
</span><span id="line-427"></span><span>                      </span><span class="hs-special">)</span><span>
</span><span id="line-428"></span><span>                  </span><span class="hs-special">)</span><span>
</span><span id="line-429"></span><span>              </span><span class="hs-special">)</span><span>
</span><span id="line-430"></span><span>              </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.IndexingSlicingJoining.html#UnsqueezeF"><span class="hs-identifier hs-type">UnsqueezeF</span></a></span><span>
</span><span id="line-431"></span><span>                  </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SelectDim"><span class="hs-identifier hs-type">SelectDim</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#ByIndex"><span class="hs-identifier hs-type">ByIndex</span></a></span><span> </span><span class="annot"><span class="hs-number">1</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-432"></span><span>                  </span><span class="annot"><a href="#local-6989586621679808657"><span class="hs-identifier hs-type">attentionMaskShape</span></a></span><span>
</span><span id="line-433"></span><span>              </span><span class="hs-special">)</span><span>
</span><span id="line-434"></span><span>          </span><span class="hs-special">)</span><span>
</span><span id="line-435"></span><span>      </span><span class="hs-special">)</span><span>
</span><span id="line-436"></span><span>      </span><span class="annot"><a href="#local-6989586621679808677"><span class="hs-identifier hs-type">dropoutGeneratorOutputDevice</span></a></span><span>
</span><span id="line-437"></span><span>      </span><span class="annot"><a href="#local-6989586621679808656"><span class="hs-identifier hs-type">stackOutput</span></a></span><span>
</span><span id="line-438"></span><span>      </span><span class="annot"><a href="#local-6989586621679808655"><span class="hs-identifier hs-type">stackGeneratorOutputDevice</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-439"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasForward"><span class="hs-identifier hs-type">HasForward</span></a></span><span>
</span><span id="line-440"></span><span>      </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Encoder.html#TELayerNormF"><span class="hs-identifier hs-type">TELayerNormF</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#T5"><span class="hs-identifier hs-type">T5</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808675"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808674"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808673"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808669"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-441"></span><span>      </span><span class="annot"><a href="#local-6989586621679808656"><span class="hs-identifier hs-type">stackOutput</span></a></span><span>
</span><span id="line-442"></span><span>      </span><span class="annot"><a href="#local-6989586621679808655"><span class="hs-identifier hs-type">stackGeneratorOutputDevice</span></a></span><span>
</span><span id="line-443"></span><span>      </span><span class="annot"><a href="#local-6989586621679808654"><span class="hs-identifier hs-type">layerNormOutput</span></a></span><span>
</span><span id="line-444"></span><span>      </span><span class="annot"><a href="#local-6989586621679808653"><span class="hs-identifier hs-type">layerNormGeneratorOutputDevice</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-445"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasForward"><span class="hs-identifier hs-type">HasForward</span></a></span><span>
</span><span id="line-446"></span><span>      </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Encoder.html#TEDropoutF"><span class="hs-identifier hs-type">TEDropoutF</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#T5"><span class="hs-identifier hs-type">T5</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-447"></span><span>      </span><span class="annot"><a href="#local-6989586621679808654"><span class="hs-identifier hs-type">layerNormOutput</span></a></span><span>
</span><span id="line-448"></span><span>      </span><span class="annot"><a href="#local-6989586621679808653"><span class="hs-identifier hs-type">layerNormGeneratorOutputDevice</span></a></span><span>
</span><span id="line-449"></span><span>      </span><span class="annot"><a href="#local-6989586621679808652"><span class="hs-identifier hs-type">output</span></a></span><span>
</span><span id="line-450"></span><span>      </span><span class="annot"><a href="#local-6989586621679808651"><span class="hs-identifier hs-type">generatorOutputDevice</span></a></span><span>
</span><span id="line-451"></span><span>  </span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-452"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasForward"><span class="hs-identifier hs-type">HasForward</span></a></span><span>
</span><span id="line-453"></span><span>    </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Encoder.html#TransformerEncoder"><span class="hs-identifier hs-type">TransformerEncoder</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#T5"><span class="hs-identifier hs-type">T5</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808676"><span class="hs-identifier hs-type">numLayers</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808675"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808674"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808673"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808672"><span class="hs-identifier hs-type">headDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808671"><span class="hs-identifier hs-type">headEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808670"><span class="hs-identifier hs-type">embedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808669"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808668"><span class="hs-identifier hs-type">ffnDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808659"><span class="hs-identifier hs-type">posEncDim</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-454"></span><span>    </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="#local-6989586621679808680"><span class="hs-identifier hs-type">input</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-455"></span><span>      </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808667"><span class="hs-identifier hs-type">relPosGradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808665"><span class="hs-identifier hs-type">relPosLayout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808663"><span class="hs-identifier hs-type">relPosDevice</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808661"><span class="hs-identifier hs-type">relPosDataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808658"><span class="hs-identifier hs-type">relPosShape</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-456"></span><span>      </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808666"><span class="hs-identifier hs-type">attentionMaskGradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808664"><span class="hs-identifier hs-type">attentionMaskLayout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808662"><span class="hs-identifier hs-type">attentionMaskDevice</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808660"><span class="hs-identifier hs-type">attentionMaskDataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808657"><span class="hs-identifier hs-type">attentionMaskShape</span></a></span><span>
</span><span id="line-457"></span><span>    </span><span class="hs-special">)</span><span>
</span><span id="line-458"></span><span>    </span><span class="annot"><a href="#local-6989586621679808679"><span class="hs-identifier hs-type">generatorDevice</span></a></span><span>
</span><span id="line-459"></span><span>    </span><span class="annot"><a href="#local-6989586621679808652"><span class="hs-identifier hs-type">output</span></a></span><span>
</span><span id="line-460"></span><span>    </span><span class="annot"><a href="#local-6989586621679808651"><span class="hs-identifier hs-type">generatorOutputDevice</span></a></span><span>
</span><span id="line-461"></span><span>  </span><span class="hs-keyword">where</span><span>
</span><span id="line-462"></span><span>  </span><span id="local-6989586621679808648"><span class="annot"><span class="annottext">forward :: TransformerEncoder
  'T5
  numLayers
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  inputEmbedDim
  ffnDim
  posEncDim
-&gt; (input,
    Tensor
      relPosGradient
      relPosLayout
      relPosDevice
      relPosDataType
      relPosShape,
    Tensor
      attentionMaskGradient
      attentionMaskLayout
      attentionMaskDevice
      attentionMaskDataType
      attentionMaskShape)
-&gt; Generator generatorDevice
-&gt; m (output, Generator generatorOutputDevice)
</span><a href="Torch.GraduallyTyped.NN.Class.html#forward"><span class="hs-identifier hs-var hs-var hs-var hs-var">forward</span></a></span></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Encoder.html#TransformerEncoder"><span class="hs-identifier hs-type">TransformerEncoder</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Encoder.html#GTransformerEncoder"><span class="hs-identifier hs-type">GTransformerEncoder</span></a></span><span> </span><span class="hs-special">{</span><span id="local-6989586621679808642"><span id="local-6989586621679808643"><span id="local-6989586621679808644"><span id="local-6989586621679808645"><span id="local-6989586621679808646"><span class="annot"><span class="annottext">TEPosEncF
  'T5 gradient device dataType headDim inputEmbedDim posEncDim
TEDropoutF 'T5
TELayerNormF 'T5 gradient device dataType inputEmbedDim
TEEmbedLayerNormF 'T5 gradient device dataType inputEmbedDim
TEStackF
  'T5
  numLayers
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  inputEmbedDim
  ffnDim
tePosEnc :: TEPosEncF
  'T5 gradient device dataType headDim inputEmbedDim posEncDim
teDropout :: TEDropoutF 'T5
teLayerNorm :: TELayerNormF 'T5 gradient device dataType inputEmbedDim
teEmbedLayerNorm :: TEEmbedLayerNormF 'T5 gradient device dataType inputEmbedDim
teStack :: TEStackF
  'T5
  numLayers
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  inputEmbedDim
  ffnDim
tePosEnc :: forall stack embedLayerNorm layerNorm dropout posEnc.
GTransformerEncoder stack embedLayerNorm layerNorm dropout posEnc
-&gt; posEnc
teDropout :: forall stack embedLayerNorm layerNorm dropout posEnc.
GTransformerEncoder stack embedLayerNorm layerNorm dropout posEnc
-&gt; dropout
teLayerNorm :: forall stack embedLayerNorm layerNorm dropout posEnc.
GTransformerEncoder stack embedLayerNorm layerNorm dropout posEnc
-&gt; layerNorm
teEmbedLayerNorm :: forall stack embedLayerNorm layerNorm dropout posEnc.
GTransformerEncoder stack embedLayerNorm layerNorm dropout posEnc
-&gt; embedLayerNorm
teStack :: forall stack embedLayerNorm layerNorm dropout posEnc.
GTransformerEncoder stack embedLayerNorm layerNorm dropout posEnc
-&gt; stack
</span><a href="#local-6989586621679808642"><span class="hs-glyph hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var">..</span></a></span></span></span></span></span></span><span class="hs-special">}</span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span id="local-6989586621679808641"><span class="annot"><span class="annottext">input
</span><a href="#local-6989586621679808641"><span class="hs-identifier hs-var">input</span></a></span></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679808640"><span class="annot"><span class="annottext">Tensor
  relPosGradient relPosLayout relPosDevice relPosDataType relPosShape
</span><a href="#local-6989586621679808640"><span class="hs-identifier hs-var">relPos</span></a></span></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679808639"><span class="annot"><span class="annottext">Tensor
  attentionMaskGradient
  attentionMaskLayout
  attentionMaskDevice
  attentionMaskDataType
  attentionMaskShape
</span><a href="#local-6989586621679808639"><span class="hs-identifier hs-var">attentionMask</span></a></span></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-463"></span><span>    </span><span class="hs-keyword">let</span><span> </span><span id="local-6989586621679808638"><span class="annot"><span class="annottext">relPosBias :: IxStateT
  m
  (Generator dropoutGeneratorOutputDevice)
  (Generator dropoutGeneratorOutputDevice)
  (Tensor
     (Or (Gradient RequiresGradient) gradient relPosGradient)
     (Unify (Layout LayoutType) ('Layout 'Dense) relPosLayout)
     (Unify (Device (DeviceType Nat)) device relPosDevice)
     (Seq
        (Unify (DataType DType) relPosDataType ('DataType 'Int64))
        dataType)
     (TransposeF
        ('SelectDim ('ByIndex 1))
        ('SelectDim ('ByIndex 2))
        (TransposeF
           ('SelectDim ('ByIndex 2))
           ('SelectDim ('ByIndex 3))
           (EmbeddingF ('Shape '[posEncDim, headDim]) relPosShape))))
</span><a href="#local-6989586621679808638"><span class="hs-identifier hs-var hs-var">relPosBias</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-464"></span><span>          </span><span class="annot"><span class="annottext">Tensor
  relPosGradient relPosLayout relPosDevice relPosDataType relPosShape
-&gt; IxStateT
     m
     (Generator dropoutGeneratorOutputDevice)
     (Generator dropoutGeneratorOutputDevice)
     (Tensor
        relPosGradient
        relPosLayout
        relPosDevice
        relPosDataType
        relPosShape)
forall k (m :: k -&gt; k -&gt; * -&gt; *) a (i :: k).
IxPointed m =&gt;
a -&gt; m i i a
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-identifier hs-var">ireturn</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor
  relPosGradient relPosLayout relPosDevice relPosDataType relPosShape
</span><a href="#local-6989586621679808640"><span class="hs-identifier hs-var">relPos</span></a></span><span>
</span><span id="line-465"></span><span>            </span><span class="annot"><span class="annottext">IxStateT
  m
  (Generator dropoutGeneratorOutputDevice)
  (Generator dropoutGeneratorOutputDevice)
  (Tensor
     relPosGradient
     relPosLayout
     relPosDevice
     relPosDataType
     relPosShape)
-&gt; (Tensor
      relPosGradient relPosLayout relPosDevice relPosDataType relPosShape
    -&gt; IxStateT
         m
         (Generator dropoutGeneratorOutputDevice)
         (Generator dropoutGeneratorOutputDevice)
         (Tensor
            (Or (Gradient RequiresGradient) gradient relPosGradient)
            (Unify (Layout LayoutType) ('Layout 'Dense) relPosLayout)
            (Unify (Device (DeviceType Nat)) device relPosDevice)
            (Seq
               (Unify (DataType DType) relPosDataType ('DataType 'Int64))
               dataType)
            (EmbeddingF ('Shape '[posEncDim, headDim]) relPosShape)))
-&gt; IxStateT
     m
     (Generator dropoutGeneratorOutputDevice)
     (Generator dropoutGeneratorOutputDevice)
     (Tensor
        (Or (Gradient RequiresGradient) gradient relPosGradient)
        (Unify (Layout LayoutType) ('Layout 'Dense) relPosLayout)
        (Unify (Device (DeviceType Nat)) device relPosDevice)
        (Seq
           (Unify (DataType DType) relPosDataType ('DataType 'Int64))
           dataType)
        (EmbeddingF ('Shape '[posEncDim, headDim]) relPosShape))
forall k1 (m :: k1 -&gt; k1 -&gt; * -&gt; *) (i :: k1) (j :: k1) a
       (k2 :: k1) b.
IxMonad m =&gt;
m i j a -&gt; (a -&gt; m j k2 b) -&gt; m i k2 b
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&gt;&gt;&gt;=</span></a></span><span> </span><span class="annot"><span class="annottext">(Generator dropoutGeneratorOutputDevice
 -&gt; m (Tensor
         (Or (Gradient RequiresGradient) gradient relPosGradient)
         (Unify (Layout LayoutType) ('Layout 'Dense) relPosLayout)
         (Unify (Device (DeviceType Nat)) device relPosDevice)
         (Seq
            (Unify (DataType DType) relPosDataType ('DataType 'Int64))
            dataType)
         (EmbeddingF ('Shape '[posEncDim, headDim]) relPosShape),
       Generator dropoutGeneratorOutputDevice))
-&gt; IxStateT
     m
     (Generator dropoutGeneratorOutputDevice)
     (Generator dropoutGeneratorOutputDevice)
     (Tensor
        (Or (Gradient RequiresGradient) gradient relPosGradient)
        (Unify (Layout LayoutType) ('Layout 'Dense) relPosLayout)
        (Unify (Device (DeviceType Nat)) device relPosDevice)
        (Seq
           (Unify (DataType DType) relPosDataType ('DataType 'Int64))
           dataType)
        (EmbeddingF ('Shape '[posEncDim, headDim]) relPosShape))
forall (m :: * -&gt; *) i j a. (i -&gt; m (a, j)) -&gt; IxStateT m i j a
</span><a href="../file:///nix/store/8vjaffqxij7bih93d9mlzmc7ksanlw0i-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier hs-var">IxStateT</span></a></span><span> </span><span class="annot"><span class="annottext">((Generator dropoutGeneratorOutputDevice
  -&gt; m (Tensor
          (Or (Gradient RequiresGradient) gradient relPosGradient)
          (Unify (Layout LayoutType) ('Layout 'Dense) relPosLayout)
          (Unify (Device (DeviceType Nat)) device relPosDevice)
          (Seq
             (Unify (DataType DType) relPosDataType ('DataType 'Int64))
             dataType)
          (EmbeddingF ('Shape '[posEncDim, headDim]) relPosShape),
        Generator dropoutGeneratorOutputDevice))
 -&gt; IxStateT
      m
      (Generator dropoutGeneratorOutputDevice)
      (Generator dropoutGeneratorOutputDevice)
      (Tensor
         (Or (Gradient RequiresGradient) gradient relPosGradient)
         (Unify (Layout LayoutType) ('Layout 'Dense) relPosLayout)
         (Unify (Device (DeviceType Nat)) device relPosDevice)
         (Seq
            (Unify (DataType DType) relPosDataType ('DataType 'Int64))
            dataType)
         (EmbeddingF ('Shape '[posEncDim, headDim]) relPosShape)))
-&gt; (Tensor
      relPosGradient relPosLayout relPosDevice relPosDataType relPosShape
    -&gt; Generator dropoutGeneratorOutputDevice
    -&gt; m (Tensor
            (Or (Gradient RequiresGradient) gradient relPosGradient)
            (Unify (Layout LayoutType) ('Layout 'Dense) relPosLayout)
            (Unify (Device (DeviceType Nat)) device relPosDevice)
            (Seq
               (Unify (DataType DType) relPosDataType ('DataType 'Int64))
               dataType)
            (EmbeddingF ('Shape '[posEncDim, headDim]) relPosShape),
          Generator dropoutGeneratorOutputDevice))
-&gt; Tensor
     relPosGradient relPosLayout relPosDevice relPosDataType relPosShape
-&gt; IxStateT
     m
     (Generator dropoutGeneratorOutputDevice)
     (Generator dropoutGeneratorOutputDevice)
     (Tensor
        (Or (Gradient RequiresGradient) gradient relPosGradient)
        (Unify (Layout LayoutType) ('Layout 'Dense) relPosLayout)
        (Unify (Device (DeviceType Nat)) device relPosDevice)
        (Seq
           (Unify (DataType DType) relPosDataType ('DataType 'Int64))
           dataType)
        (EmbeddingF ('Shape '[posEncDim, headDim]) relPosShape))
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">Embedding
  gradient
  ('Layout 'Dense)
  device
  dataType
  posEncDim
  headDim
  'Nothing
-&gt; Tensor
     relPosGradient relPosLayout relPosDevice relPosDataType relPosShape
-&gt; Generator dropoutGeneratorOutputDevice
-&gt; m (Tensor
        (Or (Gradient RequiresGradient) gradient relPosGradient)
        (Unify (Layout LayoutType) ('Layout 'Dense) relPosLayout)
        (Unify (Device (DeviceType Nat)) device relPosDevice)
        (Seq
           (Unify (DataType DType) relPosDataType ('DataType 'Int64))
           dataType)
        (EmbeddingF ('Shape '[posEncDim, headDim]) relPosShape),
      Generator dropoutGeneratorOutputDevice)
forall model input (generatorDevice :: Device (DeviceType Nat))
       output (generatorOutputDevice :: Device (DeviceType Nat))
       (m :: * -&gt; *).
(HasForward
   model input generatorDevice output generatorOutputDevice,
 MonadThrow m) =&gt;
model
-&gt; input
-&gt; Generator generatorDevice
-&gt; m (output, Generator generatorOutputDevice)
</span><a href="Torch.GraduallyTyped.NN.Class.html#forward"><span class="hs-identifier hs-var">forward</span></a></span><span> </span><span class="annot"><span class="annottext">Embedding
  gradient
  ('Layout 'Dense)
  device
  dataType
  posEncDim
  headDim
  'Nothing
TEPosEncF
  'T5 gradient device dataType headDim inputEmbedDim posEncDim
</span><a href="#local-6989586621679808642"><span class="hs-identifier hs-var">tePosEnc</span></a></span><span>
</span><span id="line-466"></span><span>            </span><span class="annot"><span class="annottext">IxStateT
  m
  (Generator dropoutGeneratorOutputDevice)
  (Generator dropoutGeneratorOutputDevice)
  (Tensor
     (Or (Gradient RequiresGradient) gradient relPosGradient)
     (Unify (Layout LayoutType) ('Layout 'Dense) relPosLayout)
     (Unify (Device (DeviceType Nat)) device relPosDevice)
     (Seq
        (Unify (DataType DType) relPosDataType ('DataType 'Int64))
        dataType)
     (EmbeddingF ('Shape '[posEncDim, headDim]) relPosShape))
-&gt; (Tensor
      (Or (Gradient RequiresGradient) gradient relPosGradient)
      (Unify (Layout LayoutType) ('Layout 'Dense) relPosLayout)
      (Unify (Device (DeviceType Nat)) device relPosDevice)
      (Seq
         (Unify (DataType DType) relPosDataType ('DataType 'Int64))
         dataType)
      (EmbeddingF ('Shape '[posEncDim, headDim]) relPosShape)
    -&gt; IxStateT
         m
         (Generator dropoutGeneratorOutputDevice)
         (Generator dropoutGeneratorOutputDevice)
         (Tensor
            (Or (Gradient RequiresGradient) gradient relPosGradient)
            (Unify (Layout LayoutType) ('Layout 'Dense) relPosLayout)
            (Unify (Device (DeviceType Nat)) device relPosDevice)
            (Seq
               (Unify (DataType DType) relPosDataType ('DataType 'Int64))
               dataType)
            (TransposeF
               ('SelectDim ('ByIndex 2))
               ('SelectDim ('ByIndex 3))
               (EmbeddingF ('Shape '[posEncDim, headDim]) relPosShape))))
-&gt; IxStateT
     m
     (Generator dropoutGeneratorOutputDevice)
     (Generator dropoutGeneratorOutputDevice)
     (Tensor
        (Or (Gradient RequiresGradient) gradient relPosGradient)
        (Unify (Layout LayoutType) ('Layout 'Dense) relPosLayout)
        (Unify (Device (DeviceType Nat)) device relPosDevice)
        (Seq
           (Unify (DataType DType) relPosDataType ('DataType 'Int64))
           dataType)
        (TransposeF
           ('SelectDim ('ByIndex 2))
           ('SelectDim ('ByIndex 3))
           (EmbeddingF ('Shape '[posEncDim, headDim]) relPosShape)))
forall k1 (m :: k1 -&gt; k1 -&gt; * -&gt; *) (i :: k1) (j :: k1) a
       (k2 :: k1) b.
IxMonad m =&gt;
m i j a -&gt; (a -&gt; m j k2 b) -&gt; m i k2 b
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&gt;&gt;&gt;=</span></a></span><span> </span><span class="annot"><span class="annottext">m (Tensor
     (Or (Gradient RequiresGradient) gradient relPosGradient)
     (Unify (Layout LayoutType) ('Layout 'Dense) relPosLayout)
     (Unify (Device (DeviceType Nat)) device relPosDevice)
     (Seq
        (Unify (DataType DType) relPosDataType ('DataType 'Int64))
        dataType)
     (TransposeF
        ('SelectDim ('ByIndex 2))
        ('SelectDim ('ByIndex 3))
        (EmbeddingF ('Shape '[posEncDim, headDim]) relPosShape)))
-&gt; IxStateT
     m
     (Generator dropoutGeneratorOutputDevice)
     (Generator dropoutGeneratorOutputDevice)
     (Tensor
        (Or (Gradient RequiresGradient) gradient relPosGradient)
        (Unify (Layout LayoutType) ('Layout 'Dense) relPosLayout)
        (Unify (Device (DeviceType Nat)) device relPosDevice)
        (Seq
           (Unify (DataType DType) relPosDataType ('DataType 'Int64))
           dataType)
        (TransposeF
           ('SelectDim ('ByIndex 2))
           ('SelectDim ('ByIndex 3))
           (EmbeddingF ('Shape '[posEncDim, headDim]) relPosShape)))
forall k (t :: (* -&gt; *) -&gt; k -&gt; k -&gt; * -&gt; *) (m :: * -&gt; *) a
       (i :: k).
(IxMonadTrans t, Monad m) =&gt;
m a -&gt; t m i i a
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-identifier hs-var">ilift</span></a></span><span> </span><span class="annot"><span class="annottext">(m (Tensor
      (Or (Gradient RequiresGradient) gradient relPosGradient)
      (Unify (Layout LayoutType) ('Layout 'Dense) relPosLayout)
      (Unify (Device (DeviceType Nat)) device relPosDevice)
      (Seq
         (Unify (DataType DType) relPosDataType ('DataType 'Int64))
         dataType)
      (TransposeF
         ('SelectDim ('ByIndex 2))
         ('SelectDim ('ByIndex 3))
         (EmbeddingF ('Shape '[posEncDim, headDim]) relPosShape)))
 -&gt; IxStateT
      m
      (Generator dropoutGeneratorOutputDevice)
      (Generator dropoutGeneratorOutputDevice)
      (Tensor
         (Or (Gradient RequiresGradient) gradient relPosGradient)
         (Unify (Layout LayoutType) ('Layout 'Dense) relPosLayout)
         (Unify (Device (DeviceType Nat)) device relPosDevice)
         (Seq
            (Unify (DataType DType) relPosDataType ('DataType 'Int64))
            dataType)
         (TransposeF
            ('SelectDim ('ByIndex 2))
            ('SelectDim ('ByIndex 3))
            (EmbeddingF ('Shape '[posEncDim, headDim]) relPosShape))))
-&gt; (Tensor
      (Or (Gradient RequiresGradient) gradient relPosGradient)
      (Unify (Layout LayoutType) ('Layout 'Dense) relPosLayout)
      (Unify (Device (DeviceType Nat)) device relPosDevice)
      (Seq
         (Unify (DataType DType) relPosDataType ('DataType 'Int64))
         dataType)
      (EmbeddingF ('Shape '[posEncDim, headDim]) relPosShape)
    -&gt; m (Tensor
            (Or (Gradient RequiresGradient) gradient relPosGradient)
            (Unify (Layout LayoutType) ('Layout 'Dense) relPosLayout)
            (Unify (Device (DeviceType Nat)) device relPosDevice)
            (Seq
               (Unify (DataType DType) relPosDataType ('DataType 'Int64))
               dataType)
            (TransposeF
               ('SelectDim ('ByIndex 2))
               ('SelectDim ('ByIndex 3))
               (EmbeddingF ('Shape '[posEncDim, headDim]) relPosShape))))
-&gt; Tensor
     (Or (Gradient RequiresGradient) gradient relPosGradient)
     (Unify (Layout LayoutType) ('Layout 'Dense) relPosLayout)
     (Unify (Device (DeviceType Nat)) device relPosDevice)
     (Seq
        (Unify (DataType DType) relPosDataType ('DataType 'Int64))
        dataType)
     (EmbeddingF ('Shape '[posEncDim, headDim]) relPosShape)
-&gt; IxStateT
     m
     (Generator dropoutGeneratorOutputDevice)
     (Generator dropoutGeneratorOutputDevice)
     (Tensor
        (Or (Gradient RequiresGradient) gradient relPosGradient)
        (Unify (Layout LayoutType) ('Layout 'Dense) relPosLayout)
        (Unify (Device (DeviceType Nat)) device relPosDevice)
        (Seq
           (Unify (DataType DType) relPosDataType ('DataType 'Int64))
           dataType)
        (TransposeF
           ('SelectDim ('ByIndex 2))
           ('SelectDim ('ByIndex 3))
           (EmbeddingF ('Shape '[posEncDim, headDim]) relPosShape)))
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">forall (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)])
       (shape' :: Shape [Dim (Name Symbol) (Size Nat)]) (m :: * -&gt; *).
(shape'
 ~ TransposeF
     ('SelectDim ('ByIndex 2)) ('SelectDim ('ByIndex 3)) shape,
 SingI ('SelectDim ('ByIndex 2)), SingI ('SelectDim ('ByIndex 3)),
 MonadThrow m) =&gt;
Tensor gradient layout device dataType shape
-&gt; m (Tensor gradient layout device dataType shape')
forall (selectDim0 :: SelectDim (By Symbol Nat))
       (selectDim1 :: SelectDim (By Symbol Nat))
       (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)])
       (shape' :: Shape [Dim (Name Symbol) (Size Nat)]) (m :: * -&gt; *).
(shape' ~ TransposeF selectDim0 selectDim1 shape, SingI selectDim0,
 SingI selectDim1, MonadThrow m) =&gt;
Tensor gradient layout device dataType shape
-&gt; m (Tensor gradient layout device dataType shape')
</span><a href="Torch.GraduallyTyped.Tensor.IndexingSlicingJoining.html#transpose"><span class="hs-identifier hs-var">transpose</span></a></span><span> </span><span class="hs-glyph">@</span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SelectDim"><span class="hs-identifier hs-type">SelectDim</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#ByIndex"><span class="hs-identifier hs-type">ByIndex</span></a></span><span> </span><span class="annot"><span class="hs-number">2</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span> </span><span class="hs-glyph">@</span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SelectDim"><span class="hs-identifier hs-type">SelectDim</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#ByIndex"><span class="hs-identifier hs-type">ByIndex</span></a></span><span> </span><span class="annot"><span class="hs-number">3</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-467"></span><span>            </span><span class="annot"><span class="annottext">IxStateT
  m
  (Generator dropoutGeneratorOutputDevice)
  (Generator dropoutGeneratorOutputDevice)
  (Tensor
     (Or (Gradient RequiresGradient) gradient relPosGradient)
     (Unify (Layout LayoutType) ('Layout 'Dense) relPosLayout)
     (Unify (Device (DeviceType Nat)) device relPosDevice)
     (Seq
        (Unify (DataType DType) relPosDataType ('DataType 'Int64))
        dataType)
     (TransposeF
        ('SelectDim ('ByIndex 2))
        ('SelectDim ('ByIndex 3))
        (EmbeddingF ('Shape '[posEncDim, headDim]) relPosShape)))
-&gt; (Tensor
      (Or (Gradient RequiresGradient) gradient relPosGradient)
      (Unify (Layout LayoutType) ('Layout 'Dense) relPosLayout)
      (Unify (Device (DeviceType Nat)) device relPosDevice)
      (Seq
         (Unify (DataType DType) relPosDataType ('DataType 'Int64))
         dataType)
      (TransposeF
         ('SelectDim ('ByIndex 2))
         ('SelectDim ('ByIndex 3))
         (EmbeddingF ('Shape '[posEncDim, headDim]) relPosShape))
    -&gt; IxStateT
         m
         (Generator dropoutGeneratorOutputDevice)
         (Generator dropoutGeneratorOutputDevice)
         (Tensor
            (Or (Gradient RequiresGradient) gradient relPosGradient)
            (Unify (Layout LayoutType) ('Layout 'Dense) relPosLayout)
            (Unify (Device (DeviceType Nat)) device relPosDevice)
            (Seq
               (Unify (DataType DType) relPosDataType ('DataType 'Int64))
               dataType)
            (TransposeF
               ('SelectDim ('ByIndex 1))
               ('SelectDim ('ByIndex 2))
               (TransposeF
                  ('SelectDim ('ByIndex 2))
                  ('SelectDim ('ByIndex 3))
                  (EmbeddingF ('Shape '[posEncDim, headDim]) relPosShape)))))
-&gt; IxStateT
     m
     (Generator dropoutGeneratorOutputDevice)
     (Generator dropoutGeneratorOutputDevice)
     (Tensor
        (Or (Gradient RequiresGradient) gradient relPosGradient)
        (Unify (Layout LayoutType) ('Layout 'Dense) relPosLayout)
        (Unify (Device (DeviceType Nat)) device relPosDevice)
        (Seq
           (Unify (DataType DType) relPosDataType ('DataType 'Int64))
           dataType)
        (TransposeF
           ('SelectDim ('ByIndex 1))
           ('SelectDim ('ByIndex 2))
           (TransposeF
              ('SelectDim ('ByIndex 2))
              ('SelectDim ('ByIndex 3))
              (EmbeddingF ('Shape '[posEncDim, headDim]) relPosShape))))
forall k1 (m :: k1 -&gt; k1 -&gt; * -&gt; *) (i :: k1) (j :: k1) a
       (k2 :: k1) b.
IxMonad m =&gt;
m i j a -&gt; (a -&gt; m j k2 b) -&gt; m i k2 b
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&gt;&gt;&gt;=</span></a></span><span> </span><span class="annot"><span class="annottext">m (Tensor
     (Or (Gradient RequiresGradient) gradient relPosGradient)
     (Unify (Layout LayoutType) ('Layout 'Dense) relPosLayout)
     (Unify (Device (DeviceType Nat)) device relPosDevice)
     (Seq
        (Unify (DataType DType) relPosDataType ('DataType 'Int64))
        dataType)
     (TransposeF
        ('SelectDim ('ByIndex 1))
        ('SelectDim ('ByIndex 2))
        (TransposeF
           ('SelectDim ('ByIndex 2))
           ('SelectDim ('ByIndex 3))
           (EmbeddingF ('Shape '[posEncDim, headDim]) relPosShape))))
-&gt; IxStateT
     m
     (Generator dropoutGeneratorOutputDevice)
     (Generator dropoutGeneratorOutputDevice)
     (Tensor
        (Or (Gradient RequiresGradient) gradient relPosGradient)
        (Unify (Layout LayoutType) ('Layout 'Dense) relPosLayout)
        (Unify (Device (DeviceType Nat)) device relPosDevice)
        (Seq
           (Unify (DataType DType) relPosDataType ('DataType 'Int64))
           dataType)
        (TransposeF
           ('SelectDim ('ByIndex 1))
           ('SelectDim ('ByIndex 2))
           (TransposeF
              ('SelectDim ('ByIndex 2))
              ('SelectDim ('ByIndex 3))
              (EmbeddingF ('Shape '[posEncDim, headDim]) relPosShape))))
forall k (t :: (* -&gt; *) -&gt; k -&gt; k -&gt; * -&gt; *) (m :: * -&gt; *) a
       (i :: k).
(IxMonadTrans t, Monad m) =&gt;
m a -&gt; t m i i a
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-identifier hs-var">ilift</span></a></span><span> </span><span class="annot"><span class="annottext">(m (Tensor
      (Or (Gradient RequiresGradient) gradient relPosGradient)
      (Unify (Layout LayoutType) ('Layout 'Dense) relPosLayout)
      (Unify (Device (DeviceType Nat)) device relPosDevice)
      (Seq
         (Unify (DataType DType) relPosDataType ('DataType 'Int64))
         dataType)
      (TransposeF
         ('SelectDim ('ByIndex 1))
         ('SelectDim ('ByIndex 2))
         (TransposeF
            ('SelectDim ('ByIndex 2))
            ('SelectDim ('ByIndex 3))
            (EmbeddingF ('Shape '[posEncDim, headDim]) relPosShape))))
 -&gt; IxStateT
      m
      (Generator dropoutGeneratorOutputDevice)
      (Generator dropoutGeneratorOutputDevice)
      (Tensor
         (Or (Gradient RequiresGradient) gradient relPosGradient)
         (Unify (Layout LayoutType) ('Layout 'Dense) relPosLayout)
         (Unify (Device (DeviceType Nat)) device relPosDevice)
         (Seq
            (Unify (DataType DType) relPosDataType ('DataType 'Int64))
            dataType)
         (TransposeF
            ('SelectDim ('ByIndex 1))
            ('SelectDim ('ByIndex 2))
            (TransposeF
               ('SelectDim ('ByIndex 2))
               ('SelectDim ('ByIndex 3))
               (EmbeddingF ('Shape '[posEncDim, headDim]) relPosShape)))))
-&gt; (Tensor
      (Or (Gradient RequiresGradient) gradient relPosGradient)
      (Unify (Layout LayoutType) ('Layout 'Dense) relPosLayout)
      (Unify (Device (DeviceType Nat)) device relPosDevice)
      (Seq
         (Unify (DataType DType) relPosDataType ('DataType 'Int64))
         dataType)
      (TransposeF
         ('SelectDim ('ByIndex 2))
         ('SelectDim ('ByIndex 3))
         (EmbeddingF ('Shape '[posEncDim, headDim]) relPosShape))
    -&gt; m (Tensor
            (Or (Gradient RequiresGradient) gradient relPosGradient)
            (Unify (Layout LayoutType) ('Layout 'Dense) relPosLayout)
            (Unify (Device (DeviceType Nat)) device relPosDevice)
            (Seq
               (Unify (DataType DType) relPosDataType ('DataType 'Int64))
               dataType)
            (TransposeF
               ('SelectDim ('ByIndex 1))
               ('SelectDim ('ByIndex 2))
               (TransposeF
                  ('SelectDim ('ByIndex 2))
                  ('SelectDim ('ByIndex 3))
                  (EmbeddingF ('Shape '[posEncDim, headDim]) relPosShape)))))
-&gt; Tensor
     (Or (Gradient RequiresGradient) gradient relPosGradient)
     (Unify (Layout LayoutType) ('Layout 'Dense) relPosLayout)
     (Unify (Device (DeviceType Nat)) device relPosDevice)
     (Seq
        (Unify (DataType DType) relPosDataType ('DataType 'Int64))
        dataType)
     (TransposeF
        ('SelectDim ('ByIndex 2))
        ('SelectDim ('ByIndex 3))
        (EmbeddingF ('Shape '[posEncDim, headDim]) relPosShape))
-&gt; IxStateT
     m
     (Generator dropoutGeneratorOutputDevice)
     (Generator dropoutGeneratorOutputDevice)
     (Tensor
        (Or (Gradient RequiresGradient) gradient relPosGradient)
        (Unify (Layout LayoutType) ('Layout 'Dense) relPosLayout)
        (Unify (Device (DeviceType Nat)) device relPosDevice)
        (Seq
           (Unify (DataType DType) relPosDataType ('DataType 'Int64))
           dataType)
        (TransposeF
           ('SelectDim ('ByIndex 1))
           ('SelectDim ('ByIndex 2))
           (TransposeF
              ('SelectDim ('ByIndex 2))
              ('SelectDim ('ByIndex 3))
              (EmbeddingF ('Shape '[posEncDim, headDim]) relPosShape))))
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">forall (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)])
       (shape' :: Shape [Dim (Name Symbol) (Size Nat)]) (m :: * -&gt; *).
(shape'
 ~ TransposeF
     ('SelectDim ('ByIndex 1)) ('SelectDim ('ByIndex 2)) shape,
 SingI ('SelectDim ('ByIndex 1)), SingI ('SelectDim ('ByIndex 2)),
 MonadThrow m) =&gt;
Tensor gradient layout device dataType shape
-&gt; m (Tensor gradient layout device dataType shape')
forall (selectDim0 :: SelectDim (By Symbol Nat))
       (selectDim1 :: SelectDim (By Symbol Nat))
       (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)])
       (shape' :: Shape [Dim (Name Symbol) (Size Nat)]) (m :: * -&gt; *).
(shape' ~ TransposeF selectDim0 selectDim1 shape, SingI selectDim0,
 SingI selectDim1, MonadThrow m) =&gt;
Tensor gradient layout device dataType shape
-&gt; m (Tensor gradient layout device dataType shape')
</span><a href="Torch.GraduallyTyped.Tensor.IndexingSlicingJoining.html#transpose"><span class="hs-identifier hs-var">transpose</span></a></span><span> </span><span class="hs-glyph">@</span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SelectDim"><span class="hs-identifier hs-type">SelectDim</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#ByIndex"><span class="hs-identifier hs-type">ByIndex</span></a></span><span> </span><span class="annot"><span class="hs-number">1</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span> </span><span class="hs-glyph">@</span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SelectDim"><span class="hs-identifier hs-type">SelectDim</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#ByIndex"><span class="hs-identifier hs-type">ByIndex</span></a></span><span> </span><span class="annot"><span class="hs-number">2</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-468"></span><span>        </span><span id="local-6989586621679808637"><span class="annot"><span class="annottext">attentionBias :: IxStateT
  m
  (Generator dropoutGeneratorOutputDevice)
  (Generator dropoutGeneratorOutputDevice)
  (Tensor
     (Or
        (Gradient RequiresGradient)
        (Or (Gradient RequiresGradient) gradient relPosGradient)
        attentionMaskGradient)
     (Unify
        (Layout LayoutType)
        (Unify (Layout LayoutType) ('Layout 'Dense) relPosLayout)
        attentionMaskLayout)
     (Unify
        (Device (DeviceType Nat))
        (Unify (Device (DeviceType Nat)) device relPosDevice)
        attentionMaskDevice)
     (Unify
        (DataType DType)
        (Seq
           (Unify (DataType DType) relPosDataType ('DataType 'Int64))
           dataType)
        attentionMaskDataType)
     (BroadcastShapesF
        (TransposeF
           ('SelectDim ('ByIndex 1))
           ('SelectDim ('ByIndex 2))
           (TransposeF
              ('SelectDim ('ByIndex 2))
              ('SelectDim ('ByIndex 3))
              (EmbeddingF ('Shape '[posEncDim, headDim]) relPosShape)))
        (UnsqueezeF ('SelectDim ('ByIndex 1)) attentionMaskShape)))
</span><a href="#local-6989586621679808637"><span class="hs-identifier hs-var hs-var">attentionBias</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-469"></span><span>          </span><span class="annot"><span class="annottext">IxStateT
  m
  (Generator dropoutGeneratorOutputDevice)
  (Generator dropoutGeneratorOutputDevice)
  (Tensor
     (Or (Gradient RequiresGradient) gradient relPosGradient)
     (Unify (Layout LayoutType) ('Layout 'Dense) relPosLayout)
     (Unify (Device (DeviceType Nat)) device relPosDevice)
     (Seq
        (Unify (DataType DType) relPosDataType ('DataType 'Int64))
        dataType)
     (TransposeF
        ('SelectDim ('ByIndex 1))
        ('SelectDim ('ByIndex 2))
        (TransposeF
           ('SelectDim ('ByIndex 2))
           ('SelectDim ('ByIndex 3))
           (EmbeddingF ('Shape '[posEncDim, headDim]) relPosShape))))
</span><a href="#local-6989586621679808638"><span class="hs-identifier hs-var">relPosBias</span></a></span><span>
</span><span id="line-470"></span><span>            </span><span class="annot"><span class="annottext">IxStateT
  m
  (Generator dropoutGeneratorOutputDevice)
  (Generator dropoutGeneratorOutputDevice)
  (Tensor
     (Or (Gradient RequiresGradient) gradient relPosGradient)
     (Unify (Layout LayoutType) ('Layout 'Dense) relPosLayout)
     (Unify (Device (DeviceType Nat)) device relPosDevice)
     (Seq
        (Unify (DataType DType) relPosDataType ('DataType 'Int64))
        dataType)
     (TransposeF
        ('SelectDim ('ByIndex 1))
        ('SelectDim ('ByIndex 2))
        (TransposeF
           ('SelectDim ('ByIndex 2))
           ('SelectDim ('ByIndex 3))
           (EmbeddingF ('Shape '[posEncDim, headDim]) relPosShape))))
-&gt; (Tensor
      (Or (Gradient RequiresGradient) gradient relPosGradient)
      (Unify (Layout LayoutType) ('Layout 'Dense) relPosLayout)
      (Unify (Device (DeviceType Nat)) device relPosDevice)
      (Seq
         (Unify (DataType DType) relPosDataType ('DataType 'Int64))
         dataType)
      (TransposeF
         ('SelectDim ('ByIndex 1))
         ('SelectDim ('ByIndex 2))
         (TransposeF
            ('SelectDim ('ByIndex 2))
            ('SelectDim ('ByIndex 3))
            (EmbeddingF ('Shape '[posEncDim, headDim]) relPosShape)))
    -&gt; IxStateT
         m
         (Generator dropoutGeneratorOutputDevice)
         (Generator dropoutGeneratorOutputDevice)
         (Tensor
            (Or
               (Gradient RequiresGradient)
               (Or (Gradient RequiresGradient) gradient relPosGradient)
               attentionMaskGradient)
            (Unify
               (Layout LayoutType)
               (Unify (Layout LayoutType) ('Layout 'Dense) relPosLayout)
               attentionMaskLayout)
            (Unify
               (Device (DeviceType Nat))
               (Unify (Device (DeviceType Nat)) device relPosDevice)
               attentionMaskDevice)
            (Unify
               (DataType DType)
               (Seq
                  (Unify (DataType DType) relPosDataType ('DataType 'Int64))
                  dataType)
               attentionMaskDataType)
            (BroadcastShapesF
               (TransposeF
                  ('SelectDim ('ByIndex 1))
                  ('SelectDim ('ByIndex 2))
                  (TransposeF
                     ('SelectDim ('ByIndex 2))
                     ('SelectDim ('ByIndex 3))
                     (EmbeddingF ('Shape '[posEncDim, headDim]) relPosShape)))
               (UnsqueezeF ('SelectDim ('ByIndex 1)) attentionMaskShape))))
-&gt; IxStateT
     m
     (Generator dropoutGeneratorOutputDevice)
     (Generator dropoutGeneratorOutputDevice)
     (Tensor
        (Or
           (Gradient RequiresGradient)
           (Or (Gradient RequiresGradient) gradient relPosGradient)
           attentionMaskGradient)
        (Unify
           (Layout LayoutType)
           (Unify (Layout LayoutType) ('Layout 'Dense) relPosLayout)
           attentionMaskLayout)
        (Unify
           (Device (DeviceType Nat))
           (Unify (Device (DeviceType Nat)) device relPosDevice)
           attentionMaskDevice)
        (Unify
           (DataType DType)
           (Seq
              (Unify (DataType DType) relPosDataType ('DataType 'Int64))
              dataType)
           attentionMaskDataType)
        (BroadcastShapesF
           (TransposeF
              ('SelectDim ('ByIndex 1))
              ('SelectDim ('ByIndex 2))
              (TransposeF
                 ('SelectDim ('ByIndex 2))
                 ('SelectDim ('ByIndex 3))
                 (EmbeddingF ('Shape '[posEncDim, headDim]) relPosShape)))
           (UnsqueezeF ('SelectDim ('ByIndex 1)) attentionMaskShape)))
forall k1 (m :: k1 -&gt; k1 -&gt; * -&gt; *) (i :: k1) (j :: k1) a
       (k2 :: k1) b.
IxMonad m =&gt;
m i j a -&gt; (a -&gt; m j k2 b) -&gt; m i k2 b
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&gt;&gt;&gt;=</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor
  (Or
     (Gradient RequiresGradient)
     (Or (Gradient RequiresGradient) gradient relPosGradient)
     attentionMaskGradient)
  (Unify
     (Layout LayoutType)
     (Unify (Layout LayoutType) ('Layout 'Dense) relPosLayout)
     attentionMaskLayout)
  (Unify
     (Device (DeviceType Nat))
     (Unify (Device (DeviceType Nat)) device relPosDevice)
     attentionMaskDevice)
  (Unify
     (DataType DType)
     (Seq
        (Unify (DataType DType) relPosDataType ('DataType 'Int64))
        dataType)
     attentionMaskDataType)
  (BroadcastShapesF
     (TransposeF
        ('SelectDim ('ByIndex 1))
        ('SelectDim ('ByIndex 2))
        (TransposeF
           ('SelectDim ('ByIndex 2))
           ('SelectDim ('ByIndex 3))
           (EmbeddingF ('Shape '[posEncDim, headDim]) relPosShape)))
     (UnsqueezeF ('SelectDim ('ByIndex 1)) attentionMaskShape))
-&gt; IxStateT
     m
     (Generator dropoutGeneratorOutputDevice)
     (Generator dropoutGeneratorOutputDevice)
     (Tensor
        (Or
           (Gradient RequiresGradient)
           (Or (Gradient RequiresGradient) gradient relPosGradient)
           attentionMaskGradient)
        (Unify
           (Layout LayoutType)
           (Unify (Layout LayoutType) ('Layout 'Dense) relPosLayout)
           attentionMaskLayout)
        (Unify
           (Device (DeviceType Nat))
           (Unify (Device (DeviceType Nat)) device relPosDevice)
           attentionMaskDevice)
        (Unify
           (DataType DType)
           (Seq
              (Unify (DataType DType) relPosDataType ('DataType 'Int64))
              dataType)
           attentionMaskDataType)
        (BroadcastShapesF
           (TransposeF
              ('SelectDim ('ByIndex 1))
              ('SelectDim ('ByIndex 2))
              (TransposeF
                 ('SelectDim ('ByIndex 2))
                 ('SelectDim ('ByIndex 3))
                 (EmbeddingF ('Shape '[posEncDim, headDim]) relPosShape)))
           (UnsqueezeF ('SelectDim ('ByIndex 1)) attentionMaskShape)))
forall k (m :: k -&gt; k -&gt; * -&gt; *) a (i :: k).
IxPointed m =&gt;
a -&gt; m i i a
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-identifier hs-var">ireturn</span></a></span><span> </span><span class="annot"><span class="annottext">(Tensor
   (Or
      (Gradient RequiresGradient)
      (Or (Gradient RequiresGradient) gradient relPosGradient)
      attentionMaskGradient)
   (Unify
      (Layout LayoutType)
      (Unify (Layout LayoutType) ('Layout 'Dense) relPosLayout)
      attentionMaskLayout)
   (Unify
      (Device (DeviceType Nat))
      (Unify (Device (DeviceType Nat)) device relPosDevice)
      attentionMaskDevice)
   (Unify
      (DataType DType)
      (Seq
         (Unify (DataType DType) relPosDataType ('DataType 'Int64))
         dataType)
      attentionMaskDataType)
   (BroadcastShapesF
      (TransposeF
         ('SelectDim ('ByIndex 1))
         ('SelectDim ('ByIndex 2))
         (TransposeF
            ('SelectDim ('ByIndex 2))
            ('SelectDim ('ByIndex 3))
            (EmbeddingF ('Shape '[posEncDim, headDim]) relPosShape)))
      (UnsqueezeF ('SelectDim ('ByIndex 1)) attentionMaskShape))
 -&gt; IxStateT
      m
      (Generator dropoutGeneratorOutputDevice)
      (Generator dropoutGeneratorOutputDevice)
      (Tensor
         (Or
            (Gradient RequiresGradient)
            (Or (Gradient RequiresGradient) gradient relPosGradient)
            attentionMaskGradient)
         (Unify
            (Layout LayoutType)
            (Unify (Layout LayoutType) ('Layout 'Dense) relPosLayout)
            attentionMaskLayout)
         (Unify
            (Device (DeviceType Nat))
            (Unify (Device (DeviceType Nat)) device relPosDevice)
            attentionMaskDevice)
         (Unify
            (DataType DType)
            (Seq
               (Unify (DataType DType) relPosDataType ('DataType 'Int64))
               dataType)
            attentionMaskDataType)
         (BroadcastShapesF
            (TransposeF
               ('SelectDim ('ByIndex 1))
               ('SelectDim ('ByIndex 2))
               (TransposeF
                  ('SelectDim ('ByIndex 2))
                  ('SelectDim ('ByIndex 3))
                  (EmbeddingF ('Shape '[posEncDim, headDim]) relPosShape)))
            (UnsqueezeF ('SelectDim ('ByIndex 1)) attentionMaskShape))))
-&gt; (Tensor
      (Or (Gradient RequiresGradient) gradient relPosGradient)
      (Unify (Layout LayoutType) ('Layout 'Dense) relPosLayout)
      (Unify (Device (DeviceType Nat)) device relPosDevice)
      (Seq
         (Unify (DataType DType) relPosDataType ('DataType 'Int64))
         dataType)
      (TransposeF
         ('SelectDim ('ByIndex 1))
         ('SelectDim ('ByIndex 2))
         (TransposeF
            ('SelectDim ('ByIndex 2))
            ('SelectDim ('ByIndex 3))
            (EmbeddingF ('Shape '[posEncDim, headDim]) relPosShape)))
    -&gt; Tensor
         (Or
            (Gradient RequiresGradient)
            (Or (Gradient RequiresGradient) gradient relPosGradient)
            attentionMaskGradient)
         (Unify
            (Layout LayoutType)
            (Unify (Layout LayoutType) ('Layout 'Dense) relPosLayout)
            attentionMaskLayout)
         (Unify
            (Device (DeviceType Nat))
            (Unify (Device (DeviceType Nat)) device relPosDevice)
            attentionMaskDevice)
         (Unify
            (DataType DType)
            (Seq
               (Unify (DataType DType) relPosDataType ('DataType 'Int64))
               dataType)
            attentionMaskDataType)
         (BroadcastShapesF
            (TransposeF
               ('SelectDim ('ByIndex 1))
               ('SelectDim ('ByIndex 2))
               (TransposeF
                  ('SelectDim ('ByIndex 2))
                  ('SelectDim ('ByIndex 3))
                  (EmbeddingF ('Shape '[posEncDim, headDim]) relPosShape)))
            (UnsqueezeF ('SelectDim ('ByIndex 1)) attentionMaskShape)))
-&gt; Tensor
     (Or (Gradient RequiresGradient) gradient relPosGradient)
     (Unify (Layout LayoutType) ('Layout 'Dense) relPosLayout)
     (Unify (Device (DeviceType Nat)) device relPosDevice)
     (Seq
        (Unify (DataType DType) relPosDataType ('DataType 'Int64))
        dataType)
     (TransposeF
        ('SelectDim ('ByIndex 1))
        ('SelectDim ('ByIndex 2))
        (TransposeF
           ('SelectDim ('ByIndex 2))
           ('SelectDim ('ByIndex 3))
           (EmbeddingF ('Shape '[posEncDim, headDim]) relPosShape)))
-&gt; IxStateT
     m
     (Generator dropoutGeneratorOutputDevice)
     (Generator dropoutGeneratorOutputDevice)
     (Tensor
        (Or
           (Gradient RequiresGradient)
           (Or (Gradient RequiresGradient) gradient relPosGradient)
           attentionMaskGradient)
        (Unify
           (Layout LayoutType)
           (Unify (Layout LayoutType) ('Layout 'Dense) relPosLayout)
           attentionMaskLayout)
        (Unify
           (Device (DeviceType Nat))
           (Unify (Device (DeviceType Nat)) device relPosDevice)
           attentionMaskDevice)
        (Unify
           (DataType DType)
           (Seq
              (Unify (DataType DType) relPosDataType ('DataType 'Int64))
              dataType)
           attentionMaskDataType)
        (BroadcastShapesF
           (TransposeF
              ('SelectDim ('ByIndex 1))
              ('SelectDim ('ByIndex 2))
              (TransposeF
                 ('SelectDim ('ByIndex 2))
                 ('SelectDim ('ByIndex 3))
                 (EmbeddingF ('Shape '[posEncDim, headDim]) relPosShape)))
           (UnsqueezeF ('SelectDim ('ByIndex 1)) attentionMaskShape)))
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">Tensor
  (Or (Gradient RequiresGradient) gradient relPosGradient)
  (Unify (Layout LayoutType) ('Layout 'Dense) relPosLayout)
  (Unify (Device (DeviceType Nat)) device relPosDevice)
  (Seq
     (Unify (DataType DType) relPosDataType ('DataType 'Int64))
     dataType)
  (TransposeF
     ('SelectDim ('ByIndex 1))
     ('SelectDim ('ByIndex 2))
     (TransposeF
        ('SelectDim ('ByIndex 2))
        ('SelectDim ('ByIndex 3))
        (EmbeddingF ('Shape '[posEncDim, headDim]) relPosShape)))
-&gt; Tensor
     attentionMaskGradient
     attentionMaskLayout
     attentionMaskDevice
     attentionMaskDataType
     (UnsqueezeF ('SelectDim ('ByIndex 1)) attentionMaskShape)
-&gt; Tensor
     (Or (Gradient RequiresGradient) gradient relPosGradient
      &lt;|&gt; attentionMaskGradient)
     (Unify (Layout LayoutType) ('Layout 'Dense) relPosLayout
      &lt;+&gt; attentionMaskLayout)
     (Unify (Device (DeviceType Nat)) device relPosDevice
      &lt;+&gt; attentionMaskDevice)
     (Seq
        (Unify (DataType DType) relPosDataType ('DataType 'Int64)) dataType
      &lt;+&gt; attentionMaskDataType)
     (BroadcastShapesF
        (TransposeF
           ('SelectDim ('ByIndex 1))
           ('SelectDim ('ByIndex 2))
           (TransposeF
              ('SelectDim ('ByIndex 2))
              ('SelectDim ('ByIndex 3))
              (EmbeddingF ('Shape '[posEncDim, headDim]) relPosShape)))
        (UnsqueezeF ('SelectDim ('ByIndex 1)) attentionMaskShape))
forall (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)])
       (gradient' :: Gradient RequiresGradient)
       (layout' :: Layout LayoutType) (device' :: Device (DeviceType Nat))
       (dataType' :: DataType DType)
       (shape' :: Shape [Dim (Name Symbol) (Size Nat)]).
Tensor gradient layout device dataType shape
-&gt; Tensor gradient' layout' device' dataType' shape'
-&gt; Tensor
     (gradient &lt;|&gt; gradient')
     (layout &lt;+&gt; layout')
     (device &lt;+&gt; device')
     (dataType &lt;+&gt; dataType')
     (BroadcastShapesF shape shape')
</span><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#add"><span class="hs-operator hs-var">`add`</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor
  attentionMaskGradient
  attentionMaskLayout
  attentionMaskDevice
  attentionMaskDataType
  attentionMaskShape
-&gt; Tensor
     attentionMaskGradient
     attentionMaskLayout
     attentionMaskDevice
     attentionMaskDataType
     (UnsqueezeF ('SelectDim ('ByIndex 1)) attentionMaskShape)
forall (selectDim :: SelectDim (By Symbol Nat))
       (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)])
       (shape' :: Shape [Dim (Name Symbol) (Size Nat)]).
(shape' ~ UnsqueezeF selectDim shape, SingI selectDim) =&gt;
Tensor gradient layout device dataType shape
-&gt; Tensor gradient layout device dataType shape'
</span><a href="Torch.GraduallyTyped.Tensor.IndexingSlicingJoining.html#unsqueeze"><span class="hs-identifier hs-var">unsqueeze</span></a></span><span> </span><span class="hs-glyph">@</span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SelectDim"><span class="hs-identifier hs-type">SelectDim</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#ByIndex"><span class="hs-identifier hs-type">ByIndex</span></a></span><span> </span><span class="annot"><span class="hs-number">1</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">Tensor
  attentionMaskGradient
  attentionMaskLayout
  attentionMaskDevice
  attentionMaskDataType
  attentionMaskShape
</span><a href="#local-6989586621679808639"><span class="hs-identifier hs-var">attentionMask</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-471"></span><span>     </span><span class="hs-keyword">in</span><span> </span><span class="annot"><span class="annottext">IxStateT
  m
  (Generator generatorDevice)
  (Generator generatorOutputDevice)
  output
-&gt; Generator generatorDevice
-&gt; m (output, Generator generatorOutputDevice)
forall (m :: * -&gt; *) i j a. IxStateT m i j a -&gt; i -&gt; m (a, j)
</span><a href="../file:///nix/store/8vjaffqxij7bih93d9mlzmc7ksanlw0i-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier hs-var hs-var">runIxStateT</span></a></span><span> </span><span class="annot"><span class="annottext">(IxStateT
   m
   (Generator generatorDevice)
   (Generator generatorOutputDevice)
   output
 -&gt; Generator generatorDevice
 -&gt; m (output, Generator generatorOutputDevice))
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator generatorOutputDevice)
     output
-&gt; Generator generatorDevice
-&gt; m (output, Generator generatorOutputDevice)
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span>
</span><span id="line-472"></span><span>          </span><span class="annot"><span class="annottext">input
-&gt; IxStateT
     m (Generator generatorDevice) (Generator generatorDevice) input
forall k (m :: k -&gt; k -&gt; * -&gt; *) a (i :: k).
IxPointed m =&gt;
a -&gt; m i i a
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-identifier hs-var">ireturn</span></a></span><span> </span><span class="annot"><span class="annottext">input
</span><a href="#local-6989586621679808641"><span class="hs-identifier hs-var">input</span></a></span><span>
</span><span id="line-473"></span><span>            </span><span class="annot"><span class="annottext">IxStateT
  m (Generator generatorDevice) (Generator generatorDevice) input
-&gt; (input
    -&gt; IxStateT
         m
         (Generator generatorDevice)
         (Generator dropoutGeneratorOutputDevice)
         dropoutOutput)
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator dropoutGeneratorOutputDevice)
     dropoutOutput
forall k1 (m :: k1 -&gt; k1 -&gt; * -&gt; *) (i :: k1) (j :: k1) a
       (k2 :: k1) b.
IxMonad m =&gt;
m i j a -&gt; (a -&gt; m j k2 b) -&gt; m i k2 b
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&gt;&gt;&gt;=</span></a></span><span> </span><span class="annot"><span class="annottext">(Generator generatorDevice
 -&gt; m (dropoutOutput, Generator dropoutGeneratorOutputDevice))
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator dropoutGeneratorOutputDevice)
     dropoutOutput
forall (m :: * -&gt; *) i j a. (i -&gt; m (a, j)) -&gt; IxStateT m i j a
</span><a href="../file:///nix/store/8vjaffqxij7bih93d9mlzmc7ksanlw0i-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier hs-var">IxStateT</span></a></span><span> </span><span class="annot"><span class="annottext">((Generator generatorDevice
  -&gt; m (dropoutOutput, Generator dropoutGeneratorOutputDevice))
 -&gt; IxStateT
      m
      (Generator generatorDevice)
      (Generator dropoutGeneratorOutputDevice)
      dropoutOutput)
-&gt; (input
    -&gt; Generator generatorDevice
    -&gt; m (dropoutOutput, Generator dropoutGeneratorOutputDevice))
-&gt; input
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator dropoutGeneratorOutputDevice)
     dropoutOutput
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">Dropout
-&gt; input
-&gt; Generator generatorDevice
-&gt; m (dropoutOutput, Generator dropoutGeneratorOutputDevice)
forall model input (generatorDevice :: Device (DeviceType Nat))
       output (generatorOutputDevice :: Device (DeviceType Nat))
       (m :: * -&gt; *).
(HasForward
   model input generatorDevice output generatorOutputDevice,
 MonadThrow m) =&gt;
model
-&gt; input
-&gt; Generator generatorDevice
-&gt; m (output, Generator generatorOutputDevice)
</span><a href="Torch.GraduallyTyped.NN.Class.html#forward"><span class="hs-identifier hs-var">forward</span></a></span><span> </span><span class="annot"><span class="annottext">Dropout
TEDropoutF 'T5
</span><a href="#local-6989586621679808643"><span class="hs-identifier hs-var">teDropout</span></a></span><span>
</span><span id="line-474"></span><span>            </span><span class="annot"><span class="annottext">IxStateT
  m
  (Generator generatorDevice)
  (Generator dropoutGeneratorOutputDevice)
  dropoutOutput
-&gt; (dropoutOutput
    -&gt; IxStateT
         m
         (Generator dropoutGeneratorOutputDevice)
         (Generator stackGeneratorOutputDevice)
         stackOutput)
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator stackGeneratorOutputDevice)
     stackOutput
forall k1 (m :: k1 -&gt; k1 -&gt; * -&gt; *) (i :: k1) (j :: k1) a
       (k2 :: k1) b.
IxMonad m =&gt;
m i j a -&gt; (a -&gt; m j k2 b) -&gt; m i k2 b
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&gt;&gt;&gt;=</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">\</span><span id="local-6989586621679808636"><span class="annot"><span class="annottext">dropoutOutput
</span><a href="#local-6989586621679808636"><span class="hs-identifier hs-var">input'</span></a></span></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><span class="annottext">IxStateT
  m
  (Generator dropoutGeneratorOutputDevice)
  (Generator dropoutGeneratorOutputDevice)
  (Tensor
     (Or
        (Gradient RequiresGradient)
        (Or (Gradient RequiresGradient) gradient relPosGradient)
        attentionMaskGradient)
     (Unify
        (Layout LayoutType)
        (Unify (Layout LayoutType) ('Layout 'Dense) relPosLayout)
        attentionMaskLayout)
     (Unify
        (Device (DeviceType Nat))
        (Unify (Device (DeviceType Nat)) device relPosDevice)
        attentionMaskDevice)
     (Unify
        (DataType DType)
        (Seq
           (Unify (DataType DType) relPosDataType ('DataType 'Int64))
           dataType)
        attentionMaskDataType)
     (BroadcastShapesF
        (TransposeF
           ('SelectDim ('ByIndex 1))
           ('SelectDim ('ByIndex 2))
           (TransposeF
              ('SelectDim ('ByIndex 2))
              ('SelectDim ('ByIndex 3))
              (EmbeddingF ('Shape '[posEncDim, headDim]) relPosShape)))
        (UnsqueezeF ('SelectDim ('ByIndex 1)) attentionMaskShape)))
</span><a href="#local-6989586621679808637"><span class="hs-identifier hs-var">attentionBias</span></a></span><span> </span><span class="annot"><span class="annottext">IxStateT
  m
  (Generator dropoutGeneratorOutputDevice)
  (Generator dropoutGeneratorOutputDevice)
  (Tensor
     (Or
        (Gradient RequiresGradient)
        (Or (Gradient RequiresGradient) gradient relPosGradient)
        attentionMaskGradient)
     (Unify
        (Layout LayoutType)
        (Unify (Layout LayoutType) ('Layout 'Dense) relPosLayout)
        attentionMaskLayout)
     (Unify
        (Device (DeviceType Nat))
        (Unify (Device (DeviceType Nat)) device relPosDevice)
        attentionMaskDevice)
     (Unify
        (DataType DType)
        (Seq
           (Unify (DataType DType) relPosDataType ('DataType 'Int64))
           dataType)
        attentionMaskDataType)
     (BroadcastShapesF
        (TransposeF
           ('SelectDim ('ByIndex 1))
           ('SelectDim ('ByIndex 2))
           (TransposeF
              ('SelectDim ('ByIndex 2))
              ('SelectDim ('ByIndex 3))
              (EmbeddingF ('Shape '[posEncDim, headDim]) relPosShape)))
        (UnsqueezeF ('SelectDim ('ByIndex 1)) attentionMaskShape)))
-&gt; (Tensor
      (Or
         (Gradient RequiresGradient)
         (Or (Gradient RequiresGradient) gradient relPosGradient)
         attentionMaskGradient)
      (Unify
         (Layout LayoutType)
         (Unify (Layout LayoutType) ('Layout 'Dense) relPosLayout)
         attentionMaskLayout)
      (Unify
         (Device (DeviceType Nat))
         (Unify (Device (DeviceType Nat)) device relPosDevice)
         attentionMaskDevice)
      (Unify
         (DataType DType)
         (Seq
            (Unify (DataType DType) relPosDataType ('DataType 'Int64))
            dataType)
         attentionMaskDataType)
      (BroadcastShapesF
         (TransposeF
            ('SelectDim ('ByIndex 1))
            ('SelectDim ('ByIndex 2))
            (TransposeF
               ('SelectDim ('ByIndex 2))
               ('SelectDim ('ByIndex 3))
               (EmbeddingF ('Shape '[posEncDim, headDim]) relPosShape)))
         (UnsqueezeF ('SelectDim ('ByIndex 1)) attentionMaskShape))
    -&gt; IxStateT
         m
         (Generator dropoutGeneratorOutputDevice)
         (Generator stackGeneratorOutputDevice)
         stackOutput)
-&gt; IxStateT
     m
     (Generator dropoutGeneratorOutputDevice)
     (Generator stackGeneratorOutputDevice)
     stackOutput
forall k1 (m :: k1 -&gt; k1 -&gt; * -&gt; *) (i :: k1) (j :: k1) a
       (k2 :: k1) b.
IxMonad m =&gt;
m i j a -&gt; (a -&gt; m j k2 b) -&gt; m i k2 b
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&gt;&gt;&gt;=</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">\</span><span id="local-6989586621679808635"><span class="annot"><span class="annottext">Tensor
  (Or
     (Gradient RequiresGradient)
     (Or (Gradient RequiresGradient) gradient relPosGradient)
     attentionMaskGradient)
  (Unify
     (Layout LayoutType)
     (Unify (Layout LayoutType) ('Layout 'Dense) relPosLayout)
     attentionMaskLayout)
  (Unify
     (Device (DeviceType Nat))
     (Unify (Device (DeviceType Nat)) device relPosDevice)
     attentionMaskDevice)
  (Unify
     (DataType DType)
     (Seq
        (Unify (DataType DType) relPosDataType ('DataType 'Int64))
        dataType)
     attentionMaskDataType)
  (BroadcastShapesF
     (TransposeF
        ('SelectDim ('ByIndex 1))
        ('SelectDim ('ByIndex 2))
        (TransposeF
           ('SelectDim ('ByIndex 2))
           ('SelectDim ('ByIndex 3))
           (EmbeddingF ('Shape '[posEncDim, headDim]) relPosShape)))
     (UnsqueezeF ('SelectDim ('ByIndex 1)) attentionMaskShape))
</span><a href="#local-6989586621679808635"><span class="hs-identifier hs-var">attentionBias'</span></a></span></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><span class="annottext">(Generator dropoutGeneratorOutputDevice
 -&gt; m (stackOutput, Generator stackGeneratorOutputDevice))
-&gt; IxStateT
     m
     (Generator dropoutGeneratorOutputDevice)
     (Generator stackGeneratorOutputDevice)
     stackOutput
forall (m :: * -&gt; *) i j a. (i -&gt; m (a, j)) -&gt; IxStateT m i j a
</span><a href="../file:///nix/store/8vjaffqxij7bih93d9mlzmc7ksanlw0i-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier hs-var">IxStateT</span></a></span><span> </span><span class="annot"><span class="annottext">((Generator dropoutGeneratorOutputDevice
  -&gt; m (stackOutput, Generator stackGeneratorOutputDevice))
 -&gt; IxStateT
      m
      (Generator dropoutGeneratorOutputDevice)
      (Generator stackGeneratorOutputDevice)
      stackOutput)
-&gt; (Generator dropoutGeneratorOutputDevice
    -&gt; m (stackOutput, Generator stackGeneratorOutputDevice))
-&gt; IxStateT
     m
     (Generator dropoutGeneratorOutputDevice)
     (Generator stackGeneratorOutputDevice)
     stackOutput
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">TransformerStack
  'T5
  numLayers
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  inputEmbedDim
  ffnDim
-&gt; (dropoutOutput,
    Tensor
      (Or
         (Gradient RequiresGradient)
         (Or (Gradient RequiresGradient) gradient relPosGradient)
         attentionMaskGradient)
      (Unify
         (Layout LayoutType)
         (Unify (Layout LayoutType) ('Layout 'Dense) relPosLayout)
         attentionMaskLayout)
      (Unify
         (Device (DeviceType Nat))
         (Unify (Device (DeviceType Nat)) device relPosDevice)
         attentionMaskDevice)
      (Unify
         (DataType DType)
         (Seq
            (Unify (DataType DType) relPosDataType ('DataType 'Int64))
            dataType)
         attentionMaskDataType)
      (BroadcastShapesF
         (TransposeF
            ('SelectDim ('ByIndex 1))
            ('SelectDim ('ByIndex 2))
            (TransposeF
               ('SelectDim ('ByIndex 2))
               ('SelectDim ('ByIndex 3))
               (EmbeddingF ('Shape '[posEncDim, headDim]) relPosShape)))
         (UnsqueezeF ('SelectDim ('ByIndex 1)) attentionMaskShape)))
-&gt; Generator dropoutGeneratorOutputDevice
-&gt; m (stackOutput, Generator stackGeneratorOutputDevice)
forall model input (generatorDevice :: Device (DeviceType Nat))
       output (generatorOutputDevice :: Device (DeviceType Nat))
       (m :: * -&gt; *).
(HasForward
   model input generatorDevice output generatorOutputDevice,
 MonadThrow m) =&gt;
model
-&gt; input
-&gt; Generator generatorDevice
-&gt; m (output, Generator generatorOutputDevice)
</span><a href="Torch.GraduallyTyped.NN.Class.html#forward"><span class="hs-identifier hs-var">forward</span></a></span><span> </span><span class="annot"><span class="annottext">TransformerStack
  'T5
  numLayers
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  inputEmbedDim
  ffnDim
TEStackF
  'T5
  numLayers
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  inputEmbedDim
  ffnDim
</span><a href="#local-6989586621679808646"><span class="hs-identifier hs-var">teStack</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">dropoutOutput
</span><a href="#local-6989586621679808636"><span class="hs-identifier hs-var">input'</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">Tensor
  (Or
     (Gradient RequiresGradient)
     (Or (Gradient RequiresGradient) gradient relPosGradient)
     attentionMaskGradient)
  (Unify
     (Layout LayoutType)
     (Unify (Layout LayoutType) ('Layout 'Dense) relPosLayout)
     attentionMaskLayout)
  (Unify
     (Device (DeviceType Nat))
     (Unify (Device (DeviceType Nat)) device relPosDevice)
     attentionMaskDevice)
  (Unify
     (DataType DType)
     (Seq
        (Unify (DataType DType) relPosDataType ('DataType 'Int64))
        dataType)
     attentionMaskDataType)
  (BroadcastShapesF
     (TransposeF
        ('SelectDim ('ByIndex 1))
        ('SelectDim ('ByIndex 2))
        (TransposeF
           ('SelectDim ('ByIndex 2))
           ('SelectDim ('ByIndex 3))
           (EmbeddingF ('Shape '[posEncDim, headDim]) relPosShape)))
     (UnsqueezeF ('SelectDim ('ByIndex 1)) attentionMaskShape))
</span><a href="#local-6989586621679808635"><span class="hs-identifier hs-var">attentionBias'</span></a></span><span class="hs-special">)</span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-475"></span><span>            </span><span class="annot"><span class="annottext">IxStateT
  m
  (Generator generatorDevice)
  (Generator stackGeneratorOutputDevice)
  stackOutput
-&gt; (stackOutput
    -&gt; IxStateT
         m
         (Generator stackGeneratorOutputDevice)
         (Generator layerNormGeneratorOutputDevice)
         layerNormOutput)
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator layerNormGeneratorOutputDevice)
     layerNormOutput
forall k1 (m :: k1 -&gt; k1 -&gt; * -&gt; *) (i :: k1) (j :: k1) a
       (k2 :: k1) b.
IxMonad m =&gt;
m i j a -&gt; (a -&gt; m j k2 b) -&gt; m i k2 b
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&gt;&gt;&gt;=</span></a></span><span> </span><span class="annot"><span class="annottext">(Generator stackGeneratorOutputDevice
 -&gt; m (layerNormOutput, Generator layerNormGeneratorOutputDevice))
-&gt; IxStateT
     m
     (Generator stackGeneratorOutputDevice)
     (Generator layerNormGeneratorOutputDevice)
     layerNormOutput
forall (m :: * -&gt; *) i j a. (i -&gt; m (a, j)) -&gt; IxStateT m i j a
</span><a href="../file:///nix/store/8vjaffqxij7bih93d9mlzmc7ksanlw0i-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier hs-var">IxStateT</span></a></span><span> </span><span class="annot"><span class="annottext">((Generator stackGeneratorOutputDevice
  -&gt; m (layerNormOutput, Generator layerNormGeneratorOutputDevice))
 -&gt; IxStateT
      m
      (Generator stackGeneratorOutputDevice)
      (Generator layerNormGeneratorOutputDevice)
      layerNormOutput)
-&gt; (stackOutput
    -&gt; Generator stackGeneratorOutputDevice
    -&gt; m (layerNormOutput, Generator layerNormGeneratorOutputDevice))
-&gt; stackOutput
-&gt; IxStateT
     m
     (Generator stackGeneratorOutputDevice)
     (Generator layerNormGeneratorOutputDevice)
     layerNormOutput
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">LayerNorm
  'WithoutBias gradient device dataType ('Shape '[inputEmbedDim])
-&gt; stackOutput
-&gt; Generator stackGeneratorOutputDevice
-&gt; m (layerNormOutput, Generator layerNormGeneratorOutputDevice)
forall model input (generatorDevice :: Device (DeviceType Nat))
       output (generatorOutputDevice :: Device (DeviceType Nat))
       (m :: * -&gt; *).
(HasForward
   model input generatorDevice output generatorOutputDevice,
 MonadThrow m) =&gt;
model
-&gt; input
-&gt; Generator generatorDevice
-&gt; m (output, Generator generatorOutputDevice)
</span><a href="Torch.GraduallyTyped.NN.Class.html#forward"><span class="hs-identifier hs-var">forward</span></a></span><span> </span><span class="annot"><span class="annottext">LayerNorm
  'WithoutBias gradient device dataType ('Shape '[inputEmbedDim])
TELayerNormF 'T5 gradient device dataType inputEmbedDim
</span><a href="#local-6989586621679808644"><span class="hs-identifier hs-var">teLayerNorm</span></a></span><span>
</span><span id="line-476"></span><span>            </span><span class="annot"><span class="annottext">IxStateT
  m
  (Generator generatorDevice)
  (Generator layerNormGeneratorOutputDevice)
  layerNormOutput
-&gt; (layerNormOutput
    -&gt; IxStateT
         m
         (Generator layerNormGeneratorOutputDevice)
         (Generator generatorOutputDevice)
         output)
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator generatorOutputDevice)
     output
forall k1 (m :: k1 -&gt; k1 -&gt; * -&gt; *) (i :: k1) (j :: k1) a
       (k2 :: k1) b.
IxMonad m =&gt;
m i j a -&gt; (a -&gt; m j k2 b) -&gt; m i k2 b
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&gt;&gt;&gt;=</span></a></span><span> </span><span class="annot"><span class="annottext">(Generator layerNormGeneratorOutputDevice
 -&gt; m (output, Generator generatorOutputDevice))
-&gt; IxStateT
     m
     (Generator layerNormGeneratorOutputDevice)
     (Generator generatorOutputDevice)
     output
forall (m :: * -&gt; *) i j a. (i -&gt; m (a, j)) -&gt; IxStateT m i j a
</span><a href="../file:///nix/store/8vjaffqxij7bih93d9mlzmc7ksanlw0i-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier hs-var">IxStateT</span></a></span><span> </span><span class="annot"><span class="annottext">((Generator layerNormGeneratorOutputDevice
  -&gt; m (output, Generator generatorOutputDevice))
 -&gt; IxStateT
      m
      (Generator layerNormGeneratorOutputDevice)
      (Generator generatorOutputDevice)
      output)
-&gt; (layerNormOutput
    -&gt; Generator layerNormGeneratorOutputDevice
    -&gt; m (output, Generator generatorOutputDevice))
-&gt; layerNormOutput
-&gt; IxStateT
     m
     (Generator layerNormGeneratorOutputDevice)
     (Generator generatorOutputDevice)
     output
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">Dropout
-&gt; layerNormOutput
-&gt; Generator layerNormGeneratorOutputDevice
-&gt; m (output, Generator generatorOutputDevice)
forall model input (generatorDevice :: Device (DeviceType Nat))
       output (generatorOutputDevice :: Device (DeviceType Nat))
       (m :: * -&gt; *).
(HasForward
   model input generatorDevice output generatorOutputDevice,
 MonadThrow m) =&gt;
model
-&gt; input
-&gt; Generator generatorDevice
-&gt; m (output, Generator generatorOutputDevice)
</span><a href="Torch.GraduallyTyped.NN.Class.html#forward"><span class="hs-identifier hs-var">forward</span></a></span><span> </span><span class="annot"><span class="annottext">Dropout
TEDropoutF 'T5
</span><a href="#local-6989586621679808643"><span class="hs-identifier hs-var">teDropout</span></a></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span><span>
</span><span id="line-477"></span><span>
</span><span id="line-478"></span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Encoder.html#testEncoder"><span class="hs-identifier hs-type">testEncoder</span></a></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">IO</span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span>
</span><span id="line-479"></span><span id="testEncoder"><span class="annot"><span class="annottext">testEncoder :: IO
  (Tensor
     ('Gradient 'WithGradient)
     ('Layout 'Dense)
     ('Device 'CPU)
     ('DataType 'Float)
     ('Shape
        '[ 'Dim ('Name &quot;*&quot;) ('Size 3), 'Dim ('Name &quot;*&quot;) ('Size 13),
           'Dim ('Name &quot;*&quot;) ('Size 512)]))
</span><a href="Torch.GraduallyTyped.NN.Transformer.Encoder.html#testEncoder"><span class="hs-identifier hs-var hs-var">testEncoder</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="hs-keyword">do</span><span>
</span><span id="line-480"></span><span>  </span><span class="hs-keyword">let</span><span> </span><span id="local-6989586621679808633"><span class="annot"><span class="annottext">gradient :: SGradient ('Gradient 'WithGradient)
</span><a href="#local-6989586621679808633"><span class="hs-identifier hs-var hs-var">gradient</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">SRequiresGradient 'WithGradient
-&gt; SGradient ('Gradient 'WithGradient)
forall (requiresGradient :: RequiresGradient).
SRequiresGradient requiresGradient
-&gt; SGradient ('Gradient requiresGradient)
</span><a href="Torch.GraduallyTyped.RequiresGradient.html#SGradient"><span class="hs-identifier hs-var">SGradient</span></a></span><span> </span><span class="annot"><span class="annottext">SRequiresGradient 'WithGradient
</span><a href="Torch.GraduallyTyped.RequiresGradient.html#SWithGradient"><span class="hs-identifier hs-var">SWithGradient</span></a></span><span>
</span><span id="line-481"></span><span>      </span><span id="local-6989586621679808630"><span class="annot"><span class="annottext">device :: SDevice ('Device 'CPU)
</span><a href="#local-6989586621679808630"><span class="hs-identifier hs-var hs-var">device</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">SDeviceType 'CPU -&gt; SDevice ('Device 'CPU)
forall (deviceType :: DeviceType Nat).
SDeviceType deviceType -&gt; SDevice ('Device deviceType)
</span><a href="Torch.GraduallyTyped.Device.html#SDevice"><span class="hs-identifier hs-var">SDevice</span></a></span><span> </span><span class="annot"><span class="annottext">SDeviceType 'CPU
</span><a href="Torch.GraduallyTyped.Device.html#SCPU"><span class="hs-identifier hs-var">SCPU</span></a></span><span>
</span><span id="line-482"></span><span>      </span><span id="local-6989586621679808627"><span class="annot"><span class="annottext">dataType :: SDataType ('DataType 'Float)
</span><a href="#local-6989586621679808627"><span class="hs-identifier hs-var hs-var">dataType</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">SDType 'Float -&gt; SDataType ('DataType 'Float)
forall (dType :: DType).
SDType dType -&gt; SDataType ('DataType dType)
</span><a href="Torch.GraduallyTyped.DType.html#SDataType"><span class="hs-identifier hs-var">SDataType</span></a></span><span> </span><span class="annot"><span class="annottext">SDType 'Float
</span><a href="Torch.GraduallyTyped.DType.html#SFloat"><span class="hs-identifier hs-var">SFloat</span></a></span><span>
</span><span id="line-483"></span><span>      </span><span id="local-6989586621679808624"><span class="annot"><span class="annottext">headDim :: SDim ('Dim ('Name &quot;*&quot;) ('Size 8))
</span><a href="#local-6989586621679808624"><span class="hs-identifier hs-var hs-var">headDim</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">KnownSymbol &quot;*&quot; =&gt; SName ('Name &quot;*&quot;)
forall (name :: Symbol). KnownSymbol name =&gt; SName ('Name name)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SName"><span class="hs-identifier hs-var">SName</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><span class="hs-string">&quot;*&quot;</span></span><span> </span><span class="annot"><span class="annottext">SName ('Name &quot;*&quot;)
-&gt; SSize ('Size 8) -&gt; SDim ('Dim ('Name &quot;*&quot;) ('Size 8))
forall (name :: Name Symbol) (size :: Size Nat).
SName name -&gt; SSize size -&gt; SDim ('Dim name size)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%26%3A"><span class="hs-operator hs-var">:&amp;:</span></a></span><span> </span><span class="annot"><span class="annottext">KnownNat 8 =&gt; SSize ('Size 8)
forall (size :: Nat). KnownNat size =&gt; SSize ('Size size)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SSize"><span class="hs-identifier hs-var">SSize</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><span class="hs-number">8</span></span><span>
</span><span id="line-484"></span><span>      </span><span id="local-6989586621679808621"><span class="annot"><span class="annottext">headEmbedDim :: SDim ('Dim ('Name &quot;*&quot;) ('Size 64))
</span><a href="#local-6989586621679808621"><span class="hs-identifier hs-var hs-var">headEmbedDim</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">KnownSymbol &quot;*&quot; =&gt; SName ('Name &quot;*&quot;)
forall (name :: Symbol). KnownSymbol name =&gt; SName ('Name name)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SName"><span class="hs-identifier hs-var">SName</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><span class="hs-string">&quot;*&quot;</span></span><span> </span><span class="annot"><span class="annottext">SName ('Name &quot;*&quot;)
-&gt; SSize ('Size 64) -&gt; SDim ('Dim ('Name &quot;*&quot;) ('Size 64))
forall (name :: Name Symbol) (size :: Size Nat).
SName name -&gt; SSize size -&gt; SDim ('Dim name size)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%26%3A"><span class="hs-operator hs-var">:&amp;:</span></a></span><span> </span><span class="annot"><span class="annottext">KnownNat 64 =&gt; SSize ('Size 64)
forall (size :: Nat). KnownNat size =&gt; SSize ('Size size)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SSize"><span class="hs-identifier hs-var">SSize</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><span class="hs-number">64</span></span><span>
</span><span id="line-485"></span><span>      </span><span id="local-6989586621679808620"><span class="annot"><span class="annottext">embedDim :: SDim ('Dim ('Name &quot;*&quot;) ('Size 512))
</span><a href="#local-6989586621679808620"><span class="hs-identifier hs-var hs-var">embedDim</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">KnownSymbol &quot;*&quot; =&gt; SName ('Name &quot;*&quot;)
forall (name :: Symbol). KnownSymbol name =&gt; SName ('Name name)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SName"><span class="hs-identifier hs-var">SName</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><span class="hs-string">&quot;*&quot;</span></span><span> </span><span class="annot"><span class="annottext">SName ('Name &quot;*&quot;)
-&gt; SSize ('Size 512) -&gt; SDim ('Dim ('Name &quot;*&quot;) ('Size 512))
forall (name :: Name Symbol) (size :: Size Nat).
SName name -&gt; SSize size -&gt; SDim ('Dim name size)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%26%3A"><span class="hs-operator hs-var">:&amp;:</span></a></span><span> </span><span class="annot"><span class="annottext">KnownNat 512 =&gt; SSize ('Size 512)
forall (size :: Nat). KnownNat size =&gt; SSize ('Size size)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SSize"><span class="hs-identifier hs-var">SSize</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><span class="hs-number">512</span></span><span>
</span><span id="line-486"></span><span>      </span><span id="local-6989586621679808619"><span class="annot"><span class="annottext">inputEmbedDim :: SDim ('Dim ('Name &quot;*&quot;) ('Size 512))
</span><a href="#local-6989586621679808619"><span class="hs-identifier hs-var hs-var">inputEmbedDim</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">KnownSymbol &quot;*&quot; =&gt; SName ('Name &quot;*&quot;)
forall (name :: Symbol). KnownSymbol name =&gt; SName ('Name name)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SName"><span class="hs-identifier hs-var">SName</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><span class="hs-string">&quot;*&quot;</span></span><span> </span><span class="annot"><span class="annottext">SName ('Name &quot;*&quot;)
-&gt; SSize ('Size 512) -&gt; SDim ('Dim ('Name &quot;*&quot;) ('Size 512))
forall (name :: Name Symbol) (size :: Size Nat).
SName name -&gt; SSize size -&gt; SDim ('Dim name size)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%26%3A"><span class="hs-operator hs-var">:&amp;:</span></a></span><span> </span><span class="annot"><span class="annottext">KnownNat 512 =&gt; SSize ('Size 512)
forall (size :: Nat). KnownNat size =&gt; SSize ('Size size)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SSize"><span class="hs-identifier hs-var">SSize</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><span class="hs-number">512</span></span><span>
</span><span id="line-487"></span><span>      </span><span id="local-6989586621679808618"><span class="annot"><span class="annottext">ffnDim :: SDim ('Dim ('Name &quot;*&quot;) ('Size 2048))
</span><a href="#local-6989586621679808618"><span class="hs-identifier hs-var hs-var">ffnDim</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">KnownSymbol &quot;*&quot; =&gt; SName ('Name &quot;*&quot;)
forall (name :: Symbol). KnownSymbol name =&gt; SName ('Name name)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SName"><span class="hs-identifier hs-var">SName</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><span class="hs-string">&quot;*&quot;</span></span><span> </span><span class="annot"><span class="annottext">SName ('Name &quot;*&quot;)
-&gt; SSize ('Size 2048) -&gt; SDim ('Dim ('Name &quot;*&quot;) ('Size 2048))
forall (name :: Name Symbol) (size :: Size Nat).
SName name -&gt; SSize size -&gt; SDim ('Dim name size)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%26%3A"><span class="hs-operator hs-var">:&amp;:</span></a></span><span> </span><span class="annot"><span class="annottext">KnownNat 2048 =&gt; SSize ('Size 2048)
forall (size :: Nat). KnownNat size =&gt; SSize ('Size size)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SSize"><span class="hs-identifier hs-var">SSize</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><span class="hs-number">2048</span></span><span>
</span><span id="line-488"></span><span>      </span><span id="local-6989586621679808617"><span class="annot"><span class="annottext">posEncDim :: SDim ('Dim ('Name &quot;*&quot;) ('Size 32))
</span><a href="#local-6989586621679808617"><span class="hs-identifier hs-var hs-var">posEncDim</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">KnownSymbol &quot;*&quot; =&gt; SName ('Name &quot;*&quot;)
forall (name :: Symbol). KnownSymbol name =&gt; SName ('Name name)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SName"><span class="hs-identifier hs-var">SName</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><span class="hs-string">&quot;*&quot;</span></span><span> </span><span class="annot"><span class="annottext">SName ('Name &quot;*&quot;)
-&gt; SSize ('Size 32) -&gt; SDim ('Dim ('Name &quot;*&quot;) ('Size 32))
forall (name :: Name Symbol) (size :: Size Nat).
SName name -&gt; SSize size -&gt; SDim ('Dim name size)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%26%3A"><span class="hs-operator hs-var">:&amp;:</span></a></span><span> </span><span class="annot"><span class="annottext">KnownNat 32 =&gt; SSize ('Size 32)
forall (size :: Nat). KnownNat size =&gt; SSize ('Size size)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SSize"><span class="hs-identifier hs-var">SSize</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><span class="hs-number">32</span></span><span>
</span><span id="line-489"></span><span>      </span><span id="local-6989586621679808616"><span class="annot"><span class="annottext">dropoutP :: Double
</span><a href="#local-6989586621679808616"><span class="hs-identifier hs-var hs-var">dropoutP</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Double
</span><span class="hs-number">0.0</span></span><span>
</span><span id="line-490"></span><span>      </span><span id="local-6989586621679808615"><span class="annot"><span class="annottext">eps :: Double
</span><a href="#local-6989586621679808615"><span class="hs-identifier hs-var hs-var">eps</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Double
</span><span class="hs-number">1e-6</span></span><span>
</span><span id="line-491"></span><span>  </span><span class="hs-keyword">let</span><span> </span><span id="local-6989586621679808614"><span class="annot"><span class="annottext">g :: Generator ('Device 'CPU)
</span><a href="#local-6989586621679808614"><span class="hs-identifier hs-var hs-var">g</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">SDevice ('Device 'CPU) -&gt; Word64 -&gt; Generator ('Device 'CPU)
forall (device :: Device (DeviceType Nat)).
SDevice device -&gt; Word64 -&gt; Generator device
</span><a href="Torch.GraduallyTyped.Random.html#sMkGenerator"><span class="hs-identifier hs-var">sMkGenerator</span></a></span><span> </span><span class="annot"><span class="annottext">SDevice ('Device 'CPU)
</span><a href="#local-6989586621679808630"><span class="hs-identifier hs-var">device</span></a></span><span> </span><span class="annot"><span class="annottext">Word64
</span><span class="hs-number">0</span></span><span>
</span><span id="line-492"></span><span>  </span><span class="hs-special">(</span><span id="local-6989586621679808613"><span class="annot"><span class="annottext">TransformerEncoder
  'T5
  10
  ('Gradient 'WithGradient)
  ('Device 'CPU)
  ('DataType 'Float)
  ('Dim ('Name &quot;*&quot;) ('Size 8))
  ('Dim ('Name &quot;*&quot;) ('Size 64))
  ('Dim ('Name &quot;*&quot;) ('Size 512))
  ('Dim ('Name &quot;*&quot;) ('Size 512))
  ('Dim ('Name &quot;*&quot;) ('Size 2048))
  ('Dim ('Name &quot;*&quot;) ('Size 32))
</span><a href="#local-6989586621679808613"><span class="hs-identifier hs-var">encoder</span></a></span></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679808612"><span class="annot"><span class="annottext">Generator ('Device 'CPU)
</span><a href="#local-6989586621679808612"><span class="hs-identifier hs-var">g'</span></a></span></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">&lt;-</span><span> </span><span class="annot"><span class="annottext">ModelSpec
  (TransformerEncoder
     'T5
     10
     ('Gradient 'WithGradient)
     ('Device 'CPU)
     ('DataType 'Float)
     ('Dim ('Name &quot;*&quot;) ('Size 8))
     ('Dim ('Name &quot;*&quot;) ('Size 64))
     ('Dim ('Name &quot;*&quot;) ('Size 512))
     ('Dim ('Name &quot;*&quot;) ('Size 512))
     ('Dim ('Name &quot;*&quot;) ('Size 2048))
     ('Dim ('Name &quot;*&quot;) ('Size 32)))
-&gt; Generator ('Device 'CPU)
-&gt; IO
     (TransformerEncoder
        'T5
        10
        ('Gradient 'WithGradient)
        ('Device 'CPU)
        ('DataType 'Float)
        ('Dim ('Name &quot;*&quot;) ('Size 8))
        ('Dim ('Name &quot;*&quot;) ('Size 64))
        ('Dim ('Name &quot;*&quot;) ('Size 512))
        ('Dim ('Name &quot;*&quot;) ('Size 512))
        ('Dim ('Name &quot;*&quot;) ('Size 2048))
        ('Dim ('Name &quot;*&quot;) ('Size 32)),
      Generator ('Device 'CPU))
forall model (generatorDevice :: Device (DeviceType Nat)) output
       (generatorOutputDevice :: Device (DeviceType Nat)) (m :: * -&gt; *).
(HasInitialize model generatorDevice output generatorOutputDevice,
 MonadThrow m) =&gt;
ModelSpec model
-&gt; Generator generatorDevice
-&gt; m (output, Generator generatorOutputDevice)
</span><a href="Torch.GraduallyTyped.NN.Class.html#initialize"><span class="hs-identifier hs-var">initialize</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">STransformerStyle 'T5
-&gt; SNat 10
-&gt; SGradient ('Gradient 'WithGradient)
-&gt; SDevice ('Device 'CPU)
-&gt; SDataType ('DataType 'Float)
-&gt; SDim ('Dim ('Name &quot;*&quot;) ('Size 8))
-&gt; SDim ('Dim ('Name &quot;*&quot;) ('Size 64))
-&gt; SDim ('Dim ('Name &quot;*&quot;) ('Size 512))
-&gt; SDim ('Dim ('Name &quot;*&quot;) ('Size 512))
-&gt; SDim ('Dim ('Name &quot;*&quot;) ('Size 2048))
-&gt; SDim ('Dim ('Name &quot;*&quot;) ('Size 32))
-&gt; Double
-&gt; Double
-&gt; TransformerEncoderSpec
     'T5
     10
     ('Gradient 'WithGradient)
     ('Device 'CPU)
     ('DataType 'Float)
     ('Dim ('Name &quot;*&quot;) ('Size 8))
     ('Dim ('Name &quot;*&quot;) ('Size 64))
     ('Dim ('Name &quot;*&quot;) ('Size 512))
     ('Dim ('Name &quot;*&quot;) ('Size 512))
     ('Dim ('Name &quot;*&quot;) ('Size 2048))
     ('Dim ('Name &quot;*&quot;) ('Size 32))
forall (style :: TransformerStyle) (numLayers :: Nat)
       (gradient :: Gradient RequiresGradient)
       (device :: Device (DeviceType Nat)) (dataType :: DataType DType)
       (headDim :: Dim (Name Symbol) (Size Nat))
       (headEmbedDim :: Dim (Name Symbol) (Size Nat))
       (embedDim :: Dim (Name Symbol) (Size Nat))
       (inputEmbedDim :: Dim (Name Symbol) (Size Nat))
       (ffnDim :: Dim (Name Symbol) (Size Nat))
       (posEncDim :: Dim (Name Symbol) (Size Nat)).
STransformerStyle style
-&gt; SNat numLayers
-&gt; SGradient gradient
-&gt; SDevice device
-&gt; SDataType dataType
-&gt; SDim headDim
-&gt; SDim headEmbedDim
-&gt; SDim embedDim
-&gt; SDim inputEmbedDim
-&gt; SDim ffnDim
-&gt; SDim posEncDim
-&gt; Double
-&gt; Double
-&gt; TransformerEncoderSpec
     style
     numLayers
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     inputEmbedDim
     ffnDim
     posEncDim
</span><a href="Torch.GraduallyTyped.NN.Transformer.Encoder.html#TransformerEncoderSpec"><span class="hs-identifier hs-var">TransformerEncoderSpec</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle 'T5
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#ST5"><span class="hs-identifier hs-var">ST5</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">KnownNat 10 =&gt; SNat 10
forall (n :: Nat). KnownNat n =&gt; SNat n
</span><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-var">SNat</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><span class="hs-number">10</span></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">SGradient ('Gradient 'WithGradient)
</span><a href="#local-6989586621679808633"><span class="hs-identifier hs-var">gradient</span></a></span><span> </span><span class="annot"><span class="annottext">SDevice ('Device 'CPU)
</span><a href="#local-6989586621679808630"><span class="hs-identifier hs-var">device</span></a></span><span> </span><span class="annot"><span class="annottext">SDataType ('DataType 'Float)
</span><a href="#local-6989586621679808627"><span class="hs-identifier hs-var">dataType</span></a></span><span> </span><span class="annot"><span class="annottext">SDim ('Dim ('Name &quot;*&quot;) ('Size 8))
</span><a href="#local-6989586621679808624"><span class="hs-identifier hs-var">headDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim ('Dim ('Name &quot;*&quot;) ('Size 64))
</span><a href="#local-6989586621679808621"><span class="hs-identifier hs-var">headEmbedDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim ('Dim ('Name &quot;*&quot;) ('Size 512))
</span><a href="#local-6989586621679808620"><span class="hs-identifier hs-var">embedDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim ('Dim ('Name &quot;*&quot;) ('Size 512))
</span><a href="#local-6989586621679808619"><span class="hs-identifier hs-var">inputEmbedDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim ('Dim ('Name &quot;*&quot;) ('Size 2048))
</span><a href="#local-6989586621679808618"><span class="hs-identifier hs-var">ffnDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim ('Dim ('Name &quot;*&quot;) ('Size 32))
</span><a href="#local-6989586621679808617"><span class="hs-identifier hs-var">posEncDim</span></a></span><span> </span><span class="annot"><span class="annottext">Double
</span><a href="#local-6989586621679808616"><span class="hs-identifier hs-var">dropoutP</span></a></span><span> </span><span class="annot"><span class="annottext">Double
</span><a href="#local-6989586621679808615"><span class="hs-identifier hs-var">eps</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">Generator ('Device 'CPU)
</span><a href="#local-6989586621679808614"><span class="hs-identifier hs-var">g</span></a></span><span>
</span><span id="line-493"></span><span>  </span><span class="hs-keyword">let</span><span> </span><span id="local-6989586621679808610"><span class="annot"><span class="annottext">batchDim :: SDim ('Dim ('Name &quot;*&quot;) ('Size 3))
</span><a href="#local-6989586621679808610"><span class="hs-identifier hs-var hs-var">batchDim</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">KnownSymbol &quot;*&quot; =&gt; SName ('Name &quot;*&quot;)
forall (name :: Symbol). KnownSymbol name =&gt; SName ('Name name)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SName"><span class="hs-identifier hs-var">SName</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><span class="hs-string">&quot;*&quot;</span></span><span> </span><span class="annot"><span class="annottext">SName ('Name &quot;*&quot;)
-&gt; SSize ('Size 3) -&gt; SDim ('Dim ('Name &quot;*&quot;) ('Size 3))
forall (name :: Name Symbol) (size :: Size Nat).
SName name -&gt; SSize size -&gt; SDim ('Dim name size)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%26%3A"><span class="hs-operator hs-var">:&amp;:</span></a></span><span> </span><span class="annot"><span class="annottext">KnownNat 3 =&gt; SSize ('Size 3)
forall (size :: Nat). KnownNat size =&gt; SSize ('Size size)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SSize"><span class="hs-identifier hs-var">SSize</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><span class="hs-number">3</span></span><span>
</span><span id="line-494"></span><span>      </span><span id="local-6989586621679808609"><span class="annot"><span class="annottext">seqDim :: SDim ('Dim ('Name &quot;*&quot;) ('Size 13))
</span><a href="#local-6989586621679808609"><span class="hs-identifier hs-var hs-var">seqDim</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">KnownSymbol &quot;*&quot; =&gt; SName ('Name &quot;*&quot;)
forall (name :: Symbol). KnownSymbol name =&gt; SName ('Name name)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SName"><span class="hs-identifier hs-var">SName</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><span class="hs-string">&quot;*&quot;</span></span><span> </span><span class="annot"><span class="annottext">SName ('Name &quot;*&quot;)
-&gt; SSize ('Size 13) -&gt; SDim ('Dim ('Name &quot;*&quot;) ('Size 13))
forall (name :: Name Symbol) (size :: Size Nat).
SName name -&gt; SSize size -&gt; SDim ('Dim name size)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%26%3A"><span class="hs-operator hs-var">:&amp;:</span></a></span><span> </span><span class="annot"><span class="annottext">KnownNat 13 =&gt; SSize ('Size 13)
forall (size :: Nat). KnownNat size =&gt; SSize ('Size size)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SSize"><span class="hs-identifier hs-var">SSize</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><span class="hs-number">13</span></span><span>
</span><span id="line-495"></span><span>      </span><span id="local-6989586621679808608"><span class="annot"><span class="annottext">sOnes' :: SDataType dataType
-&gt; SShape shape
-&gt; Tensor
     ('Gradient 'WithoutGradient)
     ('Layout 'Dense)
     ('Device 'CPU)
     dataType
     shape
</span><a href="#local-6989586621679808608"><span class="hs-identifier hs-var hs-var">sOnes'</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">TensorSpec
  ('Gradient 'WithoutGradient)
  ('Layout 'Dense)
  ('Device 'CPU)
  dataType
  shape
-&gt; Tensor
     ('Gradient 'WithoutGradient)
     ('Layout 'Dense)
     ('Device 'CPU)
     dataType
     shape
forall (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)]).
TensorSpec gradient layout device dataType shape
-&gt; Tensor gradient layout device dataType shape
</span><a href="Torch.GraduallyTyped.Tensor.Creation.html#sOnes"><span class="hs-identifier hs-var">sOnes</span></a></span><span> </span><span class="annot"><span class="annottext">(TensorSpec
   ('Gradient 'WithoutGradient)
   ('Layout 'Dense)
   ('Device 'CPU)
   dataType
   shape
 -&gt; Tensor
      ('Gradient 'WithoutGradient)
      ('Layout 'Dense)
      ('Device 'CPU)
      dataType
      shape)
-&gt; (SShape shape
    -&gt; TensorSpec
         ('Gradient 'WithoutGradient)
         ('Layout 'Dense)
         ('Device 'CPU)
         dataType
         shape)
-&gt; SShape shape
-&gt; Tensor
     ('Gradient 'WithoutGradient)
     ('Layout 'Dense)
     ('Device 'CPU)
     dataType
     shape
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">((SShape shape
  -&gt; TensorSpec
       ('Gradient 'WithoutGradient)
       ('Layout 'Dense)
       ('Device 'CPU)
       dataType
       shape)
 -&gt; SShape shape
 -&gt; Tensor
      ('Gradient 'WithoutGradient)
      ('Layout 'Dense)
      ('Device 'CPU)
      dataType
      shape)
-&gt; (SDataType dataType
    -&gt; SShape shape
    -&gt; TensorSpec
         ('Gradient 'WithoutGradient)
         ('Layout 'Dense)
         ('Device 'CPU)
         dataType
         shape)
-&gt; SDataType dataType
-&gt; SShape shape
-&gt; Tensor
     ('Gradient 'WithoutGradient)
     ('Layout 'Dense)
     ('Device 'CPU)
     dataType
     shape
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">SGradient ('Gradient 'WithoutGradient)
-&gt; SLayout ('Layout 'Dense)
-&gt; SDevice ('Device 'CPU)
-&gt; SDataType dataType
-&gt; SShape shape
-&gt; TensorSpec
     ('Gradient 'WithoutGradient)
     ('Layout 'Dense)
     ('Device 'CPU)
     dataType
     shape
forall (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)]).
SGradient gradient
-&gt; SLayout layout
-&gt; SDevice device
-&gt; SDataType dataType
-&gt; SShape shape
-&gt; TensorSpec gradient layout device dataType shape
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#TensorSpec"><span class="hs-identifier hs-var">TensorSpec</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SRequiresGradient 'WithoutGradient
-&gt; SGradient ('Gradient 'WithoutGradient)
forall (requiresGradient :: RequiresGradient).
SRequiresGradient requiresGradient
-&gt; SGradient ('Gradient requiresGradient)
</span><a href="Torch.GraduallyTyped.RequiresGradient.html#SGradient"><span class="hs-identifier hs-var">SGradient</span></a></span><span> </span><span class="annot"><span class="annottext">SRequiresGradient 'WithoutGradient
</span><a href="Torch.GraduallyTyped.RequiresGradient.html#SWithoutGradient"><span class="hs-identifier hs-var">SWithoutGradient</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SLayoutType 'Dense -&gt; SLayout ('Layout 'Dense)
forall (layoutType :: LayoutType).
SLayoutType layoutType -&gt; SLayout ('Layout layoutType)
</span><a href="Torch.GraduallyTyped.Layout.html#SLayout"><span class="hs-identifier hs-var">SLayout</span></a></span><span> </span><span class="annot"><span class="annottext">SLayoutType 'Dense
</span><a href="Torch.GraduallyTyped.Layout.html#SDense"><span class="hs-identifier hs-var">SDense</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">SDevice ('Device 'CPU)
</span><a href="#local-6989586621679808630"><span class="hs-identifier hs-var">device</span></a></span><span>
</span><span id="line-496"></span><span>      </span><span id="local-6989586621679808605"><span class="annot"><span class="annottext">input :: Tensor
  ('Gradient 'WithoutGradient)
  ('Layout 'Dense)
  ('Device 'CPU)
  ('DataType 'Float)
  ('Shape
     '[ 'Dim ('Name &quot;*&quot;) ('Size 3), 'Dim ('Name &quot;*&quot;) ('Size 13),
        'Dim ('Name &quot;*&quot;) ('Size 512)])
</span><a href="#local-6989586621679808605"><span class="hs-identifier hs-var hs-var">input</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">SDataType ('DataType 'Float)
-&gt; SShape
     ('Shape
        '[ 'Dim ('Name &quot;*&quot;) ('Size 3), 'Dim ('Name &quot;*&quot;) ('Size 13),
           'Dim ('Name &quot;*&quot;) ('Size 512)])
-&gt; Tensor
     ('Gradient 'WithoutGradient)
     ('Layout 'Dense)
     ('Device 'CPU)
     ('DataType 'Float)
     ('Shape
        '[ 'Dim ('Name &quot;*&quot;) ('Size 3), 'Dim ('Name &quot;*&quot;) ('Size 13),
           'Dim ('Name &quot;*&quot;) ('Size 512)])
forall (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)]).
SDataType dataType
-&gt; SShape shape
-&gt; Tensor
     ('Gradient 'WithoutGradient)
     ('Layout 'Dense)
     ('Device 'CPU)
     dataType
     shape
</span><a href="#local-6989586621679808608"><span class="hs-identifier hs-var">sOnes'</span></a></span><span> </span><span class="annot"><span class="annottext">SDataType ('DataType 'Float)
</span><a href="#local-6989586621679808627"><span class="hs-identifier hs-var">dataType</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SList
  '[ 'Dim ('Name &quot;*&quot;) ('Size 3), 'Dim ('Name &quot;*&quot;) ('Size 13),
     'Dim ('Name &quot;*&quot;) ('Size 512)]
-&gt; SShape
     ('Shape
        '[ 'Dim ('Name &quot;*&quot;) ('Size 3), 'Dim ('Name &quot;*&quot;) ('Size 13),
           'Dim ('Name &quot;*&quot;) ('Size 512)])
forall (dims :: [Dim (Name Symbol) (Size Nat)]).
SList dims -&gt; SShape ('Shape dims)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SShape"><span class="hs-identifier hs-var">SShape</span></a></span><span> </span><span class="annot"><span class="annottext">(SList
   '[ 'Dim ('Name &quot;*&quot;) ('Size 3), 'Dim ('Name &quot;*&quot;) ('Size 13),
      'Dim ('Name &quot;*&quot;) ('Size 512)]
 -&gt; SShape
      ('Shape
         '[ 'Dim ('Name &quot;*&quot;) ('Size 3), 'Dim ('Name &quot;*&quot;) ('Size 13),
            'Dim ('Name &quot;*&quot;) ('Size 512)]))
-&gt; SList
     '[ 'Dim ('Name &quot;*&quot;) ('Size 3), 'Dim ('Name &quot;*&quot;) ('Size 13),
        'Dim ('Name &quot;*&quot;) ('Size 512)]
-&gt; SShape
     ('Shape
        '[ 'Dim ('Name &quot;*&quot;) ('Size 3), 'Dim ('Name &quot;*&quot;) ('Size 13),
           'Dim ('Name &quot;*&quot;) ('Size 512)])
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">SDim ('Dim ('Name &quot;*&quot;) ('Size 3))
</span><a href="#local-6989586621679808610"><span class="hs-identifier hs-var">batchDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim ('Dim ('Name &quot;*&quot;) ('Size 3))
-&gt; SList
     '[ 'Dim ('Name &quot;*&quot;) ('Size 13), 'Dim ('Name &quot;*&quot;) ('Size 512)]
-&gt; SList
     '[ 'Dim ('Name &quot;*&quot;) ('Size 3), 'Dim ('Name &quot;*&quot;) ('Size 13),
        'Dim ('Name &quot;*&quot;) ('Size 512)]
forall (dim :: Dim (Name Symbol) (Size Nat))
       (dims :: [Dim (Name Symbol) (Size Nat)]).
SDim dim -&gt; SList dims -&gt; SList (dim : dims)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%7C%3A"><span class="hs-operator hs-var">:|:</span></a></span><span> </span><span class="annot"><span class="annottext">SDim ('Dim ('Name &quot;*&quot;) ('Size 13))
</span><a href="#local-6989586621679808609"><span class="hs-identifier hs-var">seqDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim ('Dim ('Name &quot;*&quot;) ('Size 13))
-&gt; SList '[ 'Dim ('Name &quot;*&quot;) ('Size 512)]
-&gt; SList
     '[ 'Dim ('Name &quot;*&quot;) ('Size 13), 'Dim ('Name &quot;*&quot;) ('Size 512)]
forall (dim :: Dim (Name Symbol) (Size Nat))
       (dims :: [Dim (Name Symbol) (Size Nat)]).
SDim dim -&gt; SList dims -&gt; SList (dim : dims)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%7C%3A"><span class="hs-operator hs-var">:|:</span></a></span><span> </span><span class="annot"><span class="annottext">SDim ('Dim ('Name &quot;*&quot;) ('Size 512))
</span><a href="#local-6989586621679808619"><span class="hs-identifier hs-var">inputEmbedDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim ('Dim ('Name &quot;*&quot;) ('Size 512))
-&gt; SList '[] -&gt; SList '[ 'Dim ('Name &quot;*&quot;) ('Size 512)]
forall (dim :: Dim (Name Symbol) (Size Nat))
       (dims :: [Dim (Name Symbol) (Size Nat)]).
SDim dim -&gt; SList dims -&gt; SList (dim : dims)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%7C%3A"><span class="hs-operator hs-var">:|:</span></a></span><span> </span><span class="annot"><span class="annottext">SList '[]
forall a. SList '[]
</span><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-var">SNil</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-497"></span><span>      </span><span id="local-6989586621679808604"><span class="annot"><span class="annottext">relPos :: Tensor
  ('Gradient 'WithoutGradient)
  ('Layout 'Dense)
  ('Device 'CPU)
  ('DataType 'Int64)
  ('Shape
     '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) ('Size 13),
        'Dim ('Name &quot;*&quot;) ('Size 13)])
</span><a href="#local-6989586621679808604"><span class="hs-identifier hs-var hs-var">relPos</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">SDataType ('DataType 'Int64)
-&gt; SShape
     ('Shape
        '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) ('Size 13),
           'Dim ('Name &quot;*&quot;) ('Size 13)])
-&gt; Tensor
     ('Gradient 'WithoutGradient)
     ('Layout 'Dense)
     ('Device 'CPU)
     ('DataType 'Int64)
     ('Shape
        '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) ('Size 13),
           'Dim ('Name &quot;*&quot;) ('Size 13)])
forall (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)]).
SDataType dataType
-&gt; SShape shape
-&gt; Tensor
     ('Gradient 'WithoutGradient)
     ('Layout 'Dense)
     ('Device 'CPU)
     dataType
     shape
</span><a href="#local-6989586621679808608"><span class="hs-identifier hs-var">sOnes'</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SDType 'Int64 -&gt; SDataType ('DataType 'Int64)
forall (dType :: DType).
SDType dType -&gt; SDataType ('DataType dType)
</span><a href="Torch.GraduallyTyped.DType.html#SDataType"><span class="hs-identifier hs-var">SDataType</span></a></span><span> </span><span class="annot"><span class="annottext">SDType 'Int64
</span><a href="Torch.GraduallyTyped.DType.html#SInt64"><span class="hs-identifier hs-var">SInt64</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SList
  '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) ('Size 13),
     'Dim ('Name &quot;*&quot;) ('Size 13)]
-&gt; SShape
     ('Shape
        '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) ('Size 13),
           'Dim ('Name &quot;*&quot;) ('Size 13)])
forall (dims :: [Dim (Name Symbol) (Size Nat)]).
SList dims -&gt; SShape ('Shape dims)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SShape"><span class="hs-identifier hs-var">SShape</span></a></span><span> </span><span class="annot"><span class="annottext">(SList
   '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) ('Size 13),
      'Dim ('Name &quot;*&quot;) ('Size 13)]
 -&gt; SShape
      ('Shape
         '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) ('Size 13),
            'Dim ('Name &quot;*&quot;) ('Size 13)]))
-&gt; SList
     '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) ('Size 13),
        'Dim ('Name &quot;*&quot;) ('Size 13)]
-&gt; SShape
     ('Shape
        '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) ('Size 13),
           'Dim ('Name &quot;*&quot;) ('Size 13)])
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">KnownSymbol &quot;*&quot; =&gt; SName ('Name &quot;*&quot;)
forall (name :: Symbol). KnownSymbol name =&gt; SName ('Name name)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SName"><span class="hs-identifier hs-var">SName</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><span class="hs-string">&quot;*&quot;</span></span><span> </span><span class="annot"><span class="annottext">SName ('Name &quot;*&quot;)
-&gt; SSize ('Size 1) -&gt; SDim ('Dim ('Name &quot;*&quot;) ('Size 1))
forall (name :: Name Symbol) (size :: Size Nat).
SName name -&gt; SSize size -&gt; SDim ('Dim name size)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%26%3A"><span class="hs-operator hs-var">:&amp;:</span></a></span><span> </span><span class="annot"><span class="annottext">KnownNat 1 =&gt; SSize ('Size 1)
forall (size :: Nat). KnownNat size =&gt; SSize ('Size size)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SSize"><span class="hs-identifier hs-var">SSize</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><span class="hs-number">1</span></span><span> </span><span class="annot"><span class="annottext">SDim ('Dim ('Name &quot;*&quot;) ('Size 1))
-&gt; SList
     '[ 'Dim ('Name &quot;*&quot;) ('Size 13), 'Dim ('Name &quot;*&quot;) ('Size 13)]
-&gt; SList
     '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) ('Size 13),
        'Dim ('Name &quot;*&quot;) ('Size 13)]
forall (dim :: Dim (Name Symbol) (Size Nat))
       (dims :: [Dim (Name Symbol) (Size Nat)]).
SDim dim -&gt; SList dims -&gt; SList (dim : dims)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%7C%3A"><span class="hs-operator hs-var">:|:</span></a></span><span> </span><span class="annot"><span class="annottext">SDim ('Dim ('Name &quot;*&quot;) ('Size 13))
</span><a href="#local-6989586621679808609"><span class="hs-identifier hs-var">seqDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim ('Dim ('Name &quot;*&quot;) ('Size 13))
-&gt; SList '[ 'Dim ('Name &quot;*&quot;) ('Size 13)]
-&gt; SList
     '[ 'Dim ('Name &quot;*&quot;) ('Size 13), 'Dim ('Name &quot;*&quot;) ('Size 13)]
forall (dim :: Dim (Name Symbol) (Size Nat))
       (dims :: [Dim (Name Symbol) (Size Nat)]).
SDim dim -&gt; SList dims -&gt; SList (dim : dims)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%7C%3A"><span class="hs-operator hs-var">:|:</span></a></span><span> </span><span class="annot"><span class="annottext">SDim ('Dim ('Name &quot;*&quot;) ('Size 13))
</span><a href="#local-6989586621679808609"><span class="hs-identifier hs-var">seqDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim ('Dim ('Name &quot;*&quot;) ('Size 13))
-&gt; SList '[] -&gt; SList '[ 'Dim ('Name &quot;*&quot;) ('Size 13)]
forall (dim :: Dim (Name Symbol) (Size Nat))
       (dims :: [Dim (Name Symbol) (Size Nat)]).
SDim dim -&gt; SList dims -&gt; SList (dim : dims)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%7C%3A"><span class="hs-operator hs-var">:|:</span></a></span><span> </span><span class="annot"><span class="annottext">SList '[]
forall a. SList '[]
</span><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-var">SNil</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-498"></span><span>      </span><span id="local-6989586621679808602"><span class="annot"><span class="annottext">attentionMask :: Tensor
  ('Gradient 'WithoutGradient)
  ('Layout 'Dense)
  ('Device 'CPU)
  ('DataType 'Float)
  ('Shape
     '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) ('Size 13),
        'Dim ('Name &quot;*&quot;) ('Size 13)])
</span><a href="#local-6989586621679808602"><span class="hs-identifier hs-var hs-var">attentionMask</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">SDataType ('DataType 'Float)
-&gt; SShape
     ('Shape
        '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) ('Size 13),
           'Dim ('Name &quot;*&quot;) ('Size 13)])
-&gt; Tensor
     ('Gradient 'WithoutGradient)
     ('Layout 'Dense)
     ('Device 'CPU)
     ('DataType 'Float)
     ('Shape
        '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) ('Size 13),
           'Dim ('Name &quot;*&quot;) ('Size 13)])
forall (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)]).
SDataType dataType
-&gt; SShape shape
-&gt; Tensor
     ('Gradient 'WithoutGradient)
     ('Layout 'Dense)
     ('Device 'CPU)
     dataType
     shape
</span><a href="#local-6989586621679808608"><span class="hs-identifier hs-var">sOnes'</span></a></span><span> </span><span class="annot"><span class="annottext">SDataType ('DataType 'Float)
</span><a href="#local-6989586621679808627"><span class="hs-identifier hs-var">dataType</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SList
  '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) ('Size 13),
     'Dim ('Name &quot;*&quot;) ('Size 13)]
-&gt; SShape
     ('Shape
        '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) ('Size 13),
           'Dim ('Name &quot;*&quot;) ('Size 13)])
forall (dims :: [Dim (Name Symbol) (Size Nat)]).
SList dims -&gt; SShape ('Shape dims)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SShape"><span class="hs-identifier hs-var">SShape</span></a></span><span> </span><span class="annot"><span class="annottext">(SList
   '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) ('Size 13),
      'Dim ('Name &quot;*&quot;) ('Size 13)]
 -&gt; SShape
      ('Shape
         '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) ('Size 13),
            'Dim ('Name &quot;*&quot;) ('Size 13)]))
-&gt; SList
     '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) ('Size 13),
        'Dim ('Name &quot;*&quot;) ('Size 13)]
-&gt; SShape
     ('Shape
        '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) ('Size 13),
           'Dim ('Name &quot;*&quot;) ('Size 13)])
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">KnownSymbol &quot;*&quot; =&gt; SName ('Name &quot;*&quot;)
forall (name :: Symbol). KnownSymbol name =&gt; SName ('Name name)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SName"><span class="hs-identifier hs-var">SName</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><span class="hs-string">&quot;*&quot;</span></span><span> </span><span class="annot"><span class="annottext">SName ('Name &quot;*&quot;)
-&gt; SSize ('Size 1) -&gt; SDim ('Dim ('Name &quot;*&quot;) ('Size 1))
forall (name :: Name Symbol) (size :: Size Nat).
SName name -&gt; SSize size -&gt; SDim ('Dim name size)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%26%3A"><span class="hs-operator hs-var">:&amp;:</span></a></span><span> </span><span class="annot"><span class="annottext">KnownNat 1 =&gt; SSize ('Size 1)
forall (size :: Nat). KnownNat size =&gt; SSize ('Size size)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SSize"><span class="hs-identifier hs-var">SSize</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><span class="hs-number">1</span></span><span> </span><span class="annot"><span class="annottext">SDim ('Dim ('Name &quot;*&quot;) ('Size 1))
-&gt; SList
     '[ 'Dim ('Name &quot;*&quot;) ('Size 13), 'Dim ('Name &quot;*&quot;) ('Size 13)]
-&gt; SList
     '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) ('Size 13),
        'Dim ('Name &quot;*&quot;) ('Size 13)]
forall (dim :: Dim (Name Symbol) (Size Nat))
       (dims :: [Dim (Name Symbol) (Size Nat)]).
SDim dim -&gt; SList dims -&gt; SList (dim : dims)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%7C%3A"><span class="hs-operator hs-var">:|:</span></a></span><span> </span><span class="annot"><span class="annottext">SDim ('Dim ('Name &quot;*&quot;) ('Size 13))
</span><a href="#local-6989586621679808609"><span class="hs-identifier hs-var">seqDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim ('Dim ('Name &quot;*&quot;) ('Size 13))
-&gt; SList '[ 'Dim ('Name &quot;*&quot;) ('Size 13)]
-&gt; SList
     '[ 'Dim ('Name &quot;*&quot;) ('Size 13), 'Dim ('Name &quot;*&quot;) ('Size 13)]
forall (dim :: Dim (Name Symbol) (Size Nat))
       (dims :: [Dim (Name Symbol) (Size Nat)]).
SDim dim -&gt; SList dims -&gt; SList (dim : dims)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%7C%3A"><span class="hs-operator hs-var">:|:</span></a></span><span> </span><span class="annot"><span class="annottext">SDim ('Dim ('Name &quot;*&quot;) ('Size 13))
</span><a href="#local-6989586621679808609"><span class="hs-identifier hs-var">seqDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim ('Dim ('Name &quot;*&quot;) ('Size 13))
-&gt; SList '[] -&gt; SList '[ 'Dim ('Name &quot;*&quot;) ('Size 13)]
forall (dim :: Dim (Name Symbol) (Size Nat))
       (dims :: [Dim (Name Symbol) (Size Nat)]).
SDim dim -&gt; SList dims -&gt; SList (dim : dims)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%7C%3A"><span class="hs-operator hs-var">:|:</span></a></span><span> </span><span class="annot"><span class="annottext">SList '[]
forall a. SList '[]
</span><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-var">SNil</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-499"></span><span>  </span><span class="hs-special">(</span><span id="local-6989586621679808601"><span class="annot"><span class="annottext">Tensor
  ('Gradient 'WithGradient)
  ('Layout 'Dense)
  ('Device 'CPU)
  ('DataType 'Float)
  ('Shape
     '[ 'Dim ('Name &quot;*&quot;) ('Size 3), 'Dim ('Name &quot;*&quot;) ('Size 13),
        'Dim ('Name &quot;*&quot;) ('Size 512)])
</span><a href="#local-6989586621679808601"><span class="hs-identifier hs-var">output</span></a></span></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">Generator ('Device 'CPU)
</span><span class="hs-identifier">_</span></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">&lt;-</span><span> </span><span class="annot"><span class="annottext">TransformerEncoder
  'T5
  10
  ('Gradient 'WithGradient)
  ('Device 'CPU)
  ('DataType 'Float)
  ('Dim ('Name &quot;*&quot;) ('Size 8))
  ('Dim ('Name &quot;*&quot;) ('Size 64))
  ('Dim ('Name &quot;*&quot;) ('Size 512))
  ('Dim ('Name &quot;*&quot;) ('Size 512))
  ('Dim ('Name &quot;*&quot;) ('Size 2048))
  ('Dim ('Name &quot;*&quot;) ('Size 32))
-&gt; (Tensor
      ('Gradient 'WithoutGradient)
      ('Layout 'Dense)
      ('Device 'CPU)
      ('DataType 'Float)
      ('Shape
         '[ 'Dim ('Name &quot;*&quot;) ('Size 3), 'Dim ('Name &quot;*&quot;) ('Size 13),
            'Dim ('Name &quot;*&quot;) ('Size 512)]),
    Tensor
      ('Gradient 'WithoutGradient)
      ('Layout 'Dense)
      ('Device 'CPU)
      ('DataType 'Int64)
      ('Shape
         '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) ('Size 13),
            'Dim ('Name &quot;*&quot;) ('Size 13)]),
    Tensor
      ('Gradient 'WithoutGradient)
      ('Layout 'Dense)
      ('Device 'CPU)
      ('DataType 'Float)
      ('Shape
         '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) ('Size 13),
            'Dim ('Name &quot;*&quot;) ('Size 13)]))
-&gt; Generator ('Device 'CPU)
-&gt; IO
     (Tensor
        ('Gradient 'WithGradient)
        ('Layout 'Dense)
        ('Device 'CPU)
        ('DataType 'Float)
        ('Shape
           '[ 'Dim ('Name &quot;*&quot;) ('Size 3), 'Dim ('Name &quot;*&quot;) ('Size 13),
              'Dim ('Name &quot;*&quot;) ('Size 512)]),
      Generator ('Device 'CPU))
forall model input (generatorDevice :: Device (DeviceType Nat))
       output (generatorOutputDevice :: Device (DeviceType Nat))
       (m :: * -&gt; *).
(HasForward
   model input generatorDevice output generatorOutputDevice,
 MonadThrow m) =&gt;
model
-&gt; input
-&gt; Generator generatorDevice
-&gt; m (output, Generator generatorOutputDevice)
</span><a href="Torch.GraduallyTyped.NN.Class.html#forward"><span class="hs-identifier hs-var">forward</span></a></span><span> </span><span class="annot"><span class="annottext">TransformerEncoder
  'T5
  10
  ('Gradient 'WithGradient)
  ('Device 'CPU)
  ('DataType 'Float)
  ('Dim ('Name &quot;*&quot;) ('Size 8))
  ('Dim ('Name &quot;*&quot;) ('Size 64))
  ('Dim ('Name &quot;*&quot;) ('Size 512))
  ('Dim ('Name &quot;*&quot;) ('Size 512))
  ('Dim ('Name &quot;*&quot;) ('Size 2048))
  ('Dim ('Name &quot;*&quot;) ('Size 32))
</span><a href="#local-6989586621679808613"><span class="hs-identifier hs-var">encoder</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">Tensor
  ('Gradient 'WithoutGradient)
  ('Layout 'Dense)
  ('Device 'CPU)
  ('DataType 'Float)
  ('Shape
     '[ 'Dim ('Name &quot;*&quot;) ('Size 3), 'Dim ('Name &quot;*&quot;) ('Size 13),
        'Dim ('Name &quot;*&quot;) ('Size 512)])
</span><a href="#local-6989586621679808605"><span class="hs-identifier hs-var">input</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">Tensor
  ('Gradient 'WithoutGradient)
  ('Layout 'Dense)
  ('Device 'CPU)
  ('DataType 'Int64)
  ('Shape
     '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) ('Size 13),
        'Dim ('Name &quot;*&quot;) ('Size 13)])
</span><a href="#local-6989586621679808604"><span class="hs-identifier hs-var">relPos</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">Tensor
  ('Gradient 'WithoutGradient)
  ('Layout 'Dense)
  ('Device 'CPU)
  ('DataType 'Float)
  ('Shape
     '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) ('Size 13),
        'Dim ('Name &quot;*&quot;) ('Size 13)])
</span><a href="#local-6989586621679808602"><span class="hs-identifier hs-var">attentionMask</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">Generator ('Device 'CPU)
</span><a href="#local-6989586621679808612"><span class="hs-identifier hs-var">g'</span></a></span><span>
</span><span id="line-500"></span><span>  </span><span class="annot"><span class="annottext">Tensor
  ('Gradient 'WithGradient)
  ('Layout 'Dense)
  ('Device 'CPU)
  ('DataType 'Float)
  ('Shape
     '[ 'Dim ('Name &quot;*&quot;) ('Size 3), 'Dim ('Name &quot;*&quot;) ('Size 13),
        'Dim ('Name &quot;*&quot;) ('Size 512)])
-&gt; IO
     (Tensor
        ('Gradient 'WithGradient)
        ('Layout 'Dense)
        ('Device 'CPU)
        ('DataType 'Float)
        ('Shape
           '[ 'Dim ('Name &quot;*&quot;) ('Size 3), 'Dim ('Name &quot;*&quot;) ('Size 13),
              'Dim ('Name &quot;*&quot;) ('Size 512)]))
forall (f :: * -&gt; *) a. Applicative f =&gt; a -&gt; f a
</span><span class="hs-identifier hs-var">pure</span></span><span> </span><span class="annot"><span class="annottext">Tensor
  ('Gradient 'WithGradient)
  ('Layout 'Dense)
  ('Device 'CPU)
  ('DataType 'Float)
  ('Shape
     '[ 'Dim ('Name &quot;*&quot;) ('Size 3), 'Dim ('Name &quot;*&quot;) ('Size 13),
        'Dim ('Name &quot;*&quot;) ('Size 512)])
</span><a href="#local-6989586621679808601"><span class="hs-identifier hs-var">output</span></a></span><span>
</span><span id="line-501"></span><span>
</span><span id="line-502"></span><span class="hs-comment">-- | 'HasForward' instance for @TransformerEncoder numLayers 'ByT5@.</span><span>
</span><span id="line-503"></span><span class="hs-comment">--</span><span>
</span><span id="line-504"></span><span class="hs-comment">-- @</span><span>
</span><span id="line-505"></span><span class="hs-comment">--  &#9484;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9488;  &#9484;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9488;  &#9484;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9488;</span><span>
</span><span id="line-506"></span><span class="hs-comment">--  &#9474; input &#9474;  &#9474; relPos &#9474;  &#9474; attentionMask &#9474;</span><span>
</span><span id="line-507"></span><span class="hs-comment">--  &#9492;&#9472;&#9472;&#9472;&#9516;&#9472;&#9472;&#9472;&#9496;  &#9492;&#9472;&#9472;&#9472;&#9516;&#9472;&#9472;&#9472;&#9472;&#9496;  &#9492;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9516;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9496;</span><span>
</span><span id="line-508"></span><span class="hs-comment">--      &#9474;          &#9474;               &#9474;</span><span>
</span><span id="line-509"></span><span class="hs-comment">--      &#9474;          &#9660;               &#9474;</span><span>
</span><span id="line-510"></span><span class="hs-comment">--      &#9474;      tePosEnc            &#9474;</span><span>
</span><span id="line-511"></span><span class="hs-comment">--      &#9474;          &#9660;               &#9474;</span><span>
</span><span id="line-512"></span><span class="hs-comment">--      &#9474;      transpose           &#9474;</span><span>
</span><span id="line-513"></span><span class="hs-comment">--      &#9474;          &#9660;               &#9660;</span><span>
</span><span id="line-514"></span><span class="hs-comment">--      &#9474;      transpose       unsqueeze</span><span>
</span><span id="line-515"></span><span class="hs-comment">--      &#9660;          &#9474;               &#9474;</span><span>
</span><span id="line-516"></span><span class="hs-comment">--  teDropout      &#9492;&#9472;&#9472;&#9472;&#9472;&#9472;&#9658;add&#9668;&#9472;&#9472;&#9472;&#9472;&#9472;&#9496;</span><span>
</span><span id="line-517"></span><span class="hs-comment">--      &#9660;                  &#9474;</span><span>
</span><span id="line-518"></span><span class="hs-comment">--   teStack&#9668;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9496;</span><span>
</span><span id="line-519"></span><span class="hs-comment">--      &#9660;</span><span>
</span><span id="line-520"></span><span class="hs-comment">-- teLayerNorm</span><span>
</span><span id="line-521"></span><span class="hs-comment">--      &#9660;</span><span>
</span><span id="line-522"></span><span class="hs-comment">--  teDropout</span><span>
</span><span id="line-523"></span><span class="hs-comment">--      &#9474;</span><span>
</span><span id="line-524"></span><span class="hs-comment">--      &#9660;</span><span>
</span><span id="line-525"></span><span class="hs-comment">--  &#9484;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9488;</span><span>
</span><span id="line-526"></span><span class="hs-comment">--  &#9474; output &#9474;</span><span>
</span><span id="line-527"></span><span class="hs-comment">--  &#9492;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9496;</span><span>
</span><span id="line-528"></span><span class="hs-comment">-- @</span><span>
</span><span id="line-529"></span><span id="local-6989586621679808571"><span id="local-6989586621679808572"><span id="local-6989586621679808573"><span id="local-6989586621679808574"><span id="local-6989586621679808575"><span id="local-6989586621679808576"><span id="local-6989586621679808577"><span id="local-6989586621679808578"><span id="local-6989586621679808579"><span id="local-6989586621679808580"><span id="local-6989586621679808581"><span id="local-6989586621679808582"><span id="local-6989586621679808583"><span id="local-6989586621679808584"><span id="local-6989586621679808585"><span id="local-6989586621679808586"><span id="local-6989586621679808587"><span id="local-6989586621679808588"><span id="local-6989586621679808589"><span id="local-6989586621679808590"><span id="local-6989586621679808591"><span id="local-6989586621679808592"><span id="local-6989586621679808593"><span id="local-6989586621679808594"><span id="local-6989586621679808595"><span id="local-6989586621679808596"><span id="local-6989586621679808597"><span id="local-6989586621679808598"><span id="local-6989586621679808599"><span id="local-6989586621679808600"><span class="hs-keyword">instance</span><span>
</span><span id="line-530"></span><span>  </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasForward"><span class="hs-identifier hs-type">HasForward</span></a></span><span>
</span><span id="line-531"></span><span>      </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Encoder.html#TEDropoutF"><span class="hs-identifier hs-type">TEDropoutF</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#ByT5"><span class="hs-identifier hs-type">ByT5</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-532"></span><span>      </span><span class="annot"><a href="#local-6989586621679808600"><span class="hs-identifier hs-type">input</span></a></span><span>
</span><span id="line-533"></span><span>      </span><span class="annot"><a href="#local-6989586621679808599"><span class="hs-identifier hs-type">generatorDevice</span></a></span><span>
</span><span id="line-534"></span><span>      </span><span class="annot"><a href="#local-6989586621679808598"><span class="hs-identifier hs-type">dropoutOutput</span></a></span><span>
</span><span id="line-535"></span><span>      </span><span class="annot"><a href="#local-6989586621679808597"><span class="hs-identifier hs-type">dropoutGeneratorOutputDevice</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-536"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasForward"><span class="hs-identifier hs-type">HasForward</span></a></span><span>
</span><span id="line-537"></span><span>      </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Encoder.html#TEStackF"><span class="hs-identifier hs-type">TEStackF</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#ByT5"><span class="hs-identifier hs-type">ByT5</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808596"><span class="hs-identifier hs-type">numLayers</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808595"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808594"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808593"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808592"><span class="hs-identifier hs-type">headDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808591"><span class="hs-identifier hs-type">headEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808590"><span class="hs-identifier hs-type">embedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808589"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808588"><span class="hs-identifier hs-type">ffnDim</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-538"></span><span>      </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="#local-6989586621679808598"><span class="hs-identifier hs-type">dropoutOutput</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-539"></span><span>        </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span>
</span><span id="line-540"></span><span>          </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679808595"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%7C%3E"><span class="hs-operator hs-type">&lt;|&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808587"><span class="hs-identifier hs-type">relPosGradient</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%7C%3E"><span class="hs-operator hs-type">&lt;|&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808586"><span class="hs-identifier hs-type">attentionMaskGradient</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-541"></span><span>          </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#Layout"><span class="hs-identifier hs-type">Layout</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#Dense"><span class="hs-identifier hs-type">Dense</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808585"><span class="hs-identifier hs-type">relPosLayout</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808584"><span class="hs-identifier hs-type">attentionMaskLayout</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-542"></span><span>          </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679808594"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808583"><span class="hs-identifier hs-type">relPosDevice</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808582"><span class="hs-identifier hs-type">attentionMaskDevice</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-543"></span><span>          </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Prelude.html#Seq"><span class="hs-identifier hs-type">Seq</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679808581"><span class="hs-identifier hs-type">relPosDataType</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#DataType"><span class="hs-identifier hs-type">DataType</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#Int64"><span class="hs-identifier hs-type">Int64</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679808593"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808580"><span class="hs-identifier hs-type">attentionMaskDataType</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-544"></span><span>          </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Class.html#BroadcastShapesF"><span class="hs-identifier hs-type">BroadcastShapesF</span></a></span><span>
</span><span id="line-545"></span><span>              </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.IndexingSlicingJoining.html#TransposeF"><span class="hs-identifier hs-type">TransposeF</span></a></span><span>
</span><span id="line-546"></span><span>                  </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SelectDim"><span class="hs-identifier hs-type">SelectDim</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#ByIndex"><span class="hs-identifier hs-type">ByIndex</span></a></span><span> </span><span class="annot"><span class="hs-number">1</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-547"></span><span>                  </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SelectDim"><span class="hs-identifier hs-type">SelectDim</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#ByIndex"><span class="hs-identifier hs-type">ByIndex</span></a></span><span> </span><span class="annot"><span class="hs-number">2</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-548"></span><span>                  </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.IndexingSlicingJoining.html#TransposeF"><span class="hs-identifier hs-type">TransposeF</span></a></span><span>
</span><span id="line-549"></span><span>                      </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SelectDim"><span class="hs-identifier hs-type">SelectDim</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#ByIndex"><span class="hs-identifier hs-type">ByIndex</span></a></span><span> </span><span class="annot"><span class="hs-number">2</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-550"></span><span>                      </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SelectDim"><span class="hs-identifier hs-type">SelectDim</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#ByIndex"><span class="hs-identifier hs-type">ByIndex</span></a></span><span> </span><span class="annot"><span class="hs-number">3</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-551"></span><span>                      </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Functional.Sparse.html#EmbeddingF"><span class="hs-identifier hs-type">EmbeddingF</span></a></span><span>
</span><span id="line-552"></span><span>                          </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Shape"><span class="hs-identifier hs-type">Shape</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="annot"><a href="#local-6989586621679808579"><span class="hs-identifier hs-type">posEncDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679808592"><span class="hs-identifier hs-type">headDim</span></a></span><span class="hs-special">]</span><span class="hs-special">)</span><span>
</span><span id="line-553"></span><span>                          </span><span class="annot"><a href="#local-6989586621679808578"><span class="hs-identifier hs-type">relPosShape</span></a></span><span>
</span><span id="line-554"></span><span>                      </span><span class="hs-special">)</span><span>
</span><span id="line-555"></span><span>                  </span><span class="hs-special">)</span><span>
</span><span id="line-556"></span><span>              </span><span class="hs-special">)</span><span>
</span><span id="line-557"></span><span>              </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.IndexingSlicingJoining.html#UnsqueezeF"><span class="hs-identifier hs-type">UnsqueezeF</span></a></span><span>
</span><span id="line-558"></span><span>                  </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SelectDim"><span class="hs-identifier hs-type">SelectDim</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#ByIndex"><span class="hs-identifier hs-type">ByIndex</span></a></span><span> </span><span class="annot"><span class="hs-number">1</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-559"></span><span>                  </span><span class="annot"><a href="#local-6989586621679808577"><span class="hs-identifier hs-type">attentionMaskShape</span></a></span><span>
</span><span id="line-560"></span><span>              </span><span class="hs-special">)</span><span>
</span><span id="line-561"></span><span>          </span><span class="hs-special">)</span><span>
</span><span id="line-562"></span><span>      </span><span class="hs-special">)</span><span>
</span><span id="line-563"></span><span>      </span><span class="annot"><a href="#local-6989586621679808597"><span class="hs-identifier hs-type">dropoutGeneratorOutputDevice</span></a></span><span>
</span><span id="line-564"></span><span>      </span><span class="annot"><a href="#local-6989586621679808576"><span class="hs-identifier hs-type">stackOutput</span></a></span><span>
</span><span id="line-565"></span><span>      </span><span class="annot"><a href="#local-6989586621679808575"><span class="hs-identifier hs-type">stackGeneratorOutputDevice</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-566"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasForward"><span class="hs-identifier hs-type">HasForward</span></a></span><span>
</span><span id="line-567"></span><span>      </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Encoder.html#TELayerNormF"><span class="hs-identifier hs-type">TELayerNormF</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#ByT5"><span class="hs-identifier hs-type">ByT5</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808595"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808594"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808593"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808589"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-568"></span><span>      </span><span class="annot"><a href="#local-6989586621679808576"><span class="hs-identifier hs-type">stackOutput</span></a></span><span>
</span><span id="line-569"></span><span>      </span><span class="annot"><a href="#local-6989586621679808575"><span class="hs-identifier hs-type">stackGeneratorOutputDevice</span></a></span><span>
</span><span id="line-570"></span><span>      </span><span class="annot"><a href="#local-6989586621679808574"><span class="hs-identifier hs-type">layerNormOutput</span></a></span><span>
</span><span id="line-571"></span><span>      </span><span class="annot"><a href="#local-6989586621679808573"><span class="hs-identifier hs-type">layerNormGeneratorOutputDevice</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-572"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasForward"><span class="hs-identifier hs-type">HasForward</span></a></span><span>
</span><span id="line-573"></span><span>      </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Encoder.html#TEDropoutF"><span class="hs-identifier hs-type">TEDropoutF</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#ByT5"><span class="hs-identifier hs-type">ByT5</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-574"></span><span>      </span><span class="annot"><a href="#local-6989586621679808574"><span class="hs-identifier hs-type">layerNormOutput</span></a></span><span>
</span><span id="line-575"></span><span>      </span><span class="annot"><a href="#local-6989586621679808573"><span class="hs-identifier hs-type">layerNormGeneratorOutputDevice</span></a></span><span>
</span><span id="line-576"></span><span>      </span><span class="annot"><a href="#local-6989586621679808572"><span class="hs-identifier hs-type">output</span></a></span><span>
</span><span id="line-577"></span><span>      </span><span class="annot"><a href="#local-6989586621679808571"><span class="hs-identifier hs-type">generatorOutputDevice</span></a></span><span>
</span><span id="line-578"></span><span>  </span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-579"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasForward"><span class="hs-identifier hs-type">HasForward</span></a></span><span>
</span><span id="line-580"></span><span>    </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Encoder.html#TransformerEncoder"><span class="hs-identifier hs-type">TransformerEncoder</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#ByT5"><span class="hs-identifier hs-type">ByT5</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808596"><span class="hs-identifier hs-type">numLayers</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808595"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808594"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808593"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808592"><span class="hs-identifier hs-type">headDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808591"><span class="hs-identifier hs-type">headEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808590"><span class="hs-identifier hs-type">embedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808589"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808588"><span class="hs-identifier hs-type">ffnDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808579"><span class="hs-identifier hs-type">posEncDim</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-581"></span><span>    </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="#local-6989586621679808600"><span class="hs-identifier hs-type">input</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-582"></span><span>      </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808587"><span class="hs-identifier hs-type">relPosGradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808585"><span class="hs-identifier hs-type">relPosLayout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808583"><span class="hs-identifier hs-type">relPosDevice</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808581"><span class="hs-identifier hs-type">relPosDataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808578"><span class="hs-identifier hs-type">relPosShape</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-583"></span><span>      </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808586"><span class="hs-identifier hs-type">attentionMaskGradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808584"><span class="hs-identifier hs-type">attentionMaskLayout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808582"><span class="hs-identifier hs-type">attentionMaskDevice</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808580"><span class="hs-identifier hs-type">attentionMaskDataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808577"><span class="hs-identifier hs-type">attentionMaskShape</span></a></span><span>
</span><span id="line-584"></span><span>    </span><span class="hs-special">)</span><span>
</span><span id="line-585"></span><span>    </span><span class="annot"><a href="#local-6989586621679808599"><span class="hs-identifier hs-type">generatorDevice</span></a></span><span>
</span><span id="line-586"></span><span>    </span><span class="annot"><a href="#local-6989586621679808572"><span class="hs-identifier hs-type">output</span></a></span><span>
</span><span id="line-587"></span><span>    </span><span class="annot"><a href="#local-6989586621679808571"><span class="hs-identifier hs-type">generatorOutputDevice</span></a></span><span>
</span><span id="line-588"></span><span>  </span><span class="hs-keyword">where</span><span>
</span><span id="line-589"></span><span>  </span><span id="local-6989586621679808569"><span class="annot"><span class="annottext">forward :: TransformerEncoder
  'ByT5
  numLayers
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  inputEmbedDim
  ffnDim
  posEncDim
-&gt; (input,
    Tensor
      relPosGradient
      relPosLayout
      relPosDevice
      relPosDataType
      relPosShape,
    Tensor
      attentionMaskGradient
      attentionMaskLayout
      attentionMaskDevice
      attentionMaskDataType
      attentionMaskShape)
-&gt; Generator generatorDevice
-&gt; m (output, Generator generatorOutputDevice)
</span><a href="#local-6989586621679808569"><span class="hs-identifier hs-var hs-var hs-var hs-var">forward</span></a></span></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Encoder.html#TransformerEncoder"><span class="hs-identifier hs-type">TransformerEncoder</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Encoder.html#GTransformerEncoder"><span class="hs-identifier hs-type">GTransformerEncoder</span></a></span><span> </span><span class="hs-special">{</span><span id="local-6989586621679808564"><span id="local-6989586621679808565"><span id="local-6989586621679808566"><span id="local-6989586621679808567"><span id="local-6989586621679808568"><span class="annot"><span class="annottext">TEPosEncF
  'ByT5 gradient device dataType headDim inputEmbedDim posEncDim
TEDropoutF 'ByT5
TELayerNormF 'ByT5 gradient device dataType inputEmbedDim
TEEmbedLayerNormF 'ByT5 gradient device dataType inputEmbedDim
TEStackF
  'ByT5
  numLayers
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  inputEmbedDim
  ffnDim
tePosEnc :: TEPosEncF
  'ByT5 gradient device dataType headDim inputEmbedDim posEncDim
teDropout :: TEDropoutF 'ByT5
teLayerNorm :: TELayerNormF 'ByT5 gradient device dataType inputEmbedDim
teEmbedLayerNorm :: TEEmbedLayerNormF 'ByT5 gradient device dataType inputEmbedDim
teStack :: TEStackF
  'ByT5
  numLayers
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  inputEmbedDim
  ffnDim
tePosEnc :: forall stack embedLayerNorm layerNorm dropout posEnc.
GTransformerEncoder stack embedLayerNorm layerNorm dropout posEnc
-&gt; posEnc
teDropout :: forall stack embedLayerNorm layerNorm dropout posEnc.
GTransformerEncoder stack embedLayerNorm layerNorm dropout posEnc
-&gt; dropout
teLayerNorm :: forall stack embedLayerNorm layerNorm dropout posEnc.
GTransformerEncoder stack embedLayerNorm layerNorm dropout posEnc
-&gt; layerNorm
teEmbedLayerNorm :: forall stack embedLayerNorm layerNorm dropout posEnc.
GTransformerEncoder stack embedLayerNorm layerNorm dropout posEnc
-&gt; embedLayerNorm
teStack :: forall stack embedLayerNorm layerNorm dropout posEnc.
GTransformerEncoder stack embedLayerNorm layerNorm dropout posEnc
-&gt; stack
</span><a href="#local-6989586621679808564"><span class="hs-glyph hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var">..</span></a></span></span></span></span></span></span><span class="hs-special">}</span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span id="local-6989586621679808563"><span class="annot"><span class="annottext">input
</span><a href="#local-6989586621679808563"><span class="hs-identifier hs-var">input</span></a></span></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679808562"><span class="annot"><span class="annottext">Tensor
  relPosGradient relPosLayout relPosDevice relPosDataType relPosShape
</span><a href="#local-6989586621679808562"><span class="hs-identifier hs-var">relPos</span></a></span></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679808561"><span class="annot"><span class="annottext">Tensor
  attentionMaskGradient
  attentionMaskLayout
  attentionMaskDevice
  attentionMaskDataType
  attentionMaskShape
</span><a href="#local-6989586621679808561"><span class="hs-identifier hs-var">attentionMask</span></a></span></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-590"></span><span>    </span><span class="hs-keyword">let</span><span> </span><span id="local-6989586621679808560"><span class="annot"><span class="annottext">relPosBias :: IxStateT
  m
  (Generator dropoutGeneratorOutputDevice)
  (Generator dropoutGeneratorOutputDevice)
  (Tensor
     (Or (Gradient RequiresGradient) gradient relPosGradient)
     (Unify (Layout LayoutType) ('Layout 'Dense) relPosLayout)
     (Unify (Device (DeviceType Nat)) device relPosDevice)
     (Seq
        (Unify (DataType DType) relPosDataType ('DataType 'Int64))
        dataType)
     (TransposeF
        ('SelectDim ('ByIndex 1))
        ('SelectDim ('ByIndex 2))
        (TransposeF
           ('SelectDim ('ByIndex 2))
           ('SelectDim ('ByIndex 3))
           (EmbeddingF ('Shape '[posEncDim, headDim]) relPosShape))))
</span><a href="#local-6989586621679808560"><span class="hs-identifier hs-var hs-var">relPosBias</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-591"></span><span>          </span><span class="annot"><span class="annottext">Tensor
  relPosGradient relPosLayout relPosDevice relPosDataType relPosShape
-&gt; IxStateT
     m
     (Generator dropoutGeneratorOutputDevice)
     (Generator dropoutGeneratorOutputDevice)
     (Tensor
        relPosGradient
        relPosLayout
        relPosDevice
        relPosDataType
        relPosShape)
forall k (m :: k -&gt; k -&gt; * -&gt; *) a (i :: k).
IxPointed m =&gt;
a -&gt; m i i a
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-identifier hs-var">ireturn</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor
  relPosGradient relPosLayout relPosDevice relPosDataType relPosShape
</span><a href="#local-6989586621679808562"><span class="hs-identifier hs-var">relPos</span></a></span><span>
</span><span id="line-592"></span><span>            </span><span class="annot"><span class="annottext">IxStateT
  m
  (Generator dropoutGeneratorOutputDevice)
  (Generator dropoutGeneratorOutputDevice)
  (Tensor
     relPosGradient
     relPosLayout
     relPosDevice
     relPosDataType
     relPosShape)
-&gt; (Tensor
      relPosGradient relPosLayout relPosDevice relPosDataType relPosShape
    -&gt; IxStateT
         m
         (Generator dropoutGeneratorOutputDevice)
         (Generator dropoutGeneratorOutputDevice)
         (Tensor
            (Or (Gradient RequiresGradient) gradient relPosGradient)
            (Unify (Layout LayoutType) ('Layout 'Dense) relPosLayout)
            (Unify (Device (DeviceType Nat)) device relPosDevice)
            (Seq
               (Unify (DataType DType) relPosDataType ('DataType 'Int64))
               dataType)
            (EmbeddingF ('Shape '[posEncDim, headDim]) relPosShape)))
-&gt; IxStateT
     m
     (Generator dropoutGeneratorOutputDevice)
     (Generator dropoutGeneratorOutputDevice)
     (Tensor
        (Or (Gradient RequiresGradient) gradient relPosGradient)
        (Unify (Layout LayoutType) ('Layout 'Dense) relPosLayout)
        (Unify (Device (DeviceType Nat)) device relPosDevice)
        (Seq
           (Unify (DataType DType) relPosDataType ('DataType 'Int64))
           dataType)
        (EmbeddingF ('Shape '[posEncDim, headDim]) relPosShape))
forall k1 (m :: k1 -&gt; k1 -&gt; * -&gt; *) (i :: k1) (j :: k1) a
       (k2 :: k1) b.
IxMonad m =&gt;
m i j a -&gt; (a -&gt; m j k2 b) -&gt; m i k2 b
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&gt;&gt;&gt;=</span></a></span><span> </span><span class="annot"><span class="annottext">(Generator dropoutGeneratorOutputDevice
 -&gt; m (Tensor
         (Or (Gradient RequiresGradient) gradient relPosGradient)
         (Unify (Layout LayoutType) ('Layout 'Dense) relPosLayout)
         (Unify (Device (DeviceType Nat)) device relPosDevice)
         (Seq
            (Unify (DataType DType) relPosDataType ('DataType 'Int64))
            dataType)
         (EmbeddingF ('Shape '[posEncDim, headDim]) relPosShape),
       Generator dropoutGeneratorOutputDevice))
-&gt; IxStateT
     m
     (Generator dropoutGeneratorOutputDevice)
     (Generator dropoutGeneratorOutputDevice)
     (Tensor
        (Or (Gradient RequiresGradient) gradient relPosGradient)
        (Unify (Layout LayoutType) ('Layout 'Dense) relPosLayout)
        (Unify (Device (DeviceType Nat)) device relPosDevice)
        (Seq
           (Unify (DataType DType) relPosDataType ('DataType 'Int64))
           dataType)
        (EmbeddingF ('Shape '[posEncDim, headDim]) relPosShape))
forall (m :: * -&gt; *) i j a. (i -&gt; m (a, j)) -&gt; IxStateT m i j a
</span><a href="../file:///nix/store/8vjaffqxij7bih93d9mlzmc7ksanlw0i-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier hs-var">IxStateT</span></a></span><span> </span><span class="annot"><span class="annottext">((Generator dropoutGeneratorOutputDevice
  -&gt; m (Tensor
          (Or (Gradient RequiresGradient) gradient relPosGradient)
          (Unify (Layout LayoutType) ('Layout 'Dense) relPosLayout)
          (Unify (Device (DeviceType Nat)) device relPosDevice)
          (Seq
             (Unify (DataType DType) relPosDataType ('DataType 'Int64))
             dataType)
          (EmbeddingF ('Shape '[posEncDim, headDim]) relPosShape),
        Generator dropoutGeneratorOutputDevice))
 -&gt; IxStateT
      m
      (Generator dropoutGeneratorOutputDevice)
      (Generator dropoutGeneratorOutputDevice)
      (Tensor
         (Or (Gradient RequiresGradient) gradient relPosGradient)
         (Unify (Layout LayoutType) ('Layout 'Dense) relPosLayout)
         (Unify (Device (DeviceType Nat)) device relPosDevice)
         (Seq
            (Unify (DataType DType) relPosDataType ('DataType 'Int64))
            dataType)
         (EmbeddingF ('Shape '[posEncDim, headDim]) relPosShape)))
-&gt; (Tensor
      relPosGradient relPosLayout relPosDevice relPosDataType relPosShape
    -&gt; Generator dropoutGeneratorOutputDevice
    -&gt; m (Tensor
            (Or (Gradient RequiresGradient) gradient relPosGradient)
            (Unify (Layout LayoutType) ('Layout 'Dense) relPosLayout)
            (Unify (Device (DeviceType Nat)) device relPosDevice)
            (Seq
               (Unify (DataType DType) relPosDataType ('DataType 'Int64))
               dataType)
            (EmbeddingF ('Shape '[posEncDim, headDim]) relPosShape),
          Generator dropoutGeneratorOutputDevice))
-&gt; Tensor
     relPosGradient relPosLayout relPosDevice relPosDataType relPosShape
-&gt; IxStateT
     m
     (Generator dropoutGeneratorOutputDevice)
     (Generator dropoutGeneratorOutputDevice)
     (Tensor
        (Or (Gradient RequiresGradient) gradient relPosGradient)
        (Unify (Layout LayoutType) ('Layout 'Dense) relPosLayout)
        (Unify (Device (DeviceType Nat)) device relPosDevice)
        (Seq
           (Unify (DataType DType) relPosDataType ('DataType 'Int64))
           dataType)
        (EmbeddingF ('Shape '[posEncDim, headDim]) relPosShape))
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">Embedding
  gradient
  ('Layout 'Dense)
  device
  dataType
  posEncDim
  headDim
  'Nothing
-&gt; Tensor
     relPosGradient relPosLayout relPosDevice relPosDataType relPosShape
-&gt; Generator dropoutGeneratorOutputDevice
-&gt; m (Tensor
        (Or (Gradient RequiresGradient) gradient relPosGradient)
        (Unify (Layout LayoutType) ('Layout 'Dense) relPosLayout)
        (Unify (Device (DeviceType Nat)) device relPosDevice)
        (Seq
           (Unify (DataType DType) relPosDataType ('DataType 'Int64))
           dataType)
        (EmbeddingF ('Shape '[posEncDim, headDim]) relPosShape),
      Generator dropoutGeneratorOutputDevice)
forall model input (generatorDevice :: Device (DeviceType Nat))
       output (generatorOutputDevice :: Device (DeviceType Nat))
       (m :: * -&gt; *).
(HasForward
   model input generatorDevice output generatorOutputDevice,
 MonadThrow m) =&gt;
model
-&gt; input
-&gt; Generator generatorDevice
-&gt; m (output, Generator generatorOutputDevice)
</span><a href="Torch.GraduallyTyped.NN.Class.html#forward"><span class="hs-identifier hs-var">forward</span></a></span><span> </span><span class="annot"><span class="annottext">Embedding
  gradient
  ('Layout 'Dense)
  device
  dataType
  posEncDim
  headDim
  'Nothing
TEPosEncF
  'ByT5 gradient device dataType headDim inputEmbedDim posEncDim
</span><a href="#local-6989586621679808564"><span class="hs-identifier hs-var">tePosEnc</span></a></span><span>
</span><span id="line-593"></span><span>            </span><span class="annot"><span class="annottext">IxStateT
  m
  (Generator dropoutGeneratorOutputDevice)
  (Generator dropoutGeneratorOutputDevice)
  (Tensor
     (Or (Gradient RequiresGradient) gradient relPosGradient)
     (Unify (Layout LayoutType) ('Layout 'Dense) relPosLayout)
     (Unify (Device (DeviceType Nat)) device relPosDevice)
     (Seq
        (Unify (DataType DType) relPosDataType ('DataType 'Int64))
        dataType)
     (EmbeddingF ('Shape '[posEncDim, headDim]) relPosShape))
-&gt; (Tensor
      (Or (Gradient RequiresGradient) gradient relPosGradient)
      (Unify (Layout LayoutType) ('Layout 'Dense) relPosLayout)
      (Unify (Device (DeviceType Nat)) device relPosDevice)
      (Seq
         (Unify (DataType DType) relPosDataType ('DataType 'Int64))
         dataType)
      (EmbeddingF ('Shape '[posEncDim, headDim]) relPosShape)
    -&gt; IxStateT
         m
         (Generator dropoutGeneratorOutputDevice)
         (Generator dropoutGeneratorOutputDevice)
         (Tensor
            (Or (Gradient RequiresGradient) gradient relPosGradient)
            (Unify (Layout LayoutType) ('Layout 'Dense) relPosLayout)
            (Unify (Device (DeviceType Nat)) device relPosDevice)
            (Seq
               (Unify (DataType DType) relPosDataType ('DataType 'Int64))
               dataType)
            (TransposeF
               ('SelectDim ('ByIndex 2))
               ('SelectDim ('ByIndex 3))
               (EmbeddingF ('Shape '[posEncDim, headDim]) relPosShape))))
-&gt; IxStateT
     m
     (Generator dropoutGeneratorOutputDevice)
     (Generator dropoutGeneratorOutputDevice)
     (Tensor
        (Or (Gradient RequiresGradient) gradient relPosGradient)
        (Unify (Layout LayoutType) ('Layout 'Dense) relPosLayout)
        (Unify (Device (DeviceType Nat)) device relPosDevice)
        (Seq
           (Unify (DataType DType) relPosDataType ('DataType 'Int64))
           dataType)
        (TransposeF
           ('SelectDim ('ByIndex 2))
           ('SelectDim ('ByIndex 3))
           (EmbeddingF ('Shape '[posEncDim, headDim]) relPosShape)))
forall k1 (m :: k1 -&gt; k1 -&gt; * -&gt; *) (i :: k1) (j :: k1) a
       (k2 :: k1) b.
IxMonad m =&gt;
m i j a -&gt; (a -&gt; m j k2 b) -&gt; m i k2 b
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&gt;&gt;&gt;=</span></a></span><span> </span><span class="annot"><span class="annottext">m (Tensor
     (Or (Gradient RequiresGradient) gradient relPosGradient)
     (Unify (Layout LayoutType) ('Layout 'Dense) relPosLayout)
     (Unify (Device (DeviceType Nat)) device relPosDevice)
     (Seq
        (Unify (DataType DType) relPosDataType ('DataType 'Int64))
        dataType)
     (TransposeF
        ('SelectDim ('ByIndex 2))
        ('SelectDim ('ByIndex 3))
        (EmbeddingF ('Shape '[posEncDim, headDim]) relPosShape)))
-&gt; IxStateT
     m
     (Generator dropoutGeneratorOutputDevice)
     (Generator dropoutGeneratorOutputDevice)
     (Tensor
        (Or (Gradient RequiresGradient) gradient relPosGradient)
        (Unify (Layout LayoutType) ('Layout 'Dense) relPosLayout)
        (Unify (Device (DeviceType Nat)) device relPosDevice)
        (Seq
           (Unify (DataType DType) relPosDataType ('DataType 'Int64))
           dataType)
        (TransposeF
           ('SelectDim ('ByIndex 2))
           ('SelectDim ('ByIndex 3))
           (EmbeddingF ('Shape '[posEncDim, headDim]) relPosShape)))
forall k (t :: (* -&gt; *) -&gt; k -&gt; k -&gt; * -&gt; *) (m :: * -&gt; *) a
       (i :: k).
(IxMonadTrans t, Monad m) =&gt;
m a -&gt; t m i i a
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-identifier hs-var">ilift</span></a></span><span> </span><span class="annot"><span class="annottext">(m (Tensor
      (Or (Gradient RequiresGradient) gradient relPosGradient)
      (Unify (Layout LayoutType) ('Layout 'Dense) relPosLayout)
      (Unify (Device (DeviceType Nat)) device relPosDevice)
      (Seq
         (Unify (DataType DType) relPosDataType ('DataType 'Int64))
         dataType)
      (TransposeF
         ('SelectDim ('ByIndex 2))
         ('SelectDim ('ByIndex 3))
         (EmbeddingF ('Shape '[posEncDim, headDim]) relPosShape)))
 -&gt; IxStateT
      m
      (Generator dropoutGeneratorOutputDevice)
      (Generator dropoutGeneratorOutputDevice)
      (Tensor
         (Or (Gradient RequiresGradient) gradient relPosGradient)
         (Unify (Layout LayoutType) ('Layout 'Dense) relPosLayout)
         (Unify (Device (DeviceType Nat)) device relPosDevice)
         (Seq
            (Unify (DataType DType) relPosDataType ('DataType 'Int64))
            dataType)
         (TransposeF
            ('SelectDim ('ByIndex 2))
            ('SelectDim ('ByIndex 3))
            (EmbeddingF ('Shape '[posEncDim, headDim]) relPosShape))))
-&gt; (Tensor
      (Or (Gradient RequiresGradient) gradient relPosGradient)
      (Unify (Layout LayoutType) ('Layout 'Dense) relPosLayout)
      (Unify (Device (DeviceType Nat)) device relPosDevice)
      (Seq
         (Unify (DataType DType) relPosDataType ('DataType 'Int64))
         dataType)
      (EmbeddingF ('Shape '[posEncDim, headDim]) relPosShape)
    -&gt; m (Tensor
            (Or (Gradient RequiresGradient) gradient relPosGradient)
            (Unify (Layout LayoutType) ('Layout 'Dense) relPosLayout)
            (Unify (Device (DeviceType Nat)) device relPosDevice)
            (Seq
               (Unify (DataType DType) relPosDataType ('DataType 'Int64))
               dataType)
            (TransposeF
               ('SelectDim ('ByIndex 2))
               ('SelectDim ('ByIndex 3))
               (EmbeddingF ('Shape '[posEncDim, headDim]) relPosShape))))
-&gt; Tensor
     (Or (Gradient RequiresGradient) gradient relPosGradient)
     (Unify (Layout LayoutType) ('Layout 'Dense) relPosLayout)
     (Unify (Device (DeviceType Nat)) device relPosDevice)
     (Seq
        (Unify (DataType DType) relPosDataType ('DataType 'Int64))
        dataType)
     (EmbeddingF ('Shape '[posEncDim, headDim]) relPosShape)
-&gt; IxStateT
     m
     (Generator dropoutGeneratorOutputDevice)
     (Generator dropoutGeneratorOutputDevice)
     (Tensor
        (Or (Gradient RequiresGradient) gradient relPosGradient)
        (Unify (Layout LayoutType) ('Layout 'Dense) relPosLayout)
        (Unify (Device (DeviceType Nat)) device relPosDevice)
        (Seq
           (Unify (DataType DType) relPosDataType ('DataType 'Int64))
           dataType)
        (TransposeF
           ('SelectDim ('ByIndex 2))
           ('SelectDim ('ByIndex 3))
           (EmbeddingF ('Shape '[posEncDim, headDim]) relPosShape)))
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">forall (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)])
       (shape' :: Shape [Dim (Name Symbol) (Size Nat)]) (m :: * -&gt; *).
(shape'
 ~ TransposeF
     ('SelectDim ('ByIndex 2)) ('SelectDim ('ByIndex 3)) shape,
 SingI ('SelectDim ('ByIndex 2)), SingI ('SelectDim ('ByIndex 3)),
 MonadThrow m) =&gt;
Tensor gradient layout device dataType shape
-&gt; m (Tensor gradient layout device dataType shape')
forall (selectDim0 :: SelectDim (By Symbol Nat))
       (selectDim1 :: SelectDim (By Symbol Nat))
       (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)])
       (shape' :: Shape [Dim (Name Symbol) (Size Nat)]) (m :: * -&gt; *).
(shape' ~ TransposeF selectDim0 selectDim1 shape, SingI selectDim0,
 SingI selectDim1, MonadThrow m) =&gt;
Tensor gradient layout device dataType shape
-&gt; m (Tensor gradient layout device dataType shape')
</span><a href="Torch.GraduallyTyped.Tensor.IndexingSlicingJoining.html#transpose"><span class="hs-identifier hs-var">transpose</span></a></span><span> </span><span class="hs-glyph">@</span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SelectDim"><span class="hs-identifier hs-type">SelectDim</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#ByIndex"><span class="hs-identifier hs-type">ByIndex</span></a></span><span> </span><span class="annot"><span class="hs-number">2</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span> </span><span class="hs-glyph">@</span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SelectDim"><span class="hs-identifier hs-type">SelectDim</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#ByIndex"><span class="hs-identifier hs-type">ByIndex</span></a></span><span> </span><span class="annot"><span class="hs-number">3</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-594"></span><span>            </span><span class="annot"><span class="annottext">IxStateT
  m
  (Generator dropoutGeneratorOutputDevice)
  (Generator dropoutGeneratorOutputDevice)
  (Tensor
     (Or (Gradient RequiresGradient) gradient relPosGradient)
     (Unify (Layout LayoutType) ('Layout 'Dense) relPosLayout)
     (Unify (Device (DeviceType Nat)) device relPosDevice)
     (Seq
        (Unify (DataType DType) relPosDataType ('DataType 'Int64))
        dataType)
     (TransposeF
        ('SelectDim ('ByIndex 2))
        ('SelectDim ('ByIndex 3))
        (EmbeddingF ('Shape '[posEncDim, headDim]) relPosShape)))
-&gt; (Tensor
      (Or (Gradient RequiresGradient) gradient relPosGradient)
      (Unify (Layout LayoutType) ('Layout 'Dense) relPosLayout)
      (Unify (Device (DeviceType Nat)) device relPosDevice)
      (Seq
         (Unify (DataType DType) relPosDataType ('DataType 'Int64))
         dataType)
      (TransposeF
         ('SelectDim ('ByIndex 2))
         ('SelectDim ('ByIndex 3))
         (EmbeddingF ('Shape '[posEncDim, headDim]) relPosShape))
    -&gt; IxStateT
         m
         (Generator dropoutGeneratorOutputDevice)
         (Generator dropoutGeneratorOutputDevice)
         (Tensor
            (Or (Gradient RequiresGradient) gradient relPosGradient)
            (Unify (Layout LayoutType) ('Layout 'Dense) relPosLayout)
            (Unify (Device (DeviceType Nat)) device relPosDevice)
            (Seq
               (Unify (DataType DType) relPosDataType ('DataType 'Int64))
               dataType)
            (TransposeF
               ('SelectDim ('ByIndex 1))
               ('SelectDim ('ByIndex 2))
               (TransposeF
                  ('SelectDim ('ByIndex 2))
                  ('SelectDim ('ByIndex 3))
                  (EmbeddingF ('Shape '[posEncDim, headDim]) relPosShape)))))
-&gt; IxStateT
     m
     (Generator dropoutGeneratorOutputDevice)
     (Generator dropoutGeneratorOutputDevice)
     (Tensor
        (Or (Gradient RequiresGradient) gradient relPosGradient)
        (Unify (Layout LayoutType) ('Layout 'Dense) relPosLayout)
        (Unify (Device (DeviceType Nat)) device relPosDevice)
        (Seq
           (Unify (DataType DType) relPosDataType ('DataType 'Int64))
           dataType)
        (TransposeF
           ('SelectDim ('ByIndex 1))
           ('SelectDim ('ByIndex 2))
           (TransposeF
              ('SelectDim ('ByIndex 2))
              ('SelectDim ('ByIndex 3))
              (EmbeddingF ('Shape '[posEncDim, headDim]) relPosShape))))
forall k1 (m :: k1 -&gt; k1 -&gt; * -&gt; *) (i :: k1) (j :: k1) a
       (k2 :: k1) b.
IxMonad m =&gt;
m i j a -&gt; (a -&gt; m j k2 b) -&gt; m i k2 b
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&gt;&gt;&gt;=</span></a></span><span> </span><span class="annot"><span class="annottext">m (Tensor
     (Or (Gradient RequiresGradient) gradient relPosGradient)
     (Unify (Layout LayoutType) ('Layout 'Dense) relPosLayout)
     (Unify (Device (DeviceType Nat)) device relPosDevice)
     (Seq
        (Unify (DataType DType) relPosDataType ('DataType 'Int64))
        dataType)
     (TransposeF
        ('SelectDim ('ByIndex 1))
        ('SelectDim ('ByIndex 2))
        (TransposeF
           ('SelectDim ('ByIndex 2))
           ('SelectDim ('ByIndex 3))
           (EmbeddingF ('Shape '[posEncDim, headDim]) relPosShape))))
-&gt; IxStateT
     m
     (Generator dropoutGeneratorOutputDevice)
     (Generator dropoutGeneratorOutputDevice)
     (Tensor
        (Or (Gradient RequiresGradient) gradient relPosGradient)
        (Unify (Layout LayoutType) ('Layout 'Dense) relPosLayout)
        (Unify (Device (DeviceType Nat)) device relPosDevice)
        (Seq
           (Unify (DataType DType) relPosDataType ('DataType 'Int64))
           dataType)
        (TransposeF
           ('SelectDim ('ByIndex 1))
           ('SelectDim ('ByIndex 2))
           (TransposeF
              ('SelectDim ('ByIndex 2))
              ('SelectDim ('ByIndex 3))
              (EmbeddingF ('Shape '[posEncDim, headDim]) relPosShape))))
forall k (t :: (* -&gt; *) -&gt; k -&gt; k -&gt; * -&gt; *) (m :: * -&gt; *) a
       (i :: k).
(IxMonadTrans t, Monad m) =&gt;
m a -&gt; t m i i a
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-identifier hs-var">ilift</span></a></span><span> </span><span class="annot"><span class="annottext">(m (Tensor
      (Or (Gradient RequiresGradient) gradient relPosGradient)
      (Unify (Layout LayoutType) ('Layout 'Dense) relPosLayout)
      (Unify (Device (DeviceType Nat)) device relPosDevice)
      (Seq
         (Unify (DataType DType) relPosDataType ('DataType 'Int64))
         dataType)
      (TransposeF
         ('SelectDim ('ByIndex 1))
         ('SelectDim ('ByIndex 2))
         (TransposeF
            ('SelectDim ('ByIndex 2))
            ('SelectDim ('ByIndex 3))
            (EmbeddingF ('Shape '[posEncDim, headDim]) relPosShape))))
 -&gt; IxStateT
      m
      (Generator dropoutGeneratorOutputDevice)
      (Generator dropoutGeneratorOutputDevice)
      (Tensor
         (Or (Gradient RequiresGradient) gradient relPosGradient)
         (Unify (Layout LayoutType) ('Layout 'Dense) relPosLayout)
         (Unify (Device (DeviceType Nat)) device relPosDevice)
         (Seq
            (Unify (DataType DType) relPosDataType ('DataType 'Int64))
            dataType)
         (TransposeF
            ('SelectDim ('ByIndex 1))
            ('SelectDim ('ByIndex 2))
            (TransposeF
               ('SelectDim ('ByIndex 2))
               ('SelectDim ('ByIndex 3))
               (EmbeddingF ('Shape '[posEncDim, headDim]) relPosShape)))))
-&gt; (Tensor
      (Or (Gradient RequiresGradient) gradient relPosGradient)
      (Unify (Layout LayoutType) ('Layout 'Dense) relPosLayout)
      (Unify (Device (DeviceType Nat)) device relPosDevice)
      (Seq
         (Unify (DataType DType) relPosDataType ('DataType 'Int64))
         dataType)
      (TransposeF
         ('SelectDim ('ByIndex 2))
         ('SelectDim ('ByIndex 3))
         (EmbeddingF ('Shape '[posEncDim, headDim]) relPosShape))
    -&gt; m (Tensor
            (Or (Gradient RequiresGradient) gradient relPosGradient)
            (Unify (Layout LayoutType) ('Layout 'Dense) relPosLayout)
            (Unify (Device (DeviceType Nat)) device relPosDevice)
            (Seq
               (Unify (DataType DType) relPosDataType ('DataType 'Int64))
               dataType)
            (TransposeF
               ('SelectDim ('ByIndex 1))
               ('SelectDim ('ByIndex 2))
               (TransposeF
                  ('SelectDim ('ByIndex 2))
                  ('SelectDim ('ByIndex 3))
                  (EmbeddingF ('Shape '[posEncDim, headDim]) relPosShape)))))
-&gt; Tensor
     (Or (Gradient RequiresGradient) gradient relPosGradient)
     (Unify (Layout LayoutType) ('Layout 'Dense) relPosLayout)
     (Unify (Device (DeviceType Nat)) device relPosDevice)
     (Seq
        (Unify (DataType DType) relPosDataType ('DataType 'Int64))
        dataType)
     (TransposeF
        ('SelectDim ('ByIndex 2))
        ('SelectDim ('ByIndex 3))
        (EmbeddingF ('Shape '[posEncDim, headDim]) relPosShape))
-&gt; IxStateT
     m
     (Generator dropoutGeneratorOutputDevice)
     (Generator dropoutGeneratorOutputDevice)
     (Tensor
        (Or (Gradient RequiresGradient) gradient relPosGradient)
        (Unify (Layout LayoutType) ('Layout 'Dense) relPosLayout)
        (Unify (Device (DeviceType Nat)) device relPosDevice)
        (Seq
           (Unify (DataType DType) relPosDataType ('DataType 'Int64))
           dataType)
        (TransposeF
           ('SelectDim ('ByIndex 1))
           ('SelectDim ('ByIndex 2))
           (TransposeF
              ('SelectDim ('ByIndex 2))
              ('SelectDim ('ByIndex 3))
              (EmbeddingF ('Shape '[posEncDim, headDim]) relPosShape))))
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">forall (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)])
       (shape' :: Shape [Dim (Name Symbol) (Size Nat)]) (m :: * -&gt; *).
(shape'
 ~ TransposeF
     ('SelectDim ('ByIndex 1)) ('SelectDim ('ByIndex 2)) shape,
 SingI ('SelectDim ('ByIndex 1)), SingI ('SelectDim ('ByIndex 2)),
 MonadThrow m) =&gt;
Tensor gradient layout device dataType shape
-&gt; m (Tensor gradient layout device dataType shape')
forall (selectDim0 :: SelectDim (By Symbol Nat))
       (selectDim1 :: SelectDim (By Symbol Nat))
       (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)])
       (shape' :: Shape [Dim (Name Symbol) (Size Nat)]) (m :: * -&gt; *).
(shape' ~ TransposeF selectDim0 selectDim1 shape, SingI selectDim0,
 SingI selectDim1, MonadThrow m) =&gt;
Tensor gradient layout device dataType shape
-&gt; m (Tensor gradient layout device dataType shape')
</span><a href="Torch.GraduallyTyped.Tensor.IndexingSlicingJoining.html#transpose"><span class="hs-identifier hs-var">transpose</span></a></span><span> </span><span class="hs-glyph">@</span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SelectDim"><span class="hs-identifier hs-type">SelectDim</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#ByIndex"><span class="hs-identifier hs-type">ByIndex</span></a></span><span> </span><span class="annot"><span class="hs-number">1</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span> </span><span class="hs-glyph">@</span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SelectDim"><span class="hs-identifier hs-type">SelectDim</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#ByIndex"><span class="hs-identifier hs-type">ByIndex</span></a></span><span> </span><span class="annot"><span class="hs-number">2</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-595"></span><span>        </span><span id="local-6989586621679808559"><span class="annot"><span class="annottext">attentionBias :: IxStateT
  m
  (Generator dropoutGeneratorOutputDevice)
  (Generator dropoutGeneratorOutputDevice)
  (Tensor
     (Or
        (Gradient RequiresGradient)
        (Or (Gradient RequiresGradient) gradient relPosGradient)
        attentionMaskGradient)
     (Unify
        (Layout LayoutType)
        (Unify (Layout LayoutType) ('Layout 'Dense) relPosLayout)
        attentionMaskLayout)
     (Unify
        (Device (DeviceType Nat))
        (Unify (Device (DeviceType Nat)) device relPosDevice)
        attentionMaskDevice)
     (Unify
        (DataType DType)
        (Seq
           (Unify (DataType DType) relPosDataType ('DataType 'Int64))
           dataType)
        attentionMaskDataType)
     (BroadcastShapesF
        (TransposeF
           ('SelectDim ('ByIndex 1))
           ('SelectDim ('ByIndex 2))
           (TransposeF
              ('SelectDim ('ByIndex 2))
              ('SelectDim ('ByIndex 3))
              (EmbeddingF ('Shape '[posEncDim, headDim]) relPosShape)))
        (UnsqueezeF ('SelectDim ('ByIndex 1)) attentionMaskShape)))
</span><a href="#local-6989586621679808559"><span class="hs-identifier hs-var hs-var">attentionBias</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-596"></span><span>          </span><span class="annot"><span class="annottext">IxStateT
  m
  (Generator dropoutGeneratorOutputDevice)
  (Generator dropoutGeneratorOutputDevice)
  (Tensor
     (Or (Gradient RequiresGradient) gradient relPosGradient)
     (Unify (Layout LayoutType) ('Layout 'Dense) relPosLayout)
     (Unify (Device (DeviceType Nat)) device relPosDevice)
     (Seq
        (Unify (DataType DType) relPosDataType ('DataType 'Int64))
        dataType)
     (TransposeF
        ('SelectDim ('ByIndex 1))
        ('SelectDim ('ByIndex 2))
        (TransposeF
           ('SelectDim ('ByIndex 2))
           ('SelectDim ('ByIndex 3))
           (EmbeddingF ('Shape '[posEncDim, headDim]) relPosShape))))
</span><a href="#local-6989586621679808560"><span class="hs-identifier hs-var">relPosBias</span></a></span><span>
</span><span id="line-597"></span><span>            </span><span class="annot"><span class="annottext">IxStateT
  m
  (Generator dropoutGeneratorOutputDevice)
  (Generator dropoutGeneratorOutputDevice)
  (Tensor
     (Or (Gradient RequiresGradient) gradient relPosGradient)
     (Unify (Layout LayoutType) ('Layout 'Dense) relPosLayout)
     (Unify (Device (DeviceType Nat)) device relPosDevice)
     (Seq
        (Unify (DataType DType) relPosDataType ('DataType 'Int64))
        dataType)
     (TransposeF
        ('SelectDim ('ByIndex 1))
        ('SelectDim ('ByIndex 2))
        (TransposeF
           ('SelectDim ('ByIndex 2))
           ('SelectDim ('ByIndex 3))
           (EmbeddingF ('Shape '[posEncDim, headDim]) relPosShape))))
-&gt; (Tensor
      (Or (Gradient RequiresGradient) gradient relPosGradient)
      (Unify (Layout LayoutType) ('Layout 'Dense) relPosLayout)
      (Unify (Device (DeviceType Nat)) device relPosDevice)
      (Seq
         (Unify (DataType DType) relPosDataType ('DataType 'Int64))
         dataType)
      (TransposeF
         ('SelectDim ('ByIndex 1))
         ('SelectDim ('ByIndex 2))
         (TransposeF
            ('SelectDim ('ByIndex 2))
            ('SelectDim ('ByIndex 3))
            (EmbeddingF ('Shape '[posEncDim, headDim]) relPosShape)))
    -&gt; IxStateT
         m
         (Generator dropoutGeneratorOutputDevice)
         (Generator dropoutGeneratorOutputDevice)
         (Tensor
            (Or
               (Gradient RequiresGradient)
               (Or (Gradient RequiresGradient) gradient relPosGradient)
               attentionMaskGradient)
            (Unify
               (Layout LayoutType)
               (Unify (Layout LayoutType) ('Layout 'Dense) relPosLayout)
               attentionMaskLayout)
            (Unify
               (Device (DeviceType Nat))
               (Unify (Device (DeviceType Nat)) device relPosDevice)
               attentionMaskDevice)
            (Unify
               (DataType DType)
               (Seq
                  (Unify (DataType DType) relPosDataType ('DataType 'Int64))
                  dataType)
               attentionMaskDataType)
            (BroadcastShapesF
               (TransposeF
                  ('SelectDim ('ByIndex 1))
                  ('SelectDim ('ByIndex 2))
                  (TransposeF
                     ('SelectDim ('ByIndex 2))
                     ('SelectDim ('ByIndex 3))
                     (EmbeddingF ('Shape '[posEncDim, headDim]) relPosShape)))
               (UnsqueezeF ('SelectDim ('ByIndex 1)) attentionMaskShape))))
-&gt; IxStateT
     m
     (Generator dropoutGeneratorOutputDevice)
     (Generator dropoutGeneratorOutputDevice)
     (Tensor
        (Or
           (Gradient RequiresGradient)
           (Or (Gradient RequiresGradient) gradient relPosGradient)
           attentionMaskGradient)
        (Unify
           (Layout LayoutType)
           (Unify (Layout LayoutType) ('Layout 'Dense) relPosLayout)
           attentionMaskLayout)
        (Unify
           (Device (DeviceType Nat))
           (Unify (Device (DeviceType Nat)) device relPosDevice)
           attentionMaskDevice)
        (Unify
           (DataType DType)
           (Seq
              (Unify (DataType DType) relPosDataType ('DataType 'Int64))
              dataType)
           attentionMaskDataType)
        (BroadcastShapesF
           (TransposeF
              ('SelectDim ('ByIndex 1))
              ('SelectDim ('ByIndex 2))
              (TransposeF
                 ('SelectDim ('ByIndex 2))
                 ('SelectDim ('ByIndex 3))
                 (EmbeddingF ('Shape '[posEncDim, headDim]) relPosShape)))
           (UnsqueezeF ('SelectDim ('ByIndex 1)) attentionMaskShape)))
forall k1 (m :: k1 -&gt; k1 -&gt; * -&gt; *) (i :: k1) (j :: k1) a
       (k2 :: k1) b.
IxMonad m =&gt;
m i j a -&gt; (a -&gt; m j k2 b) -&gt; m i k2 b
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&gt;&gt;&gt;=</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor
  (Or
     (Gradient RequiresGradient)
     (Or (Gradient RequiresGradient) gradient relPosGradient)
     attentionMaskGradient)
  (Unify
     (Layout LayoutType)
     (Unify (Layout LayoutType) ('Layout 'Dense) relPosLayout)
     attentionMaskLayout)
  (Unify
     (Device (DeviceType Nat))
     (Unify (Device (DeviceType Nat)) device relPosDevice)
     attentionMaskDevice)
  (Unify
     (DataType DType)
     (Seq
        (Unify (DataType DType) relPosDataType ('DataType 'Int64))
        dataType)
     attentionMaskDataType)
  (BroadcastShapesF
     (TransposeF
        ('SelectDim ('ByIndex 1))
        ('SelectDim ('ByIndex 2))
        (TransposeF
           ('SelectDim ('ByIndex 2))
           ('SelectDim ('ByIndex 3))
           (EmbeddingF ('Shape '[posEncDim, headDim]) relPosShape)))
     (UnsqueezeF ('SelectDim ('ByIndex 1)) attentionMaskShape))
-&gt; IxStateT
     m
     (Generator dropoutGeneratorOutputDevice)
     (Generator dropoutGeneratorOutputDevice)
     (Tensor
        (Or
           (Gradient RequiresGradient)
           (Or (Gradient RequiresGradient) gradient relPosGradient)
           attentionMaskGradient)
        (Unify
           (Layout LayoutType)
           (Unify (Layout LayoutType) ('Layout 'Dense) relPosLayout)
           attentionMaskLayout)
        (Unify
           (Device (DeviceType Nat))
           (Unify (Device (DeviceType Nat)) device relPosDevice)
           attentionMaskDevice)
        (Unify
           (DataType DType)
           (Seq
              (Unify (DataType DType) relPosDataType ('DataType 'Int64))
              dataType)
           attentionMaskDataType)
        (BroadcastShapesF
           (TransposeF
              ('SelectDim ('ByIndex 1))
              ('SelectDim ('ByIndex 2))
              (TransposeF
                 ('SelectDim ('ByIndex 2))
                 ('SelectDim ('ByIndex 3))
                 (EmbeddingF ('Shape '[posEncDim, headDim]) relPosShape)))
           (UnsqueezeF ('SelectDim ('ByIndex 1)) attentionMaskShape)))
forall k (m :: k -&gt; k -&gt; * -&gt; *) a (i :: k).
IxPointed m =&gt;
a -&gt; m i i a
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-identifier hs-var">ireturn</span></a></span><span> </span><span class="annot"><span class="annottext">(Tensor
   (Or
      (Gradient RequiresGradient)
      (Or (Gradient RequiresGradient) gradient relPosGradient)
      attentionMaskGradient)
   (Unify
      (Layout LayoutType)
      (Unify (Layout LayoutType) ('Layout 'Dense) relPosLayout)
      attentionMaskLayout)
   (Unify
      (Device (DeviceType Nat))
      (Unify (Device (DeviceType Nat)) device relPosDevice)
      attentionMaskDevice)
   (Unify
      (DataType DType)
      (Seq
         (Unify (DataType DType) relPosDataType ('DataType 'Int64))
         dataType)
      attentionMaskDataType)
   (BroadcastShapesF
      (TransposeF
         ('SelectDim ('ByIndex 1))
         ('SelectDim ('ByIndex 2))
         (TransposeF
            ('SelectDim ('ByIndex 2))
            ('SelectDim ('ByIndex 3))
            (EmbeddingF ('Shape '[posEncDim, headDim]) relPosShape)))
      (UnsqueezeF ('SelectDim ('ByIndex 1)) attentionMaskShape))
 -&gt; IxStateT
      m
      (Generator dropoutGeneratorOutputDevice)
      (Generator dropoutGeneratorOutputDevice)
      (Tensor
         (Or
            (Gradient RequiresGradient)
            (Or (Gradient RequiresGradient) gradient relPosGradient)
            attentionMaskGradient)
         (Unify
            (Layout LayoutType)
            (Unify (Layout LayoutType) ('Layout 'Dense) relPosLayout)
            attentionMaskLayout)
         (Unify
            (Device (DeviceType Nat))
            (Unify (Device (DeviceType Nat)) device relPosDevice)
            attentionMaskDevice)
         (Unify
            (DataType DType)
            (Seq
               (Unify (DataType DType) relPosDataType ('DataType 'Int64))
               dataType)
            attentionMaskDataType)
         (BroadcastShapesF
            (TransposeF
               ('SelectDim ('ByIndex 1))
               ('SelectDim ('ByIndex 2))
               (TransposeF
                  ('SelectDim ('ByIndex 2))
                  ('SelectDim ('ByIndex 3))
                  (EmbeddingF ('Shape '[posEncDim, headDim]) relPosShape)))
            (UnsqueezeF ('SelectDim ('ByIndex 1)) attentionMaskShape))))
-&gt; (Tensor
      (Or (Gradient RequiresGradient) gradient relPosGradient)
      (Unify (Layout LayoutType) ('Layout 'Dense) relPosLayout)
      (Unify (Device (DeviceType Nat)) device relPosDevice)
      (Seq
         (Unify (DataType DType) relPosDataType ('DataType 'Int64))
         dataType)
      (TransposeF
         ('SelectDim ('ByIndex 1))
         ('SelectDim ('ByIndex 2))
         (TransposeF
            ('SelectDim ('ByIndex 2))
            ('SelectDim ('ByIndex 3))
            (EmbeddingF ('Shape '[posEncDim, headDim]) relPosShape)))
    -&gt; Tensor
         (Or
            (Gradient RequiresGradient)
            (Or (Gradient RequiresGradient) gradient relPosGradient)
            attentionMaskGradient)
         (Unify
            (Layout LayoutType)
            (Unify (Layout LayoutType) ('Layout 'Dense) relPosLayout)
            attentionMaskLayout)
         (Unify
            (Device (DeviceType Nat))
            (Unify (Device (DeviceType Nat)) device relPosDevice)
            attentionMaskDevice)
         (Unify
            (DataType DType)
            (Seq
               (Unify (DataType DType) relPosDataType ('DataType 'Int64))
               dataType)
            attentionMaskDataType)
         (BroadcastShapesF
            (TransposeF
               ('SelectDim ('ByIndex 1))
               ('SelectDim ('ByIndex 2))
               (TransposeF
                  ('SelectDim ('ByIndex 2))
                  ('SelectDim ('ByIndex 3))
                  (EmbeddingF ('Shape '[posEncDim, headDim]) relPosShape)))
            (UnsqueezeF ('SelectDim ('ByIndex 1)) attentionMaskShape)))
-&gt; Tensor
     (Or (Gradient RequiresGradient) gradient relPosGradient)
     (Unify (Layout LayoutType) ('Layout 'Dense) relPosLayout)
     (Unify (Device (DeviceType Nat)) device relPosDevice)
     (Seq
        (Unify (DataType DType) relPosDataType ('DataType 'Int64))
        dataType)
     (TransposeF
        ('SelectDim ('ByIndex 1))
        ('SelectDim ('ByIndex 2))
        (TransposeF
           ('SelectDim ('ByIndex 2))
           ('SelectDim ('ByIndex 3))
           (EmbeddingF ('Shape '[posEncDim, headDim]) relPosShape)))
-&gt; IxStateT
     m
     (Generator dropoutGeneratorOutputDevice)
     (Generator dropoutGeneratorOutputDevice)
     (Tensor
        (Or
           (Gradient RequiresGradient)
           (Or (Gradient RequiresGradient) gradient relPosGradient)
           attentionMaskGradient)
        (Unify
           (Layout LayoutType)
           (Unify (Layout LayoutType) ('Layout 'Dense) relPosLayout)
           attentionMaskLayout)
        (Unify
           (Device (DeviceType Nat))
           (Unify (Device (DeviceType Nat)) device relPosDevice)
           attentionMaskDevice)
        (Unify
           (DataType DType)
           (Seq
              (Unify (DataType DType) relPosDataType ('DataType 'Int64))
              dataType)
           attentionMaskDataType)
        (BroadcastShapesF
           (TransposeF
              ('SelectDim ('ByIndex 1))
              ('SelectDim ('ByIndex 2))
              (TransposeF
                 ('SelectDim ('ByIndex 2))
                 ('SelectDim ('ByIndex 3))
                 (EmbeddingF ('Shape '[posEncDim, headDim]) relPosShape)))
           (UnsqueezeF ('SelectDim ('ByIndex 1)) attentionMaskShape)))
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">Tensor
  (Or (Gradient RequiresGradient) gradient relPosGradient)
  (Unify (Layout LayoutType) ('Layout 'Dense) relPosLayout)
  (Unify (Device (DeviceType Nat)) device relPosDevice)
  (Seq
     (Unify (DataType DType) relPosDataType ('DataType 'Int64))
     dataType)
  (TransposeF
     ('SelectDim ('ByIndex 1))
     ('SelectDim ('ByIndex 2))
     (TransposeF
        ('SelectDim ('ByIndex 2))
        ('SelectDim ('ByIndex 3))
        (EmbeddingF ('Shape '[posEncDim, headDim]) relPosShape)))
-&gt; Tensor
     attentionMaskGradient
     attentionMaskLayout
     attentionMaskDevice
     attentionMaskDataType
     (UnsqueezeF ('SelectDim ('ByIndex 1)) attentionMaskShape)
-&gt; Tensor
     (Or (Gradient RequiresGradient) gradient relPosGradient
      &lt;|&gt; attentionMaskGradient)
     (Unify (Layout LayoutType) ('Layout 'Dense) relPosLayout
      &lt;+&gt; attentionMaskLayout)
     (Unify (Device (DeviceType Nat)) device relPosDevice
      &lt;+&gt; attentionMaskDevice)
     (Seq
        (Unify (DataType DType) relPosDataType ('DataType 'Int64)) dataType
      &lt;+&gt; attentionMaskDataType)
     (BroadcastShapesF
        (TransposeF
           ('SelectDim ('ByIndex 1))
           ('SelectDim ('ByIndex 2))
           (TransposeF
              ('SelectDim ('ByIndex 2))
              ('SelectDim ('ByIndex 3))
              (EmbeddingF ('Shape '[posEncDim, headDim]) relPosShape)))
        (UnsqueezeF ('SelectDim ('ByIndex 1)) attentionMaskShape))
forall (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)])
       (gradient' :: Gradient RequiresGradient)
       (layout' :: Layout LayoutType) (device' :: Device (DeviceType Nat))
       (dataType' :: DataType DType)
       (shape' :: Shape [Dim (Name Symbol) (Size Nat)]).
Tensor gradient layout device dataType shape
-&gt; Tensor gradient' layout' device' dataType' shape'
-&gt; Tensor
     (gradient &lt;|&gt; gradient')
     (layout &lt;+&gt; layout')
     (device &lt;+&gt; device')
     (dataType &lt;+&gt; dataType')
     (BroadcastShapesF shape shape')
</span><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#add"><span class="hs-operator hs-var">`add`</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor
  attentionMaskGradient
  attentionMaskLayout
  attentionMaskDevice
  attentionMaskDataType
  attentionMaskShape
-&gt; Tensor
     attentionMaskGradient
     attentionMaskLayout
     attentionMaskDevice
     attentionMaskDataType
     (UnsqueezeF ('SelectDim ('ByIndex 1)) attentionMaskShape)
forall (selectDim :: SelectDim (By Symbol Nat))
       (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)])
       (shape' :: Shape [Dim (Name Symbol) (Size Nat)]).
(shape' ~ UnsqueezeF selectDim shape, SingI selectDim) =&gt;
Tensor gradient layout device dataType shape
-&gt; Tensor gradient layout device dataType shape'
</span><a href="Torch.GraduallyTyped.Tensor.IndexingSlicingJoining.html#unsqueeze"><span class="hs-identifier hs-var">unsqueeze</span></a></span><span> </span><span class="hs-glyph">@</span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SelectDim"><span class="hs-identifier hs-type">SelectDim</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#ByIndex"><span class="hs-identifier hs-type">ByIndex</span></a></span><span> </span><span class="annot"><span class="hs-number">1</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">Tensor
  attentionMaskGradient
  attentionMaskLayout
  attentionMaskDevice
  attentionMaskDataType
  attentionMaskShape
</span><a href="#local-6989586621679808561"><span class="hs-identifier hs-var">attentionMask</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-598"></span><span>     </span><span class="hs-keyword">in</span><span> </span><span class="annot"><span class="annottext">IxStateT
  m
  (Generator generatorDevice)
  (Generator generatorOutputDevice)
  output
-&gt; Generator generatorDevice
-&gt; m (output, Generator generatorOutputDevice)
forall (m :: * -&gt; *) i j a. IxStateT m i j a -&gt; i -&gt; m (a, j)
</span><a href="../file:///nix/store/8vjaffqxij7bih93d9mlzmc7ksanlw0i-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier hs-var hs-var">runIxStateT</span></a></span><span> </span><span class="annot"><span class="annottext">(IxStateT
   m
   (Generator generatorDevice)
   (Generator generatorOutputDevice)
   output
 -&gt; Generator generatorDevice
 -&gt; m (output, Generator generatorOutputDevice))
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator generatorOutputDevice)
     output
-&gt; Generator generatorDevice
-&gt; m (output, Generator generatorOutputDevice)
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span>
</span><span id="line-599"></span><span>          </span><span class="annot"><span class="annottext">input
-&gt; IxStateT
     m (Generator generatorDevice) (Generator generatorDevice) input
forall k (m :: k -&gt; k -&gt; * -&gt; *) a (i :: k).
IxPointed m =&gt;
a -&gt; m i i a
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-identifier hs-var">ireturn</span></a></span><span> </span><span class="annot"><span class="annottext">input
</span><a href="#local-6989586621679808563"><span class="hs-identifier hs-var">input</span></a></span><span>
</span><span id="line-600"></span><span>            </span><span class="annot"><span class="annottext">IxStateT
  m (Generator generatorDevice) (Generator generatorDevice) input
-&gt; (input
    -&gt; IxStateT
         m
         (Generator generatorDevice)
         (Generator dropoutGeneratorOutputDevice)
         dropoutOutput)
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator dropoutGeneratorOutputDevice)
     dropoutOutput
forall k1 (m :: k1 -&gt; k1 -&gt; * -&gt; *) (i :: k1) (j :: k1) a
       (k2 :: k1) b.
IxMonad m =&gt;
m i j a -&gt; (a -&gt; m j k2 b) -&gt; m i k2 b
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&gt;&gt;&gt;=</span></a></span><span> </span><span class="annot"><span class="annottext">(Generator generatorDevice
 -&gt; m (dropoutOutput, Generator dropoutGeneratorOutputDevice))
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator dropoutGeneratorOutputDevice)
     dropoutOutput
forall (m :: * -&gt; *) i j a. (i -&gt; m (a, j)) -&gt; IxStateT m i j a
</span><a href="../file:///nix/store/8vjaffqxij7bih93d9mlzmc7ksanlw0i-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier hs-var">IxStateT</span></a></span><span> </span><span class="annot"><span class="annottext">((Generator generatorDevice
  -&gt; m (dropoutOutput, Generator dropoutGeneratorOutputDevice))
 -&gt; IxStateT
      m
      (Generator generatorDevice)
      (Generator dropoutGeneratorOutputDevice)
      dropoutOutput)
-&gt; (input
    -&gt; Generator generatorDevice
    -&gt; m (dropoutOutput, Generator dropoutGeneratorOutputDevice))
-&gt; input
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator dropoutGeneratorOutputDevice)
     dropoutOutput
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">Dropout
-&gt; input
-&gt; Generator generatorDevice
-&gt; m (dropoutOutput, Generator dropoutGeneratorOutputDevice)
forall model input (generatorDevice :: Device (DeviceType Nat))
       output (generatorOutputDevice :: Device (DeviceType Nat))
       (m :: * -&gt; *).
(HasForward
   model input generatorDevice output generatorOutputDevice,
 MonadThrow m) =&gt;
model
-&gt; input
-&gt; Generator generatorDevice
-&gt; m (output, Generator generatorOutputDevice)
</span><a href="Torch.GraduallyTyped.NN.Class.html#forward"><span class="hs-identifier hs-var">forward</span></a></span><span> </span><span class="annot"><span class="annottext">Dropout
TEDropoutF 'ByT5
</span><a href="#local-6989586621679808565"><span class="hs-identifier hs-var">teDropout</span></a></span><span>
</span><span id="line-601"></span><span>            </span><span class="annot"><span class="annottext">IxStateT
  m
  (Generator generatorDevice)
  (Generator dropoutGeneratorOutputDevice)
  dropoutOutput
-&gt; (dropoutOutput
    -&gt; IxStateT
         m
         (Generator dropoutGeneratorOutputDevice)
         (Generator stackGeneratorOutputDevice)
         stackOutput)
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator stackGeneratorOutputDevice)
     stackOutput
forall k1 (m :: k1 -&gt; k1 -&gt; * -&gt; *) (i :: k1) (j :: k1) a
       (k2 :: k1) b.
IxMonad m =&gt;
m i j a -&gt; (a -&gt; m j k2 b) -&gt; m i k2 b
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&gt;&gt;&gt;=</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">\</span><span id="local-6989586621679808558"><span class="annot"><span class="annottext">dropoutOutput
</span><a href="#local-6989586621679808558"><span class="hs-identifier hs-var">input'</span></a></span></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><span class="annottext">IxStateT
  m
  (Generator dropoutGeneratorOutputDevice)
  (Generator dropoutGeneratorOutputDevice)
  (Tensor
     (Or
        (Gradient RequiresGradient)
        (Or (Gradient RequiresGradient) gradient relPosGradient)
        attentionMaskGradient)
     (Unify
        (Layout LayoutType)
        (Unify (Layout LayoutType) ('Layout 'Dense) relPosLayout)
        attentionMaskLayout)
     (Unify
        (Device (DeviceType Nat))
        (Unify (Device (DeviceType Nat)) device relPosDevice)
        attentionMaskDevice)
     (Unify
        (DataType DType)
        (Seq
           (Unify (DataType DType) relPosDataType ('DataType 'Int64))
           dataType)
        attentionMaskDataType)
     (BroadcastShapesF
        (TransposeF
           ('SelectDim ('ByIndex 1))
           ('SelectDim ('ByIndex 2))
           (TransposeF
              ('SelectDim ('ByIndex 2))
              ('SelectDim ('ByIndex 3))
              (EmbeddingF ('Shape '[posEncDim, headDim]) relPosShape)))
        (UnsqueezeF ('SelectDim ('ByIndex 1)) attentionMaskShape)))
</span><a href="#local-6989586621679808559"><span class="hs-identifier hs-var">attentionBias</span></a></span><span> </span><span class="annot"><span class="annottext">IxStateT
  m
  (Generator dropoutGeneratorOutputDevice)
  (Generator dropoutGeneratorOutputDevice)
  (Tensor
     (Or
        (Gradient RequiresGradient)
        (Or (Gradient RequiresGradient) gradient relPosGradient)
        attentionMaskGradient)
     (Unify
        (Layout LayoutType)
        (Unify (Layout LayoutType) ('Layout 'Dense) relPosLayout)
        attentionMaskLayout)
     (Unify
        (Device (DeviceType Nat))
        (Unify (Device (DeviceType Nat)) device relPosDevice)
        attentionMaskDevice)
     (Unify
        (DataType DType)
        (Seq
           (Unify (DataType DType) relPosDataType ('DataType 'Int64))
           dataType)
        attentionMaskDataType)
     (BroadcastShapesF
        (TransposeF
           ('SelectDim ('ByIndex 1))
           ('SelectDim ('ByIndex 2))
           (TransposeF
              ('SelectDim ('ByIndex 2))
              ('SelectDim ('ByIndex 3))
              (EmbeddingF ('Shape '[posEncDim, headDim]) relPosShape)))
        (UnsqueezeF ('SelectDim ('ByIndex 1)) attentionMaskShape)))
-&gt; (Tensor
      (Or
         (Gradient RequiresGradient)
         (Or (Gradient RequiresGradient) gradient relPosGradient)
         attentionMaskGradient)
      (Unify
         (Layout LayoutType)
         (Unify (Layout LayoutType) ('Layout 'Dense) relPosLayout)
         attentionMaskLayout)
      (Unify
         (Device (DeviceType Nat))
         (Unify (Device (DeviceType Nat)) device relPosDevice)
         attentionMaskDevice)
      (Unify
         (DataType DType)
         (Seq
            (Unify (DataType DType) relPosDataType ('DataType 'Int64))
            dataType)
         attentionMaskDataType)
      (BroadcastShapesF
         (TransposeF
            ('SelectDim ('ByIndex 1))
            ('SelectDim ('ByIndex 2))
            (TransposeF
               ('SelectDim ('ByIndex 2))
               ('SelectDim ('ByIndex 3))
               (EmbeddingF ('Shape '[posEncDim, headDim]) relPosShape)))
         (UnsqueezeF ('SelectDim ('ByIndex 1)) attentionMaskShape))
    -&gt; IxStateT
         m
         (Generator dropoutGeneratorOutputDevice)
         (Generator stackGeneratorOutputDevice)
         stackOutput)
-&gt; IxStateT
     m
     (Generator dropoutGeneratorOutputDevice)
     (Generator stackGeneratorOutputDevice)
     stackOutput
forall k1 (m :: k1 -&gt; k1 -&gt; * -&gt; *) (i :: k1) (j :: k1) a
       (k2 :: k1) b.
IxMonad m =&gt;
m i j a -&gt; (a -&gt; m j k2 b) -&gt; m i k2 b
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&gt;&gt;&gt;=</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">\</span><span id="local-6989586621679808557"><span class="annot"><span class="annottext">Tensor
  (Or
     (Gradient RequiresGradient)
     (Or (Gradient RequiresGradient) gradient relPosGradient)
     attentionMaskGradient)
  (Unify
     (Layout LayoutType)
     (Unify (Layout LayoutType) ('Layout 'Dense) relPosLayout)
     attentionMaskLayout)
  (Unify
     (Device (DeviceType Nat))
     (Unify (Device (DeviceType Nat)) device relPosDevice)
     attentionMaskDevice)
  (Unify
     (DataType DType)
     (Seq
        (Unify (DataType DType) relPosDataType ('DataType 'Int64))
        dataType)
     attentionMaskDataType)
  (BroadcastShapesF
     (TransposeF
        ('SelectDim ('ByIndex 1))
        ('SelectDim ('ByIndex 2))
        (TransposeF
           ('SelectDim ('ByIndex 2))
           ('SelectDim ('ByIndex 3))
           (EmbeddingF ('Shape '[posEncDim, headDim]) relPosShape)))
     (UnsqueezeF ('SelectDim ('ByIndex 1)) attentionMaskShape))
</span><a href="#local-6989586621679808557"><span class="hs-identifier hs-var">attentionBias'</span></a></span></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><span class="annottext">(Generator dropoutGeneratorOutputDevice
 -&gt; m (stackOutput, Generator stackGeneratorOutputDevice))
-&gt; IxStateT
     m
     (Generator dropoutGeneratorOutputDevice)
     (Generator stackGeneratorOutputDevice)
     stackOutput
forall (m :: * -&gt; *) i j a. (i -&gt; m (a, j)) -&gt; IxStateT m i j a
</span><a href="../file:///nix/store/8vjaffqxij7bih93d9mlzmc7ksanlw0i-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier hs-var">IxStateT</span></a></span><span> </span><span class="annot"><span class="annottext">((Generator dropoutGeneratorOutputDevice
  -&gt; m (stackOutput, Generator stackGeneratorOutputDevice))
 -&gt; IxStateT
      m
      (Generator dropoutGeneratorOutputDevice)
      (Generator stackGeneratorOutputDevice)
      stackOutput)
-&gt; (Generator dropoutGeneratorOutputDevice
    -&gt; m (stackOutput, Generator stackGeneratorOutputDevice))
-&gt; IxStateT
     m
     (Generator dropoutGeneratorOutputDevice)
     (Generator stackGeneratorOutputDevice)
     stackOutput
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">TransformerStack
  'ByT5
  numLayers
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  inputEmbedDim
  ffnDim
-&gt; (dropoutOutput,
    Tensor
      (Or
         (Gradient RequiresGradient)
         (Or (Gradient RequiresGradient) gradient relPosGradient)
         attentionMaskGradient)
      (Unify
         (Layout LayoutType)
         (Unify (Layout LayoutType) ('Layout 'Dense) relPosLayout)
         attentionMaskLayout)
      (Unify
         (Device (DeviceType Nat))
         (Unify (Device (DeviceType Nat)) device relPosDevice)
         attentionMaskDevice)
      (Unify
         (DataType DType)
         (Seq
            (Unify (DataType DType) relPosDataType ('DataType 'Int64))
            dataType)
         attentionMaskDataType)
      (BroadcastShapesF
         (TransposeF
            ('SelectDim ('ByIndex 1))
            ('SelectDim ('ByIndex 2))
            (TransposeF
               ('SelectDim ('ByIndex 2))
               ('SelectDim ('ByIndex 3))
               (EmbeddingF ('Shape '[posEncDim, headDim]) relPosShape)))
         (UnsqueezeF ('SelectDim ('ByIndex 1)) attentionMaskShape)))
-&gt; Generator dropoutGeneratorOutputDevice
-&gt; m (stackOutput, Generator stackGeneratorOutputDevice)
forall model input (generatorDevice :: Device (DeviceType Nat))
       output (generatorOutputDevice :: Device (DeviceType Nat))
       (m :: * -&gt; *).
(HasForward
   model input generatorDevice output generatorOutputDevice,
 MonadThrow m) =&gt;
model
-&gt; input
-&gt; Generator generatorDevice
-&gt; m (output, Generator generatorOutputDevice)
</span><a href="Torch.GraduallyTyped.NN.Class.html#forward"><span class="hs-identifier hs-var">forward</span></a></span><span> </span><span class="annot"><span class="annottext">TransformerStack
  'ByT5
  numLayers
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  inputEmbedDim
  ffnDim
TEStackF
  'ByT5
  numLayers
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  inputEmbedDim
  ffnDim
</span><a href="#local-6989586621679808568"><span class="hs-identifier hs-var">teStack</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">dropoutOutput
</span><a href="#local-6989586621679808558"><span class="hs-identifier hs-var">input'</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">Tensor
  (Or
     (Gradient RequiresGradient)
     (Or (Gradient RequiresGradient) gradient relPosGradient)
     attentionMaskGradient)
  (Unify
     (Layout LayoutType)
     (Unify (Layout LayoutType) ('Layout 'Dense) relPosLayout)
     attentionMaskLayout)
  (Unify
     (Device (DeviceType Nat))
     (Unify (Device (DeviceType Nat)) device relPosDevice)
     attentionMaskDevice)
  (Unify
     (DataType DType)
     (Seq
        (Unify (DataType DType) relPosDataType ('DataType 'Int64))
        dataType)
     attentionMaskDataType)
  (BroadcastShapesF
     (TransposeF
        ('SelectDim ('ByIndex 1))
        ('SelectDim ('ByIndex 2))
        (TransposeF
           ('SelectDim ('ByIndex 2))
           ('SelectDim ('ByIndex 3))
           (EmbeddingF ('Shape '[posEncDim, headDim]) relPosShape)))
     (UnsqueezeF ('SelectDim ('ByIndex 1)) attentionMaskShape))
</span><a href="#local-6989586621679808557"><span class="hs-identifier hs-var">attentionBias'</span></a></span><span class="hs-special">)</span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-602"></span><span>            </span><span class="annot"><span class="annottext">IxStateT
  m
  (Generator generatorDevice)
  (Generator stackGeneratorOutputDevice)
  stackOutput
-&gt; (stackOutput
    -&gt; IxStateT
         m
         (Generator stackGeneratorOutputDevice)
         (Generator layerNormGeneratorOutputDevice)
         layerNormOutput)
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator layerNormGeneratorOutputDevice)
     layerNormOutput
forall k1 (m :: k1 -&gt; k1 -&gt; * -&gt; *) (i :: k1) (j :: k1) a
       (k2 :: k1) b.
IxMonad m =&gt;
m i j a -&gt; (a -&gt; m j k2 b) -&gt; m i k2 b
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&gt;&gt;&gt;=</span></a></span><span> </span><span class="annot"><span class="annottext">(Generator stackGeneratorOutputDevice
 -&gt; m (layerNormOutput, Generator layerNormGeneratorOutputDevice))
-&gt; IxStateT
     m
     (Generator stackGeneratorOutputDevice)
     (Generator layerNormGeneratorOutputDevice)
     layerNormOutput
forall (m :: * -&gt; *) i j a. (i -&gt; m (a, j)) -&gt; IxStateT m i j a
</span><a href="../file:///nix/store/8vjaffqxij7bih93d9mlzmc7ksanlw0i-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier hs-var">IxStateT</span></a></span><span> </span><span class="annot"><span class="annottext">((Generator stackGeneratorOutputDevice
  -&gt; m (layerNormOutput, Generator layerNormGeneratorOutputDevice))
 -&gt; IxStateT
      m
      (Generator stackGeneratorOutputDevice)
      (Generator layerNormGeneratorOutputDevice)
      layerNormOutput)
-&gt; (stackOutput
    -&gt; Generator stackGeneratorOutputDevice
    -&gt; m (layerNormOutput, Generator layerNormGeneratorOutputDevice))
-&gt; stackOutput
-&gt; IxStateT
     m
     (Generator stackGeneratorOutputDevice)
     (Generator layerNormGeneratorOutputDevice)
     layerNormOutput
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">LayerNorm
  'WithoutBias gradient device dataType ('Shape '[inputEmbedDim])
-&gt; stackOutput
-&gt; Generator stackGeneratorOutputDevice
-&gt; m (layerNormOutput, Generator layerNormGeneratorOutputDevice)
forall model input (generatorDevice :: Device (DeviceType Nat))
       output (generatorOutputDevice :: Device (DeviceType Nat))
       (m :: * -&gt; *).
(HasForward
   model input generatorDevice output generatorOutputDevice,
 MonadThrow m) =&gt;
model
-&gt; input
-&gt; Generator generatorDevice
-&gt; m (output, Generator generatorOutputDevice)
</span><a href="Torch.GraduallyTyped.NN.Class.html#forward"><span class="hs-identifier hs-var">forward</span></a></span><span> </span><span class="annot"><span class="annottext">LayerNorm
  'WithoutBias gradient device dataType ('Shape '[inputEmbedDim])
TELayerNormF 'ByT5 gradient device dataType inputEmbedDim
</span><a href="#local-6989586621679808566"><span class="hs-identifier hs-var">teLayerNorm</span></a></span><span>
</span><span id="line-603"></span><span>            </span><span class="annot"><span class="annottext">IxStateT
  m
  (Generator generatorDevice)
  (Generator layerNormGeneratorOutputDevice)
  layerNormOutput
-&gt; (layerNormOutput
    -&gt; IxStateT
         m
         (Generator layerNormGeneratorOutputDevice)
         (Generator generatorOutputDevice)
         output)
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator generatorOutputDevice)
     output
forall k1 (m :: k1 -&gt; k1 -&gt; * -&gt; *) (i :: k1) (j :: k1) a
       (k2 :: k1) b.
IxMonad m =&gt;
m i j a -&gt; (a -&gt; m j k2 b) -&gt; m i k2 b
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&gt;&gt;&gt;=</span></a></span><span> </span><span class="annot"><span class="annottext">(Generator layerNormGeneratorOutputDevice
 -&gt; m (output, Generator generatorOutputDevice))
-&gt; IxStateT
     m
     (Generator layerNormGeneratorOutputDevice)
     (Generator generatorOutputDevice)
     output
forall (m :: * -&gt; *) i j a. (i -&gt; m (a, j)) -&gt; IxStateT m i j a
</span><a href="../file:///nix/store/8vjaffqxij7bih93d9mlzmc7ksanlw0i-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier hs-var">IxStateT</span></a></span><span> </span><span class="annot"><span class="annottext">((Generator layerNormGeneratorOutputDevice
  -&gt; m (output, Generator generatorOutputDevice))
 -&gt; IxStateT
      m
      (Generator layerNormGeneratorOutputDevice)
      (Generator generatorOutputDevice)
      output)
-&gt; (layerNormOutput
    -&gt; Generator layerNormGeneratorOutputDevice
    -&gt; m (output, Generator generatorOutputDevice))
-&gt; layerNormOutput
-&gt; IxStateT
     m
     (Generator layerNormGeneratorOutputDevice)
     (Generator generatorOutputDevice)
     output
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">Dropout
-&gt; layerNormOutput
-&gt; Generator layerNormGeneratorOutputDevice
-&gt; m (output, Generator generatorOutputDevice)
forall model input (generatorDevice :: Device (DeviceType Nat))
       output (generatorOutputDevice :: Device (DeviceType Nat))
       (m :: * -&gt; *).
(HasForward
   model input generatorDevice output generatorOutputDevice,
 MonadThrow m) =&gt;
model
-&gt; input
-&gt; Generator generatorDevice
-&gt; m (output, Generator generatorOutputDevice)
</span><a href="Torch.GraduallyTyped.NN.Class.html#forward"><span class="hs-identifier hs-var">forward</span></a></span><span> </span><span class="annot"><span class="annottext">Dropout
TEDropoutF 'ByT5
</span><a href="#local-6989586621679808565"><span class="hs-identifier hs-var">teDropout</span></a></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span><span>
</span><span id="line-604"></span><span>
</span><span id="line-605"></span><span class="hs-comment">-- | 'HasForward' instance for @TransformerEncoder numLayers 'BART@.</span><span>
</span><span id="line-606"></span><span class="hs-comment">--</span><span>
</span><span id="line-607"></span><span class="hs-comment">-- @</span><span>
</span><span id="line-608"></span><span class="hs-comment">-- &#9484;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9488;  &#9484;&#9472;&#9472;&#9472;&#9472;&#9472;&#9488;  &#9484;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9488;</span><span>
</span><span id="line-609"></span><span class="hs-comment">-- &#9474; input &#9474;  &#9474; pos &#9474;  &#9474; attentionMask &#9474;</span><span>
</span><span id="line-610"></span><span class="hs-comment">-- &#9492;&#9472;&#9472;&#9472;&#9516;&#9472;&#9472;&#9472;&#9496;  &#9492;&#9472;&#9472;&#9472;&#9472;&#9472;&#9496;  &#9492;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9516;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9496;</span><span>
</span><span id="line-611"></span><span class="hs-comment">--     &#9474;         &#9474;             &#9474;</span><span>
</span><span id="line-612"></span><span class="hs-comment">--     &#9474;         &#9660;             &#9474;</span><span>
</span><span id="line-613"></span><span class="hs-comment">--     &#9474;     tePosEnc          &#9474;</span><span>
</span><span id="line-614"></span><span class="hs-comment">--     &#9474;         &#9474;             &#9474;</span><span>
</span><span id="line-615"></span><span class="hs-comment">--     &#9492;&#9472;&#9472;&#9658;add&#9668;&#9472;&#9472;&#9496;             &#9474;</span><span>
</span><span id="line-616"></span><span class="hs-comment">--          &#9474;                  &#9474;</span><span>
</span><span id="line-617"></span><span class="hs-comment">--          &#9660;                  &#9474;</span><span>
</span><span id="line-618"></span><span class="hs-comment">--   teEmbedLayerNorm          &#9474;</span><span>
</span><span id="line-619"></span><span class="hs-comment">--          &#9660;                  &#9660;</span><span>
</span><span id="line-620"></span><span class="hs-comment">--      teDropout          unsqueeze</span><span>
</span><span id="line-621"></span><span class="hs-comment">--          &#9660;                  &#9474;</span><span>
</span><span id="line-622"></span><span class="hs-comment">--       teStack&#9668;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9496;</span><span>
</span><span id="line-623"></span><span class="hs-comment">--          &#9474;</span><span>
</span><span id="line-624"></span><span class="hs-comment">--          &#9660;</span><span>
</span><span id="line-625"></span><span class="hs-comment">--     &#9484;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9488;</span><span>
</span><span id="line-626"></span><span class="hs-comment">--     &#9474; output &#9474;</span><span>
</span><span id="line-627"></span><span class="hs-comment">--     &#9492;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9496;</span><span>
</span><span id="line-628"></span><span class="hs-comment">-- @</span><span>
</span><span id="line-629"></span><span id="local-6989586621679808526"><span id="local-6989586621679808527"><span id="local-6989586621679808528"><span id="local-6989586621679808529"><span id="local-6989586621679808530"><span id="local-6989586621679808531"><span id="local-6989586621679808532"><span id="local-6989586621679808533"><span id="local-6989586621679808534"><span id="local-6989586621679808535"><span id="local-6989586621679808536"><span id="local-6989586621679808537"><span id="local-6989586621679808538"><span id="local-6989586621679808539"><span id="local-6989586621679808540"><span id="local-6989586621679808541"><span id="local-6989586621679808542"><span id="local-6989586621679808543"><span id="local-6989586621679808544"><span id="local-6989586621679808545"><span id="local-6989586621679808546"><span id="local-6989586621679808547"><span id="local-6989586621679808548"><span id="local-6989586621679808549"><span id="local-6989586621679808550"><span id="local-6989586621679808551"><span id="local-6989586621679808552"><span id="local-6989586621679808553"><span id="local-6989586621679808554"><span id="local-6989586621679808555"><span id="local-6989586621679808556"><span class="hs-keyword">instance</span><span>
</span><span id="line-630"></span><span>  </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasForward"><span class="hs-identifier hs-type">HasForward</span></a></span><span>
</span><span id="line-631"></span><span>      </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Encoder.html#TEEmbedLayerNormF"><span class="hs-identifier hs-type">TEEmbedLayerNormF</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#BART"><span class="hs-identifier hs-type">BART</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808556"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808555"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808554"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808553"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-632"></span><span>      </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span>
</span><span id="line-633"></span><span>          </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679808552"><span class="hs-identifier hs-type">inputGradient</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%7C%3E"><span class="hs-operator hs-type">&lt;|&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808556"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%7C%3E"><span class="hs-operator hs-type">&lt;|&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808551"><span class="hs-identifier hs-type">posGradient</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-634"></span><span>          </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679808550"><span class="hs-identifier hs-type">inputLayout</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#Layout"><span class="hs-identifier hs-type">Layout</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#Dense"><span class="hs-identifier hs-type">Dense</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808549"><span class="hs-identifier hs-type">posLayout</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-635"></span><span>          </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679808548"><span class="hs-identifier hs-type">inputDevice</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808555"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808547"><span class="hs-identifier hs-type">posDevice</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-636"></span><span>          </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679808546"><span class="hs-identifier hs-type">inputDataType</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Prelude.html#Seq"><span class="hs-identifier hs-type">Seq</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679808545"><span class="hs-identifier hs-type">posDataType</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#DataType"><span class="hs-identifier hs-type">DataType</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#Int64"><span class="hs-identifier hs-type">Int64</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679808554"><span class="hs-identifier hs-type">dataType</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-637"></span><span>          </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Class.html#BroadcastShapesF"><span class="hs-identifier hs-type">BroadcastShapesF</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808544"><span class="hs-identifier hs-type">inputShape</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Functional.Sparse.html#EmbeddingF"><span class="hs-identifier hs-type">EmbeddingF</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Shape"><span class="hs-identifier hs-type">Shape</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="annot"><a href="#local-6989586621679808543"><span class="hs-identifier hs-type">posEncDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679808553"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span><span class="hs-special">]</span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679808542"><span class="hs-identifier hs-type">posShape</span></a></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-638"></span><span>      </span><span class="hs-special">)</span><span>
</span><span id="line-639"></span><span>      </span><span class="annot"><a href="#local-6989586621679808541"><span class="hs-identifier hs-type">generatorDevice</span></a></span><span>
</span><span id="line-640"></span><span>      </span><span class="annot"><a href="#local-6989586621679808540"><span class="hs-identifier hs-type">layerNormOutput</span></a></span><span>
</span><span id="line-641"></span><span>      </span><span class="annot"><a href="#local-6989586621679808541"><span class="hs-identifier hs-type">generatorDevice</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-642"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasForward"><span class="hs-identifier hs-type">HasForward</span></a></span><span>
</span><span id="line-643"></span><span>      </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Encoder.html#TEDropoutF"><span class="hs-identifier hs-type">TEDropoutF</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#BART"><span class="hs-identifier hs-type">BART</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-644"></span><span>      </span><span class="annot"><a href="#local-6989586621679808540"><span class="hs-identifier hs-type">layerNormOutput</span></a></span><span>
</span><span id="line-645"></span><span>      </span><span class="annot"><a href="#local-6989586621679808541"><span class="hs-identifier hs-type">generatorDevice</span></a></span><span>
</span><span id="line-646"></span><span>      </span><span class="annot"><a href="#local-6989586621679808539"><span class="hs-identifier hs-type">dropoutOutput</span></a></span><span>
</span><span id="line-647"></span><span>      </span><span class="annot"><a href="#local-6989586621679808538"><span class="hs-identifier hs-type">dropoutGeneratorOutputDevice</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-648"></span><span>    </span><span class="annot"><span class="hs-identifier hs-type">Show</span></span><span> </span><span class="annot"><a href="#local-6989586621679808539"><span class="hs-identifier hs-type">dropoutOutput</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-649"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasForward"><span class="hs-identifier hs-type">HasForward</span></a></span><span>
</span><span id="line-650"></span><span>      </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Encoder.html#TEStackF"><span class="hs-identifier hs-type">TEStackF</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#BART"><span class="hs-identifier hs-type">BART</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808537"><span class="hs-identifier hs-type">numLayers</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808556"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808555"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808554"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808536"><span class="hs-identifier hs-type">headDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808535"><span class="hs-identifier hs-type">headEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808534"><span class="hs-identifier hs-type">embedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808553"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808533"><span class="hs-identifier hs-type">ffnDim</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-651"></span><span>      </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="#local-6989586621679808539"><span class="hs-identifier hs-type">dropoutOutput</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-652"></span><span>        </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span>
</span><span id="line-653"></span><span>          </span><span class="annot"><a href="#local-6989586621679808532"><span class="hs-identifier hs-type">attentionMaskGradient</span></a></span><span>
</span><span id="line-654"></span><span>          </span><span class="annot"><a href="#local-6989586621679808531"><span class="hs-identifier hs-type">attentionMaskLayout</span></a></span><span>
</span><span id="line-655"></span><span>          </span><span class="annot"><a href="#local-6989586621679808530"><span class="hs-identifier hs-type">attentionMaskDevice</span></a></span><span>
</span><span id="line-656"></span><span>          </span><span class="annot"><a href="#local-6989586621679808529"><span class="hs-identifier hs-type">attentionMaskDataType</span></a></span><span>
</span><span id="line-657"></span><span>          </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.IndexingSlicingJoining.html#UnsqueezeF"><span class="hs-identifier hs-type">UnsqueezeF</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SelectDim"><span class="hs-identifier hs-type">SelectDim</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#ByIndex"><span class="hs-identifier hs-type">ByIndex</span></a></span><span> </span><span class="annot"><span class="hs-number">1</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679808528"><span class="hs-identifier hs-type">attentionMaskShape</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-658"></span><span>      </span><span class="hs-special">)</span><span>
</span><span id="line-659"></span><span>      </span><span class="annot"><a href="#local-6989586621679808538"><span class="hs-identifier hs-type">dropoutGeneratorOutputDevice</span></a></span><span>
</span><span id="line-660"></span><span>      </span><span class="annot"><a href="#local-6989586621679808527"><span class="hs-identifier hs-type">output</span></a></span><span>
</span><span id="line-661"></span><span>      </span><span class="annot"><a href="#local-6989586621679808526"><span class="hs-identifier hs-type">generatorOutputDevice</span></a></span><span>
</span><span id="line-662"></span><span>  </span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-663"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasForward"><span class="hs-identifier hs-type">HasForward</span></a></span><span>
</span><span id="line-664"></span><span>    </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Encoder.html#TransformerEncoder"><span class="hs-identifier hs-type">TransformerEncoder</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#BART"><span class="hs-identifier hs-type">BART</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808537"><span class="hs-identifier hs-type">numLayers</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808556"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808555"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808554"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808536"><span class="hs-identifier hs-type">headDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808535"><span class="hs-identifier hs-type">headEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808534"><span class="hs-identifier hs-type">embedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808553"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808533"><span class="hs-identifier hs-type">ffnDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808543"><span class="hs-identifier hs-type">posEncDim</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-665"></span><span>    </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808552"><span class="hs-identifier hs-type">inputGradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808550"><span class="hs-identifier hs-type">inputLayout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808548"><span class="hs-identifier hs-type">inputDevice</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808546"><span class="hs-identifier hs-type">inputDataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808544"><span class="hs-identifier hs-type">inputShape</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-666"></span><span>      </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808551"><span class="hs-identifier hs-type">posGradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808549"><span class="hs-identifier hs-type">posLayout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808547"><span class="hs-identifier hs-type">posDevice</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808545"><span class="hs-identifier hs-type">posDataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808542"><span class="hs-identifier hs-type">posShape</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-667"></span><span>      </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808532"><span class="hs-identifier hs-type">attentionMaskGradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808531"><span class="hs-identifier hs-type">attentionMaskLayout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808530"><span class="hs-identifier hs-type">attentionMaskDevice</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808529"><span class="hs-identifier hs-type">attentionMaskDataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808528"><span class="hs-identifier hs-type">attentionMaskShape</span></a></span><span>
</span><span id="line-668"></span><span>    </span><span class="hs-special">)</span><span>
</span><span id="line-669"></span><span>    </span><span class="annot"><a href="#local-6989586621679808541"><span class="hs-identifier hs-type">generatorDevice</span></a></span><span>
</span><span id="line-670"></span><span>    </span><span class="annot"><a href="#local-6989586621679808527"><span class="hs-identifier hs-type">output</span></a></span><span>
</span><span id="line-671"></span><span>    </span><span class="annot"><a href="#local-6989586621679808526"><span class="hs-identifier hs-type">generatorOutputDevice</span></a></span><span>
</span><span id="line-672"></span><span>  </span><span class="hs-keyword">where</span><span>
</span><span id="line-673"></span><span>  </span><span id="local-6989586621679808524"><span class="annot"><span class="annottext">forward :: TransformerEncoder
  'BART
  numLayers
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  inputEmbedDim
  ffnDim
  posEncDim
-&gt; (Tensor
      inputGradient inputLayout inputDevice inputDataType inputShape,
    Tensor posGradient posLayout posDevice posDataType posShape,
    Tensor
      attentionMaskGradient
      attentionMaskLayout
      attentionMaskDevice
      attentionMaskDataType
      attentionMaskShape)
-&gt; Generator generatorDevice
-&gt; m (output, Generator generatorOutputDevice)
</span><a href="#local-6989586621679808524"><span class="hs-identifier hs-var hs-var hs-var hs-var">forward</span></a></span></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Encoder.html#TransformerEncoder"><span class="hs-identifier hs-type">TransformerEncoder</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Encoder.html#GTransformerEncoder"><span class="hs-identifier hs-type">GTransformerEncoder</span></a></span><span> </span><span class="hs-special">{</span><span id="local-6989586621679808519"><span id="local-6989586621679808520"><span id="local-6989586621679808521"><span id="local-6989586621679808522"><span id="local-6989586621679808523"><span class="annot"><span class="annottext">TEPosEncF
  'BART gradient device dataType headDim inputEmbedDim posEncDim
TEDropoutF 'BART
TELayerNormF 'BART gradient device dataType inputEmbedDim
TEEmbedLayerNormF 'BART gradient device dataType inputEmbedDim
TEStackF
  'BART
  numLayers
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  inputEmbedDim
  ffnDim
tePosEnc :: TEPosEncF
  'BART gradient device dataType headDim inputEmbedDim posEncDim
teDropout :: TEDropoutF 'BART
teLayerNorm :: TELayerNormF 'BART gradient device dataType inputEmbedDim
teEmbedLayerNorm :: TEEmbedLayerNormF 'BART gradient device dataType inputEmbedDim
teStack :: TEStackF
  'BART
  numLayers
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  inputEmbedDim
  ffnDim
tePosEnc :: forall stack embedLayerNorm layerNorm dropout posEnc.
GTransformerEncoder stack embedLayerNorm layerNorm dropout posEnc
-&gt; posEnc
teDropout :: forall stack embedLayerNorm layerNorm dropout posEnc.
GTransformerEncoder stack embedLayerNorm layerNorm dropout posEnc
-&gt; dropout
teLayerNorm :: forall stack embedLayerNorm layerNorm dropout posEnc.
GTransformerEncoder stack embedLayerNorm layerNorm dropout posEnc
-&gt; layerNorm
teEmbedLayerNorm :: forall stack embedLayerNorm layerNorm dropout posEnc.
GTransformerEncoder stack embedLayerNorm layerNorm dropout posEnc
-&gt; embedLayerNorm
teStack :: forall stack embedLayerNorm layerNorm dropout posEnc.
GTransformerEncoder stack embedLayerNorm layerNorm dropout posEnc
-&gt; stack
</span><a href="#local-6989586621679808519"><span class="hs-glyph hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var">..</span></a></span></span></span></span></span></span><span class="hs-special">}</span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span id="local-6989586621679808518"><span class="annot"><span class="annottext">Tensor
  inputGradient inputLayout inputDevice inputDataType inputShape
</span><a href="#local-6989586621679808518"><span class="hs-identifier hs-var">input</span></a></span></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679808517"><span class="annot"><span class="annottext">Tensor posGradient posLayout posDevice posDataType posShape
</span><a href="#local-6989586621679808517"><span class="hs-identifier hs-var">pos</span></a></span></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679808516"><span class="annot"><span class="annottext">Tensor
  attentionMaskGradient
  attentionMaskLayout
  attentionMaskDevice
  attentionMaskDataType
  attentionMaskShape
</span><a href="#local-6989586621679808516"><span class="hs-identifier hs-var">attentionMask</span></a></span></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-674"></span><span>    </span><span class="hs-keyword">let</span><span> </span><span id="local-6989586621679808515"><span class="annot"><span class="annottext">attentionBias :: Tensor
  attentionMaskGradient
  attentionMaskLayout
  attentionMaskDevice
  attentionMaskDataType
  (UnsqueezeF ('SelectDim ('ByIndex 1)) attentionMaskShape)
</span><a href="#local-6989586621679808515"><span class="hs-identifier hs-var hs-var">attentionBias</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Tensor
  attentionMaskGradient
  attentionMaskLayout
  attentionMaskDevice
  attentionMaskDataType
  attentionMaskShape
-&gt; Tensor
     attentionMaskGradient
     attentionMaskLayout
     attentionMaskDevice
     attentionMaskDataType
     (UnsqueezeF ('SelectDim ('ByIndex 1)) attentionMaskShape)
forall (selectDim :: SelectDim (By Symbol Nat))
       (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)])
       (shape' :: Shape [Dim (Name Symbol) (Size Nat)]).
(shape' ~ UnsqueezeF selectDim shape, SingI selectDim) =&gt;
Tensor gradient layout device dataType shape
-&gt; Tensor gradient layout device dataType shape'
</span><a href="Torch.GraduallyTyped.Tensor.IndexingSlicingJoining.html#unsqueeze"><span class="hs-identifier hs-var">unsqueeze</span></a></span><span> </span><span class="hs-glyph">@</span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SelectDim"><span class="hs-identifier hs-type">SelectDim</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#ByIndex"><span class="hs-identifier hs-type">ByIndex</span></a></span><span> </span><span class="annot"><span class="hs-number">1</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">Tensor
  attentionMaskGradient
  attentionMaskLayout
  attentionMaskDevice
  attentionMaskDataType
  attentionMaskShape
</span><a href="#local-6989586621679808516"><span class="hs-identifier hs-var">attentionMask</span></a></span><span>
</span><span id="line-675"></span><span>     </span><span class="hs-keyword">in</span><span> </span><span class="annot"><span class="annottext">IxStateT
  m
  (Generator generatorDevice)
  (Generator generatorOutputDevice)
  output
-&gt; Generator generatorDevice
-&gt; m (output, Generator generatorOutputDevice)
forall (m :: * -&gt; *) i j a. IxStateT m i j a -&gt; i -&gt; m (a, j)
</span><a href="../file:///nix/store/8vjaffqxij7bih93d9mlzmc7ksanlw0i-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier hs-var hs-var">runIxStateT</span></a></span><span> </span><span class="annot"><span class="annottext">(IxStateT
   m
   (Generator generatorDevice)
   (Generator generatorOutputDevice)
   output
 -&gt; Generator generatorDevice
 -&gt; m (output, Generator generatorOutputDevice))
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator generatorOutputDevice)
     output
-&gt; Generator generatorDevice
-&gt; m (output, Generator generatorOutputDevice)
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span>
</span><span id="line-676"></span><span>          </span><span class="annot"><span class="annottext">Tensor posGradient posLayout posDevice posDataType posShape
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator generatorDevice)
     (Tensor posGradient posLayout posDevice posDataType posShape)
forall k (m :: k -&gt; k -&gt; * -&gt; *) a (i :: k).
IxPointed m =&gt;
a -&gt; m i i a
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-identifier hs-var">ireturn</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor posGradient posLayout posDevice posDataType posShape
</span><a href="#local-6989586621679808517"><span class="hs-identifier hs-var">pos</span></a></span><span>
</span><span id="line-677"></span><span>            </span><span class="annot"><span class="annottext">IxStateT
  m
  (Generator generatorDevice)
  (Generator generatorDevice)
  (Tensor posGradient posLayout posDevice posDataType posShape)
-&gt; (Tensor posGradient posLayout posDevice posDataType posShape
    -&gt; IxStateT
         m
         (Generator generatorDevice)
         (Generator generatorDevice)
         (Tensor
            (Or (Gradient RequiresGradient) gradient posGradient)
            (Unify (Layout LayoutType) ('Layout 'Dense) posLayout)
            (Unify (Device (DeviceType Nat)) device posDevice)
            (Seq
               (Unify (DataType DType) posDataType ('DataType 'Int64)) dataType)
            (EmbeddingF ('Shape '[posEncDim, inputEmbedDim]) posShape)))
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator generatorDevice)
     (Tensor
        (Or (Gradient RequiresGradient) gradient posGradient)
        (Unify (Layout LayoutType) ('Layout 'Dense) posLayout)
        (Unify (Device (DeviceType Nat)) device posDevice)
        (Seq
           (Unify (DataType DType) posDataType ('DataType 'Int64)) dataType)
        (EmbeddingF ('Shape '[posEncDim, inputEmbedDim]) posShape))
forall k1 (m :: k1 -&gt; k1 -&gt; * -&gt; *) (i :: k1) (j :: k1) a
       (k2 :: k1) b.
IxMonad m =&gt;
m i j a -&gt; (a -&gt; m j k2 b) -&gt; m i k2 b
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&gt;&gt;&gt;=</span></a></span><span> </span><span class="annot"><span class="annottext">(Generator generatorDevice
 -&gt; m (Tensor
         (Or (Gradient RequiresGradient) gradient posGradient)
         (Unify (Layout LayoutType) ('Layout 'Dense) posLayout)
         (Unify (Device (DeviceType Nat)) device posDevice)
         (Seq
            (Unify (DataType DType) posDataType ('DataType 'Int64)) dataType)
         (EmbeddingF ('Shape '[posEncDim, inputEmbedDim]) posShape),
       Generator generatorDevice))
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator generatorDevice)
     (Tensor
        (Or (Gradient RequiresGradient) gradient posGradient)
        (Unify (Layout LayoutType) ('Layout 'Dense) posLayout)
        (Unify (Device (DeviceType Nat)) device posDevice)
        (Seq
           (Unify (DataType DType) posDataType ('DataType 'Int64)) dataType)
        (EmbeddingF ('Shape '[posEncDim, inputEmbedDim]) posShape))
forall (m :: * -&gt; *) i j a. (i -&gt; m (a, j)) -&gt; IxStateT m i j a
</span><a href="../file:///nix/store/8vjaffqxij7bih93d9mlzmc7ksanlw0i-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier hs-var">IxStateT</span></a></span><span> </span><span class="annot"><span class="annottext">((Generator generatorDevice
  -&gt; m (Tensor
          (Or (Gradient RequiresGradient) gradient posGradient)
          (Unify (Layout LayoutType) ('Layout 'Dense) posLayout)
          (Unify (Device (DeviceType Nat)) device posDevice)
          (Seq
             (Unify (DataType DType) posDataType ('DataType 'Int64)) dataType)
          (EmbeddingF ('Shape '[posEncDim, inputEmbedDim]) posShape),
        Generator generatorDevice))
 -&gt; IxStateT
      m
      (Generator generatorDevice)
      (Generator generatorDevice)
      (Tensor
         (Or (Gradient RequiresGradient) gradient posGradient)
         (Unify (Layout LayoutType) ('Layout 'Dense) posLayout)
         (Unify (Device (DeviceType Nat)) device posDevice)
         (Seq
            (Unify (DataType DType) posDataType ('DataType 'Int64)) dataType)
         (EmbeddingF ('Shape '[posEncDim, inputEmbedDim]) posShape)))
-&gt; (Tensor posGradient posLayout posDevice posDataType posShape
    -&gt; Generator generatorDevice
    -&gt; m (Tensor
            (Or (Gradient RequiresGradient) gradient posGradient)
            (Unify (Layout LayoutType) ('Layout 'Dense) posLayout)
            (Unify (Device (DeviceType Nat)) device posDevice)
            (Seq
               (Unify (DataType DType) posDataType ('DataType 'Int64)) dataType)
            (EmbeddingF ('Shape '[posEncDim, inputEmbedDim]) posShape),
          Generator generatorDevice))
-&gt; Tensor posGradient posLayout posDevice posDataType posShape
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator generatorDevice)
     (Tensor
        (Or (Gradient RequiresGradient) gradient posGradient)
        (Unify (Layout LayoutType) ('Layout 'Dense) posLayout)
        (Unify (Device (DeviceType Nat)) device posDevice)
        (Seq
           (Unify (DataType DType) posDataType ('DataType 'Int64)) dataType)
        (EmbeddingF ('Shape '[posEncDim, inputEmbedDim]) posShape))
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">Embedding
  gradient
  ('Layout 'Dense)
  device
  dataType
  posEncDim
  inputEmbedDim
  'Nothing
-&gt; Tensor posGradient posLayout posDevice posDataType posShape
-&gt; Generator generatorDevice
-&gt; m (Tensor
        (Or (Gradient RequiresGradient) gradient posGradient)
        (Unify (Layout LayoutType) ('Layout 'Dense) posLayout)
        (Unify (Device (DeviceType Nat)) device posDevice)
        (Seq
           (Unify (DataType DType) posDataType ('DataType 'Int64)) dataType)
        (EmbeddingF ('Shape '[posEncDim, inputEmbedDim]) posShape),
      Generator generatorDevice)
forall model input (generatorDevice :: Device (DeviceType Nat))
       output (generatorOutputDevice :: Device (DeviceType Nat))
       (m :: * -&gt; *).
(HasForward
   model input generatorDevice output generatorOutputDevice,
 MonadThrow m) =&gt;
model
-&gt; input
-&gt; Generator generatorDevice
-&gt; m (output, Generator generatorOutputDevice)
</span><a href="Torch.GraduallyTyped.NN.Class.html#forward"><span class="hs-identifier hs-var">forward</span></a></span><span> </span><span class="annot"><span class="annottext">Embedding
  gradient
  ('Layout 'Dense)
  device
  dataType
  posEncDim
  inputEmbedDim
  'Nothing
TEPosEncF
  'BART gradient device dataType headDim inputEmbedDim posEncDim
</span><a href="#local-6989586621679808519"><span class="hs-identifier hs-var">tePosEnc</span></a></span><span>
</span><span id="line-678"></span><span>            </span><span class="annot"><span class="annottext">IxStateT
  m
  (Generator generatorDevice)
  (Generator generatorDevice)
  (Tensor
     (Or (Gradient RequiresGradient) gradient posGradient)
     (Unify (Layout LayoutType) ('Layout 'Dense) posLayout)
     (Unify (Device (DeviceType Nat)) device posDevice)
     (Seq
        (Unify (DataType DType) posDataType ('DataType 'Int64)) dataType)
     (EmbeddingF ('Shape '[posEncDim, inputEmbedDim]) posShape))
-&gt; (Tensor
      (Or (Gradient RequiresGradient) gradient posGradient)
      (Unify (Layout LayoutType) ('Layout 'Dense) posLayout)
      (Unify (Device (DeviceType Nat)) device posDevice)
      (Seq
         (Unify (DataType DType) posDataType ('DataType 'Int64)) dataType)
      (EmbeddingF ('Shape '[posEncDim, inputEmbedDim]) posShape)
    -&gt; IxStateT
         m
         (Generator generatorDevice)
         (Generator generatorDevice)
         (Tensor
            (Or
               (Gradient RequiresGradient)
               inputGradient
               (Or (Gradient RequiresGradient) gradient posGradient))
            (Unify
               (Layout LayoutType)
               inputLayout
               (Unify (Layout LayoutType) ('Layout 'Dense) posLayout))
            (Unify
               (Device (DeviceType Nat))
               inputDevice
               (Unify (Device (DeviceType Nat)) device posDevice))
            (Unify
               (DataType DType)
               inputDataType
               (Seq
                  (Unify (DataType DType) posDataType ('DataType 'Int64)) dataType))
            (BroadcastShapesF
               inputShape
               (EmbeddingF ('Shape '[posEncDim, inputEmbedDim]) posShape))))
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator generatorDevice)
     (Tensor
        (Or
           (Gradient RequiresGradient)
           inputGradient
           (Or (Gradient RequiresGradient) gradient posGradient))
        (Unify
           (Layout LayoutType)
           inputLayout
           (Unify (Layout LayoutType) ('Layout 'Dense) posLayout))
        (Unify
           (Device (DeviceType Nat))
           inputDevice
           (Unify (Device (DeviceType Nat)) device posDevice))
        (Unify
           (DataType DType)
           inputDataType
           (Seq
              (Unify (DataType DType) posDataType ('DataType 'Int64)) dataType))
        (BroadcastShapesF
           inputShape
           (EmbeddingF ('Shape '[posEncDim, inputEmbedDim]) posShape)))
forall k1 (m :: k1 -&gt; k1 -&gt; * -&gt; *) (i :: k1) (j :: k1) a
       (k2 :: k1) b.
IxMonad m =&gt;
m i j a -&gt; (a -&gt; m j k2 b) -&gt; m i k2 b
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&gt;&gt;&gt;=</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor
  (Or
     (Gradient RequiresGradient)
     inputGradient
     (Or (Gradient RequiresGradient) gradient posGradient))
  (Unify
     (Layout LayoutType)
     inputLayout
     (Unify (Layout LayoutType) ('Layout 'Dense) posLayout))
  (Unify
     (Device (DeviceType Nat))
     inputDevice
     (Unify (Device (DeviceType Nat)) device posDevice))
  (Unify
     (DataType DType)
     inputDataType
     (Seq
        (Unify (DataType DType) posDataType ('DataType 'Int64)) dataType))
  (BroadcastShapesF
     inputShape
     (EmbeddingF ('Shape '[posEncDim, inputEmbedDim]) posShape))
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator generatorDevice)
     (Tensor
        (Or
           (Gradient RequiresGradient)
           inputGradient
           (Or (Gradient RequiresGradient) gradient posGradient))
        (Unify
           (Layout LayoutType)
           inputLayout
           (Unify (Layout LayoutType) ('Layout 'Dense) posLayout))
        (Unify
           (Device (DeviceType Nat))
           inputDevice
           (Unify (Device (DeviceType Nat)) device posDevice))
        (Unify
           (DataType DType)
           inputDataType
           (Seq
              (Unify (DataType DType) posDataType ('DataType 'Int64)) dataType))
        (BroadcastShapesF
           inputShape
           (EmbeddingF ('Shape '[posEncDim, inputEmbedDim]) posShape)))
forall k (m :: k -&gt; k -&gt; * -&gt; *) a (i :: k).
IxPointed m =&gt;
a -&gt; m i i a
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-identifier hs-var">ireturn</span></a></span><span> </span><span class="annot"><span class="annottext">(Tensor
   (Or
      (Gradient RequiresGradient)
      inputGradient
      (Or (Gradient RequiresGradient) gradient posGradient))
   (Unify
      (Layout LayoutType)
      inputLayout
      (Unify (Layout LayoutType) ('Layout 'Dense) posLayout))
   (Unify
      (Device (DeviceType Nat))
      inputDevice
      (Unify (Device (DeviceType Nat)) device posDevice))
   (Unify
      (DataType DType)
      inputDataType
      (Seq
         (Unify (DataType DType) posDataType ('DataType 'Int64)) dataType))
   (BroadcastShapesF
      inputShape
      (EmbeddingF ('Shape '[posEncDim, inputEmbedDim]) posShape))
 -&gt; IxStateT
      m
      (Generator generatorDevice)
      (Generator generatorDevice)
      (Tensor
         (Or
            (Gradient RequiresGradient)
            inputGradient
            (Or (Gradient RequiresGradient) gradient posGradient))
         (Unify
            (Layout LayoutType)
            inputLayout
            (Unify (Layout LayoutType) ('Layout 'Dense) posLayout))
         (Unify
            (Device (DeviceType Nat))
            inputDevice
            (Unify (Device (DeviceType Nat)) device posDevice))
         (Unify
            (DataType DType)
            inputDataType
            (Seq
               (Unify (DataType DType) posDataType ('DataType 'Int64)) dataType))
         (BroadcastShapesF
            inputShape
            (EmbeddingF ('Shape '[posEncDim, inputEmbedDim]) posShape))))
-&gt; (Tensor
      (Or (Gradient RequiresGradient) gradient posGradient)
      (Unify (Layout LayoutType) ('Layout 'Dense) posLayout)
      (Unify (Device (DeviceType Nat)) device posDevice)
      (Seq
         (Unify (DataType DType) posDataType ('DataType 'Int64)) dataType)
      (EmbeddingF ('Shape '[posEncDim, inputEmbedDim]) posShape)
    -&gt; Tensor
         (Or
            (Gradient RequiresGradient)
            inputGradient
            (Or (Gradient RequiresGradient) gradient posGradient))
         (Unify
            (Layout LayoutType)
            inputLayout
            (Unify (Layout LayoutType) ('Layout 'Dense) posLayout))
         (Unify
            (Device (DeviceType Nat))
            inputDevice
            (Unify (Device (DeviceType Nat)) device posDevice))
         (Unify
            (DataType DType)
            inputDataType
            (Seq
               (Unify (DataType DType) posDataType ('DataType 'Int64)) dataType))
         (BroadcastShapesF
            inputShape
            (EmbeddingF ('Shape '[posEncDim, inputEmbedDim]) posShape)))
-&gt; Tensor
     (Or (Gradient RequiresGradient) gradient posGradient)
     (Unify (Layout LayoutType) ('Layout 'Dense) posLayout)
     (Unify (Device (DeviceType Nat)) device posDevice)
     (Seq
        (Unify (DataType DType) posDataType ('DataType 'Int64)) dataType)
     (EmbeddingF ('Shape '[posEncDim, inputEmbedDim]) posShape)
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator generatorDevice)
     (Tensor
        (Or
           (Gradient RequiresGradient)
           inputGradient
           (Or (Gradient RequiresGradient) gradient posGradient))
        (Unify
           (Layout LayoutType)
           inputLayout
           (Unify (Layout LayoutType) ('Layout 'Dense) posLayout))
        (Unify
           (Device (DeviceType Nat))
           inputDevice
           (Unify (Device (DeviceType Nat)) device posDevice))
        (Unify
           (DataType DType)
           inputDataType
           (Seq
              (Unify (DataType DType) posDataType ('DataType 'Int64)) dataType))
        (BroadcastShapesF
           inputShape
           (EmbeddingF ('Shape '[posEncDim, inputEmbedDim]) posShape)))
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">Tensor
  inputGradient inputLayout inputDevice inputDataType inputShape
</span><a href="#local-6989586621679808518"><span class="hs-identifier hs-var">input</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor
  inputGradient inputLayout inputDevice inputDataType inputShape
-&gt; Tensor
     (Or (Gradient RequiresGradient) gradient posGradient)
     (Unify (Layout LayoutType) ('Layout 'Dense) posLayout)
     (Unify (Device (DeviceType Nat)) device posDevice)
     (Seq
        (Unify (DataType DType) posDataType ('DataType 'Int64)) dataType)
     (EmbeddingF ('Shape '[posEncDim, inputEmbedDim]) posShape)
-&gt; Tensor
     (inputGradient
      &lt;|&gt; Or (Gradient RequiresGradient) gradient posGradient)
     (inputLayout
      &lt;+&gt; Unify (Layout LayoutType) ('Layout 'Dense) posLayout)
     (inputDevice &lt;+&gt; Unify (Device (DeviceType Nat)) device posDevice)
     (inputDataType
      &lt;+&gt; Seq
            (Unify (DataType DType) posDataType ('DataType 'Int64)) dataType)
     (BroadcastShapesF
        inputShape
        (EmbeddingF ('Shape '[posEncDim, inputEmbedDim]) posShape))
forall (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)])
       (gradient' :: Gradient RequiresGradient)
       (layout' :: Layout LayoutType) (device' :: Device (DeviceType Nat))
       (dataType' :: DataType DType)
       (shape' :: Shape [Dim (Name Symbol) (Size Nat)]).
Tensor gradient layout device dataType shape
-&gt; Tensor gradient' layout' device' dataType' shape'
-&gt; Tensor
     (gradient &lt;|&gt; gradient')
     (layout &lt;+&gt; layout')
     (device &lt;+&gt; device')
     (dataType &lt;+&gt; dataType')
     (BroadcastShapesF shape shape')
</span><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#add"><span class="hs-operator hs-var">`add`</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-679"></span><span>            </span><span class="annot"><span class="annottext">IxStateT
  m
  (Generator generatorDevice)
  (Generator generatorDevice)
  (Tensor
     (Or
        (Gradient RequiresGradient)
        inputGradient
        (Or (Gradient RequiresGradient) gradient posGradient))
     (Unify
        (Layout LayoutType)
        inputLayout
        (Unify (Layout LayoutType) ('Layout 'Dense) posLayout))
     (Unify
        (Device (DeviceType Nat))
        inputDevice
        (Unify (Device (DeviceType Nat)) device posDevice))
     (Unify
        (DataType DType)
        inputDataType
        (Seq
           (Unify (DataType DType) posDataType ('DataType 'Int64)) dataType))
     (BroadcastShapesF
        inputShape
        (EmbeddingF ('Shape '[posEncDim, inputEmbedDim]) posShape)))
-&gt; (Tensor
      (Or
         (Gradient RequiresGradient)
         inputGradient
         (Or (Gradient RequiresGradient) gradient posGradient))
      (Unify
         (Layout LayoutType)
         inputLayout
         (Unify (Layout LayoutType) ('Layout 'Dense) posLayout))
      (Unify
         (Device (DeviceType Nat))
         inputDevice
         (Unify (Device (DeviceType Nat)) device posDevice))
      (Unify
         (DataType DType)
         inputDataType
         (Seq
            (Unify (DataType DType) posDataType ('DataType 'Int64)) dataType))
      (BroadcastShapesF
         inputShape
         (EmbeddingF ('Shape '[posEncDim, inputEmbedDim]) posShape))
    -&gt; IxStateT
         m
         (Generator generatorDevice)
         (Generator generatorDevice)
         layerNormOutput)
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator generatorDevice)
     layerNormOutput
forall k1 (m :: k1 -&gt; k1 -&gt; * -&gt; *) (i :: k1) (j :: k1) a
       (k2 :: k1) b.
IxMonad m =&gt;
m i j a -&gt; (a -&gt; m j k2 b) -&gt; m i k2 b
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&gt;&gt;&gt;=</span></a></span><span> </span><span class="annot"><span class="annottext">(Generator generatorDevice
 -&gt; m (layerNormOutput, Generator generatorDevice))
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator generatorDevice)
     layerNormOutput
forall (m :: * -&gt; *) i j a. (i -&gt; m (a, j)) -&gt; IxStateT m i j a
</span><a href="../file:///nix/store/8vjaffqxij7bih93d9mlzmc7ksanlw0i-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier hs-var">IxStateT</span></a></span><span> </span><span class="annot"><span class="annottext">((Generator generatorDevice
  -&gt; m (layerNormOutput, Generator generatorDevice))
 -&gt; IxStateT
      m
      (Generator generatorDevice)
      (Generator generatorDevice)
      layerNormOutput)
-&gt; (Tensor
      (Or
         (Gradient RequiresGradient)
         inputGradient
         (Or (Gradient RequiresGradient) gradient posGradient))
      (Unify
         (Layout LayoutType)
         inputLayout
         (Unify (Layout LayoutType) ('Layout 'Dense) posLayout))
      (Unify
         (Device (DeviceType Nat))
         inputDevice
         (Unify (Device (DeviceType Nat)) device posDevice))
      (Unify
         (DataType DType)
         inputDataType
         (Seq
            (Unify (DataType DType) posDataType ('DataType 'Int64)) dataType))
      (BroadcastShapesF
         inputShape
         (EmbeddingF ('Shape '[posEncDim, inputEmbedDim]) posShape))
    -&gt; Generator generatorDevice
    -&gt; m (layerNormOutput, Generator generatorDevice))
-&gt; Tensor
     (Or
        (Gradient RequiresGradient)
        inputGradient
        (Or (Gradient RequiresGradient) gradient posGradient))
     (Unify
        (Layout LayoutType)
        inputLayout
        (Unify (Layout LayoutType) ('Layout 'Dense) posLayout))
     (Unify
        (Device (DeviceType Nat))
        inputDevice
        (Unify (Device (DeviceType Nat)) device posDevice))
     (Unify
        (DataType DType)
        inputDataType
        (Seq
           (Unify (DataType DType) posDataType ('DataType 'Int64)) dataType))
     (BroadcastShapesF
        inputShape
        (EmbeddingF ('Shape '[posEncDim, inputEmbedDim]) posShape))
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator generatorDevice)
     layerNormOutput
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">LayerNorm
  'WithBias gradient device dataType ('Shape '[inputEmbedDim])
-&gt; Tensor
     (Or
        (Gradient RequiresGradient)
        inputGradient
        (Or (Gradient RequiresGradient) gradient posGradient))
     (Unify
        (Layout LayoutType)
        inputLayout
        (Unify (Layout LayoutType) ('Layout 'Dense) posLayout))
     (Unify
        (Device (DeviceType Nat))
        inputDevice
        (Unify (Device (DeviceType Nat)) device posDevice))
     (Unify
        (DataType DType)
        inputDataType
        (Seq
           (Unify (DataType DType) posDataType ('DataType 'Int64)) dataType))
     (BroadcastShapesF
        inputShape
        (EmbeddingF ('Shape '[posEncDim, inputEmbedDim]) posShape))
-&gt; Generator generatorDevice
-&gt; m (layerNormOutput, Generator generatorDevice)
forall model input (generatorDevice :: Device (DeviceType Nat))
       output (generatorOutputDevice :: Device (DeviceType Nat))
       (m :: * -&gt; *).
(HasForward
   model input generatorDevice output generatorOutputDevice,
 MonadThrow m) =&gt;
model
-&gt; input
-&gt; Generator generatorDevice
-&gt; m (output, Generator generatorOutputDevice)
</span><a href="Torch.GraduallyTyped.NN.Class.html#forward"><span class="hs-identifier hs-var">forward</span></a></span><span> </span><span class="annot"><span class="annottext">LayerNorm
  'WithBias gradient device dataType ('Shape '[inputEmbedDim])
TEEmbedLayerNormF 'BART gradient device dataType inputEmbedDim
</span><a href="#local-6989586621679808522"><span class="hs-identifier hs-var">teEmbedLayerNorm</span></a></span><span>
</span><span id="line-680"></span><span>            </span><span class="annot"><span class="annottext">IxStateT
  m
  (Generator generatorDevice)
  (Generator generatorDevice)
  layerNormOutput
-&gt; (layerNormOutput
    -&gt; IxStateT
         m
         (Generator generatorDevice)
         (Generator dropoutGeneratorOutputDevice)
         dropoutOutput)
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator dropoutGeneratorOutputDevice)
     dropoutOutput
forall k1 (m :: k1 -&gt; k1 -&gt; * -&gt; *) (i :: k1) (j :: k1) a
       (k2 :: k1) b.
IxMonad m =&gt;
m i j a -&gt; (a -&gt; m j k2 b) -&gt; m i k2 b
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&gt;&gt;&gt;=</span></a></span><span> </span><span class="annot"><span class="annottext">(Generator generatorDevice
 -&gt; m (dropoutOutput, Generator dropoutGeneratorOutputDevice))
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator dropoutGeneratorOutputDevice)
     dropoutOutput
forall (m :: * -&gt; *) i j a. (i -&gt; m (a, j)) -&gt; IxStateT m i j a
</span><a href="../file:///nix/store/8vjaffqxij7bih93d9mlzmc7ksanlw0i-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier hs-var">IxStateT</span></a></span><span> </span><span class="annot"><span class="annottext">((Generator generatorDevice
  -&gt; m (dropoutOutput, Generator dropoutGeneratorOutputDevice))
 -&gt; IxStateT
      m
      (Generator generatorDevice)
      (Generator dropoutGeneratorOutputDevice)
      dropoutOutput)
-&gt; (layerNormOutput
    -&gt; Generator generatorDevice
    -&gt; m (dropoutOutput, Generator dropoutGeneratorOutputDevice))
-&gt; layerNormOutput
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator dropoutGeneratorOutputDevice)
     dropoutOutput
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">Dropout
-&gt; layerNormOutput
-&gt; Generator generatorDevice
-&gt; m (dropoutOutput, Generator dropoutGeneratorOutputDevice)
forall model input (generatorDevice :: Device (DeviceType Nat))
       output (generatorOutputDevice :: Device (DeviceType Nat))
       (m :: * -&gt; *).
(HasForward
   model input generatorDevice output generatorOutputDevice,
 MonadThrow m) =&gt;
model
-&gt; input
-&gt; Generator generatorDevice
-&gt; m (output, Generator generatorOutputDevice)
</span><a href="Torch.GraduallyTyped.NN.Class.html#forward"><span class="hs-identifier hs-var">forward</span></a></span><span> </span><span class="annot"><span class="annottext">Dropout
TEDropoutF 'BART
</span><a href="#local-6989586621679808520"><span class="hs-identifier hs-var">teDropout</span></a></span><span>
</span><span id="line-681"></span><span>            </span><span class="annot"><span class="annottext">IxStateT
  m
  (Generator generatorDevice)
  (Generator dropoutGeneratorOutputDevice)
  dropoutOutput
-&gt; (dropoutOutput
    -&gt; IxStateT
         m
         (Generator dropoutGeneratorOutputDevice)
         (Generator generatorOutputDevice)
         output)
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator generatorOutputDevice)
     output
forall k1 (m :: k1 -&gt; k1 -&gt; * -&gt; *) (i :: k1) (j :: k1) a
       (k2 :: k1) b.
IxMonad m =&gt;
m i j a -&gt; (a -&gt; m j k2 b) -&gt; m i k2 b
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&gt;&gt;&gt;=</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">\</span><span id="local-6989586621679808514"><span class="annot"><span class="annottext">dropoutOutput
</span><a href="#local-6989586621679808514"><span class="hs-identifier hs-var">input'</span></a></span></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><span class="annottext">(Generator dropoutGeneratorOutputDevice
 -&gt; m (output, Generator generatorOutputDevice))
-&gt; IxStateT
     m
     (Generator dropoutGeneratorOutputDevice)
     (Generator generatorOutputDevice)
     output
forall (m :: * -&gt; *) i j a. (i -&gt; m (a, j)) -&gt; IxStateT m i j a
</span><a href="../file:///nix/store/8vjaffqxij7bih93d9mlzmc7ksanlw0i-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier hs-var">IxStateT</span></a></span><span> </span><span class="annot"><span class="annottext">((Generator dropoutGeneratorOutputDevice
  -&gt; m (output, Generator generatorOutputDevice))
 -&gt; IxStateT
      m
      (Generator dropoutGeneratorOutputDevice)
      (Generator generatorOutputDevice)
      output)
-&gt; (Generator dropoutGeneratorOutputDevice
    -&gt; m (output, Generator generatorOutputDevice))
-&gt; IxStateT
     m
     (Generator dropoutGeneratorOutputDevice)
     (Generator generatorOutputDevice)
     output
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">TransformerStack
  'BART
  numLayers
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  inputEmbedDim
  ffnDim
-&gt; (dropoutOutput,
    Tensor
      attentionMaskGradient
      attentionMaskLayout
      attentionMaskDevice
      attentionMaskDataType
      (UnsqueezeF ('SelectDim ('ByIndex 1)) attentionMaskShape))
-&gt; Generator dropoutGeneratorOutputDevice
-&gt; m (output, Generator generatorOutputDevice)
forall model input (generatorDevice :: Device (DeviceType Nat))
       output (generatorOutputDevice :: Device (DeviceType Nat))
       (m :: * -&gt; *).
(HasForward
   model input generatorDevice output generatorOutputDevice,
 MonadThrow m) =&gt;
model
-&gt; input
-&gt; Generator generatorDevice
-&gt; m (output, Generator generatorOutputDevice)
</span><a href="Torch.GraduallyTyped.NN.Class.html#forward"><span class="hs-identifier hs-var">forward</span></a></span><span> </span><span class="annot"><span class="annottext">TransformerStack
  'BART
  numLayers
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  inputEmbedDim
  ffnDim
TEStackF
  'BART
  numLayers
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  inputEmbedDim
  ffnDim
</span><a href="#local-6989586621679808523"><span class="hs-identifier hs-var">teStack</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">dropoutOutput
</span><a href="#local-6989586621679808514"><span class="hs-identifier hs-var">input'</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">Tensor
  attentionMaskGradient
  attentionMaskLayout
  attentionMaskDevice
  attentionMaskDataType
  (UnsqueezeF ('SelectDim ('ByIndex 1)) attentionMaskShape)
</span><a href="#local-6989586621679808515"><span class="hs-identifier hs-var">attentionBias</span></a></span><span class="hs-special">)</span><span class="hs-special">)</span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span><span>
</span><span id="line-682"></span><span>
</span><span id="line-683"></span><span class="hs-comment">-- | 'HasForward' instance for @TransformerEncoder numLayers 'MBART@.</span><span>
</span><span id="line-684"></span><span class="hs-comment">--</span><span>
</span><span id="line-685"></span><span class="hs-comment">-- @</span><span>
</span><span id="line-686"></span><span class="hs-comment">-- &#9484;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9488;  &#9484;&#9472;&#9472;&#9472;&#9472;&#9472;&#9488;  &#9484;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9488;</span><span>
</span><span id="line-687"></span><span class="hs-comment">-- &#9474; input &#9474;  &#9474; pos &#9474;  &#9474; attentionMask &#9474;</span><span>
</span><span id="line-688"></span><span class="hs-comment">-- &#9492;&#9472;&#9472;&#9472;&#9516;&#9472;&#9472;&#9472;&#9496;  &#9492;&#9472;&#9472;&#9472;&#9472;&#9472;&#9496;  &#9492;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9516;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9496;</span><span>
</span><span id="line-689"></span><span class="hs-comment">--     &#9474;         &#9474;             &#9474;</span><span>
</span><span id="line-690"></span><span class="hs-comment">--     &#9474;         &#9660;             &#9474;</span><span>
</span><span id="line-691"></span><span class="hs-comment">--     &#9474;     tePosEnc          &#9474;</span><span>
</span><span id="line-692"></span><span class="hs-comment">--     &#9474;         &#9474;             &#9474;</span><span>
</span><span id="line-693"></span><span class="hs-comment">--     &#9492;&#9472;&#9472;&#9658;add&#9668;&#9472;&#9472;&#9496;             &#9474;</span><span>
</span><span id="line-694"></span><span class="hs-comment">--          &#9474;                  &#9474;</span><span>
</span><span id="line-695"></span><span class="hs-comment">--          &#9660;                  &#9474;</span><span>
</span><span id="line-696"></span><span class="hs-comment">--   teEmbedLayerNorm          &#9474;</span><span>
</span><span id="line-697"></span><span class="hs-comment">--          &#9660;                  &#9660;</span><span>
</span><span id="line-698"></span><span class="hs-comment">--      teDropout          unsqueeze</span><span>
</span><span id="line-699"></span><span class="hs-comment">--          &#9660;                  &#9474;</span><span>
</span><span id="line-700"></span><span class="hs-comment">--       teStack&#9668;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9496;</span><span>
</span><span id="line-701"></span><span class="hs-comment">--          &#9660;</span><span>
</span><span id="line-702"></span><span class="hs-comment">--     teLayerNorm</span><span>
</span><span id="line-703"></span><span class="hs-comment">--          &#9474;</span><span>
</span><span id="line-704"></span><span class="hs-comment">--          &#9660;</span><span>
</span><span id="line-705"></span><span class="hs-comment">--     &#9484;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9488;</span><span>
</span><span id="line-706"></span><span class="hs-comment">--     &#9474; output &#9474;</span><span>
</span><span id="line-707"></span><span class="hs-comment">--     &#9492;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9496;</span><span>
</span><span id="line-708"></span><span class="hs-comment">-- @</span><span>
</span><span id="line-709"></span><span>
</span><span id="line-710"></span><span class="hs-comment">-- | 'HasForward' instance for @TransformerEncoder numLayers 'BERT@.</span><span>
</span><span id="line-711"></span><span class="hs-comment">--</span><span>
</span><span id="line-712"></span><span class="hs-comment">-- @</span><span>
</span><span id="line-713"></span><span class="hs-comment">-- &#9484;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9488;  &#9484;&#9472;&#9472;&#9472;&#9472;&#9472;&#9488;  &#9484;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9488;</span><span>
</span><span id="line-714"></span><span class="hs-comment">-- &#9474; input &#9474;  &#9474; pos &#9474;  &#9474; attentionMask &#9474;</span><span>
</span><span id="line-715"></span><span class="hs-comment">-- &#9492;&#9472;&#9472;&#9472;&#9516;&#9472;&#9472;&#9472;&#9496;  &#9492;&#9472;&#9472;&#9472;&#9472;&#9472;&#9496;  &#9492;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9516;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9496;</span><span>
</span><span id="line-716"></span><span class="hs-comment">--     &#9474;         &#9474;             &#9474;</span><span>
</span><span id="line-717"></span><span class="hs-comment">--     &#9474;         &#9660;             &#9474;</span><span>
</span><span id="line-718"></span><span class="hs-comment">--     &#9474;     tePosEnc          &#9474;</span><span>
</span><span id="line-719"></span><span class="hs-comment">--     &#9474;         &#9474;             &#9474;</span><span>
</span><span id="line-720"></span><span class="hs-comment">--     &#9492;&#9472;&#9472;&#9658;add&#9668;&#9472;&#9472;&#9496;             &#9474;</span><span>
</span><span id="line-721"></span><span class="hs-comment">--          &#9474;                  &#9474;</span><span>
</span><span id="line-722"></span><span class="hs-comment">--          &#9660;                  &#9474;</span><span>
</span><span id="line-723"></span><span class="hs-comment">--   teEmbedLayerNorm          &#9474;</span><span>
</span><span id="line-724"></span><span class="hs-comment">--          &#9660;                  &#9660;</span><span>
</span><span id="line-725"></span><span class="hs-comment">--      teDropout          unsqueeze</span><span>
</span><span id="line-726"></span><span class="hs-comment">--          &#9660;                  &#9474;</span><span>
</span><span id="line-727"></span><span class="hs-comment">--       teStack&#9668;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9496;</span><span>
</span><span id="line-728"></span><span class="hs-comment">--          &#9474;</span><span>
</span><span id="line-729"></span><span class="hs-comment">--          &#9660;</span><span>
</span><span id="line-730"></span><span class="hs-comment">--     &#9484;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9488;</span><span>
</span><span id="line-731"></span><span class="hs-comment">--     &#9474; output &#9474;</span><span>
</span><span id="line-732"></span><span class="hs-comment">--     &#9492;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9496;</span><span>
</span><span id="line-733"></span><span class="hs-comment">-- @</span><span>
</span><span id="line-734"></span><span id="local-6989586621679808483"><span id="local-6989586621679808484"><span id="local-6989586621679808485"><span id="local-6989586621679808486"><span id="local-6989586621679808487"><span id="local-6989586621679808488"><span id="local-6989586621679808489"><span id="local-6989586621679808490"><span id="local-6989586621679808491"><span id="local-6989586621679808492"><span id="local-6989586621679808493"><span id="local-6989586621679808494"><span id="local-6989586621679808495"><span id="local-6989586621679808496"><span id="local-6989586621679808497"><span id="local-6989586621679808498"><span id="local-6989586621679808499"><span id="local-6989586621679808500"><span id="local-6989586621679808501"><span id="local-6989586621679808502"><span id="local-6989586621679808503"><span id="local-6989586621679808504"><span id="local-6989586621679808505"><span id="local-6989586621679808506"><span id="local-6989586621679808507"><span id="local-6989586621679808508"><span id="local-6989586621679808509"><span id="local-6989586621679808510"><span id="local-6989586621679808511"><span id="local-6989586621679808512"><span id="local-6989586621679808513"><span class="hs-keyword">instance</span><span>
</span><span id="line-735"></span><span>  </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasForward"><span class="hs-identifier hs-type">HasForward</span></a></span><span>
</span><span id="line-736"></span><span>      </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Encoder.html#TEEmbedLayerNormF"><span class="hs-identifier hs-type">TEEmbedLayerNormF</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#BERT"><span class="hs-identifier hs-type">BERT</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808513"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808512"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808511"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808510"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-737"></span><span>      </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span>
</span><span id="line-738"></span><span>          </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679808509"><span class="hs-identifier hs-type">inputGradient</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%7C%3E"><span class="hs-operator hs-type">&lt;|&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808513"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%7C%3E"><span class="hs-operator hs-type">&lt;|&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808508"><span class="hs-identifier hs-type">posGradient</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-739"></span><span>          </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679808507"><span class="hs-identifier hs-type">inputLayout</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#Layout"><span class="hs-identifier hs-type">Layout</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#Dense"><span class="hs-identifier hs-type">Dense</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808506"><span class="hs-identifier hs-type">posLayout</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-740"></span><span>          </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679808505"><span class="hs-identifier hs-type">inputDevice</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808512"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808504"><span class="hs-identifier hs-type">posDevice</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-741"></span><span>          </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679808503"><span class="hs-identifier hs-type">inputDataType</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Prelude.html#Seq"><span class="hs-identifier hs-type">Seq</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679808502"><span class="hs-identifier hs-type">posDataType</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#DataType"><span class="hs-identifier hs-type">DataType</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#Int64"><span class="hs-identifier hs-type">Int64</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679808511"><span class="hs-identifier hs-type">dataType</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-742"></span><span>          </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Class.html#BroadcastShapesF"><span class="hs-identifier hs-type">BroadcastShapesF</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808501"><span class="hs-identifier hs-type">inputShape</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Functional.Sparse.html#EmbeddingF"><span class="hs-identifier hs-type">EmbeddingF</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Shape"><span class="hs-identifier hs-type">Shape</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="annot"><a href="#local-6989586621679808500"><span class="hs-identifier hs-type">posEncDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679808510"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span><span class="hs-special">]</span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679808499"><span class="hs-identifier hs-type">posShape</span></a></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-743"></span><span>      </span><span class="hs-special">)</span><span>
</span><span id="line-744"></span><span>      </span><span class="annot"><a href="#local-6989586621679808498"><span class="hs-identifier hs-type">generatorDevice</span></a></span><span>
</span><span id="line-745"></span><span>      </span><span class="annot"><a href="#local-6989586621679808497"><span class="hs-identifier hs-type">layerNormOutput</span></a></span><span>
</span><span id="line-746"></span><span>      </span><span class="annot"><a href="#local-6989586621679808498"><span class="hs-identifier hs-type">generatorDevice</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-747"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasForward"><span class="hs-identifier hs-type">HasForward</span></a></span><span>
</span><span id="line-748"></span><span>      </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Encoder.html#TEDropoutF"><span class="hs-identifier hs-type">TEDropoutF</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#BERT"><span class="hs-identifier hs-type">BERT</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-749"></span><span>      </span><span class="annot"><a href="#local-6989586621679808497"><span class="hs-identifier hs-type">layerNormOutput</span></a></span><span>
</span><span id="line-750"></span><span>      </span><span class="annot"><a href="#local-6989586621679808498"><span class="hs-identifier hs-type">generatorDevice</span></a></span><span>
</span><span id="line-751"></span><span>      </span><span class="annot"><a href="#local-6989586621679808496"><span class="hs-identifier hs-type">dropoutOutput</span></a></span><span>
</span><span id="line-752"></span><span>      </span><span class="annot"><a href="#local-6989586621679808495"><span class="hs-identifier hs-type">dropoutGeneratorOutputDevice</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-753"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasForward"><span class="hs-identifier hs-type">HasForward</span></a></span><span>
</span><span id="line-754"></span><span>      </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Encoder.html#TEStackF"><span class="hs-identifier hs-type">TEStackF</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#BERT"><span class="hs-identifier hs-type">BERT</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808494"><span class="hs-identifier hs-type">numLayers</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808513"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808512"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808511"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808493"><span class="hs-identifier hs-type">headDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808492"><span class="hs-identifier hs-type">headEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808491"><span class="hs-identifier hs-type">embedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808510"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808490"><span class="hs-identifier hs-type">ffnDim</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-755"></span><span>      </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="#local-6989586621679808496"><span class="hs-identifier hs-type">dropoutOutput</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-756"></span><span>        </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span>
</span><span id="line-757"></span><span>          </span><span class="annot"><a href="#local-6989586621679808489"><span class="hs-identifier hs-type">attentionMaskGradient</span></a></span><span>
</span><span id="line-758"></span><span>          </span><span class="annot"><a href="#local-6989586621679808488"><span class="hs-identifier hs-type">attentionMaskLayout</span></a></span><span>
</span><span id="line-759"></span><span>          </span><span class="annot"><a href="#local-6989586621679808487"><span class="hs-identifier hs-type">attentionMaskDevice</span></a></span><span>
</span><span id="line-760"></span><span>          </span><span class="annot"><a href="#local-6989586621679808486"><span class="hs-identifier hs-type">attentionMaskDataType</span></a></span><span>
</span><span id="line-761"></span><span>          </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.IndexingSlicingJoining.html#UnsqueezeF"><span class="hs-identifier hs-type">UnsqueezeF</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SelectDim"><span class="hs-identifier hs-type">SelectDim</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#ByIndex"><span class="hs-identifier hs-type">ByIndex</span></a></span><span> </span><span class="annot"><span class="hs-number">1</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679808485"><span class="hs-identifier hs-type">attentionMaskShape</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-762"></span><span>      </span><span class="hs-special">)</span><span>
</span><span id="line-763"></span><span>      </span><span class="annot"><a href="#local-6989586621679808495"><span class="hs-identifier hs-type">dropoutGeneratorOutputDevice</span></a></span><span>
</span><span id="line-764"></span><span>      </span><span class="annot"><a href="#local-6989586621679808484"><span class="hs-identifier hs-type">output</span></a></span><span>
</span><span id="line-765"></span><span>      </span><span class="annot"><a href="#local-6989586621679808483"><span class="hs-identifier hs-type">generatorOutputDevice</span></a></span><span>
</span><span id="line-766"></span><span>  </span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-767"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasForward"><span class="hs-identifier hs-type">HasForward</span></a></span><span>
</span><span id="line-768"></span><span>    </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Encoder.html#TransformerEncoder"><span class="hs-identifier hs-type">TransformerEncoder</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#BERT"><span class="hs-identifier hs-type">BERT</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808494"><span class="hs-identifier hs-type">numLayers</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808513"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808512"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808511"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808493"><span class="hs-identifier hs-type">headDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808492"><span class="hs-identifier hs-type">headEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808491"><span class="hs-identifier hs-type">embedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808510"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808490"><span class="hs-identifier hs-type">ffnDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808500"><span class="hs-identifier hs-type">posEncDim</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-769"></span><span>    </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808509"><span class="hs-identifier hs-type">inputGradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808507"><span class="hs-identifier hs-type">inputLayout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808505"><span class="hs-identifier hs-type">inputDevice</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808503"><span class="hs-identifier hs-type">inputDataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808501"><span class="hs-identifier hs-type">inputShape</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-770"></span><span>      </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808508"><span class="hs-identifier hs-type">posGradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808506"><span class="hs-identifier hs-type">posLayout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808504"><span class="hs-identifier hs-type">posDevice</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808502"><span class="hs-identifier hs-type">posDataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808499"><span class="hs-identifier hs-type">posShape</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-771"></span><span>      </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808489"><span class="hs-identifier hs-type">attentionMaskGradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808488"><span class="hs-identifier hs-type">attentionMaskLayout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808487"><span class="hs-identifier hs-type">attentionMaskDevice</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808486"><span class="hs-identifier hs-type">attentionMaskDataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808485"><span class="hs-identifier hs-type">attentionMaskShape</span></a></span><span>
</span><span id="line-772"></span><span>    </span><span class="hs-special">)</span><span>
</span><span id="line-773"></span><span>    </span><span class="annot"><a href="#local-6989586621679808498"><span class="hs-identifier hs-type">generatorDevice</span></a></span><span>
</span><span id="line-774"></span><span>    </span><span class="annot"><a href="#local-6989586621679808484"><span class="hs-identifier hs-type">output</span></a></span><span>
</span><span id="line-775"></span><span>    </span><span class="annot"><a href="#local-6989586621679808483"><span class="hs-identifier hs-type">generatorOutputDevice</span></a></span><span>
</span><span id="line-776"></span><span>  </span><span class="hs-keyword">where</span><span>
</span><span id="line-777"></span><span>  </span><span id="local-6989586621679808481"><span class="annot"><span class="annottext">forward :: TransformerEncoder
  'BERT
  numLayers
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  inputEmbedDim
  ffnDim
  posEncDim
-&gt; (Tensor
      inputGradient inputLayout inputDevice inputDataType inputShape,
    Tensor posGradient posLayout posDevice posDataType posShape,
    Tensor
      attentionMaskGradient
      attentionMaskLayout
      attentionMaskDevice
      attentionMaskDataType
      attentionMaskShape)
-&gt; Generator generatorDevice
-&gt; m (output, Generator generatorOutputDevice)
</span><a href="#local-6989586621679808481"><span class="hs-identifier hs-var hs-var hs-var hs-var">forward</span></a></span></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Encoder.html#TransformerEncoder"><span class="hs-identifier hs-type">TransformerEncoder</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Encoder.html#GTransformerEncoder"><span class="hs-identifier hs-type">GTransformerEncoder</span></a></span><span> </span><span class="hs-special">{</span><span id="local-6989586621679808476"><span id="local-6989586621679808477"><span id="local-6989586621679808478"><span id="local-6989586621679808479"><span id="local-6989586621679808480"><span class="annot"><span class="annottext">TEPosEncF
  'BERT gradient device dataType headDim inputEmbedDim posEncDim
TEDropoutF 'BERT
TELayerNormF 'BERT gradient device dataType inputEmbedDim
TEEmbedLayerNormF 'BERT gradient device dataType inputEmbedDim
TEStackF
  'BERT
  numLayers
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  inputEmbedDim
  ffnDim
tePosEnc :: TEPosEncF
  'BERT gradient device dataType headDim inputEmbedDim posEncDim
teDropout :: TEDropoutF 'BERT
teLayerNorm :: TELayerNormF 'BERT gradient device dataType inputEmbedDim
teEmbedLayerNorm :: TEEmbedLayerNormF 'BERT gradient device dataType inputEmbedDim
teStack :: TEStackF
  'BERT
  numLayers
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  inputEmbedDim
  ffnDim
tePosEnc :: forall stack embedLayerNorm layerNorm dropout posEnc.
GTransformerEncoder stack embedLayerNorm layerNorm dropout posEnc
-&gt; posEnc
teDropout :: forall stack embedLayerNorm layerNorm dropout posEnc.
GTransformerEncoder stack embedLayerNorm layerNorm dropout posEnc
-&gt; dropout
teLayerNorm :: forall stack embedLayerNorm layerNorm dropout posEnc.
GTransformerEncoder stack embedLayerNorm layerNorm dropout posEnc
-&gt; layerNorm
teEmbedLayerNorm :: forall stack embedLayerNorm layerNorm dropout posEnc.
GTransformerEncoder stack embedLayerNorm layerNorm dropout posEnc
-&gt; embedLayerNorm
teStack :: forall stack embedLayerNorm layerNorm dropout posEnc.
GTransformerEncoder stack embedLayerNorm layerNorm dropout posEnc
-&gt; stack
</span><a href="#local-6989586621679808476"><span class="hs-glyph hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var">..</span></a></span></span></span></span></span></span><span class="hs-special">}</span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span id="local-6989586621679808475"><span class="annot"><span class="annottext">Tensor
  inputGradient inputLayout inputDevice inputDataType inputShape
</span><a href="#local-6989586621679808475"><span class="hs-identifier hs-var">input</span></a></span></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679808474"><span class="annot"><span class="annottext">Tensor posGradient posLayout posDevice posDataType posShape
</span><a href="#local-6989586621679808474"><span class="hs-identifier hs-var">pos</span></a></span></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679808473"><span class="annot"><span class="annottext">Tensor
  attentionMaskGradient
  attentionMaskLayout
  attentionMaskDevice
  attentionMaskDataType
  attentionMaskShape
</span><a href="#local-6989586621679808473"><span class="hs-identifier hs-var">attentionMask</span></a></span></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-778"></span><span>    </span><span class="hs-keyword">let</span><span> </span><span id="local-6989586621679808472"><span class="annot"><span class="annottext">attentionBias :: Tensor
  attentionMaskGradient
  attentionMaskLayout
  attentionMaskDevice
  attentionMaskDataType
  (UnsqueezeF ('SelectDim ('ByIndex 1)) attentionMaskShape)
</span><a href="#local-6989586621679808472"><span class="hs-identifier hs-var hs-var">attentionBias</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Tensor
  attentionMaskGradient
  attentionMaskLayout
  attentionMaskDevice
  attentionMaskDataType
  attentionMaskShape
-&gt; Tensor
     attentionMaskGradient
     attentionMaskLayout
     attentionMaskDevice
     attentionMaskDataType
     (UnsqueezeF ('SelectDim ('ByIndex 1)) attentionMaskShape)
forall (selectDim :: SelectDim (By Symbol Nat))
       (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)])
       (shape' :: Shape [Dim (Name Symbol) (Size Nat)]).
(shape' ~ UnsqueezeF selectDim shape, SingI selectDim) =&gt;
Tensor gradient layout device dataType shape
-&gt; Tensor gradient layout device dataType shape'
</span><a href="Torch.GraduallyTyped.Tensor.IndexingSlicingJoining.html#unsqueeze"><span class="hs-identifier hs-var">unsqueeze</span></a></span><span> </span><span class="hs-glyph">@</span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SelectDim"><span class="hs-identifier hs-type">SelectDim</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#ByIndex"><span class="hs-identifier hs-type">ByIndex</span></a></span><span> </span><span class="annot"><span class="hs-number">1</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">Tensor
  attentionMaskGradient
  attentionMaskLayout
  attentionMaskDevice
  attentionMaskDataType
  attentionMaskShape
</span><a href="#local-6989586621679808473"><span class="hs-identifier hs-var">attentionMask</span></a></span><span>
</span><span id="line-779"></span><span>     </span><span class="hs-keyword">in</span><span> </span><span class="annot"><span class="annottext">IxStateT
  m
  (Generator generatorDevice)
  (Generator generatorOutputDevice)
  output
-&gt; Generator generatorDevice
-&gt; m (output, Generator generatorOutputDevice)
forall (m :: * -&gt; *) i j a. IxStateT m i j a -&gt; i -&gt; m (a, j)
</span><a href="../file:///nix/store/8vjaffqxij7bih93d9mlzmc7ksanlw0i-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier hs-var hs-var">runIxStateT</span></a></span><span> </span><span class="annot"><span class="annottext">(IxStateT
   m
   (Generator generatorDevice)
   (Generator generatorOutputDevice)
   output
 -&gt; Generator generatorDevice
 -&gt; m (output, Generator generatorOutputDevice))
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator generatorOutputDevice)
     output
-&gt; Generator generatorDevice
-&gt; m (output, Generator generatorOutputDevice)
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span>
</span><span id="line-780"></span><span>          </span><span class="annot"><span class="annottext">Tensor posGradient posLayout posDevice posDataType posShape
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator generatorDevice)
     (Tensor posGradient posLayout posDevice posDataType posShape)
forall k (m :: k -&gt; k -&gt; * -&gt; *) a (i :: k).
IxPointed m =&gt;
a -&gt; m i i a
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-identifier hs-var">ireturn</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor posGradient posLayout posDevice posDataType posShape
</span><a href="#local-6989586621679808474"><span class="hs-identifier hs-var">pos</span></a></span><span>
</span><span id="line-781"></span><span>            </span><span class="annot"><span class="annottext">IxStateT
  m
  (Generator generatorDevice)
  (Generator generatorDevice)
  (Tensor posGradient posLayout posDevice posDataType posShape)
-&gt; (Tensor posGradient posLayout posDevice posDataType posShape
    -&gt; IxStateT
         m
         (Generator generatorDevice)
         (Generator generatorDevice)
         (Tensor
            (Or (Gradient RequiresGradient) gradient posGradient)
            (Unify (Layout LayoutType) ('Layout 'Dense) posLayout)
            (Unify (Device (DeviceType Nat)) device posDevice)
            (Seq
               (Unify (DataType DType) posDataType ('DataType 'Int64)) dataType)
            (EmbeddingF ('Shape '[posEncDim, inputEmbedDim]) posShape)))
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator generatorDevice)
     (Tensor
        (Or (Gradient RequiresGradient) gradient posGradient)
        (Unify (Layout LayoutType) ('Layout 'Dense) posLayout)
        (Unify (Device (DeviceType Nat)) device posDevice)
        (Seq
           (Unify (DataType DType) posDataType ('DataType 'Int64)) dataType)
        (EmbeddingF ('Shape '[posEncDim, inputEmbedDim]) posShape))
forall k1 (m :: k1 -&gt; k1 -&gt; * -&gt; *) (i :: k1) (j :: k1) a
       (k2 :: k1) b.
IxMonad m =&gt;
m i j a -&gt; (a -&gt; m j k2 b) -&gt; m i k2 b
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&gt;&gt;&gt;=</span></a></span><span> </span><span class="annot"><span class="annottext">(Generator generatorDevice
 -&gt; m (Tensor
         (Or (Gradient RequiresGradient) gradient posGradient)
         (Unify (Layout LayoutType) ('Layout 'Dense) posLayout)
         (Unify (Device (DeviceType Nat)) device posDevice)
         (Seq
            (Unify (DataType DType) posDataType ('DataType 'Int64)) dataType)
         (EmbeddingF ('Shape '[posEncDim, inputEmbedDim]) posShape),
       Generator generatorDevice))
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator generatorDevice)
     (Tensor
        (Or (Gradient RequiresGradient) gradient posGradient)
        (Unify (Layout LayoutType) ('Layout 'Dense) posLayout)
        (Unify (Device (DeviceType Nat)) device posDevice)
        (Seq
           (Unify (DataType DType) posDataType ('DataType 'Int64)) dataType)
        (EmbeddingF ('Shape '[posEncDim, inputEmbedDim]) posShape))
forall (m :: * -&gt; *) i j a. (i -&gt; m (a, j)) -&gt; IxStateT m i j a
</span><a href="../file:///nix/store/8vjaffqxij7bih93d9mlzmc7ksanlw0i-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier hs-var">IxStateT</span></a></span><span> </span><span class="annot"><span class="annottext">((Generator generatorDevice
  -&gt; m (Tensor
          (Or (Gradient RequiresGradient) gradient posGradient)
          (Unify (Layout LayoutType) ('Layout 'Dense) posLayout)
          (Unify (Device (DeviceType Nat)) device posDevice)
          (Seq
             (Unify (DataType DType) posDataType ('DataType 'Int64)) dataType)
          (EmbeddingF ('Shape '[posEncDim, inputEmbedDim]) posShape),
        Generator generatorDevice))
 -&gt; IxStateT
      m
      (Generator generatorDevice)
      (Generator generatorDevice)
      (Tensor
         (Or (Gradient RequiresGradient) gradient posGradient)
         (Unify (Layout LayoutType) ('Layout 'Dense) posLayout)
         (Unify (Device (DeviceType Nat)) device posDevice)
         (Seq
            (Unify (DataType DType) posDataType ('DataType 'Int64)) dataType)
         (EmbeddingF ('Shape '[posEncDim, inputEmbedDim]) posShape)))
-&gt; (Tensor posGradient posLayout posDevice posDataType posShape
    -&gt; Generator generatorDevice
    -&gt; m (Tensor
            (Or (Gradient RequiresGradient) gradient posGradient)
            (Unify (Layout LayoutType) ('Layout 'Dense) posLayout)
            (Unify (Device (DeviceType Nat)) device posDevice)
            (Seq
               (Unify (DataType DType) posDataType ('DataType 'Int64)) dataType)
            (EmbeddingF ('Shape '[posEncDim, inputEmbedDim]) posShape),
          Generator generatorDevice))
-&gt; Tensor posGradient posLayout posDevice posDataType posShape
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator generatorDevice)
     (Tensor
        (Or (Gradient RequiresGradient) gradient posGradient)
        (Unify (Layout LayoutType) ('Layout 'Dense) posLayout)
        (Unify (Device (DeviceType Nat)) device posDevice)
        (Seq
           (Unify (DataType DType) posDataType ('DataType 'Int64)) dataType)
        (EmbeddingF ('Shape '[posEncDim, inputEmbedDim]) posShape))
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">Embedding
  gradient
  ('Layout 'Dense)
  device
  dataType
  posEncDim
  inputEmbedDim
  'Nothing
-&gt; Tensor posGradient posLayout posDevice posDataType posShape
-&gt; Generator generatorDevice
-&gt; m (Tensor
        (Or (Gradient RequiresGradient) gradient posGradient)
        (Unify (Layout LayoutType) ('Layout 'Dense) posLayout)
        (Unify (Device (DeviceType Nat)) device posDevice)
        (Seq
           (Unify (DataType DType) posDataType ('DataType 'Int64)) dataType)
        (EmbeddingF ('Shape '[posEncDim, inputEmbedDim]) posShape),
      Generator generatorDevice)
forall model input (generatorDevice :: Device (DeviceType Nat))
       output (generatorOutputDevice :: Device (DeviceType Nat))
       (m :: * -&gt; *).
(HasForward
   model input generatorDevice output generatorOutputDevice,
 MonadThrow m) =&gt;
model
-&gt; input
-&gt; Generator generatorDevice
-&gt; m (output, Generator generatorOutputDevice)
</span><a href="Torch.GraduallyTyped.NN.Class.html#forward"><span class="hs-identifier hs-var">forward</span></a></span><span> </span><span class="annot"><span class="annottext">Embedding
  gradient
  ('Layout 'Dense)
  device
  dataType
  posEncDim
  inputEmbedDim
  'Nothing
TEPosEncF
  'BERT gradient device dataType headDim inputEmbedDim posEncDim
</span><a href="#local-6989586621679808476"><span class="hs-identifier hs-var">tePosEnc</span></a></span><span>
</span><span id="line-782"></span><span>            </span><span class="annot"><span class="annottext">IxStateT
  m
  (Generator generatorDevice)
  (Generator generatorDevice)
  (Tensor
     (Or (Gradient RequiresGradient) gradient posGradient)
     (Unify (Layout LayoutType) ('Layout 'Dense) posLayout)
     (Unify (Device (DeviceType Nat)) device posDevice)
     (Seq
        (Unify (DataType DType) posDataType ('DataType 'Int64)) dataType)
     (EmbeddingF ('Shape '[posEncDim, inputEmbedDim]) posShape))
-&gt; (Tensor
      (Or (Gradient RequiresGradient) gradient posGradient)
      (Unify (Layout LayoutType) ('Layout 'Dense) posLayout)
      (Unify (Device (DeviceType Nat)) device posDevice)
      (Seq
         (Unify (DataType DType) posDataType ('DataType 'Int64)) dataType)
      (EmbeddingF ('Shape '[posEncDim, inputEmbedDim]) posShape)
    -&gt; IxStateT
         m
         (Generator generatorDevice)
         (Generator generatorDevice)
         (Tensor
            (Or
               (Gradient RequiresGradient)
               inputGradient
               (Or (Gradient RequiresGradient) gradient posGradient))
            (Unify
               (Layout LayoutType)
               inputLayout
               (Unify (Layout LayoutType) ('Layout 'Dense) posLayout))
            (Unify
               (Device (DeviceType Nat))
               inputDevice
               (Unify (Device (DeviceType Nat)) device posDevice))
            (Unify
               (DataType DType)
               inputDataType
               (Seq
                  (Unify (DataType DType) posDataType ('DataType 'Int64)) dataType))
            (BroadcastShapesF
               inputShape
               (EmbeddingF ('Shape '[posEncDim, inputEmbedDim]) posShape))))
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator generatorDevice)
     (Tensor
        (Or
           (Gradient RequiresGradient)
           inputGradient
           (Or (Gradient RequiresGradient) gradient posGradient))
        (Unify
           (Layout LayoutType)
           inputLayout
           (Unify (Layout LayoutType) ('Layout 'Dense) posLayout))
        (Unify
           (Device (DeviceType Nat))
           inputDevice
           (Unify (Device (DeviceType Nat)) device posDevice))
        (Unify
           (DataType DType)
           inputDataType
           (Seq
              (Unify (DataType DType) posDataType ('DataType 'Int64)) dataType))
        (BroadcastShapesF
           inputShape
           (EmbeddingF ('Shape '[posEncDim, inputEmbedDim]) posShape)))
forall k1 (m :: k1 -&gt; k1 -&gt; * -&gt; *) (i :: k1) (j :: k1) a
       (k2 :: k1) b.
IxMonad m =&gt;
m i j a -&gt; (a -&gt; m j k2 b) -&gt; m i k2 b
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&gt;&gt;&gt;=</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor
  (Or
     (Gradient RequiresGradient)
     inputGradient
     (Or (Gradient RequiresGradient) gradient posGradient))
  (Unify
     (Layout LayoutType)
     inputLayout
     (Unify (Layout LayoutType) ('Layout 'Dense) posLayout))
  (Unify
     (Device (DeviceType Nat))
     inputDevice
     (Unify (Device (DeviceType Nat)) device posDevice))
  (Unify
     (DataType DType)
     inputDataType
     (Seq
        (Unify (DataType DType) posDataType ('DataType 'Int64)) dataType))
  (BroadcastShapesF
     inputShape
     (EmbeddingF ('Shape '[posEncDim, inputEmbedDim]) posShape))
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator generatorDevice)
     (Tensor
        (Or
           (Gradient RequiresGradient)
           inputGradient
           (Or (Gradient RequiresGradient) gradient posGradient))
        (Unify
           (Layout LayoutType)
           inputLayout
           (Unify (Layout LayoutType) ('Layout 'Dense) posLayout))
        (Unify
           (Device (DeviceType Nat))
           inputDevice
           (Unify (Device (DeviceType Nat)) device posDevice))
        (Unify
           (DataType DType)
           inputDataType
           (Seq
              (Unify (DataType DType) posDataType ('DataType 'Int64)) dataType))
        (BroadcastShapesF
           inputShape
           (EmbeddingF ('Shape '[posEncDim, inputEmbedDim]) posShape)))
forall k (m :: k -&gt; k -&gt; * -&gt; *) a (i :: k).
IxPointed m =&gt;
a -&gt; m i i a
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-identifier hs-var">ireturn</span></a></span><span> </span><span class="annot"><span class="annottext">(Tensor
   (Or
      (Gradient RequiresGradient)
      inputGradient
      (Or (Gradient RequiresGradient) gradient posGradient))
   (Unify
      (Layout LayoutType)
      inputLayout
      (Unify (Layout LayoutType) ('Layout 'Dense) posLayout))
   (Unify
      (Device (DeviceType Nat))
      inputDevice
      (Unify (Device (DeviceType Nat)) device posDevice))
   (Unify
      (DataType DType)
      inputDataType
      (Seq
         (Unify (DataType DType) posDataType ('DataType 'Int64)) dataType))
   (BroadcastShapesF
      inputShape
      (EmbeddingF ('Shape '[posEncDim, inputEmbedDim]) posShape))
 -&gt; IxStateT
      m
      (Generator generatorDevice)
      (Generator generatorDevice)
      (Tensor
         (Or
            (Gradient RequiresGradient)
            inputGradient
            (Or (Gradient RequiresGradient) gradient posGradient))
         (Unify
            (Layout LayoutType)
            inputLayout
            (Unify (Layout LayoutType) ('Layout 'Dense) posLayout))
         (Unify
            (Device (DeviceType Nat))
            inputDevice
            (Unify (Device (DeviceType Nat)) device posDevice))
         (Unify
            (DataType DType)
            inputDataType
            (Seq
               (Unify (DataType DType) posDataType ('DataType 'Int64)) dataType))
         (BroadcastShapesF
            inputShape
            (EmbeddingF ('Shape '[posEncDim, inputEmbedDim]) posShape))))
-&gt; (Tensor
      (Or (Gradient RequiresGradient) gradient posGradient)
      (Unify (Layout LayoutType) ('Layout 'Dense) posLayout)
      (Unify (Device (DeviceType Nat)) device posDevice)
      (Seq
         (Unify (DataType DType) posDataType ('DataType 'Int64)) dataType)
      (EmbeddingF ('Shape '[posEncDim, inputEmbedDim]) posShape)
    -&gt; Tensor
         (Or
            (Gradient RequiresGradient)
            inputGradient
            (Or (Gradient RequiresGradient) gradient posGradient))
         (Unify
            (Layout LayoutType)
            inputLayout
            (Unify (Layout LayoutType) ('Layout 'Dense) posLayout))
         (Unify
            (Device (DeviceType Nat))
            inputDevice
            (Unify (Device (DeviceType Nat)) device posDevice))
         (Unify
            (DataType DType)
            inputDataType
            (Seq
               (Unify (DataType DType) posDataType ('DataType 'Int64)) dataType))
         (BroadcastShapesF
            inputShape
            (EmbeddingF ('Shape '[posEncDim, inputEmbedDim]) posShape)))
-&gt; Tensor
     (Or (Gradient RequiresGradient) gradient posGradient)
     (Unify (Layout LayoutType) ('Layout 'Dense) posLayout)
     (Unify (Device (DeviceType Nat)) device posDevice)
     (Seq
        (Unify (DataType DType) posDataType ('DataType 'Int64)) dataType)
     (EmbeddingF ('Shape '[posEncDim, inputEmbedDim]) posShape)
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator generatorDevice)
     (Tensor
        (Or
           (Gradient RequiresGradient)
           inputGradient
           (Or (Gradient RequiresGradient) gradient posGradient))
        (Unify
           (Layout LayoutType)
           inputLayout
           (Unify (Layout LayoutType) ('Layout 'Dense) posLayout))
        (Unify
           (Device (DeviceType Nat))
           inputDevice
           (Unify (Device (DeviceType Nat)) device posDevice))
        (Unify
           (DataType DType)
           inputDataType
           (Seq
              (Unify (DataType DType) posDataType ('DataType 'Int64)) dataType))
        (BroadcastShapesF
           inputShape
           (EmbeddingF ('Shape '[posEncDim, inputEmbedDim]) posShape)))
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">Tensor
  inputGradient inputLayout inputDevice inputDataType inputShape
</span><a href="#local-6989586621679808475"><span class="hs-identifier hs-var">input</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor
  inputGradient inputLayout inputDevice inputDataType inputShape
-&gt; Tensor
     (Or (Gradient RequiresGradient) gradient posGradient)
     (Unify (Layout LayoutType) ('Layout 'Dense) posLayout)
     (Unify (Device (DeviceType Nat)) device posDevice)
     (Seq
        (Unify (DataType DType) posDataType ('DataType 'Int64)) dataType)
     (EmbeddingF ('Shape '[posEncDim, inputEmbedDim]) posShape)
-&gt; Tensor
     (inputGradient
      &lt;|&gt; Or (Gradient RequiresGradient) gradient posGradient)
     (inputLayout
      &lt;+&gt; Unify (Layout LayoutType) ('Layout 'Dense) posLayout)
     (inputDevice &lt;+&gt; Unify (Device (DeviceType Nat)) device posDevice)
     (inputDataType
      &lt;+&gt; Seq
            (Unify (DataType DType) posDataType ('DataType 'Int64)) dataType)
     (BroadcastShapesF
        inputShape
        (EmbeddingF ('Shape '[posEncDim, inputEmbedDim]) posShape))
forall (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)])
       (gradient' :: Gradient RequiresGradient)
       (layout' :: Layout LayoutType) (device' :: Device (DeviceType Nat))
       (dataType' :: DataType DType)
       (shape' :: Shape [Dim (Name Symbol) (Size Nat)]).
Tensor gradient layout device dataType shape
-&gt; Tensor gradient' layout' device' dataType' shape'
-&gt; Tensor
     (gradient &lt;|&gt; gradient')
     (layout &lt;+&gt; layout')
     (device &lt;+&gt; device')
     (dataType &lt;+&gt; dataType')
     (BroadcastShapesF shape shape')
</span><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#add"><span class="hs-operator hs-var">`add`</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-783"></span><span>            </span><span class="annot"><span class="annottext">IxStateT
  m
  (Generator generatorDevice)
  (Generator generatorDevice)
  (Tensor
     (Or
        (Gradient RequiresGradient)
        inputGradient
        (Or (Gradient RequiresGradient) gradient posGradient))
     (Unify
        (Layout LayoutType)
        inputLayout
        (Unify (Layout LayoutType) ('Layout 'Dense) posLayout))
     (Unify
        (Device (DeviceType Nat))
        inputDevice
        (Unify (Device (DeviceType Nat)) device posDevice))
     (Unify
        (DataType DType)
        inputDataType
        (Seq
           (Unify (DataType DType) posDataType ('DataType 'Int64)) dataType))
     (BroadcastShapesF
        inputShape
        (EmbeddingF ('Shape '[posEncDim, inputEmbedDim]) posShape)))
-&gt; (Tensor
      (Or
         (Gradient RequiresGradient)
         inputGradient
         (Or (Gradient RequiresGradient) gradient posGradient))
      (Unify
         (Layout LayoutType)
         inputLayout
         (Unify (Layout LayoutType) ('Layout 'Dense) posLayout))
      (Unify
         (Device (DeviceType Nat))
         inputDevice
         (Unify (Device (DeviceType Nat)) device posDevice))
      (Unify
         (DataType DType)
         inputDataType
         (Seq
            (Unify (DataType DType) posDataType ('DataType 'Int64)) dataType))
      (BroadcastShapesF
         inputShape
         (EmbeddingF ('Shape '[posEncDim, inputEmbedDim]) posShape))
    -&gt; IxStateT
         m
         (Generator generatorDevice)
         (Generator generatorDevice)
         layerNormOutput)
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator generatorDevice)
     layerNormOutput
forall k1 (m :: k1 -&gt; k1 -&gt; * -&gt; *) (i :: k1) (j :: k1) a
       (k2 :: k1) b.
IxMonad m =&gt;
m i j a -&gt; (a -&gt; m j k2 b) -&gt; m i k2 b
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&gt;&gt;&gt;=</span></a></span><span> </span><span class="annot"><span class="annottext">(Generator generatorDevice
 -&gt; m (layerNormOutput, Generator generatorDevice))
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator generatorDevice)
     layerNormOutput
forall (m :: * -&gt; *) i j a. (i -&gt; m (a, j)) -&gt; IxStateT m i j a
</span><a href="../file:///nix/store/8vjaffqxij7bih93d9mlzmc7ksanlw0i-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier hs-var">IxStateT</span></a></span><span> </span><span class="annot"><span class="annottext">((Generator generatorDevice
  -&gt; m (layerNormOutput, Generator generatorDevice))
 -&gt; IxStateT
      m
      (Generator generatorDevice)
      (Generator generatorDevice)
      layerNormOutput)
-&gt; (Tensor
      (Or
         (Gradient RequiresGradient)
         inputGradient
         (Or (Gradient RequiresGradient) gradient posGradient))
      (Unify
         (Layout LayoutType)
         inputLayout
         (Unify (Layout LayoutType) ('Layout 'Dense) posLayout))
      (Unify
         (Device (DeviceType Nat))
         inputDevice
         (Unify (Device (DeviceType Nat)) device posDevice))
      (Unify
         (DataType DType)
         inputDataType
         (Seq
            (Unify (DataType DType) posDataType ('DataType 'Int64)) dataType))
      (BroadcastShapesF
         inputShape
         (EmbeddingF ('Shape '[posEncDim, inputEmbedDim]) posShape))
    -&gt; Generator generatorDevice
    -&gt; m (layerNormOutput, Generator generatorDevice))
-&gt; Tensor
     (Or
        (Gradient RequiresGradient)
        inputGradient
        (Or (Gradient RequiresGradient) gradient posGradient))
     (Unify
        (Layout LayoutType)
        inputLayout
        (Unify (Layout LayoutType) ('Layout 'Dense) posLayout))
     (Unify
        (Device (DeviceType Nat))
        inputDevice
        (Unify (Device (DeviceType Nat)) device posDevice))
     (Unify
        (DataType DType)
        inputDataType
        (Seq
           (Unify (DataType DType) posDataType ('DataType 'Int64)) dataType))
     (BroadcastShapesF
        inputShape
        (EmbeddingF ('Shape '[posEncDim, inputEmbedDim]) posShape))
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator generatorDevice)
     layerNormOutput
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">LayerNorm
  'WithBias gradient device dataType ('Shape '[inputEmbedDim])
-&gt; Tensor
     (Or
        (Gradient RequiresGradient)
        inputGradient
        (Or (Gradient RequiresGradient) gradient posGradient))
     (Unify
        (Layout LayoutType)
        inputLayout
        (Unify (Layout LayoutType) ('Layout 'Dense) posLayout))
     (Unify
        (Device (DeviceType Nat))
        inputDevice
        (Unify (Device (DeviceType Nat)) device posDevice))
     (Unify
        (DataType DType)
        inputDataType
        (Seq
           (Unify (DataType DType) posDataType ('DataType 'Int64)) dataType))
     (BroadcastShapesF
        inputShape
        (EmbeddingF ('Shape '[posEncDim, inputEmbedDim]) posShape))
-&gt; Generator generatorDevice
-&gt; m (layerNormOutput, Generator generatorDevice)
forall model input (generatorDevice :: Device (DeviceType Nat))
       output (generatorOutputDevice :: Device (DeviceType Nat))
       (m :: * -&gt; *).
(HasForward
   model input generatorDevice output generatorOutputDevice,
 MonadThrow m) =&gt;
model
-&gt; input
-&gt; Generator generatorDevice
-&gt; m (output, Generator generatorOutputDevice)
</span><a href="Torch.GraduallyTyped.NN.Class.html#forward"><span class="hs-identifier hs-var">forward</span></a></span><span> </span><span class="annot"><span class="annottext">LayerNorm
  'WithBias gradient device dataType ('Shape '[inputEmbedDim])
TEEmbedLayerNormF 'BERT gradient device dataType inputEmbedDim
</span><a href="#local-6989586621679808479"><span class="hs-identifier hs-var">teEmbedLayerNorm</span></a></span><span>
</span><span id="line-784"></span><span>            </span><span class="annot"><span class="annottext">IxStateT
  m
  (Generator generatorDevice)
  (Generator generatorDevice)
  layerNormOutput
-&gt; (layerNormOutput
    -&gt; IxStateT
         m
         (Generator generatorDevice)
         (Generator dropoutGeneratorOutputDevice)
         dropoutOutput)
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator dropoutGeneratorOutputDevice)
     dropoutOutput
forall k1 (m :: k1 -&gt; k1 -&gt; * -&gt; *) (i :: k1) (j :: k1) a
       (k2 :: k1) b.
IxMonad m =&gt;
m i j a -&gt; (a -&gt; m j k2 b) -&gt; m i k2 b
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&gt;&gt;&gt;=</span></a></span><span> </span><span class="annot"><span class="annottext">(Generator generatorDevice
 -&gt; m (dropoutOutput, Generator dropoutGeneratorOutputDevice))
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator dropoutGeneratorOutputDevice)
     dropoutOutput
forall (m :: * -&gt; *) i j a. (i -&gt; m (a, j)) -&gt; IxStateT m i j a
</span><a href="../file:///nix/store/8vjaffqxij7bih93d9mlzmc7ksanlw0i-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier hs-var">IxStateT</span></a></span><span> </span><span class="annot"><span class="annottext">((Generator generatorDevice
  -&gt; m (dropoutOutput, Generator dropoutGeneratorOutputDevice))
 -&gt; IxStateT
      m
      (Generator generatorDevice)
      (Generator dropoutGeneratorOutputDevice)
      dropoutOutput)
-&gt; (layerNormOutput
    -&gt; Generator generatorDevice
    -&gt; m (dropoutOutput, Generator dropoutGeneratorOutputDevice))
-&gt; layerNormOutput
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator dropoutGeneratorOutputDevice)
     dropoutOutput
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">Dropout
-&gt; layerNormOutput
-&gt; Generator generatorDevice
-&gt; m (dropoutOutput, Generator dropoutGeneratorOutputDevice)
forall model input (generatorDevice :: Device (DeviceType Nat))
       output (generatorOutputDevice :: Device (DeviceType Nat))
       (m :: * -&gt; *).
(HasForward
   model input generatorDevice output generatorOutputDevice,
 MonadThrow m) =&gt;
model
-&gt; input
-&gt; Generator generatorDevice
-&gt; m (output, Generator generatorOutputDevice)
</span><a href="Torch.GraduallyTyped.NN.Class.html#forward"><span class="hs-identifier hs-var">forward</span></a></span><span> </span><span class="annot"><span class="annottext">Dropout
TEDropoutF 'BERT
</span><a href="#local-6989586621679808477"><span class="hs-identifier hs-var">teDropout</span></a></span><span>
</span><span id="line-785"></span><span>            </span><span class="annot"><span class="annottext">IxStateT
  m
  (Generator generatorDevice)
  (Generator dropoutGeneratorOutputDevice)
  dropoutOutput
-&gt; (dropoutOutput
    -&gt; IxStateT
         m
         (Generator dropoutGeneratorOutputDevice)
         (Generator generatorOutputDevice)
         output)
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator generatorOutputDevice)
     output
forall k1 (m :: k1 -&gt; k1 -&gt; * -&gt; *) (i :: k1) (j :: k1) a
       (k2 :: k1) b.
IxMonad m =&gt;
m i j a -&gt; (a -&gt; m j k2 b) -&gt; m i k2 b
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&gt;&gt;&gt;=</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">\</span><span id="local-6989586621679808471"><span class="annot"><span class="annottext">dropoutOutput
</span><a href="#local-6989586621679808471"><span class="hs-identifier hs-var">input'</span></a></span></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><span class="annottext">(Generator dropoutGeneratorOutputDevice
 -&gt; m (output, Generator generatorOutputDevice))
-&gt; IxStateT
     m
     (Generator dropoutGeneratorOutputDevice)
     (Generator generatorOutputDevice)
     output
forall (m :: * -&gt; *) i j a. (i -&gt; m (a, j)) -&gt; IxStateT m i j a
</span><a href="../file:///nix/store/8vjaffqxij7bih93d9mlzmc7ksanlw0i-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier hs-var">IxStateT</span></a></span><span> </span><span class="annot"><span class="annottext">((Generator dropoutGeneratorOutputDevice
  -&gt; m (output, Generator generatorOutputDevice))
 -&gt; IxStateT
      m
      (Generator dropoutGeneratorOutputDevice)
      (Generator generatorOutputDevice)
      output)
-&gt; (Generator dropoutGeneratorOutputDevice
    -&gt; m (output, Generator generatorOutputDevice))
-&gt; IxStateT
     m
     (Generator dropoutGeneratorOutputDevice)
     (Generator generatorOutputDevice)
     output
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">TransformerStack
  'BERT
  numLayers
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  inputEmbedDim
  ffnDim
-&gt; (dropoutOutput,
    Tensor
      attentionMaskGradient
      attentionMaskLayout
      attentionMaskDevice
      attentionMaskDataType
      (UnsqueezeF ('SelectDim ('ByIndex 1)) attentionMaskShape))
-&gt; Generator dropoutGeneratorOutputDevice
-&gt; m (output, Generator generatorOutputDevice)
forall model input (generatorDevice :: Device (DeviceType Nat))
       output (generatorOutputDevice :: Device (DeviceType Nat))
       (m :: * -&gt; *).
(HasForward
   model input generatorDevice output generatorOutputDevice,
 MonadThrow m) =&gt;
model
-&gt; input
-&gt; Generator generatorDevice
-&gt; m (output, Generator generatorOutputDevice)
</span><a href="Torch.GraduallyTyped.NN.Class.html#forward"><span class="hs-identifier hs-var">forward</span></a></span><span> </span><span class="annot"><span class="annottext">TransformerStack
  'BERT
  numLayers
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  inputEmbedDim
  ffnDim
TEStackF
  'BERT
  numLayers
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  inputEmbedDim
  ffnDim
</span><a href="#local-6989586621679808480"><span class="hs-identifier hs-var">teStack</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">dropoutOutput
</span><a href="#local-6989586621679808471"><span class="hs-identifier hs-var">input'</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">Tensor
  attentionMaskGradient
  attentionMaskLayout
  attentionMaskDevice
  attentionMaskDataType
  (UnsqueezeF ('SelectDim ('ByIndex 1)) attentionMaskShape)
</span><a href="#local-6989586621679808472"><span class="hs-identifier hs-var">attentionBias</span></a></span><span class="hs-special">)</span><span class="hs-special">)</span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span><span>
</span><span id="line-786"></span><span>
</span><span id="line-787"></span><span class="hs-comment">-- | 'HasForward' instance for @TransformerEncoder numLayers 'RoBERTa@.</span><span>
</span><span id="line-788"></span><span class="hs-comment">--</span><span>
</span><span id="line-789"></span><span class="hs-comment">-- @</span><span>
</span><span id="line-790"></span><span class="hs-comment">-- &#9484;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9488;  &#9484;&#9472;&#9472;&#9472;&#9472;&#9472;&#9488;  &#9484;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9488;</span><span>
</span><span id="line-791"></span><span class="hs-comment">-- &#9474; input &#9474;  &#9474; pos &#9474;  &#9474; attentionMask &#9474;</span><span>
</span><span id="line-792"></span><span class="hs-comment">-- &#9492;&#9472;&#9472;&#9472;&#9516;&#9472;&#9472;&#9472;&#9496;  &#9492;&#9472;&#9472;&#9472;&#9472;&#9472;&#9496;  &#9492;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9516;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9496;</span><span>
</span><span id="line-793"></span><span class="hs-comment">--     &#9474;         &#9474;             &#9474;</span><span>
</span><span id="line-794"></span><span class="hs-comment">--     &#9474;         &#9660;             &#9474;</span><span>
</span><span id="line-795"></span><span class="hs-comment">--     &#9474;     tePosEnc          &#9474;</span><span>
</span><span id="line-796"></span><span class="hs-comment">--     &#9474;         &#9474;             &#9474;</span><span>
</span><span id="line-797"></span><span class="hs-comment">--     &#9492;&#9472;&#9472;&#9658;add&#9668;&#9472;&#9472;&#9496;             &#9474;</span><span>
</span><span id="line-798"></span><span class="hs-comment">--          &#9474;                  &#9474;</span><span>
</span><span id="line-799"></span><span class="hs-comment">--          &#9660;                  &#9474;</span><span>
</span><span id="line-800"></span><span class="hs-comment">--   teEmbedLayerNorm          &#9474;</span><span>
</span><span id="line-801"></span><span class="hs-comment">--          &#9660;                  &#9660;</span><span>
</span><span id="line-802"></span><span class="hs-comment">--      teDropout          unsqueeze</span><span>
</span><span id="line-803"></span><span class="hs-comment">--          &#9660;                  &#9474;</span><span>
</span><span id="line-804"></span><span class="hs-comment">--       teStack&#9668;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9496;</span><span>
</span><span id="line-805"></span><span class="hs-comment">--          &#9474;</span><span>
</span><span id="line-806"></span><span class="hs-comment">--          &#9660;</span><span>
</span><span id="line-807"></span><span class="hs-comment">--     &#9484;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9488;</span><span>
</span><span id="line-808"></span><span class="hs-comment">--     &#9474; output &#9474;</span><span>
</span><span id="line-809"></span><span class="hs-comment">--     &#9492;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9496;</span><span>
</span><span id="line-810"></span><span class="hs-comment">-- @</span><span>
</span><span id="line-811"></span><span id="local-6989586621679808440"><span id="local-6989586621679808441"><span id="local-6989586621679808442"><span id="local-6989586621679808443"><span id="local-6989586621679808444"><span id="local-6989586621679808445"><span id="local-6989586621679808446"><span id="local-6989586621679808447"><span id="local-6989586621679808448"><span id="local-6989586621679808449"><span id="local-6989586621679808450"><span id="local-6989586621679808451"><span id="local-6989586621679808452"><span id="local-6989586621679808453"><span id="local-6989586621679808454"><span id="local-6989586621679808455"><span id="local-6989586621679808456"><span id="local-6989586621679808457"><span id="local-6989586621679808458"><span id="local-6989586621679808459"><span id="local-6989586621679808460"><span id="local-6989586621679808461"><span id="local-6989586621679808462"><span id="local-6989586621679808463"><span id="local-6989586621679808464"><span id="local-6989586621679808465"><span id="local-6989586621679808466"><span id="local-6989586621679808467"><span id="local-6989586621679808468"><span id="local-6989586621679808469"><span id="local-6989586621679808470"><span class="hs-keyword">instance</span><span>
</span><span id="line-812"></span><span>  </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasForward"><span class="hs-identifier hs-type">HasForward</span></a></span><span>
</span><span id="line-813"></span><span>      </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Encoder.html#TEEmbedLayerNormF"><span class="hs-identifier hs-type">TEEmbedLayerNormF</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#RoBERTa"><span class="hs-identifier hs-type">RoBERTa</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808470"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808469"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808468"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808467"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-814"></span><span>      </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span>
</span><span id="line-815"></span><span>          </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679808466"><span class="hs-identifier hs-type">inputGradient</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%7C%3E"><span class="hs-operator hs-type">&lt;|&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808470"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%7C%3E"><span class="hs-operator hs-type">&lt;|&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808465"><span class="hs-identifier hs-type">posGradient</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-816"></span><span>          </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679808464"><span class="hs-identifier hs-type">inputLayout</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#Layout"><span class="hs-identifier hs-type">Layout</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#Dense"><span class="hs-identifier hs-type">Dense</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808463"><span class="hs-identifier hs-type">posLayout</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-817"></span><span>          </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679808462"><span class="hs-identifier hs-type">inputDevice</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808469"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808461"><span class="hs-identifier hs-type">posDevice</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-818"></span><span>          </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679808460"><span class="hs-identifier hs-type">inputDataType</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Prelude.html#Seq"><span class="hs-identifier hs-type">Seq</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679808459"><span class="hs-identifier hs-type">posDataType</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#DataType"><span class="hs-identifier hs-type">DataType</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#Int64"><span class="hs-identifier hs-type">Int64</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679808468"><span class="hs-identifier hs-type">dataType</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-819"></span><span>          </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Class.html#BroadcastShapesF"><span class="hs-identifier hs-type">BroadcastShapesF</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808458"><span class="hs-identifier hs-type">inputShape</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Functional.Sparse.html#EmbeddingF"><span class="hs-identifier hs-type">EmbeddingF</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Shape"><span class="hs-identifier hs-type">Shape</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="annot"><a href="#local-6989586621679808457"><span class="hs-identifier hs-type">posEncDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679808467"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span><span class="hs-special">]</span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679808456"><span class="hs-identifier hs-type">posShape</span></a></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-820"></span><span>      </span><span class="hs-special">)</span><span>
</span><span id="line-821"></span><span>      </span><span class="annot"><a href="#local-6989586621679808455"><span class="hs-identifier hs-type">generatorDevice</span></a></span><span>
</span><span id="line-822"></span><span>      </span><span class="annot"><a href="#local-6989586621679808454"><span class="hs-identifier hs-type">layerNormOutput</span></a></span><span>
</span><span id="line-823"></span><span>      </span><span class="annot"><a href="#local-6989586621679808455"><span class="hs-identifier hs-type">generatorDevice</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-824"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasForward"><span class="hs-identifier hs-type">HasForward</span></a></span><span>
</span><span id="line-825"></span><span>      </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Encoder.html#TEDropoutF"><span class="hs-identifier hs-type">TEDropoutF</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#RoBERTa"><span class="hs-identifier hs-type">RoBERTa</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-826"></span><span>      </span><span class="annot"><a href="#local-6989586621679808454"><span class="hs-identifier hs-type">layerNormOutput</span></a></span><span>
</span><span id="line-827"></span><span>      </span><span class="annot"><a href="#local-6989586621679808455"><span class="hs-identifier hs-type">generatorDevice</span></a></span><span>
</span><span id="line-828"></span><span>      </span><span class="annot"><a href="#local-6989586621679808453"><span class="hs-identifier hs-type">dropoutOutput</span></a></span><span>
</span><span id="line-829"></span><span>      </span><span class="annot"><a href="#local-6989586621679808452"><span class="hs-identifier hs-type">dropoutGeneratorOutputDevice</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-830"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasForward"><span class="hs-identifier hs-type">HasForward</span></a></span><span>
</span><span id="line-831"></span><span>      </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Encoder.html#TEStackF"><span class="hs-identifier hs-type">TEStackF</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#RoBERTa"><span class="hs-identifier hs-type">RoBERTa</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808451"><span class="hs-identifier hs-type">numLayers</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808470"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808469"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808468"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808450"><span class="hs-identifier hs-type">headDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808449"><span class="hs-identifier hs-type">headEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808448"><span class="hs-identifier hs-type">embedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808467"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808447"><span class="hs-identifier hs-type">ffnDim</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-832"></span><span>      </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="#local-6989586621679808453"><span class="hs-identifier hs-type">dropoutOutput</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-833"></span><span>        </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span>
</span><span id="line-834"></span><span>          </span><span class="annot"><a href="#local-6989586621679808446"><span class="hs-identifier hs-type">attentionMaskGradient</span></a></span><span>
</span><span id="line-835"></span><span>          </span><span class="annot"><a href="#local-6989586621679808445"><span class="hs-identifier hs-type">attentionMaskLayout</span></a></span><span>
</span><span id="line-836"></span><span>          </span><span class="annot"><a href="#local-6989586621679808444"><span class="hs-identifier hs-type">attentionMaskDevice</span></a></span><span>
</span><span id="line-837"></span><span>          </span><span class="annot"><a href="#local-6989586621679808443"><span class="hs-identifier hs-type">attentionMaskDataType</span></a></span><span>
</span><span id="line-838"></span><span>          </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.IndexingSlicingJoining.html#UnsqueezeF"><span class="hs-identifier hs-type">UnsqueezeF</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SelectDim"><span class="hs-identifier hs-type">SelectDim</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#ByIndex"><span class="hs-identifier hs-type">ByIndex</span></a></span><span> </span><span class="annot"><span class="hs-number">1</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679808442"><span class="hs-identifier hs-type">attentionMaskShape</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-839"></span><span>      </span><span class="hs-special">)</span><span>
</span><span id="line-840"></span><span>      </span><span class="annot"><a href="#local-6989586621679808452"><span class="hs-identifier hs-type">dropoutGeneratorOutputDevice</span></a></span><span>
</span><span id="line-841"></span><span>      </span><span class="annot"><a href="#local-6989586621679808441"><span class="hs-identifier hs-type">output</span></a></span><span>
</span><span id="line-842"></span><span>      </span><span class="annot"><a href="#local-6989586621679808440"><span class="hs-identifier hs-type">generatorOutputDevice</span></a></span><span>
</span><span id="line-843"></span><span>  </span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-844"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasForward"><span class="hs-identifier hs-type">HasForward</span></a></span><span>
</span><span id="line-845"></span><span>    </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Encoder.html#TransformerEncoder"><span class="hs-identifier hs-type">TransformerEncoder</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#RoBERTa"><span class="hs-identifier hs-type">RoBERTa</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808451"><span class="hs-identifier hs-type">numLayers</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808470"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808469"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808468"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808450"><span class="hs-identifier hs-type">headDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808449"><span class="hs-identifier hs-type">headEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808448"><span class="hs-identifier hs-type">embedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808467"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808447"><span class="hs-identifier hs-type">ffnDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808457"><span class="hs-identifier hs-type">posEncDim</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-846"></span><span>    </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808466"><span class="hs-identifier hs-type">inputGradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808464"><span class="hs-identifier hs-type">inputLayout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808462"><span class="hs-identifier hs-type">inputDevice</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808460"><span class="hs-identifier hs-type">inputDataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808458"><span class="hs-identifier hs-type">inputShape</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-847"></span><span>      </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808465"><span class="hs-identifier hs-type">posGradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808463"><span class="hs-identifier hs-type">posLayout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808461"><span class="hs-identifier hs-type">posDevice</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808459"><span class="hs-identifier hs-type">posDataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808456"><span class="hs-identifier hs-type">posShape</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-848"></span><span>      </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808446"><span class="hs-identifier hs-type">attentionMaskGradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808445"><span class="hs-identifier hs-type">attentionMaskLayout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808444"><span class="hs-identifier hs-type">attentionMaskDevice</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808443"><span class="hs-identifier hs-type">attentionMaskDataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808442"><span class="hs-identifier hs-type">attentionMaskShape</span></a></span><span>
</span><span id="line-849"></span><span>    </span><span class="hs-special">)</span><span>
</span><span id="line-850"></span><span>    </span><span class="annot"><a href="#local-6989586621679808455"><span class="hs-identifier hs-type">generatorDevice</span></a></span><span>
</span><span id="line-851"></span><span>    </span><span class="annot"><a href="#local-6989586621679808441"><span class="hs-identifier hs-type">output</span></a></span><span>
</span><span id="line-852"></span><span>    </span><span class="annot"><a href="#local-6989586621679808440"><span class="hs-identifier hs-type">generatorOutputDevice</span></a></span><span>
</span><span id="line-853"></span><span>  </span><span class="hs-keyword">where</span><span>
</span><span id="line-854"></span><span>  </span><span id="local-6989586621679808438"><span class="annot"><span class="annottext">forward :: TransformerEncoder
  'RoBERTa
  numLayers
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  inputEmbedDim
  ffnDim
  posEncDim
-&gt; (Tensor
      inputGradient inputLayout inputDevice inputDataType inputShape,
    Tensor posGradient posLayout posDevice posDataType posShape,
    Tensor
      attentionMaskGradient
      attentionMaskLayout
      attentionMaskDevice
      attentionMaskDataType
      attentionMaskShape)
-&gt; Generator generatorDevice
-&gt; m (output, Generator generatorOutputDevice)
</span><a href="#local-6989586621679808438"><span class="hs-identifier hs-var hs-var hs-var hs-var">forward</span></a></span></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Encoder.html#TransformerEncoder"><span class="hs-identifier hs-type">TransformerEncoder</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Encoder.html#GTransformerEncoder"><span class="hs-identifier hs-type">GTransformerEncoder</span></a></span><span> </span><span class="hs-special">{</span><span id="local-6989586621679808433"><span id="local-6989586621679808434"><span id="local-6989586621679808435"><span id="local-6989586621679808436"><span id="local-6989586621679808437"><span class="annot"><span class="annottext">TEPosEncF
  'RoBERTa gradient device dataType headDim inputEmbedDim posEncDim
TEDropoutF 'RoBERTa
TELayerNormF 'RoBERTa gradient device dataType inputEmbedDim
TEEmbedLayerNormF 'RoBERTa gradient device dataType inputEmbedDim
TEStackF
  'RoBERTa
  numLayers
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  inputEmbedDim
  ffnDim
tePosEnc :: TEPosEncF
  'RoBERTa gradient device dataType headDim inputEmbedDim posEncDim
teDropout :: TEDropoutF 'RoBERTa
teLayerNorm :: TELayerNormF 'RoBERTa gradient device dataType inputEmbedDim
teEmbedLayerNorm :: TEEmbedLayerNormF 'RoBERTa gradient device dataType inputEmbedDim
teStack :: TEStackF
  'RoBERTa
  numLayers
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  inputEmbedDim
  ffnDim
tePosEnc :: forall stack embedLayerNorm layerNorm dropout posEnc.
GTransformerEncoder stack embedLayerNorm layerNorm dropout posEnc
-&gt; posEnc
teDropout :: forall stack embedLayerNorm layerNorm dropout posEnc.
GTransformerEncoder stack embedLayerNorm layerNorm dropout posEnc
-&gt; dropout
teLayerNorm :: forall stack embedLayerNorm layerNorm dropout posEnc.
GTransformerEncoder stack embedLayerNorm layerNorm dropout posEnc
-&gt; layerNorm
teEmbedLayerNorm :: forall stack embedLayerNorm layerNorm dropout posEnc.
GTransformerEncoder stack embedLayerNorm layerNorm dropout posEnc
-&gt; embedLayerNorm
teStack :: forall stack embedLayerNorm layerNorm dropout posEnc.
GTransformerEncoder stack embedLayerNorm layerNorm dropout posEnc
-&gt; stack
</span><a href="#local-6989586621679808433"><span class="hs-glyph hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var">..</span></a></span></span></span></span></span></span><span class="hs-special">}</span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span id="local-6989586621679808432"><span class="annot"><span class="annottext">Tensor
  inputGradient inputLayout inputDevice inputDataType inputShape
</span><a href="#local-6989586621679808432"><span class="hs-identifier hs-var">input</span></a></span></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679808431"><span class="annot"><span class="annottext">Tensor posGradient posLayout posDevice posDataType posShape
</span><a href="#local-6989586621679808431"><span class="hs-identifier hs-var">pos</span></a></span></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679808430"><span class="annot"><span class="annottext">Tensor
  attentionMaskGradient
  attentionMaskLayout
  attentionMaskDevice
  attentionMaskDataType
  attentionMaskShape
</span><a href="#local-6989586621679808430"><span class="hs-identifier hs-var">attentionMask</span></a></span></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-855"></span><span>    </span><span class="hs-keyword">let</span><span> </span><span id="local-6989586621679808429"><span class="annot"><span class="annottext">attentionBias :: Tensor
  attentionMaskGradient
  attentionMaskLayout
  attentionMaskDevice
  attentionMaskDataType
  (UnsqueezeF ('SelectDim ('ByIndex 1)) attentionMaskShape)
</span><a href="#local-6989586621679808429"><span class="hs-identifier hs-var hs-var">attentionBias</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Tensor
  attentionMaskGradient
  attentionMaskLayout
  attentionMaskDevice
  attentionMaskDataType
  attentionMaskShape
-&gt; Tensor
     attentionMaskGradient
     attentionMaskLayout
     attentionMaskDevice
     attentionMaskDataType
     (UnsqueezeF ('SelectDim ('ByIndex 1)) attentionMaskShape)
forall (selectDim :: SelectDim (By Symbol Nat))
       (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)])
       (shape' :: Shape [Dim (Name Symbol) (Size Nat)]).
(shape' ~ UnsqueezeF selectDim shape, SingI selectDim) =&gt;
Tensor gradient layout device dataType shape
-&gt; Tensor gradient layout device dataType shape'
</span><a href="Torch.GraduallyTyped.Tensor.IndexingSlicingJoining.html#unsqueeze"><span class="hs-identifier hs-var">unsqueeze</span></a></span><span> </span><span class="hs-glyph">@</span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SelectDim"><span class="hs-identifier hs-type">SelectDim</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#ByIndex"><span class="hs-identifier hs-type">ByIndex</span></a></span><span> </span><span class="annot"><span class="hs-number">1</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">Tensor
  attentionMaskGradient
  attentionMaskLayout
  attentionMaskDevice
  attentionMaskDataType
  attentionMaskShape
</span><a href="#local-6989586621679808430"><span class="hs-identifier hs-var">attentionMask</span></a></span><span>
</span><span id="line-856"></span><span>     </span><span class="hs-keyword">in</span><span> </span><span class="annot"><span class="annottext">IxStateT
  m
  (Generator generatorDevice)
  (Generator generatorOutputDevice)
  output
-&gt; Generator generatorDevice
-&gt; m (output, Generator generatorOutputDevice)
forall (m :: * -&gt; *) i j a. IxStateT m i j a -&gt; i -&gt; m (a, j)
</span><a href="../file:///nix/store/8vjaffqxij7bih93d9mlzmc7ksanlw0i-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier hs-var hs-var">runIxStateT</span></a></span><span> </span><span class="annot"><span class="annottext">(IxStateT
   m
   (Generator generatorDevice)
   (Generator generatorOutputDevice)
   output
 -&gt; Generator generatorDevice
 -&gt; m (output, Generator generatorOutputDevice))
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator generatorOutputDevice)
     output
-&gt; Generator generatorDevice
-&gt; m (output, Generator generatorOutputDevice)
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span>
</span><span id="line-857"></span><span>          </span><span class="annot"><span class="annottext">Tensor posGradient posLayout posDevice posDataType posShape
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator generatorDevice)
     (Tensor posGradient posLayout posDevice posDataType posShape)
forall k (m :: k -&gt; k -&gt; * -&gt; *) a (i :: k).
IxPointed m =&gt;
a -&gt; m i i a
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-identifier hs-var">ireturn</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor posGradient posLayout posDevice posDataType posShape
</span><a href="#local-6989586621679808431"><span class="hs-identifier hs-var">pos</span></a></span><span>
</span><span id="line-858"></span><span>            </span><span class="annot"><span class="annottext">IxStateT
  m
  (Generator generatorDevice)
  (Generator generatorDevice)
  (Tensor posGradient posLayout posDevice posDataType posShape)
-&gt; (Tensor posGradient posLayout posDevice posDataType posShape
    -&gt; IxStateT
         m
         (Generator generatorDevice)
         (Generator generatorDevice)
         (Tensor
            (Or (Gradient RequiresGradient) gradient posGradient)
            (Unify (Layout LayoutType) ('Layout 'Dense) posLayout)
            (Unify (Device (DeviceType Nat)) device posDevice)
            (Seq
               (Unify (DataType DType) posDataType ('DataType 'Int64)) dataType)
            (EmbeddingF ('Shape '[posEncDim, inputEmbedDim]) posShape)))
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator generatorDevice)
     (Tensor
        (Or (Gradient RequiresGradient) gradient posGradient)
        (Unify (Layout LayoutType) ('Layout 'Dense) posLayout)
        (Unify (Device (DeviceType Nat)) device posDevice)
        (Seq
           (Unify (DataType DType) posDataType ('DataType 'Int64)) dataType)
        (EmbeddingF ('Shape '[posEncDim, inputEmbedDim]) posShape))
forall k1 (m :: k1 -&gt; k1 -&gt; * -&gt; *) (i :: k1) (j :: k1) a
       (k2 :: k1) b.
IxMonad m =&gt;
m i j a -&gt; (a -&gt; m j k2 b) -&gt; m i k2 b
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&gt;&gt;&gt;=</span></a></span><span> </span><span class="annot"><span class="annottext">(Generator generatorDevice
 -&gt; m (Tensor
         (Or (Gradient RequiresGradient) gradient posGradient)
         (Unify (Layout LayoutType) ('Layout 'Dense) posLayout)
         (Unify (Device (DeviceType Nat)) device posDevice)
         (Seq
            (Unify (DataType DType) posDataType ('DataType 'Int64)) dataType)
         (EmbeddingF ('Shape '[posEncDim, inputEmbedDim]) posShape),
       Generator generatorDevice))
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator generatorDevice)
     (Tensor
        (Or (Gradient RequiresGradient) gradient posGradient)
        (Unify (Layout LayoutType) ('Layout 'Dense) posLayout)
        (Unify (Device (DeviceType Nat)) device posDevice)
        (Seq
           (Unify (DataType DType) posDataType ('DataType 'Int64)) dataType)
        (EmbeddingF ('Shape '[posEncDim, inputEmbedDim]) posShape))
forall (m :: * -&gt; *) i j a. (i -&gt; m (a, j)) -&gt; IxStateT m i j a
</span><a href="../file:///nix/store/8vjaffqxij7bih93d9mlzmc7ksanlw0i-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier hs-var">IxStateT</span></a></span><span> </span><span class="annot"><span class="annottext">((Generator generatorDevice
  -&gt; m (Tensor
          (Or (Gradient RequiresGradient) gradient posGradient)
          (Unify (Layout LayoutType) ('Layout 'Dense) posLayout)
          (Unify (Device (DeviceType Nat)) device posDevice)
          (Seq
             (Unify (DataType DType) posDataType ('DataType 'Int64)) dataType)
          (EmbeddingF ('Shape '[posEncDim, inputEmbedDim]) posShape),
        Generator generatorDevice))
 -&gt; IxStateT
      m
      (Generator generatorDevice)
      (Generator generatorDevice)
      (Tensor
         (Or (Gradient RequiresGradient) gradient posGradient)
         (Unify (Layout LayoutType) ('Layout 'Dense) posLayout)
         (Unify (Device (DeviceType Nat)) device posDevice)
         (Seq
            (Unify (DataType DType) posDataType ('DataType 'Int64)) dataType)
         (EmbeddingF ('Shape '[posEncDim, inputEmbedDim]) posShape)))
-&gt; (Tensor posGradient posLayout posDevice posDataType posShape
    -&gt; Generator generatorDevice
    -&gt; m (Tensor
            (Or (Gradient RequiresGradient) gradient posGradient)
            (Unify (Layout LayoutType) ('Layout 'Dense) posLayout)
            (Unify (Device (DeviceType Nat)) device posDevice)
            (Seq
               (Unify (DataType DType) posDataType ('DataType 'Int64)) dataType)
            (EmbeddingF ('Shape '[posEncDim, inputEmbedDim]) posShape),
          Generator generatorDevice))
-&gt; Tensor posGradient posLayout posDevice posDataType posShape
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator generatorDevice)
     (Tensor
        (Or (Gradient RequiresGradient) gradient posGradient)
        (Unify (Layout LayoutType) ('Layout 'Dense) posLayout)
        (Unify (Device (DeviceType Nat)) device posDevice)
        (Seq
           (Unify (DataType DType) posDataType ('DataType 'Int64)) dataType)
        (EmbeddingF ('Shape '[posEncDim, inputEmbedDim]) posShape))
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">Embedding
  gradient
  ('Layout 'Dense)
  device
  dataType
  posEncDim
  inputEmbedDim
  'Nothing
-&gt; Tensor posGradient posLayout posDevice posDataType posShape
-&gt; Generator generatorDevice
-&gt; m (Tensor
        (Or (Gradient RequiresGradient) gradient posGradient)
        (Unify (Layout LayoutType) ('Layout 'Dense) posLayout)
        (Unify (Device (DeviceType Nat)) device posDevice)
        (Seq
           (Unify (DataType DType) posDataType ('DataType 'Int64)) dataType)
        (EmbeddingF ('Shape '[posEncDim, inputEmbedDim]) posShape),
      Generator generatorDevice)
forall model input (generatorDevice :: Device (DeviceType Nat))
       output (generatorOutputDevice :: Device (DeviceType Nat))
       (m :: * -&gt; *).
(HasForward
   model input generatorDevice output generatorOutputDevice,
 MonadThrow m) =&gt;
model
-&gt; input
-&gt; Generator generatorDevice
-&gt; m (output, Generator generatorOutputDevice)
</span><a href="Torch.GraduallyTyped.NN.Class.html#forward"><span class="hs-identifier hs-var">forward</span></a></span><span> </span><span class="annot"><span class="annottext">Embedding
  gradient
  ('Layout 'Dense)
  device
  dataType
  posEncDim
  inputEmbedDim
  'Nothing
TEPosEncF
  'RoBERTa gradient device dataType headDim inputEmbedDim posEncDim
</span><a href="#local-6989586621679808433"><span class="hs-identifier hs-var">tePosEnc</span></a></span><span>
</span><span id="line-859"></span><span>            </span><span class="annot"><span class="annottext">IxStateT
  m
  (Generator generatorDevice)
  (Generator generatorDevice)
  (Tensor
     (Or (Gradient RequiresGradient) gradient posGradient)
     (Unify (Layout LayoutType) ('Layout 'Dense) posLayout)
     (Unify (Device (DeviceType Nat)) device posDevice)
     (Seq
        (Unify (DataType DType) posDataType ('DataType 'Int64)) dataType)
     (EmbeddingF ('Shape '[posEncDim, inputEmbedDim]) posShape))
-&gt; (Tensor
      (Or (Gradient RequiresGradient) gradient posGradient)
      (Unify (Layout LayoutType) ('Layout 'Dense) posLayout)
      (Unify (Device (DeviceType Nat)) device posDevice)
      (Seq
         (Unify (DataType DType) posDataType ('DataType 'Int64)) dataType)
      (EmbeddingF ('Shape '[posEncDim, inputEmbedDim]) posShape)
    -&gt; IxStateT
         m
         (Generator generatorDevice)
         (Generator generatorDevice)
         (Tensor
            (Or
               (Gradient RequiresGradient)
               inputGradient
               (Or (Gradient RequiresGradient) gradient posGradient))
            (Unify
               (Layout LayoutType)
               inputLayout
               (Unify (Layout LayoutType) ('Layout 'Dense) posLayout))
            (Unify
               (Device (DeviceType Nat))
               inputDevice
               (Unify (Device (DeviceType Nat)) device posDevice))
            (Unify
               (DataType DType)
               inputDataType
               (Seq
                  (Unify (DataType DType) posDataType ('DataType 'Int64)) dataType))
            (BroadcastShapesF
               inputShape
               (EmbeddingF ('Shape '[posEncDim, inputEmbedDim]) posShape))))
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator generatorDevice)
     (Tensor
        (Or
           (Gradient RequiresGradient)
           inputGradient
           (Or (Gradient RequiresGradient) gradient posGradient))
        (Unify
           (Layout LayoutType)
           inputLayout
           (Unify (Layout LayoutType) ('Layout 'Dense) posLayout))
        (Unify
           (Device (DeviceType Nat))
           inputDevice
           (Unify (Device (DeviceType Nat)) device posDevice))
        (Unify
           (DataType DType)
           inputDataType
           (Seq
              (Unify (DataType DType) posDataType ('DataType 'Int64)) dataType))
        (BroadcastShapesF
           inputShape
           (EmbeddingF ('Shape '[posEncDim, inputEmbedDim]) posShape)))
forall k1 (m :: k1 -&gt; k1 -&gt; * -&gt; *) (i :: k1) (j :: k1) a
       (k2 :: k1) b.
IxMonad m =&gt;
m i j a -&gt; (a -&gt; m j k2 b) -&gt; m i k2 b
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&gt;&gt;&gt;=</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor
  (Or
     (Gradient RequiresGradient)
     inputGradient
     (Or (Gradient RequiresGradient) gradient posGradient))
  (Unify
     (Layout LayoutType)
     inputLayout
     (Unify (Layout LayoutType) ('Layout 'Dense) posLayout))
  (Unify
     (Device (DeviceType Nat))
     inputDevice
     (Unify (Device (DeviceType Nat)) device posDevice))
  (Unify
     (DataType DType)
     inputDataType
     (Seq
        (Unify (DataType DType) posDataType ('DataType 'Int64)) dataType))
  (BroadcastShapesF
     inputShape
     (EmbeddingF ('Shape '[posEncDim, inputEmbedDim]) posShape))
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator generatorDevice)
     (Tensor
        (Or
           (Gradient RequiresGradient)
           inputGradient
           (Or (Gradient RequiresGradient) gradient posGradient))
        (Unify
           (Layout LayoutType)
           inputLayout
           (Unify (Layout LayoutType) ('Layout 'Dense) posLayout))
        (Unify
           (Device (DeviceType Nat))
           inputDevice
           (Unify (Device (DeviceType Nat)) device posDevice))
        (Unify
           (DataType DType)
           inputDataType
           (Seq
              (Unify (DataType DType) posDataType ('DataType 'Int64)) dataType))
        (BroadcastShapesF
           inputShape
           (EmbeddingF ('Shape '[posEncDim, inputEmbedDim]) posShape)))
forall k (m :: k -&gt; k -&gt; * -&gt; *) a (i :: k).
IxPointed m =&gt;
a -&gt; m i i a
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-identifier hs-var">ireturn</span></a></span><span> </span><span class="annot"><span class="annottext">(Tensor
   (Or
      (Gradient RequiresGradient)
      inputGradient
      (Or (Gradient RequiresGradient) gradient posGradient))
   (Unify
      (Layout LayoutType)
      inputLayout
      (Unify (Layout LayoutType) ('Layout 'Dense) posLayout))
   (Unify
      (Device (DeviceType Nat))
      inputDevice
      (Unify (Device (DeviceType Nat)) device posDevice))
   (Unify
      (DataType DType)
      inputDataType
      (Seq
         (Unify (DataType DType) posDataType ('DataType 'Int64)) dataType))
   (BroadcastShapesF
      inputShape
      (EmbeddingF ('Shape '[posEncDim, inputEmbedDim]) posShape))
 -&gt; IxStateT
      m
      (Generator generatorDevice)
      (Generator generatorDevice)
      (Tensor
         (Or
            (Gradient RequiresGradient)
            inputGradient
            (Or (Gradient RequiresGradient) gradient posGradient))
         (Unify
            (Layout LayoutType)
            inputLayout
            (Unify (Layout LayoutType) ('Layout 'Dense) posLayout))
         (Unify
            (Device (DeviceType Nat))
            inputDevice
            (Unify (Device (DeviceType Nat)) device posDevice))
         (Unify
            (DataType DType)
            inputDataType
            (Seq
               (Unify (DataType DType) posDataType ('DataType 'Int64)) dataType))
         (BroadcastShapesF
            inputShape
            (EmbeddingF ('Shape '[posEncDim, inputEmbedDim]) posShape))))
-&gt; (Tensor
      (Or (Gradient RequiresGradient) gradient posGradient)
      (Unify (Layout LayoutType) ('Layout 'Dense) posLayout)
      (Unify (Device (DeviceType Nat)) device posDevice)
      (Seq
         (Unify (DataType DType) posDataType ('DataType 'Int64)) dataType)
      (EmbeddingF ('Shape '[posEncDim, inputEmbedDim]) posShape)
    -&gt; Tensor
         (Or
            (Gradient RequiresGradient)
            inputGradient
            (Or (Gradient RequiresGradient) gradient posGradient))
         (Unify
            (Layout LayoutType)
            inputLayout
            (Unify (Layout LayoutType) ('Layout 'Dense) posLayout))
         (Unify
            (Device (DeviceType Nat))
            inputDevice
            (Unify (Device (DeviceType Nat)) device posDevice))
         (Unify
            (DataType DType)
            inputDataType
            (Seq
               (Unify (DataType DType) posDataType ('DataType 'Int64)) dataType))
         (BroadcastShapesF
            inputShape
            (EmbeddingF ('Shape '[posEncDim, inputEmbedDim]) posShape)))
-&gt; Tensor
     (Or (Gradient RequiresGradient) gradient posGradient)
     (Unify (Layout LayoutType) ('Layout 'Dense) posLayout)
     (Unify (Device (DeviceType Nat)) device posDevice)
     (Seq
        (Unify (DataType DType) posDataType ('DataType 'Int64)) dataType)
     (EmbeddingF ('Shape '[posEncDim, inputEmbedDim]) posShape)
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator generatorDevice)
     (Tensor
        (Or
           (Gradient RequiresGradient)
           inputGradient
           (Or (Gradient RequiresGradient) gradient posGradient))
        (Unify
           (Layout LayoutType)
           inputLayout
           (Unify (Layout LayoutType) ('Layout 'Dense) posLayout))
        (Unify
           (Device (DeviceType Nat))
           inputDevice
           (Unify (Device (DeviceType Nat)) device posDevice))
        (Unify
           (DataType DType)
           inputDataType
           (Seq
              (Unify (DataType DType) posDataType ('DataType 'Int64)) dataType))
        (BroadcastShapesF
           inputShape
           (EmbeddingF ('Shape '[posEncDim, inputEmbedDim]) posShape)))
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">Tensor
  inputGradient inputLayout inputDevice inputDataType inputShape
</span><a href="#local-6989586621679808432"><span class="hs-identifier hs-var">input</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor
  inputGradient inputLayout inputDevice inputDataType inputShape
-&gt; Tensor
     (Or (Gradient RequiresGradient) gradient posGradient)
     (Unify (Layout LayoutType) ('Layout 'Dense) posLayout)
     (Unify (Device (DeviceType Nat)) device posDevice)
     (Seq
        (Unify (DataType DType) posDataType ('DataType 'Int64)) dataType)
     (EmbeddingF ('Shape '[posEncDim, inputEmbedDim]) posShape)
-&gt; Tensor
     (inputGradient
      &lt;|&gt; Or (Gradient RequiresGradient) gradient posGradient)
     (inputLayout
      &lt;+&gt; Unify (Layout LayoutType) ('Layout 'Dense) posLayout)
     (inputDevice &lt;+&gt; Unify (Device (DeviceType Nat)) device posDevice)
     (inputDataType
      &lt;+&gt; Seq
            (Unify (DataType DType) posDataType ('DataType 'Int64)) dataType)
     (BroadcastShapesF
        inputShape
        (EmbeddingF ('Shape '[posEncDim, inputEmbedDim]) posShape))
forall (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)])
       (gradient' :: Gradient RequiresGradient)
       (layout' :: Layout LayoutType) (device' :: Device (DeviceType Nat))
       (dataType' :: DataType DType)
       (shape' :: Shape [Dim (Name Symbol) (Size Nat)]).
Tensor gradient layout device dataType shape
-&gt; Tensor gradient' layout' device' dataType' shape'
-&gt; Tensor
     (gradient &lt;|&gt; gradient')
     (layout &lt;+&gt; layout')
     (device &lt;+&gt; device')
     (dataType &lt;+&gt; dataType')
     (BroadcastShapesF shape shape')
</span><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#add"><span class="hs-operator hs-var">`add`</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-860"></span><span>            </span><span class="annot"><span class="annottext">IxStateT
  m
  (Generator generatorDevice)
  (Generator generatorDevice)
  (Tensor
     (Or
        (Gradient RequiresGradient)
        inputGradient
        (Or (Gradient RequiresGradient) gradient posGradient))
     (Unify
        (Layout LayoutType)
        inputLayout
        (Unify (Layout LayoutType) ('Layout 'Dense) posLayout))
     (Unify
        (Device (DeviceType Nat))
        inputDevice
        (Unify (Device (DeviceType Nat)) device posDevice))
     (Unify
        (DataType DType)
        inputDataType
        (Seq
           (Unify (DataType DType) posDataType ('DataType 'Int64)) dataType))
     (BroadcastShapesF
        inputShape
        (EmbeddingF ('Shape '[posEncDim, inputEmbedDim]) posShape)))
-&gt; (Tensor
      (Or
         (Gradient RequiresGradient)
         inputGradient
         (Or (Gradient RequiresGradient) gradient posGradient))
      (Unify
         (Layout LayoutType)
         inputLayout
         (Unify (Layout LayoutType) ('Layout 'Dense) posLayout))
      (Unify
         (Device (DeviceType Nat))
         inputDevice
         (Unify (Device (DeviceType Nat)) device posDevice))
      (Unify
         (DataType DType)
         inputDataType
         (Seq
            (Unify (DataType DType) posDataType ('DataType 'Int64)) dataType))
      (BroadcastShapesF
         inputShape
         (EmbeddingF ('Shape '[posEncDim, inputEmbedDim]) posShape))
    -&gt; IxStateT
         m
         (Generator generatorDevice)
         (Generator generatorDevice)
         layerNormOutput)
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator generatorDevice)
     layerNormOutput
forall k1 (m :: k1 -&gt; k1 -&gt; * -&gt; *) (i :: k1) (j :: k1) a
       (k2 :: k1) b.
IxMonad m =&gt;
m i j a -&gt; (a -&gt; m j k2 b) -&gt; m i k2 b
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&gt;&gt;&gt;=</span></a></span><span> </span><span class="annot"><span class="annottext">(Generator generatorDevice
 -&gt; m (layerNormOutput, Generator generatorDevice))
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator generatorDevice)
     layerNormOutput
forall (m :: * -&gt; *) i j a. (i -&gt; m (a, j)) -&gt; IxStateT m i j a
</span><a href="../file:///nix/store/8vjaffqxij7bih93d9mlzmc7ksanlw0i-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier hs-var">IxStateT</span></a></span><span> </span><span class="annot"><span class="annottext">((Generator generatorDevice
  -&gt; m (layerNormOutput, Generator generatorDevice))
 -&gt; IxStateT
      m
      (Generator generatorDevice)
      (Generator generatorDevice)
      layerNormOutput)
-&gt; (Tensor
      (Or
         (Gradient RequiresGradient)
         inputGradient
         (Or (Gradient RequiresGradient) gradient posGradient))
      (Unify
         (Layout LayoutType)
         inputLayout
         (Unify (Layout LayoutType) ('Layout 'Dense) posLayout))
      (Unify
         (Device (DeviceType Nat))
         inputDevice
         (Unify (Device (DeviceType Nat)) device posDevice))
      (Unify
         (DataType DType)
         inputDataType
         (Seq
            (Unify (DataType DType) posDataType ('DataType 'Int64)) dataType))
      (BroadcastShapesF
         inputShape
         (EmbeddingF ('Shape '[posEncDim, inputEmbedDim]) posShape))
    -&gt; Generator generatorDevice
    -&gt; m (layerNormOutput, Generator generatorDevice))
-&gt; Tensor
     (Or
        (Gradient RequiresGradient)
        inputGradient
        (Or (Gradient RequiresGradient) gradient posGradient))
     (Unify
        (Layout LayoutType)
        inputLayout
        (Unify (Layout LayoutType) ('Layout 'Dense) posLayout))
     (Unify
        (Device (DeviceType Nat))
        inputDevice
        (Unify (Device (DeviceType Nat)) device posDevice))
     (Unify
        (DataType DType)
        inputDataType
        (Seq
           (Unify (DataType DType) posDataType ('DataType 'Int64)) dataType))
     (BroadcastShapesF
        inputShape
        (EmbeddingF ('Shape '[posEncDim, inputEmbedDim]) posShape))
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator generatorDevice)
     layerNormOutput
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">LayerNorm
  'WithBias gradient device dataType ('Shape '[inputEmbedDim])
-&gt; Tensor
     (Or
        (Gradient RequiresGradient)
        inputGradient
        (Or (Gradient RequiresGradient) gradient posGradient))
     (Unify
        (Layout LayoutType)
        inputLayout
        (Unify (Layout LayoutType) ('Layout 'Dense) posLayout))
     (Unify
        (Device (DeviceType Nat))
        inputDevice
        (Unify (Device (DeviceType Nat)) device posDevice))
     (Unify
        (DataType DType)
        inputDataType
        (Seq
           (Unify (DataType DType) posDataType ('DataType 'Int64)) dataType))
     (BroadcastShapesF
        inputShape
        (EmbeddingF ('Shape '[posEncDim, inputEmbedDim]) posShape))
-&gt; Generator generatorDevice
-&gt; m (layerNormOutput, Generator generatorDevice)
forall model input (generatorDevice :: Device (DeviceType Nat))
       output (generatorOutputDevice :: Device (DeviceType Nat))
       (m :: * -&gt; *).
(HasForward
   model input generatorDevice output generatorOutputDevice,
 MonadThrow m) =&gt;
model
-&gt; input
-&gt; Generator generatorDevice
-&gt; m (output, Generator generatorOutputDevice)
</span><a href="Torch.GraduallyTyped.NN.Class.html#forward"><span class="hs-identifier hs-var">forward</span></a></span><span> </span><span class="annot"><span class="annottext">LayerNorm
  'WithBias gradient device dataType ('Shape '[inputEmbedDim])
TEEmbedLayerNormF 'RoBERTa gradient device dataType inputEmbedDim
</span><a href="#local-6989586621679808436"><span class="hs-identifier hs-var">teEmbedLayerNorm</span></a></span><span>
</span><span id="line-861"></span><span>            </span><span class="annot"><span class="annottext">IxStateT
  m
  (Generator generatorDevice)
  (Generator generatorDevice)
  layerNormOutput
-&gt; (layerNormOutput
    -&gt; IxStateT
         m
         (Generator generatorDevice)
         (Generator dropoutGeneratorOutputDevice)
         dropoutOutput)
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator dropoutGeneratorOutputDevice)
     dropoutOutput
forall k1 (m :: k1 -&gt; k1 -&gt; * -&gt; *) (i :: k1) (j :: k1) a
       (k2 :: k1) b.
IxMonad m =&gt;
m i j a -&gt; (a -&gt; m j k2 b) -&gt; m i k2 b
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&gt;&gt;&gt;=</span></a></span><span> </span><span class="annot"><span class="annottext">(Generator generatorDevice
 -&gt; m (dropoutOutput, Generator dropoutGeneratorOutputDevice))
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator dropoutGeneratorOutputDevice)
     dropoutOutput
forall (m :: * -&gt; *) i j a. (i -&gt; m (a, j)) -&gt; IxStateT m i j a
</span><a href="../file:///nix/store/8vjaffqxij7bih93d9mlzmc7ksanlw0i-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier hs-var">IxStateT</span></a></span><span> </span><span class="annot"><span class="annottext">((Generator generatorDevice
  -&gt; m (dropoutOutput, Generator dropoutGeneratorOutputDevice))
 -&gt; IxStateT
      m
      (Generator generatorDevice)
      (Generator dropoutGeneratorOutputDevice)
      dropoutOutput)
-&gt; (layerNormOutput
    -&gt; Generator generatorDevice
    -&gt; m (dropoutOutput, Generator dropoutGeneratorOutputDevice))
-&gt; layerNormOutput
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator dropoutGeneratorOutputDevice)
     dropoutOutput
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">Dropout
-&gt; layerNormOutput
-&gt; Generator generatorDevice
-&gt; m (dropoutOutput, Generator dropoutGeneratorOutputDevice)
forall model input (generatorDevice :: Device (DeviceType Nat))
       output (generatorOutputDevice :: Device (DeviceType Nat))
       (m :: * -&gt; *).
(HasForward
   model input generatorDevice output generatorOutputDevice,
 MonadThrow m) =&gt;
model
-&gt; input
-&gt; Generator generatorDevice
-&gt; m (output, Generator generatorOutputDevice)
</span><a href="Torch.GraduallyTyped.NN.Class.html#forward"><span class="hs-identifier hs-var">forward</span></a></span><span> </span><span class="annot"><span class="annottext">Dropout
TEDropoutF 'RoBERTa
</span><a href="#local-6989586621679808434"><span class="hs-identifier hs-var">teDropout</span></a></span><span>
</span><span id="line-862"></span><span>            </span><span class="annot"><span class="annottext">IxStateT
  m
  (Generator generatorDevice)
  (Generator dropoutGeneratorOutputDevice)
  dropoutOutput
-&gt; (dropoutOutput
    -&gt; IxStateT
         m
         (Generator dropoutGeneratorOutputDevice)
         (Generator generatorOutputDevice)
         output)
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator generatorOutputDevice)
     output
forall k1 (m :: k1 -&gt; k1 -&gt; * -&gt; *) (i :: k1) (j :: k1) a
       (k2 :: k1) b.
IxMonad m =&gt;
m i j a -&gt; (a -&gt; m j k2 b) -&gt; m i k2 b
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&gt;&gt;&gt;=</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">\</span><span id="local-6989586621679808428"><span class="annot"><span class="annottext">dropoutOutput
</span><a href="#local-6989586621679808428"><span class="hs-identifier hs-var">input'</span></a></span></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><span class="annottext">(Generator dropoutGeneratorOutputDevice
 -&gt; m (output, Generator generatorOutputDevice))
-&gt; IxStateT
     m
     (Generator dropoutGeneratorOutputDevice)
     (Generator generatorOutputDevice)
     output
forall (m :: * -&gt; *) i j a. (i -&gt; m (a, j)) -&gt; IxStateT m i j a
</span><a href="../file:///nix/store/8vjaffqxij7bih93d9mlzmc7ksanlw0i-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier hs-var">IxStateT</span></a></span><span> </span><span class="annot"><span class="annottext">((Generator dropoutGeneratorOutputDevice
  -&gt; m (output, Generator generatorOutputDevice))
 -&gt; IxStateT
      m
      (Generator dropoutGeneratorOutputDevice)
      (Generator generatorOutputDevice)
      output)
-&gt; (Generator dropoutGeneratorOutputDevice
    -&gt; m (output, Generator generatorOutputDevice))
-&gt; IxStateT
     m
     (Generator dropoutGeneratorOutputDevice)
     (Generator generatorOutputDevice)
     output
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">TransformerStack
  'RoBERTa
  numLayers
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  inputEmbedDim
  ffnDim
-&gt; (dropoutOutput,
    Tensor
      attentionMaskGradient
      attentionMaskLayout
      attentionMaskDevice
      attentionMaskDataType
      (UnsqueezeF ('SelectDim ('ByIndex 1)) attentionMaskShape))
-&gt; Generator dropoutGeneratorOutputDevice
-&gt; m (output, Generator generatorOutputDevice)
forall model input (generatorDevice :: Device (DeviceType Nat))
       output (generatorOutputDevice :: Device (DeviceType Nat))
       (m :: * -&gt; *).
(HasForward
   model input generatorDevice output generatorOutputDevice,
 MonadThrow m) =&gt;
model
-&gt; input
-&gt; Generator generatorDevice
-&gt; m (output, Generator generatorOutputDevice)
</span><a href="Torch.GraduallyTyped.NN.Class.html#forward"><span class="hs-identifier hs-var">forward</span></a></span><span> </span><span class="annot"><span class="annottext">TransformerStack
  'RoBERTa
  numLayers
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  inputEmbedDim
  ffnDim
TEStackF
  'RoBERTa
  numLayers
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  inputEmbedDim
  ffnDim
</span><a href="#local-6989586621679808437"><span class="hs-identifier hs-var">teStack</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">dropoutOutput
</span><a href="#local-6989586621679808428"><span class="hs-identifier hs-var">input'</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">Tensor
  attentionMaskGradient
  attentionMaskLayout
  attentionMaskDevice
  attentionMaskDataType
  (UnsqueezeF ('SelectDim ('ByIndex 1)) attentionMaskShape)
</span><a href="#local-6989586621679808429"><span class="hs-identifier hs-var">attentionBias</span></a></span><span class="hs-special">)</span><span class="hs-special">)</span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span><span>
</span><span id="line-863"></span><span>
</span><span id="line-864"></span><span class="hs-comment">-- | 'HasForward' instance for @TransformerEncoder numLayers 'Pegasus@.</span><span>
</span><span id="line-865"></span><span class="hs-comment">--</span><span>
</span><span id="line-866"></span><span class="hs-comment">-- @</span><span>
</span><span id="line-867"></span><span class="hs-comment">-- &#9484;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9488;  &#9484;&#9472;&#9472;&#9472;&#9472;&#9472;&#9488;  &#9484;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9488;</span><span>
</span><span id="line-868"></span><span class="hs-comment">-- &#9474; input &#9474;  &#9474; pos &#9474;  &#9474; attentionMask &#9474;</span><span>
</span><span id="line-869"></span><span class="hs-comment">-- &#9492;&#9472;&#9472;&#9472;&#9516;&#9472;&#9472;&#9472;&#9496;  &#9492;&#9472;&#9472;&#9472;&#9472;&#9472;&#9496;  &#9492;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9516;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9496;</span><span>
</span><span id="line-870"></span><span class="hs-comment">--     &#9474;         &#9474;             &#9474;</span><span>
</span><span id="line-871"></span><span class="hs-comment">--     &#9474;         &#9660;             &#9474;</span><span>
</span><span id="line-872"></span><span class="hs-comment">--     &#9474;     tePosEnc          &#9474;</span><span>
</span><span id="line-873"></span><span class="hs-comment">--     &#9474;         &#9474;             &#9474;</span><span>
</span><span id="line-874"></span><span class="hs-comment">--     &#9492;&#9472;&#9472;&#9658;add&#9668;&#9472;&#9472;&#9496;             &#9474;</span><span>
</span><span id="line-875"></span><span class="hs-comment">--          &#9474;                  &#9474;</span><span>
</span><span id="line-876"></span><span class="hs-comment">--          &#9660;                  &#9660;</span><span>
</span><span id="line-877"></span><span class="hs-comment">--      teDropout          unsqueeze</span><span>
</span><span id="line-878"></span><span class="hs-comment">--          &#9660;                  &#9474;</span><span>
</span><span id="line-879"></span><span class="hs-comment">--       teStack&#9668;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9496;</span><span>
</span><span id="line-880"></span><span class="hs-comment">--          &#9660;</span><span>
</span><span id="line-881"></span><span class="hs-comment">--     teLayerNorm</span><span>
</span><span id="line-882"></span><span class="hs-comment">--          &#9474;</span><span>
</span><span id="line-883"></span><span class="hs-comment">--          &#9660;</span><span>
</span><span id="line-884"></span><span class="hs-comment">--     &#9484;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9488;</span><span>
</span><span id="line-885"></span><span class="hs-comment">--     &#9474; output &#9474;</span><span>
</span><span id="line-886"></span><span class="hs-comment">--     &#9492;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9496;</span><span>
</span><span id="line-887"></span><span class="hs-comment">-- @</span><span>
</span><span id="line-888"></span><span id="local-6989586621679808397"><span id="local-6989586621679808398"><span id="local-6989586621679808399"><span id="local-6989586621679808400"><span id="local-6989586621679808401"><span id="local-6989586621679808402"><span id="local-6989586621679808403"><span id="local-6989586621679808404"><span id="local-6989586621679808405"><span id="local-6989586621679808406"><span id="local-6989586621679808407"><span id="local-6989586621679808408"><span id="local-6989586621679808409"><span id="local-6989586621679808410"><span id="local-6989586621679808411"><span id="local-6989586621679808412"><span id="local-6989586621679808413"><span id="local-6989586621679808414"><span id="local-6989586621679808415"><span id="local-6989586621679808416"><span id="local-6989586621679808417"><span id="local-6989586621679808418"><span id="local-6989586621679808419"><span id="local-6989586621679808420"><span id="local-6989586621679808421"><span id="local-6989586621679808422"><span id="local-6989586621679808423"><span id="local-6989586621679808424"><span id="local-6989586621679808425"><span id="local-6989586621679808426"><span id="local-6989586621679808427"><span class="hs-keyword">instance</span><span>
</span><span id="line-889"></span><span>  </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasForward"><span class="hs-identifier hs-type">HasForward</span></a></span><span>
</span><span id="line-890"></span><span>      </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Encoder.html#TEDropoutF"><span class="hs-identifier hs-type">TEDropoutF</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#Pegasus"><span class="hs-identifier hs-type">Pegasus</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-891"></span><span>      </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span>
</span><span id="line-892"></span><span>          </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679808427"><span class="hs-identifier hs-type">inputGradient</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%7C%3E"><span class="hs-operator hs-type">&lt;|&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808426"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%7C%3E"><span class="hs-operator hs-type">&lt;|&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808425"><span class="hs-identifier hs-type">posGradient</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-893"></span><span>          </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679808424"><span class="hs-identifier hs-type">inputLayout</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#Layout"><span class="hs-identifier hs-type">Layout</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#Dense"><span class="hs-identifier hs-type">Dense</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808423"><span class="hs-identifier hs-type">posLayout</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-894"></span><span>          </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679808422"><span class="hs-identifier hs-type">inputDevice</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808421"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808420"><span class="hs-identifier hs-type">posDevice</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-895"></span><span>          </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679808419"><span class="hs-identifier hs-type">inputDataType</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Prelude.html#Seq"><span class="hs-identifier hs-type">Seq</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679808418"><span class="hs-identifier hs-type">posDataType</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#DataType"><span class="hs-identifier hs-type">DataType</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#Int64"><span class="hs-identifier hs-type">Int64</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679808417"><span class="hs-identifier hs-type">dataType</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-896"></span><span>          </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Class.html#BroadcastShapesF"><span class="hs-identifier hs-type">BroadcastShapesF</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808416"><span class="hs-identifier hs-type">inputShape</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Functional.Sparse.html#EmbeddingF"><span class="hs-identifier hs-type">EmbeddingF</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Shape"><span class="hs-identifier hs-type">Shape</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="annot"><a href="#local-6989586621679808415"><span class="hs-identifier hs-type">posEncDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679808414"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span><span class="hs-special">]</span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679808413"><span class="hs-identifier hs-type">posShape</span></a></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-897"></span><span>      </span><span class="hs-special">)</span><span>
</span><span id="line-898"></span><span>      </span><span class="annot"><a href="#local-6989586621679808412"><span class="hs-identifier hs-type">generatorDevice</span></a></span><span>
</span><span id="line-899"></span><span>      </span><span class="annot"><a href="#local-6989586621679808411"><span class="hs-identifier hs-type">dropoutOutput</span></a></span><span>
</span><span id="line-900"></span><span>      </span><span class="annot"><a href="#local-6989586621679808410"><span class="hs-identifier hs-type">dropoutGeneratorOutputDevice</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-901"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasForward"><span class="hs-identifier hs-type">HasForward</span></a></span><span>
</span><span id="line-902"></span><span>      </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Encoder.html#TEStackF"><span class="hs-identifier hs-type">TEStackF</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#Pegasus"><span class="hs-identifier hs-type">Pegasus</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808409"><span class="hs-identifier hs-type">numLayers</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808426"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808421"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808417"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808408"><span class="hs-identifier hs-type">headDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808407"><span class="hs-identifier hs-type">headEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808406"><span class="hs-identifier hs-type">embedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808414"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808405"><span class="hs-identifier hs-type">ffnDim</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-903"></span><span>      </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="#local-6989586621679808411"><span class="hs-identifier hs-type">dropoutOutput</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-904"></span><span>        </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span>
</span><span id="line-905"></span><span>          </span><span class="annot"><a href="#local-6989586621679808404"><span class="hs-identifier hs-type">attentionMaskGradient</span></a></span><span>
</span><span id="line-906"></span><span>          </span><span class="annot"><a href="#local-6989586621679808403"><span class="hs-identifier hs-type">attentionMaskLayout</span></a></span><span>
</span><span id="line-907"></span><span>          </span><span class="annot"><a href="#local-6989586621679808402"><span class="hs-identifier hs-type">attentionMaskDevice</span></a></span><span>
</span><span id="line-908"></span><span>          </span><span class="annot"><a href="#local-6989586621679808401"><span class="hs-identifier hs-type">attentionMaskDataType</span></a></span><span>
</span><span id="line-909"></span><span>          </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.IndexingSlicingJoining.html#UnsqueezeF"><span class="hs-identifier hs-type">UnsqueezeF</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SelectDim"><span class="hs-identifier hs-type">SelectDim</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#ByIndex"><span class="hs-identifier hs-type">ByIndex</span></a></span><span> </span><span class="annot"><span class="hs-number">1</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679808400"><span class="hs-identifier hs-type">attentionMaskShape</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-910"></span><span>      </span><span class="hs-special">)</span><span>
</span><span id="line-911"></span><span>      </span><span class="annot"><a href="#local-6989586621679808410"><span class="hs-identifier hs-type">dropoutGeneratorOutputDevice</span></a></span><span>
</span><span id="line-912"></span><span>      </span><span class="annot"><a href="#local-6989586621679808399"><span class="hs-identifier hs-type">stackOutput</span></a></span><span>
</span><span id="line-913"></span><span>      </span><span class="annot"><a href="#local-6989586621679808398"><span class="hs-identifier hs-type">generatorOutputDevice</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-914"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasForward"><span class="hs-identifier hs-type">HasForward</span></a></span><span>
</span><span id="line-915"></span><span>      </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Encoder.html#TELayerNormF"><span class="hs-identifier hs-type">TELayerNormF</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#Pegasus"><span class="hs-identifier hs-type">Pegasus</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808426"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808421"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808417"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808414"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-916"></span><span>      </span><span class="annot"><a href="#local-6989586621679808399"><span class="hs-identifier hs-type">stackOutput</span></a></span><span>
</span><span id="line-917"></span><span>      </span><span class="annot"><a href="#local-6989586621679808398"><span class="hs-identifier hs-type">generatorOutputDevice</span></a></span><span>
</span><span id="line-918"></span><span>      </span><span class="annot"><a href="#local-6989586621679808397"><span class="hs-identifier hs-type">output</span></a></span><span>
</span><span id="line-919"></span><span>      </span><span class="annot"><a href="#local-6989586621679808398"><span class="hs-identifier hs-type">generatorOutputDevice</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-920"></span><span>    </span><span class="annot"><span class="hs-identifier hs-type">Show</span></span><span> </span><span class="annot"><a href="#local-6989586621679808397"><span class="hs-identifier hs-type">output</span></a></span><span>
</span><span id="line-921"></span><span>  </span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-922"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasForward"><span class="hs-identifier hs-type">HasForward</span></a></span><span>
</span><span id="line-923"></span><span>    </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Encoder.html#TransformerEncoder"><span class="hs-identifier hs-type">TransformerEncoder</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#Pegasus"><span class="hs-identifier hs-type">Pegasus</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808409"><span class="hs-identifier hs-type">numLayers</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808426"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808421"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808417"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808408"><span class="hs-identifier hs-type">headDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808407"><span class="hs-identifier hs-type">headEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808406"><span class="hs-identifier hs-type">embedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808414"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808405"><span class="hs-identifier hs-type">ffnDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808415"><span class="hs-identifier hs-type">posEncDim</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-924"></span><span>    </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808427"><span class="hs-identifier hs-type">inputGradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808424"><span class="hs-identifier hs-type">inputLayout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808422"><span class="hs-identifier hs-type">inputDevice</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808419"><span class="hs-identifier hs-type">inputDataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808416"><span class="hs-identifier hs-type">inputShape</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-925"></span><span>      </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808425"><span class="hs-identifier hs-type">posGradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808423"><span class="hs-identifier hs-type">posLayout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808420"><span class="hs-identifier hs-type">posDevice</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808418"><span class="hs-identifier hs-type">posDataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808413"><span class="hs-identifier hs-type">posShape</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-926"></span><span>      </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808404"><span class="hs-identifier hs-type">attentionMaskGradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808403"><span class="hs-identifier hs-type">attentionMaskLayout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808402"><span class="hs-identifier hs-type">attentionMaskDevice</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808401"><span class="hs-identifier hs-type">attentionMaskDataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808400"><span class="hs-identifier hs-type">attentionMaskShape</span></a></span><span>
</span><span id="line-927"></span><span>    </span><span class="hs-special">)</span><span>
</span><span id="line-928"></span><span>    </span><span class="annot"><a href="#local-6989586621679808412"><span class="hs-identifier hs-type">generatorDevice</span></a></span><span>
</span><span id="line-929"></span><span>    </span><span class="annot"><a href="#local-6989586621679808397"><span class="hs-identifier hs-type">output</span></a></span><span>
</span><span id="line-930"></span><span>    </span><span class="annot"><a href="#local-6989586621679808398"><span class="hs-identifier hs-type">generatorOutputDevice</span></a></span><span>
</span><span id="line-931"></span><span>  </span><span class="hs-keyword">where</span><span>
</span><span id="line-932"></span><span>  </span><span id="local-6989586621679808395"><span class="annot"><span class="annottext">forward :: TransformerEncoder
  'Pegasus
  numLayers
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  inputEmbedDim
  ffnDim
  posEncDim
-&gt; (Tensor
      inputGradient inputLayout inputDevice inputDataType inputShape,
    Tensor posGradient posLayout posDevice posDataType posShape,
    Tensor
      attentionMaskGradient
      attentionMaskLayout
      attentionMaskDevice
      attentionMaskDataType
      attentionMaskShape)
-&gt; Generator generatorDevice
-&gt; m (output, Generator generatorOutputDevice)
</span><a href="#local-6989586621679808395"><span class="hs-identifier hs-var hs-var hs-var hs-var">forward</span></a></span></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Encoder.html#TransformerEncoder"><span class="hs-identifier hs-type">TransformerEncoder</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Encoder.html#GTransformerEncoder"><span class="hs-identifier hs-type">GTransformerEncoder</span></a></span><span> </span><span class="hs-special">{</span><span id="local-6989586621679808390"><span id="local-6989586621679808391"><span id="local-6989586621679808392"><span id="local-6989586621679808393"><span id="local-6989586621679808394"><span class="annot"><span class="annottext">TEPosEncF
  'Pegasus gradient device dataType headDim inputEmbedDim posEncDim
TEDropoutF 'Pegasus
TELayerNormF 'Pegasus gradient device dataType inputEmbedDim
TEEmbedLayerNormF 'Pegasus gradient device dataType inputEmbedDim
TEStackF
  'Pegasus
  numLayers
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  inputEmbedDim
  ffnDim
tePosEnc :: TEPosEncF
  'Pegasus gradient device dataType headDim inputEmbedDim posEncDim
teDropout :: TEDropoutF 'Pegasus
teLayerNorm :: TELayerNormF 'Pegasus gradient device dataType inputEmbedDim
teEmbedLayerNorm :: TEEmbedLayerNormF 'Pegasus gradient device dataType inputEmbedDim
teStack :: TEStackF
  'Pegasus
  numLayers
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  inputEmbedDim
  ffnDim
tePosEnc :: forall stack embedLayerNorm layerNorm dropout posEnc.
GTransformerEncoder stack embedLayerNorm layerNorm dropout posEnc
-&gt; posEnc
teDropout :: forall stack embedLayerNorm layerNorm dropout posEnc.
GTransformerEncoder stack embedLayerNorm layerNorm dropout posEnc
-&gt; dropout
teLayerNorm :: forall stack embedLayerNorm layerNorm dropout posEnc.
GTransformerEncoder stack embedLayerNorm layerNorm dropout posEnc
-&gt; layerNorm
teEmbedLayerNorm :: forall stack embedLayerNorm layerNorm dropout posEnc.
GTransformerEncoder stack embedLayerNorm layerNorm dropout posEnc
-&gt; embedLayerNorm
teStack :: forall stack embedLayerNorm layerNorm dropout posEnc.
GTransformerEncoder stack embedLayerNorm layerNorm dropout posEnc
-&gt; stack
</span><a href="#local-6989586621679808390"><span class="hs-glyph hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var">..</span></a></span></span></span></span></span></span><span class="hs-special">}</span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span id="local-6989586621679808389"><span class="annot"><span class="annottext">Tensor
  inputGradient inputLayout inputDevice inputDataType inputShape
</span><a href="#local-6989586621679808389"><span class="hs-identifier hs-var">input</span></a></span></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679808388"><span class="annot"><span class="annottext">Tensor posGradient posLayout posDevice posDataType posShape
</span><a href="#local-6989586621679808388"><span class="hs-identifier hs-var">pos</span></a></span></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679808387"><span class="annot"><span class="annottext">Tensor
  attentionMaskGradient
  attentionMaskLayout
  attentionMaskDevice
  attentionMaskDataType
  attentionMaskShape
</span><a href="#local-6989586621679808387"><span class="hs-identifier hs-var">attentionMask</span></a></span></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-933"></span><span>    </span><span class="hs-keyword">let</span><span> </span><span id="local-6989586621679808386"><span class="annot"><span class="annottext">attentionBias :: Tensor
  attentionMaskGradient
  attentionMaskLayout
  attentionMaskDevice
  attentionMaskDataType
  (UnsqueezeF ('SelectDim ('ByIndex 1)) attentionMaskShape)
</span><a href="#local-6989586621679808386"><span class="hs-identifier hs-var hs-var">attentionBias</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Tensor
  attentionMaskGradient
  attentionMaskLayout
  attentionMaskDevice
  attentionMaskDataType
  attentionMaskShape
-&gt; Tensor
     attentionMaskGradient
     attentionMaskLayout
     attentionMaskDevice
     attentionMaskDataType
     (UnsqueezeF ('SelectDim ('ByIndex 1)) attentionMaskShape)
forall (selectDim :: SelectDim (By Symbol Nat))
       (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)])
       (shape' :: Shape [Dim (Name Symbol) (Size Nat)]).
(shape' ~ UnsqueezeF selectDim shape, SingI selectDim) =&gt;
Tensor gradient layout device dataType shape
-&gt; Tensor gradient layout device dataType shape'
</span><a href="Torch.GraduallyTyped.Tensor.IndexingSlicingJoining.html#unsqueeze"><span class="hs-identifier hs-var">unsqueeze</span></a></span><span> </span><span class="hs-glyph">@</span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SelectDim"><span class="hs-identifier hs-type">SelectDim</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#ByIndex"><span class="hs-identifier hs-type">ByIndex</span></a></span><span> </span><span class="annot"><span class="hs-number">1</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">Tensor
  attentionMaskGradient
  attentionMaskLayout
  attentionMaskDevice
  attentionMaskDataType
  attentionMaskShape
</span><a href="#local-6989586621679808387"><span class="hs-identifier hs-var">attentionMask</span></a></span><span>
</span><span id="line-934"></span><span>     </span><span class="hs-keyword">in</span><span> </span><span class="annot"><span class="annottext">IxStateT
  m
  (Generator generatorDevice)
  (Generator generatorOutputDevice)
  output
-&gt; Generator generatorDevice
-&gt; m (output, Generator generatorOutputDevice)
forall (m :: * -&gt; *) i j a. IxStateT m i j a -&gt; i -&gt; m (a, j)
</span><a href="../file:///nix/store/8vjaffqxij7bih93d9mlzmc7ksanlw0i-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier hs-var hs-var">runIxStateT</span></a></span><span> </span><span class="annot"><span class="annottext">(IxStateT
   m
   (Generator generatorDevice)
   (Generator generatorOutputDevice)
   output
 -&gt; Generator generatorDevice
 -&gt; m (output, Generator generatorOutputDevice))
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator generatorOutputDevice)
     output
-&gt; Generator generatorDevice
-&gt; m (output, Generator generatorOutputDevice)
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span>
</span><span id="line-935"></span><span>          </span><span class="annot"><span class="annottext">Tensor posGradient posLayout posDevice posDataType posShape
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator generatorDevice)
     (Tensor posGradient posLayout posDevice posDataType posShape)
forall k (m :: k -&gt; k -&gt; * -&gt; *) a (i :: k).
IxPointed m =&gt;
a -&gt; m i i a
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-identifier hs-var">ireturn</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor posGradient posLayout posDevice posDataType posShape
</span><a href="#local-6989586621679808388"><span class="hs-identifier hs-var">pos</span></a></span><span>
</span><span id="line-936"></span><span>            </span><span class="annot"><span class="annottext">IxStateT
  m
  (Generator generatorDevice)
  (Generator generatorDevice)
  (Tensor posGradient posLayout posDevice posDataType posShape)
-&gt; (Tensor posGradient posLayout posDevice posDataType posShape
    -&gt; IxStateT
         m
         (Generator generatorDevice)
         (Generator generatorDevice)
         (Tensor
            (Or (Gradient RequiresGradient) gradient posGradient)
            (Unify (Layout LayoutType) ('Layout 'Dense) posLayout)
            (Unify (Device (DeviceType Nat)) device posDevice)
            (Seq
               (Unify (DataType DType) posDataType ('DataType 'Int64)) dataType)
            (EmbeddingF ('Shape '[posEncDim, inputEmbedDim]) posShape)))
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator generatorDevice)
     (Tensor
        (Or (Gradient RequiresGradient) gradient posGradient)
        (Unify (Layout LayoutType) ('Layout 'Dense) posLayout)
        (Unify (Device (DeviceType Nat)) device posDevice)
        (Seq
           (Unify (DataType DType) posDataType ('DataType 'Int64)) dataType)
        (EmbeddingF ('Shape '[posEncDim, inputEmbedDim]) posShape))
forall k1 (m :: k1 -&gt; k1 -&gt; * -&gt; *) (i :: k1) (j :: k1) a
       (k2 :: k1) b.
IxMonad m =&gt;
m i j a -&gt; (a -&gt; m j k2 b) -&gt; m i k2 b
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&gt;&gt;&gt;=</span></a></span><span> </span><span class="annot"><span class="annottext">(Generator generatorDevice
 -&gt; m (Tensor
         (Or (Gradient RequiresGradient) gradient posGradient)
         (Unify (Layout LayoutType) ('Layout 'Dense) posLayout)
         (Unify (Device (DeviceType Nat)) device posDevice)
         (Seq
            (Unify (DataType DType) posDataType ('DataType 'Int64)) dataType)
         (EmbeddingF ('Shape '[posEncDim, inputEmbedDim]) posShape),
       Generator generatorDevice))
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator generatorDevice)
     (Tensor
        (Or (Gradient RequiresGradient) gradient posGradient)
        (Unify (Layout LayoutType) ('Layout 'Dense) posLayout)
        (Unify (Device (DeviceType Nat)) device posDevice)
        (Seq
           (Unify (DataType DType) posDataType ('DataType 'Int64)) dataType)
        (EmbeddingF ('Shape '[posEncDim, inputEmbedDim]) posShape))
forall (m :: * -&gt; *) i j a. (i -&gt; m (a, j)) -&gt; IxStateT m i j a
</span><a href="../file:///nix/store/8vjaffqxij7bih93d9mlzmc7ksanlw0i-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier hs-var">IxStateT</span></a></span><span> </span><span class="annot"><span class="annottext">((Generator generatorDevice
  -&gt; m (Tensor
          (Or (Gradient RequiresGradient) gradient posGradient)
          (Unify (Layout LayoutType) ('Layout 'Dense) posLayout)
          (Unify (Device (DeviceType Nat)) device posDevice)
          (Seq
             (Unify (DataType DType) posDataType ('DataType 'Int64)) dataType)
          (EmbeddingF ('Shape '[posEncDim, inputEmbedDim]) posShape),
        Generator generatorDevice))
 -&gt; IxStateT
      m
      (Generator generatorDevice)
      (Generator generatorDevice)
      (Tensor
         (Or (Gradient RequiresGradient) gradient posGradient)
         (Unify (Layout LayoutType) ('Layout 'Dense) posLayout)
         (Unify (Device (DeviceType Nat)) device posDevice)
         (Seq
            (Unify (DataType DType) posDataType ('DataType 'Int64)) dataType)
         (EmbeddingF ('Shape '[posEncDim, inputEmbedDim]) posShape)))
-&gt; (Tensor posGradient posLayout posDevice posDataType posShape
    -&gt; Generator generatorDevice
    -&gt; m (Tensor
            (Or (Gradient RequiresGradient) gradient posGradient)
            (Unify (Layout LayoutType) ('Layout 'Dense) posLayout)
            (Unify (Device (DeviceType Nat)) device posDevice)
            (Seq
               (Unify (DataType DType) posDataType ('DataType 'Int64)) dataType)
            (EmbeddingF ('Shape '[posEncDim, inputEmbedDim]) posShape),
          Generator generatorDevice))
-&gt; Tensor posGradient posLayout posDevice posDataType posShape
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator generatorDevice)
     (Tensor
        (Or (Gradient RequiresGradient) gradient posGradient)
        (Unify (Layout LayoutType) ('Layout 'Dense) posLayout)
        (Unify (Device (DeviceType Nat)) device posDevice)
        (Seq
           (Unify (DataType DType) posDataType ('DataType 'Int64)) dataType)
        (EmbeddingF ('Shape '[posEncDim, inputEmbedDim]) posShape))
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">Embedding
  gradient
  ('Layout 'Dense)
  device
  dataType
  posEncDim
  inputEmbedDim
  'Nothing
-&gt; Tensor posGradient posLayout posDevice posDataType posShape
-&gt; Generator generatorDevice
-&gt; m (Tensor
        (Or (Gradient RequiresGradient) gradient posGradient)
        (Unify (Layout LayoutType) ('Layout 'Dense) posLayout)
        (Unify (Device (DeviceType Nat)) device posDevice)
        (Seq
           (Unify (DataType DType) posDataType ('DataType 'Int64)) dataType)
        (EmbeddingF ('Shape '[posEncDim, inputEmbedDim]) posShape),
      Generator generatorDevice)
forall model input (generatorDevice :: Device (DeviceType Nat))
       output (generatorOutputDevice :: Device (DeviceType Nat))
       (m :: * -&gt; *).
(HasForward
   model input generatorDevice output generatorOutputDevice,
 MonadThrow m) =&gt;
model
-&gt; input
-&gt; Generator generatorDevice
-&gt; m (output, Generator generatorOutputDevice)
</span><a href="Torch.GraduallyTyped.NN.Class.html#forward"><span class="hs-identifier hs-var">forward</span></a></span><span> </span><span class="annot"><span class="annottext">Embedding
  gradient
  ('Layout 'Dense)
  device
  dataType
  posEncDim
  inputEmbedDim
  'Nothing
TEPosEncF
  'Pegasus gradient device dataType headDim inputEmbedDim posEncDim
</span><a href="#local-6989586621679808390"><span class="hs-identifier hs-var">tePosEnc</span></a></span><span>
</span><span id="line-937"></span><span>            </span><span class="annot"><span class="annottext">IxStateT
  m
  (Generator generatorDevice)
  (Generator generatorDevice)
  (Tensor
     (Or (Gradient RequiresGradient) gradient posGradient)
     (Unify (Layout LayoutType) ('Layout 'Dense) posLayout)
     (Unify (Device (DeviceType Nat)) device posDevice)
     (Seq
        (Unify (DataType DType) posDataType ('DataType 'Int64)) dataType)
     (EmbeddingF ('Shape '[posEncDim, inputEmbedDim]) posShape))
-&gt; (Tensor
      (Or (Gradient RequiresGradient) gradient posGradient)
      (Unify (Layout LayoutType) ('Layout 'Dense) posLayout)
      (Unify (Device (DeviceType Nat)) device posDevice)
      (Seq
         (Unify (DataType DType) posDataType ('DataType 'Int64)) dataType)
      (EmbeddingF ('Shape '[posEncDim, inputEmbedDim]) posShape)
    -&gt; IxStateT
         m
         (Generator generatorDevice)
         (Generator generatorDevice)
         (Tensor
            (Or
               (Gradient RequiresGradient)
               inputGradient
               (Or (Gradient RequiresGradient) gradient posGradient))
            (Unify
               (Layout LayoutType)
               inputLayout
               (Unify (Layout LayoutType) ('Layout 'Dense) posLayout))
            (Unify
               (Device (DeviceType Nat))
               inputDevice
               (Unify (Device (DeviceType Nat)) device posDevice))
            (Unify
               (DataType DType)
               inputDataType
               (Seq
                  (Unify (DataType DType) posDataType ('DataType 'Int64)) dataType))
            (BroadcastShapesF
               inputShape
               (EmbeddingF ('Shape '[posEncDim, inputEmbedDim]) posShape))))
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator generatorDevice)
     (Tensor
        (Or
           (Gradient RequiresGradient)
           inputGradient
           (Or (Gradient RequiresGradient) gradient posGradient))
        (Unify
           (Layout LayoutType)
           inputLayout
           (Unify (Layout LayoutType) ('Layout 'Dense) posLayout))
        (Unify
           (Device (DeviceType Nat))
           inputDevice
           (Unify (Device (DeviceType Nat)) device posDevice))
        (Unify
           (DataType DType)
           inputDataType
           (Seq
              (Unify (DataType DType) posDataType ('DataType 'Int64)) dataType))
        (BroadcastShapesF
           inputShape
           (EmbeddingF ('Shape '[posEncDim, inputEmbedDim]) posShape)))
forall k1 (m :: k1 -&gt; k1 -&gt; * -&gt; *) (i :: k1) (j :: k1) a
       (k2 :: k1) b.
IxMonad m =&gt;
m i j a -&gt; (a -&gt; m j k2 b) -&gt; m i k2 b
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&gt;&gt;&gt;=</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor
  (Or
     (Gradient RequiresGradient)
     inputGradient
     (Or (Gradient RequiresGradient) gradient posGradient))
  (Unify
     (Layout LayoutType)
     inputLayout
     (Unify (Layout LayoutType) ('Layout 'Dense) posLayout))
  (Unify
     (Device (DeviceType Nat))
     inputDevice
     (Unify (Device (DeviceType Nat)) device posDevice))
  (Unify
     (DataType DType)
     inputDataType
     (Seq
        (Unify (DataType DType) posDataType ('DataType 'Int64)) dataType))
  (BroadcastShapesF
     inputShape
     (EmbeddingF ('Shape '[posEncDim, inputEmbedDim]) posShape))
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator generatorDevice)
     (Tensor
        (Or
           (Gradient RequiresGradient)
           inputGradient
           (Or (Gradient RequiresGradient) gradient posGradient))
        (Unify
           (Layout LayoutType)
           inputLayout
           (Unify (Layout LayoutType) ('Layout 'Dense) posLayout))
        (Unify
           (Device (DeviceType Nat))
           inputDevice
           (Unify (Device (DeviceType Nat)) device posDevice))
        (Unify
           (DataType DType)
           inputDataType
           (Seq
              (Unify (DataType DType) posDataType ('DataType 'Int64)) dataType))
        (BroadcastShapesF
           inputShape
           (EmbeddingF ('Shape '[posEncDim, inputEmbedDim]) posShape)))
forall k (m :: k -&gt; k -&gt; * -&gt; *) a (i :: k).
IxPointed m =&gt;
a -&gt; m i i a
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-identifier hs-var">ireturn</span></a></span><span> </span><span class="annot"><span class="annottext">(Tensor
   (Or
      (Gradient RequiresGradient)
      inputGradient
      (Or (Gradient RequiresGradient) gradient posGradient))
   (Unify
      (Layout LayoutType)
      inputLayout
      (Unify (Layout LayoutType) ('Layout 'Dense) posLayout))
   (Unify
      (Device (DeviceType Nat))
      inputDevice
      (Unify (Device (DeviceType Nat)) device posDevice))
   (Unify
      (DataType DType)
      inputDataType
      (Seq
         (Unify (DataType DType) posDataType ('DataType 'Int64)) dataType))
   (BroadcastShapesF
      inputShape
      (EmbeddingF ('Shape '[posEncDim, inputEmbedDim]) posShape))
 -&gt; IxStateT
      m
      (Generator generatorDevice)
      (Generator generatorDevice)
      (Tensor
         (Or
            (Gradient RequiresGradient)
            inputGradient
            (Or (Gradient RequiresGradient) gradient posGradient))
         (Unify
            (Layout LayoutType)
            inputLayout
            (Unify (Layout LayoutType) ('Layout 'Dense) posLayout))
         (Unify
            (Device (DeviceType Nat))
            inputDevice
            (Unify (Device (DeviceType Nat)) device posDevice))
         (Unify
            (DataType DType)
            inputDataType
            (Seq
               (Unify (DataType DType) posDataType ('DataType 'Int64)) dataType))
         (BroadcastShapesF
            inputShape
            (EmbeddingF ('Shape '[posEncDim, inputEmbedDim]) posShape))))
-&gt; (Tensor
      (Or (Gradient RequiresGradient) gradient posGradient)
      (Unify (Layout LayoutType) ('Layout 'Dense) posLayout)
      (Unify (Device (DeviceType Nat)) device posDevice)
      (Seq
         (Unify (DataType DType) posDataType ('DataType 'Int64)) dataType)
      (EmbeddingF ('Shape '[posEncDim, inputEmbedDim]) posShape)
    -&gt; Tensor
         (Or
            (Gradient RequiresGradient)
            inputGradient
            (Or (Gradient RequiresGradient) gradient posGradient))
         (Unify
            (Layout LayoutType)
            inputLayout
            (Unify (Layout LayoutType) ('Layout 'Dense) posLayout))
         (Unify
            (Device (DeviceType Nat))
            inputDevice
            (Unify (Device (DeviceType Nat)) device posDevice))
         (Unify
            (DataType DType)
            inputDataType
            (Seq
               (Unify (DataType DType) posDataType ('DataType 'Int64)) dataType))
         (BroadcastShapesF
            inputShape
            (EmbeddingF ('Shape '[posEncDim, inputEmbedDim]) posShape)))
-&gt; Tensor
     (Or (Gradient RequiresGradient) gradient posGradient)
     (Unify (Layout LayoutType) ('Layout 'Dense) posLayout)
     (Unify (Device (DeviceType Nat)) device posDevice)
     (Seq
        (Unify (DataType DType) posDataType ('DataType 'Int64)) dataType)
     (EmbeddingF ('Shape '[posEncDim, inputEmbedDim]) posShape)
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator generatorDevice)
     (Tensor
        (Or
           (Gradient RequiresGradient)
           inputGradient
           (Or (Gradient RequiresGradient) gradient posGradient))
        (Unify
           (Layout LayoutType)
           inputLayout
           (Unify (Layout LayoutType) ('Layout 'Dense) posLayout))
        (Unify
           (Device (DeviceType Nat))
           inputDevice
           (Unify (Device (DeviceType Nat)) device posDevice))
        (Unify
           (DataType DType)
           inputDataType
           (Seq
              (Unify (DataType DType) posDataType ('DataType 'Int64)) dataType))
        (BroadcastShapesF
           inputShape
           (EmbeddingF ('Shape '[posEncDim, inputEmbedDim]) posShape)))
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">Tensor
  inputGradient inputLayout inputDevice inputDataType inputShape
</span><a href="#local-6989586621679808389"><span class="hs-identifier hs-var">input</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor
  inputGradient inputLayout inputDevice inputDataType inputShape
-&gt; Tensor
     (Or (Gradient RequiresGradient) gradient posGradient)
     (Unify (Layout LayoutType) ('Layout 'Dense) posLayout)
     (Unify (Device (DeviceType Nat)) device posDevice)
     (Seq
        (Unify (DataType DType) posDataType ('DataType 'Int64)) dataType)
     (EmbeddingF ('Shape '[posEncDim, inputEmbedDim]) posShape)
-&gt; Tensor
     (inputGradient
      &lt;|&gt; Or (Gradient RequiresGradient) gradient posGradient)
     (inputLayout
      &lt;+&gt; Unify (Layout LayoutType) ('Layout 'Dense) posLayout)
     (inputDevice &lt;+&gt; Unify (Device (DeviceType Nat)) device posDevice)
     (inputDataType
      &lt;+&gt; Seq
            (Unify (DataType DType) posDataType ('DataType 'Int64)) dataType)
     (BroadcastShapesF
        inputShape
        (EmbeddingF ('Shape '[posEncDim, inputEmbedDim]) posShape))
forall (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)])
       (gradient' :: Gradient RequiresGradient)
       (layout' :: Layout LayoutType) (device' :: Device (DeviceType Nat))
       (dataType' :: DataType DType)
       (shape' :: Shape [Dim (Name Symbol) (Size Nat)]).
Tensor gradient layout device dataType shape
-&gt; Tensor gradient' layout' device' dataType' shape'
-&gt; Tensor
     (gradient &lt;|&gt; gradient')
     (layout &lt;+&gt; layout')
     (device &lt;+&gt; device')
     (dataType &lt;+&gt; dataType')
     (BroadcastShapesF shape shape')
</span><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#add"><span class="hs-operator hs-var">`add`</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-938"></span><span>            </span><span class="annot"><span class="annottext">IxStateT
  m
  (Generator generatorDevice)
  (Generator generatorDevice)
  (Tensor
     (Or
        (Gradient RequiresGradient)
        inputGradient
        (Or (Gradient RequiresGradient) gradient posGradient))
     (Unify
        (Layout LayoutType)
        inputLayout
        (Unify (Layout LayoutType) ('Layout 'Dense) posLayout))
     (Unify
        (Device (DeviceType Nat))
        inputDevice
        (Unify (Device (DeviceType Nat)) device posDevice))
     (Unify
        (DataType DType)
        inputDataType
        (Seq
           (Unify (DataType DType) posDataType ('DataType 'Int64)) dataType))
     (BroadcastShapesF
        inputShape
        (EmbeddingF ('Shape '[posEncDim, inputEmbedDim]) posShape)))
-&gt; (Tensor
      (Or
         (Gradient RequiresGradient)
         inputGradient
         (Or (Gradient RequiresGradient) gradient posGradient))
      (Unify
         (Layout LayoutType)
         inputLayout
         (Unify (Layout LayoutType) ('Layout 'Dense) posLayout))
      (Unify
         (Device (DeviceType Nat))
         inputDevice
         (Unify (Device (DeviceType Nat)) device posDevice))
      (Unify
         (DataType DType)
         inputDataType
         (Seq
            (Unify (DataType DType) posDataType ('DataType 'Int64)) dataType))
      (BroadcastShapesF
         inputShape
         (EmbeddingF ('Shape '[posEncDim, inputEmbedDim]) posShape))
    -&gt; IxStateT
         m
         (Generator generatorDevice)
         (Generator dropoutGeneratorOutputDevice)
         dropoutOutput)
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator dropoutGeneratorOutputDevice)
     dropoutOutput
forall k1 (m :: k1 -&gt; k1 -&gt; * -&gt; *) (i :: k1) (j :: k1) a
       (k2 :: k1) b.
IxMonad m =&gt;
m i j a -&gt; (a -&gt; m j k2 b) -&gt; m i k2 b
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&gt;&gt;&gt;=</span></a></span><span> </span><span class="annot"><span class="annottext">(Generator generatorDevice
 -&gt; m (dropoutOutput, Generator dropoutGeneratorOutputDevice))
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator dropoutGeneratorOutputDevice)
     dropoutOutput
forall (m :: * -&gt; *) i j a. (i -&gt; m (a, j)) -&gt; IxStateT m i j a
</span><a href="../file:///nix/store/8vjaffqxij7bih93d9mlzmc7ksanlw0i-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier hs-var">IxStateT</span></a></span><span> </span><span class="annot"><span class="annottext">((Generator generatorDevice
  -&gt; m (dropoutOutput, Generator dropoutGeneratorOutputDevice))
 -&gt; IxStateT
      m
      (Generator generatorDevice)
      (Generator dropoutGeneratorOutputDevice)
      dropoutOutput)
-&gt; (Tensor
      (Or
         (Gradient RequiresGradient)
         inputGradient
         (Or (Gradient RequiresGradient) gradient posGradient))
      (Unify
         (Layout LayoutType)
         inputLayout
         (Unify (Layout LayoutType) ('Layout 'Dense) posLayout))
      (Unify
         (Device (DeviceType Nat))
         inputDevice
         (Unify (Device (DeviceType Nat)) device posDevice))
      (Unify
         (DataType DType)
         inputDataType
         (Seq
            (Unify (DataType DType) posDataType ('DataType 'Int64)) dataType))
      (BroadcastShapesF
         inputShape
         (EmbeddingF ('Shape '[posEncDim, inputEmbedDim]) posShape))
    -&gt; Generator generatorDevice
    -&gt; m (dropoutOutput, Generator dropoutGeneratorOutputDevice))
-&gt; Tensor
     (Or
        (Gradient RequiresGradient)
        inputGradient
        (Or (Gradient RequiresGradient) gradient posGradient))
     (Unify
        (Layout LayoutType)
        inputLayout
        (Unify (Layout LayoutType) ('Layout 'Dense) posLayout))
     (Unify
        (Device (DeviceType Nat))
        inputDevice
        (Unify (Device (DeviceType Nat)) device posDevice))
     (Unify
        (DataType DType)
        inputDataType
        (Seq
           (Unify (DataType DType) posDataType ('DataType 'Int64)) dataType))
     (BroadcastShapesF
        inputShape
        (EmbeddingF ('Shape '[posEncDim, inputEmbedDim]) posShape))
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator dropoutGeneratorOutputDevice)
     dropoutOutput
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">Dropout
-&gt; Tensor
     (Or
        (Gradient RequiresGradient)
        inputGradient
        (Or (Gradient RequiresGradient) gradient posGradient))
     (Unify
        (Layout LayoutType)
        inputLayout
        (Unify (Layout LayoutType) ('Layout 'Dense) posLayout))
     (Unify
        (Device (DeviceType Nat))
        inputDevice
        (Unify (Device (DeviceType Nat)) device posDevice))
     (Unify
        (DataType DType)
        inputDataType
        (Seq
           (Unify (DataType DType) posDataType ('DataType 'Int64)) dataType))
     (BroadcastShapesF
        inputShape
        (EmbeddingF ('Shape '[posEncDim, inputEmbedDim]) posShape))
-&gt; Generator generatorDevice
-&gt; m (dropoutOutput, Generator dropoutGeneratorOutputDevice)
forall model input (generatorDevice :: Device (DeviceType Nat))
       output (generatorOutputDevice :: Device (DeviceType Nat))
       (m :: * -&gt; *).
(HasForward
   model input generatorDevice output generatorOutputDevice,
 MonadThrow m) =&gt;
model
-&gt; input
-&gt; Generator generatorDevice
-&gt; m (output, Generator generatorOutputDevice)
</span><a href="Torch.GraduallyTyped.NN.Class.html#forward"><span class="hs-identifier hs-var">forward</span></a></span><span> </span><span class="annot"><span class="annottext">Dropout
TEDropoutF 'Pegasus
</span><a href="#local-6989586621679808391"><span class="hs-identifier hs-var">teDropout</span></a></span><span>
</span><span id="line-939"></span><span>            </span><span class="annot"><span class="annottext">IxStateT
  m
  (Generator generatorDevice)
  (Generator dropoutGeneratorOutputDevice)
  dropoutOutput
-&gt; (dropoutOutput
    -&gt; IxStateT
         m
         (Generator dropoutGeneratorOutputDevice)
         (Generator generatorOutputDevice)
         stackOutput)
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator generatorOutputDevice)
     stackOutput
forall k1 (m :: k1 -&gt; k1 -&gt; * -&gt; *) (i :: k1) (j :: k1) a
       (k2 :: k1) b.
IxMonad m =&gt;
m i j a -&gt; (a -&gt; m j k2 b) -&gt; m i k2 b
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&gt;&gt;&gt;=</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">\</span><span id="local-6989586621679808385"><span class="annot"><span class="annottext">dropoutOutput
</span><a href="#local-6989586621679808385"><span class="hs-identifier hs-var">input'</span></a></span></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><span class="annottext">(Generator dropoutGeneratorOutputDevice
 -&gt; m (stackOutput, Generator generatorOutputDevice))
-&gt; IxStateT
     m
     (Generator dropoutGeneratorOutputDevice)
     (Generator generatorOutputDevice)
     stackOutput
forall (m :: * -&gt; *) i j a. (i -&gt; m (a, j)) -&gt; IxStateT m i j a
</span><a href="../file:///nix/store/8vjaffqxij7bih93d9mlzmc7ksanlw0i-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier hs-var">IxStateT</span></a></span><span> </span><span class="annot"><span class="annottext">((Generator dropoutGeneratorOutputDevice
  -&gt; m (stackOutput, Generator generatorOutputDevice))
 -&gt; IxStateT
      m
      (Generator dropoutGeneratorOutputDevice)
      (Generator generatorOutputDevice)
      stackOutput)
-&gt; (Generator dropoutGeneratorOutputDevice
    -&gt; m (stackOutput, Generator generatorOutputDevice))
-&gt; IxStateT
     m
     (Generator dropoutGeneratorOutputDevice)
     (Generator generatorOutputDevice)
     stackOutput
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">TransformerStack
  'Pegasus
  numLayers
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  inputEmbedDim
  ffnDim
-&gt; (dropoutOutput,
    Tensor
      attentionMaskGradient
      attentionMaskLayout
      attentionMaskDevice
      attentionMaskDataType
      (UnsqueezeF ('SelectDim ('ByIndex 1)) attentionMaskShape))
-&gt; Generator dropoutGeneratorOutputDevice
-&gt; m (stackOutput, Generator generatorOutputDevice)
forall model input (generatorDevice :: Device (DeviceType Nat))
       output (generatorOutputDevice :: Device (DeviceType Nat))
       (m :: * -&gt; *).
(HasForward
   model input generatorDevice output generatorOutputDevice,
 MonadThrow m) =&gt;
model
-&gt; input
-&gt; Generator generatorDevice
-&gt; m (output, Generator generatorOutputDevice)
</span><a href="Torch.GraduallyTyped.NN.Class.html#forward"><span class="hs-identifier hs-var">forward</span></a></span><span> </span><span class="annot"><span class="annottext">TransformerStack
  'Pegasus
  numLayers
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  inputEmbedDim
  ffnDim
TEStackF
  'Pegasus
  numLayers
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  inputEmbedDim
  ffnDim
</span><a href="#local-6989586621679808394"><span class="hs-identifier hs-var">teStack</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">dropoutOutput
</span><a href="#local-6989586621679808385"><span class="hs-identifier hs-var">input'</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">Tensor
  attentionMaskGradient
  attentionMaskLayout
  attentionMaskDevice
  attentionMaskDataType
  (UnsqueezeF ('SelectDim ('ByIndex 1)) attentionMaskShape)
</span><a href="#local-6989586621679808386"><span class="hs-identifier hs-var">attentionBias</span></a></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-940"></span><span>            </span><span class="annot"><span class="annottext">IxStateT
  m
  (Generator generatorDevice)
  (Generator generatorOutputDevice)
  stackOutput
-&gt; (stackOutput
    -&gt; IxStateT
         m
         (Generator generatorOutputDevice)
         (Generator generatorOutputDevice)
         output)
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator generatorOutputDevice)
     output
forall k1 (m :: k1 -&gt; k1 -&gt; * -&gt; *) (i :: k1) (j :: k1) a
       (k2 :: k1) b.
IxMonad m =&gt;
m i j a -&gt; (a -&gt; m j k2 b) -&gt; m i k2 b
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&gt;&gt;&gt;=</span></a></span><span> </span><span class="annot"><span class="annottext">(Generator generatorOutputDevice
 -&gt; m (output, Generator generatorOutputDevice))
-&gt; IxStateT
     m
     (Generator generatorOutputDevice)
     (Generator generatorOutputDevice)
     output
forall (m :: * -&gt; *) i j a. (i -&gt; m (a, j)) -&gt; IxStateT m i j a
</span><a href="../file:///nix/store/8vjaffqxij7bih93d9mlzmc7ksanlw0i-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier hs-var">IxStateT</span></a></span><span> </span><span class="annot"><span class="annottext">((Generator generatorOutputDevice
  -&gt; m (output, Generator generatorOutputDevice))
 -&gt; IxStateT
      m
      (Generator generatorOutputDevice)
      (Generator generatorOutputDevice)
      output)
-&gt; (stackOutput
    -&gt; Generator generatorOutputDevice
    -&gt; m (output, Generator generatorOutputDevice))
-&gt; stackOutput
-&gt; IxStateT
     m
     (Generator generatorOutputDevice)
     (Generator generatorOutputDevice)
     output
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">LayerNorm
  'WithBias gradient device dataType ('Shape '[inputEmbedDim])
-&gt; stackOutput
-&gt; Generator generatorOutputDevice
-&gt; m (output, Generator generatorOutputDevice)
forall model input (generatorDevice :: Device (DeviceType Nat))
       output (generatorOutputDevice :: Device (DeviceType Nat))
       (m :: * -&gt; *).
(HasForward
   model input generatorDevice output generatorOutputDevice,
 MonadThrow m) =&gt;
model
-&gt; input
-&gt; Generator generatorDevice
-&gt; m (output, Generator generatorOutputDevice)
</span><a href="Torch.GraduallyTyped.NN.Class.html#forward"><span class="hs-identifier hs-var">forward</span></a></span><span> </span><span class="annot"><span class="annottext">LayerNorm
  'WithBias gradient device dataType ('Shape '[inputEmbedDim])
TELayerNormF 'Pegasus gradient device dataType inputEmbedDim
</span><a href="#local-6989586621679808392"><span class="hs-identifier hs-var">teLayerNorm</span></a></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span><span>
</span><span id="line-941"></span></pre></body></html>