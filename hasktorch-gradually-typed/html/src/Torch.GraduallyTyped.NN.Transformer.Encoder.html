<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd"><html xmlns="http://www.w3.org/1999/xhtml"><head><link rel="stylesheet" type="text/css" href="style.css" /><script type="text/javascript" src="highlight.js"></script></head><body><pre><span class="hs-pragma">{-# LANGUAGE ConstraintKinds #-}</span><span>
</span><span id="line-2"></span><span class="hs-pragma">{-# LANGUAGE DataKinds #-}</span><span>
</span><span id="line-3"></span><span class="hs-pragma">{-# LANGUAGE FlexibleContexts #-}</span><span>
</span><span id="line-4"></span><span class="hs-pragma">{-# LANGUAGE FlexibleInstances #-}</span><span>
</span><span id="line-5"></span><span class="hs-pragma">{-# LANGUAGE GADTs #-}</span><span>
</span><span id="line-6"></span><span class="hs-pragma">{-# LANGUAGE MultiParamTypeClasses #-}</span><span>
</span><span id="line-7"></span><span class="hs-pragma">{-# LANGUAGE PatternSynonyms #-}</span><span>
</span><span id="line-8"></span><span class="hs-pragma">{-# LANGUAGE RecordWildCards #-}</span><span>
</span><span id="line-9"></span><span class="hs-pragma">{-# LANGUAGE ScopedTypeVariables #-}</span><span>
</span><span id="line-10"></span><span class="hs-pragma">{-# LANGUAGE TypeApplications #-}</span><span>
</span><span id="line-11"></span><span class="hs-pragma">{-# LANGUAGE TypeFamilies #-}</span><span>
</span><span id="line-12"></span><span class="hs-pragma">{-# LANGUAGE TypeOperators #-}</span><span>
</span><span id="line-13"></span><span class="hs-pragma">{-# LANGUAGE UndecidableInstances #-}</span><span>
</span><span id="line-14"></span><span class="hs-pragma">{-# OPTIONS_GHC -fplugin TypeLevel.Rewrite
                -fplugin-opt=TypeLevel.Rewrite:Torch.GraduallyTyped.Unify.UnifyRightAssociativeL
                -fplugin-opt=TypeLevel.Rewrite:Torch.GraduallyTyped.Unify.OrRightAssociativeL #-}</span><span>
</span><span id="line-17"></span><span class="hs-pragma">{-# OPTIONS_GHC -v2 -Wall #-}</span><span>
</span><span id="line-18"></span><span>
</span><span id="line-19"></span><span class="hs-keyword">module</span><span> </span><span class="hs-identifier">Torch.GraduallyTyped.NN.Transformer.Encoder</span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-20"></span><span>
</span><span id="line-21"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-identifier">Control.Monad.Indexed</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator">(&gt;&gt;&gt;=)</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-22"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="../file:///nix/store/8vjaffqxij7bih93d9mlzmc7ksanlw0i-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier">Control.Monad.Indexed.State</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="../file:///nix/store/8vjaffqxij7bih93d9mlzmc7ksanlw0i-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier">IxState</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="../file:///nix/store/8vjaffqxij7bih93d9mlzmc7ksanlw0i-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier">IxStateT</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-23"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-identifier">Control.Monad.Indexed.Trans</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-identifier">IxMonadTrans</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-identifier">ilift</span></a></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-24"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-identifier">Data.Functor.Indexed</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-identifier">IxPointed</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-identifier">ireturn</span></a></span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator">(&lt;&lt;$&gt;&gt;)</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator">(&lt;&lt;*&gt;&gt;)</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-25"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><span class="hs-identifier">Data.Kind</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="hs-identifier">Type</span></span><span class="hs-special">)</span><span>
</span><span id="line-26"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier">Data.Singletons</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier">SingI</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier">sing</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-27"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier">Data.Singletons.Prelude.List</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier">SList</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier">SNil</span></a></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-28"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><span class="hs-identifier">GHC.TypeLits</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="hs-identifier">KnownNat</span></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="hs-identifier">Nat</span></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="hs-identifier">Symbol</span></span><span class="hs-special">)</span><span>
</span><span id="line-29"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html"><span class="hs-identifier">Torch.GraduallyTyped.DType</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#DType"><span class="hs-identifier">DType</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#DataType"><span class="hs-identifier">DataType</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#SDType"><span class="hs-identifier">SDType</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#SDataType"><span class="hs-identifier">SDataType</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-30"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Device.html"><span class="hs-identifier">Torch.GraduallyTyped.Device</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#Device"><span class="hs-identifier">Device</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#DeviceType"><span class="hs-identifier">DeviceType</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#SDevice"><span class="hs-identifier">SDevice</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#SDeviceType"><span class="hs-identifier">SDeviceType</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-31"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html"><span class="hs-identifier">Torch.GraduallyTyped.Layout</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#Layout"><span class="hs-identifier">Layout</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#LayoutType"><span class="hs-identifier">LayoutType</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#SLayout"><span class="hs-identifier">SLayout</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#SLayoutType"><span class="hs-identifier">SLayoutType</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-32"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html"><span class="hs-identifier">Torch.GraduallyTyped.NN.Class</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasForward"><span class="hs-identifier">HasForward</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasInitialize"><span class="hs-identifier">HasInitialize</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasStateDict"><span class="hs-identifier">HasStateDict</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-33"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Dropout.html"><span class="hs-identifier">Torch.GraduallyTyped.NN.Dropout</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Dropout.html#Dropout"><span class="hs-identifier">Dropout</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-34"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Functional.Sparse.html"><span class="hs-identifier">Torch.GraduallyTyped.NN.Functional.Sparse</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Functional.Sparse.html#EmbeddingF"><span class="hs-identifier">EmbeddingF</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-35"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Normalization.html"><span class="hs-identifier">Torch.GraduallyTyped.NN.Normalization</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Normalization.html#LayerNorm"><span class="hs-identifier">LayerNorm</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-36"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Sparse.html"><span class="hs-identifier">Torch.GraduallyTyped.NN.Sparse</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Sparse.html#Embedding"><span class="hs-identifier">Embedding</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-37"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Stack.html"><span class="hs-identifier">Torch.GraduallyTyped.NN.Transformer.Stack</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Stack.html#TransformerStack"><span class="hs-identifier">TransformerStack</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-38"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html"><span class="hs-identifier">Torch.GraduallyTyped.NN.Transformer.Type</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#STransformerStyle"><span class="hs-identifier">STransformerStyle</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#TransformerStyle"><span class="hs-identifier">TransformerStyle</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-39"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Type.html"><span class="hs-identifier">Torch.GraduallyTyped.NN.Type</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Type.html#HasBias"><span class="hs-identifier">HasBias</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-40"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Prelude.html"><span class="hs-identifier">Torch.GraduallyTyped.Prelude</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Prelude.html#Seq"><span class="hs-identifier">Seq</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-41"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Random.html"><span class="hs-identifier">Torch.GraduallyTyped.Random</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Random.html#sMkGenerator"><span class="hs-identifier">sMkGenerator</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-42"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html"><span class="hs-identifier">Torch.GraduallyTyped.RequiresGradient</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#Gradient"><span class="hs-identifier">Gradient</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#RequiresGradient"><span class="hs-identifier">RequiresGradient</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#SGradient"><span class="hs-identifier">SGradient</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#SRequiresGradient"><span class="hs-identifier">SRequiresGradient</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-43"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Class.html"><span class="hs-identifier">Torch.GraduallyTyped.Shape.Class</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Class.html#BroadcastShapesF"><span class="hs-identifier">BroadcastShapesF</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-44"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html"><span class="hs-identifier">Torch.GraduallyTyped.Shape.Type</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#By"><span class="hs-identifier">By</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier">Name</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SDim"><span class="hs-identifier">SDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SName"><span class="hs-identifier">SName</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SShape"><span class="hs-identifier">SShape</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SSize"><span class="hs-identifier">SSize</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SelectDim"><span class="hs-identifier">SelectDim</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Shape"><span class="hs-identifier">Shape</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier">Size</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="hs-keyword">pattern</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%26%3A"><span class="hs-operator">(:&amp;:)</span></a></span><span class="hs-special">,</span><span> </span><span class="hs-keyword">pattern</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%7C%3A"><span class="hs-operator">(:|:)</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-45"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Creation.html"><span class="hs-identifier">Torch.GraduallyTyped.Tensor.Creation</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Creation.html#sOnes"><span class="hs-identifier">sOnes</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-46"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.IndexingSlicingJoining.html"><span class="hs-identifier">Torch.GraduallyTyped.Tensor.IndexingSlicingJoining</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.IndexingSlicingJoining.html#TransposeF"><span class="hs-identifier">TransposeF</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.IndexingSlicingJoining.html#UnsqueezeF"><span class="hs-identifier">UnsqueezeF</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.IndexingSlicingJoining.html#transpose"><span class="hs-identifier">transpose</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.IndexingSlicingJoining.html#unsqueeze"><span class="hs-identifier">unsqueeze</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-47"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html"><span class="hs-identifier">Torch.GraduallyTyped.Tensor.MathOperations.Pointwise</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#add"><span class="hs-identifier">add</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-48"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html"><span class="hs-identifier">Torch.GraduallyTyped.Tensor.Type</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier">Tensor</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-49"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html"><span class="hs-identifier">Torch.GraduallyTyped.Unify</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-keyword">type</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator">(&lt;+&gt;)</span></a></span><span class="hs-special">,</span><span> </span><span class="hs-keyword">type</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%7C%3E"><span class="hs-operator">(&lt;|&gt;)</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-50"></span><span>
</span><span id="line-51"></span><span class="hs-comment">-- | Generic transformer encoder.</span><span>
</span><span id="line-52"></span><span class="hs-comment">-- Needs to be specialized to a given transformer type, e.g. 'T5'.</span><span>
</span><span id="line-53"></span><span class="hs-comment">-- See 'TransformerEncoder'.</span><span>
</span><span id="line-54"></span><span class="hs-keyword">data</span><span>
</span><span id="line-55"></span><span>  </span><span id="GTransformerEncoder"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Encoder.html#GTransformerEncoder"><span class="hs-identifier hs-var">GTransformerEncoder</span></a></span></span><span>
</span><span id="line-56"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679771537"><span class="annot"><a href="#local-6989586621679771537"><span class="hs-identifier hs-type">stack</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Type</span></span><span class="hs-special">)</span><span>
</span><span id="line-57"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679771536"><span class="annot"><a href="#local-6989586621679771536"><span class="hs-identifier hs-type">embedLayerNorm</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Type</span></span><span class="hs-special">)</span><span>
</span><span id="line-58"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679771535"><span class="annot"><a href="#local-6989586621679771535"><span class="hs-identifier hs-type">layerNorm</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Type</span></span><span class="hs-special">)</span><span>
</span><span id="line-59"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679771534"><span class="annot"><a href="#local-6989586621679771534"><span class="hs-identifier hs-type">dropout</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Type</span></span><span class="hs-special">)</span><span>
</span><span id="line-60"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679771533"><span class="annot"><a href="#local-6989586621679771533"><span class="hs-identifier hs-type">posEnc</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Type</span></span><span class="hs-special">)</span><span>
</span><span id="line-61"></span><span>  </span><span class="hs-keyword">where</span><span>
</span><span id="line-62"></span><span>  </span><span id="GTransformerEncoder"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Encoder.html#GTransformerEncoder"><span class="hs-identifier hs-var">GTransformerEncoder</span></a></span></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-63"></span><span>    </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679771933"><span class="annot"><a href="#local-6989586621679771933"><span class="hs-identifier hs-type">stack</span></a></span></span><span> </span><span id="local-6989586621679771932"><span class="annot"><a href="#local-6989586621679771932"><span class="hs-identifier hs-type">embedLayerNorm</span></a></span></span><span> </span><span id="local-6989586621679771931"><span class="annot"><a href="#local-6989586621679771931"><span class="hs-identifier hs-type">layerNorm</span></a></span></span><span> </span><span id="local-6989586621679771930"><span class="annot"><a href="#local-6989586621679771930"><span class="hs-identifier hs-type">dropout</span></a></span></span><span> </span><span id="local-6989586621679771929"><span class="annot"><a href="#local-6989586621679771929"><span class="hs-identifier hs-type">posEnc</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-64"></span><span>    </span><span class="hs-special">{</span><span> </span><span class="hs-comment">-- | encoder layer stack</span><span>
</span><span id="line-65"></span><span>      </span><span id="teStack"><span class="annot"><span class="annottext">GTransformerEncoder stack embedLayerNorm layerNorm dropout posEnc
-&gt; stack
</span><a href="Torch.GraduallyTyped.NN.Transformer.Encoder.html#teStack"><span class="hs-identifier hs-var hs-var">teStack</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="#local-6989586621679771933"><span class="hs-identifier hs-type">stack</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-66"></span><span>      </span><span class="hs-comment">-- | encoder embedding layer norm</span><span>
</span><span id="line-67"></span><span>      </span><span id="teEmbedLayerNorm"><span class="annot"><span class="annottext">GTransformerEncoder stack embedLayerNorm layerNorm dropout posEnc
-&gt; embedLayerNorm
</span><a href="Torch.GraduallyTyped.NN.Transformer.Encoder.html#teEmbedLayerNorm"><span class="hs-identifier hs-var hs-var">teEmbedLayerNorm</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="#local-6989586621679771932"><span class="hs-identifier hs-type">embedLayerNorm</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-68"></span><span>      </span><span class="hs-comment">-- | encoder layer norm</span><span>
</span><span id="line-69"></span><span>      </span><span id="teLayerNorm"><span class="annot"><span class="annottext">GTransformerEncoder stack embedLayerNorm layerNorm dropout posEnc
-&gt; layerNorm
</span><a href="Torch.GraduallyTyped.NN.Transformer.Encoder.html#teLayerNorm"><span class="hs-identifier hs-var hs-var">teLayerNorm</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="#local-6989586621679771931"><span class="hs-identifier hs-type">layerNorm</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-70"></span><span>      </span><span class="hs-comment">-- | encoder dropout</span><span>
</span><span id="line-71"></span><span>      </span><span id="teDropout"><span class="annot"><span class="annottext">GTransformerEncoder stack embedLayerNorm layerNorm dropout posEnc
-&gt; dropout
</span><a href="Torch.GraduallyTyped.NN.Transformer.Encoder.html#teDropout"><span class="hs-identifier hs-var hs-var">teDropout</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="#local-6989586621679771930"><span class="hs-identifier hs-type">dropout</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-72"></span><span>      </span><span class="hs-comment">-- | positional encoding</span><span>
</span><span id="line-73"></span><span>      </span><span id="tePosEnc"><span class="annot"><span class="annottext">GTransformerEncoder stack embedLayerNorm layerNorm dropout posEnc
-&gt; posEnc
</span><a href="Torch.GraduallyTyped.NN.Transformer.Encoder.html#tePosEnc"><span class="hs-identifier hs-var hs-var">tePosEnc</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="#local-6989586621679771929"><span class="hs-identifier hs-type">posEnc</span></a></span><span>
</span><span id="line-74"></span><span>    </span><span class="hs-special">}</span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-75"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Encoder.html#GTransformerEncoder"><span class="hs-identifier hs-type">GTransformerEncoder</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771933"><span class="hs-identifier hs-type">stack</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771932"><span class="hs-identifier hs-type">embedLayerNorm</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771931"><span class="hs-identifier hs-type">layerNorm</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771930"><span class="hs-identifier hs-type">dropout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771929"><span class="hs-identifier hs-type">posEnc</span></a></span><span>
</span><span id="line-76"></span><span>
</span><span id="line-77"></span><span class="hs-comment">-- | Transformer encoder.</span><span>
</span><span id="line-78"></span><span class="hs-keyword">newtype</span><span>
</span><span id="line-79"></span><span>  </span><span id="TransformerEncoder"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Encoder.html#TransformerEncoder"><span class="hs-identifier hs-var">TransformerEncoder</span></a></span></span><span>
</span><span id="line-80"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679771526"><span class="annot"><a href="#local-6989586621679771526"><span class="hs-identifier hs-type">style</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#TransformerStyle"><span class="hs-identifier hs-type">TransformerStyle</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-81"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679771525"><span class="annot"><a href="#local-6989586621679771525"><span class="hs-identifier hs-type">numLayers</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span>
</span><span id="line-82"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679771524"><span class="annot"><a href="#local-6989586621679771524"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#Gradient"><span class="hs-identifier hs-type">Gradient</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#RequiresGradient"><span class="hs-identifier hs-type">RequiresGradient</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-83"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679771523"><span class="annot"><a href="#local-6989586621679771523"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#Device"><span class="hs-identifier hs-type">Device</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#DeviceType"><span class="hs-identifier hs-type">DeviceType</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-84"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679771522"><span class="annot"><a href="#local-6989586621679771522"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#DataType"><span class="hs-identifier hs-type">DataType</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#DType"><span class="hs-identifier hs-type">DType</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-85"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679771521"><span class="annot"><a href="#local-6989586621679771521"><span class="hs-identifier hs-type">headDim</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Symbol</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-86"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679771520"><span class="annot"><a href="#local-6989586621679771520"><span class="hs-identifier hs-type">headEmbedDim</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Symbol</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-87"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679771519"><span class="annot"><a href="#local-6989586621679771519"><span class="hs-identifier hs-type">embedDim</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Symbol</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-88"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679771518"><span class="annot"><a href="#local-6989586621679771518"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Symbol</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-89"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679771517"><span class="annot"><a href="#local-6989586621679771517"><span class="hs-identifier hs-type">ffnDim</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Symbol</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-90"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679771516"><span class="annot"><a href="#local-6989586621679771516"><span class="hs-identifier hs-type">posEncDim</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Symbol</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-91"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679771515"><span class="annot"><a href="#local-6989586621679771515"><span class="hs-identifier hs-type">dropoutP</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Type</span></span><span class="hs-special">)</span><span>
</span><span id="line-92"></span><span>  </span><span class="hs-keyword">where</span><span>
</span><span id="line-93"></span><span>  </span><span id="TransformerEncoder"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Encoder.html#TransformerEncoder"><span class="hs-identifier hs-var">TransformerEncoder</span></a></span></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-94"></span><span>    </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679771899"><span class="annot"><a href="#local-6989586621679771899"><span class="hs-identifier hs-type">style</span></a></span></span><span> </span><span id="local-6989586621679771898"><span class="annot"><a href="#local-6989586621679771898"><span class="hs-identifier hs-type">numLayers</span></a></span></span><span> </span><span id="local-6989586621679771897"><span class="annot"><a href="#local-6989586621679771897"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679771896"><span class="annot"><a href="#local-6989586621679771896"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679771895"><span class="annot"><a href="#local-6989586621679771895"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679771894"><span class="annot"><a href="#local-6989586621679771894"><span class="hs-identifier hs-type">headDim</span></a></span></span><span> </span><span id="local-6989586621679771893"><span class="annot"><a href="#local-6989586621679771893"><span class="hs-identifier hs-type">headEmbedDim</span></a></span></span><span> </span><span id="local-6989586621679771892"><span class="annot"><a href="#local-6989586621679771892"><span class="hs-identifier hs-type">embedDim</span></a></span></span><span> </span><span id="local-6989586621679771891"><span class="annot"><a href="#local-6989586621679771891"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span></span><span> </span><span id="local-6989586621679771890"><span class="annot"><a href="#local-6989586621679771890"><span class="hs-identifier hs-type">ffnDim</span></a></span></span><span> </span><span id="local-6989586621679771888"><span class="annot"><a href="#local-6989586621679771888"><span class="hs-identifier hs-type">posEncDim</span></a></span></span><span> </span><span id="local-6989586621679771889"><span class="annot"><a href="#local-6989586621679771889"><span class="hs-identifier hs-type">dropoutP</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-95"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Encoder.html#GTransformerEncoder"><span class="hs-identifier hs-type">GTransformerEncoder</span></a></span><span>
</span><span id="line-96"></span><span>      </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Encoder.html#TEStackF"><span class="hs-identifier hs-type">TEStackF</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771899"><span class="hs-identifier hs-type">style</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771898"><span class="hs-identifier hs-type">numLayers</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771897"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771896"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771895"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771894"><span class="hs-identifier hs-type">headDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771893"><span class="hs-identifier hs-type">headEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771892"><span class="hs-identifier hs-type">embedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771891"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771890"><span class="hs-identifier hs-type">ffnDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771889"><span class="hs-identifier hs-type">dropoutP</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-97"></span><span>      </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Encoder.html#TEEmbedLayerNormF"><span class="hs-identifier hs-type">TEEmbedLayerNormF</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771899"><span class="hs-identifier hs-type">style</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771897"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771896"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771895"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771891"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-98"></span><span>      </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Encoder.html#TELayerNormF"><span class="hs-identifier hs-type">TELayerNormF</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771899"><span class="hs-identifier hs-type">style</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771897"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771896"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771895"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771891"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-99"></span><span>      </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Encoder.html#TEDropoutF"><span class="hs-identifier hs-type">TEDropoutF</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771899"><span class="hs-identifier hs-type">style</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771889"><span class="hs-identifier hs-type">dropoutP</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-100"></span><span>      </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Encoder.html#TEPosEncF"><span class="hs-identifier hs-type">TEPosEncF</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771899"><span class="hs-identifier hs-type">style</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771897"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771896"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771895"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771894"><span class="hs-identifier hs-type">headDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771891"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771888"><span class="hs-identifier hs-type">posEncDim</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-101"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Encoder.html#TransformerEncoder"><span class="hs-identifier hs-type">TransformerEncoder</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771899"><span class="hs-identifier hs-type">style</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771898"><span class="hs-identifier hs-type">numLayers</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771897"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771896"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771895"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771894"><span class="hs-identifier hs-type">headDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771893"><span class="hs-identifier hs-type">headEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771892"><span class="hs-identifier hs-type">embedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771891"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771890"><span class="hs-identifier hs-type">ffnDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771888"><span class="hs-identifier hs-type">posEncDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771889"><span class="hs-identifier hs-type">dropoutP</span></a></span><span>
</span><span id="line-102"></span><span>
</span><span id="line-103"></span><span class="hs-keyword">type</span><span> </span><span class="hs-keyword">family</span><span>
</span><span id="line-104"></span><span>  </span><span id="TEStackF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Encoder.html#TEStackF"><span class="hs-identifier hs-var">TEStackF</span></a></span></span><span>
</span><span id="line-105"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679771513"><span class="annot"><a href="#local-6989586621679771513"><span class="hs-identifier hs-type">style</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#TransformerStyle"><span class="hs-identifier hs-type">TransformerStyle</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-106"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679771512"><span class="annot"><a href="#local-6989586621679771512"><span class="hs-identifier hs-type">numLayers</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span>
</span><span id="line-107"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679771511"><span class="annot"><a href="#local-6989586621679771511"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#Gradient"><span class="hs-identifier hs-type">Gradient</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#RequiresGradient"><span class="hs-identifier hs-type">RequiresGradient</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-108"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679771510"><span class="annot"><a href="#local-6989586621679771510"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#Device"><span class="hs-identifier hs-type">Device</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#DeviceType"><span class="hs-identifier hs-type">DeviceType</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-109"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679771509"><span class="annot"><a href="#local-6989586621679771509"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#DataType"><span class="hs-identifier hs-type">DataType</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#DType"><span class="hs-identifier hs-type">DType</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-110"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679771508"><span class="annot"><a href="#local-6989586621679771508"><span class="hs-identifier hs-type">headDim</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Symbol</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-111"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679771507"><span class="annot"><a href="#local-6989586621679771507"><span class="hs-identifier hs-type">headEmbedDim</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Symbol</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-112"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679771506"><span class="annot"><a href="#local-6989586621679771506"><span class="hs-identifier hs-type">embedDim</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Symbol</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-113"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679771505"><span class="annot"><a href="#local-6989586621679771505"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Symbol</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-114"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679771504"><span class="annot"><a href="#local-6989586621679771504"><span class="hs-identifier hs-type">ffnDim</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Symbol</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-115"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679771503"><span class="annot"><a href="#local-6989586621679771503"><span class="hs-identifier hs-type">dropoutP</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Type</span></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-116"></span><span>    </span><span class="annot"><span class="hs-identifier hs-type">Type</span></span><span>
</span><span id="line-117"></span><span>  </span><span class="hs-keyword">where</span><span>
</span><span id="line-118"></span><span>  </span><span id="TEStackF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Encoder.html#TEStackF"><span class="hs-identifier hs-var">TEStackF</span></a></span></span><span> </span><span id="local-6989586621679771502"><span class="annot"><a href="#local-6989586621679771502"><span class="hs-identifier hs-type hs-type">style</span></a></span></span><span> </span><span id="local-6989586621679771501"><span class="annot"><a href="#local-6989586621679771501"><span class="hs-identifier hs-type hs-type">numLayers</span></a></span></span><span> </span><span id="local-6989586621679771500"><span class="annot"><a href="#local-6989586621679771500"><span class="hs-identifier hs-type hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679771499"><span class="annot"><a href="#local-6989586621679771499"><span class="hs-identifier hs-type hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679771498"><span class="annot"><a href="#local-6989586621679771498"><span class="hs-identifier hs-type hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679771497"><span class="annot"><a href="#local-6989586621679771497"><span class="hs-identifier hs-type hs-type">headDim</span></a></span></span><span> </span><span id="local-6989586621679771496"><span class="annot"><a href="#local-6989586621679771496"><span class="hs-identifier hs-type hs-type">headEmbedDim</span></a></span></span><span> </span><span id="local-6989586621679771495"><span class="annot"><a href="#local-6989586621679771495"><span class="hs-identifier hs-type hs-type">embedDim</span></a></span></span><span> </span><span id="local-6989586621679771494"><span class="annot"><a href="#local-6989586621679771494"><span class="hs-identifier hs-type hs-type">inputEmbedDim</span></a></span></span><span> </span><span id="local-6989586621679771493"><span class="annot"><a href="#local-6989586621679771493"><span class="hs-identifier hs-type hs-type">ffnDim</span></a></span></span><span> </span><span id="local-6989586621679771492"><span class="annot"><a href="#local-6989586621679771492"><span class="hs-identifier hs-type hs-type">dropoutP</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-119"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Stack.html#TransformerStack"><span class="hs-identifier hs-type">TransformerStack</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771502"><span class="hs-identifier hs-type">style</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771501"><span class="hs-identifier hs-type">numLayers</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771500"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771499"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771498"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771497"><span class="hs-identifier hs-type">headDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771496"><span class="hs-identifier hs-type">headEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771495"><span class="hs-identifier hs-type">embedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771494"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771493"><span class="hs-identifier hs-type">ffnDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771492"><span class="hs-identifier hs-type">dropoutP</span></a></span><span>
</span><span id="line-120"></span><span>
</span><span id="line-121"></span><span class="hs-keyword">type</span><span> </span><span class="hs-keyword">family</span><span>
</span><span id="line-122"></span><span>  </span><span id="TEEmbedLayerNormF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Encoder.html#TEEmbedLayerNormF"><span class="hs-identifier hs-var">TEEmbedLayerNormF</span></a></span></span><span>
</span><span id="line-123"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679771491"><span class="annot"><a href="#local-6989586621679771491"><span class="hs-identifier hs-type">style</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#TransformerStyle"><span class="hs-identifier hs-type">TransformerStyle</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-124"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679771490"><span class="annot"><a href="#local-6989586621679771490"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#Gradient"><span class="hs-identifier hs-type">Gradient</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#RequiresGradient"><span class="hs-identifier hs-type">RequiresGradient</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-125"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679771489"><span class="annot"><a href="#local-6989586621679771489"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#Device"><span class="hs-identifier hs-type">Device</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#DeviceType"><span class="hs-identifier hs-type">DeviceType</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-126"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679771488"><span class="annot"><a href="#local-6989586621679771488"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#DataType"><span class="hs-identifier hs-type">DataType</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#DType"><span class="hs-identifier hs-type">DType</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-127"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679771487"><span class="annot"><a href="#local-6989586621679771487"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Symbol</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-128"></span><span>    </span><span class="annot"><span class="hs-identifier hs-type">Type</span></span><span>
</span><span id="line-129"></span><span>  </span><span class="hs-keyword">where</span><span>
</span><span id="line-130"></span><span>  </span><span id="TEEmbedLayerNormF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Encoder.html#TEEmbedLayerNormF"><span class="hs-identifier hs-var">TEEmbedLayerNormF</span></a></span></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#T5"><span class="hs-identifier hs-type">T5</span></a></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="hs-special">(</span><span class="hs-special">)</span><span>
</span><span id="line-131"></span><span>  </span><span id="TEEmbedLayerNormF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Encoder.html#TEEmbedLayerNormF"><span class="hs-identifier hs-var">TEEmbedLayerNormF</span></a></span></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#ByT5"><span class="hs-identifier hs-type">ByT5</span></a></span><span> </span><span id="local-6989586621679771486"><span class="annot"><a href="#local-6989586621679771486"><span class="hs-identifier hs-type hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679771485"><span class="annot"><a href="#local-6989586621679771485"><span class="hs-identifier hs-type hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679771484"><span class="annot"><a href="#local-6989586621679771484"><span class="hs-identifier hs-type hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679771483"><span class="annot"><a href="#local-6989586621679771483"><span class="hs-identifier hs-type hs-type">inputEmbedDim</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Encoder.html#TEEmbedLayerNormF"><span class="hs-identifier hs-type">TEEmbedLayerNormF</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#T5"><span class="hs-identifier hs-type">T5</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771486"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771485"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771484"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771483"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span><span>
</span><span id="line-132"></span><span>  </span><span id="TEEmbedLayerNormF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Encoder.html#TEEmbedLayerNormF"><span class="hs-identifier hs-var">TEEmbedLayerNormF</span></a></span></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#BART"><span class="hs-identifier hs-type">BART</span></a></span><span> </span><span id="local-6989586621679771482"><span class="annot"><a href="#local-6989586621679771482"><span class="hs-identifier hs-type hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679771481"><span class="annot"><a href="#local-6989586621679771481"><span class="hs-identifier hs-type hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679771480"><span class="annot"><a href="#local-6989586621679771480"><span class="hs-identifier hs-type hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679771479"><span class="annot"><a href="#local-6989586621679771479"><span class="hs-identifier hs-type hs-type">inputEmbedDim</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Normalization.html#LayerNorm"><span class="hs-identifier hs-type">LayerNorm</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Type.html#WithBias"><span class="hs-identifier hs-type">WithBias</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771482"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771481"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771480"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Shape"><span class="hs-identifier hs-type">Shape</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="annot"><a href="#local-6989586621679771479"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span><span class="hs-special">]</span><span class="hs-special">)</span><span>
</span><span id="line-133"></span><span>  </span><span id="TEEmbedLayerNormF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Encoder.html#TEEmbedLayerNormF"><span class="hs-identifier hs-var">TEEmbedLayerNormF</span></a></span></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#MBART"><span class="hs-identifier hs-type">MBART</span></a></span><span> </span><span id="local-6989586621679771478"><span class="annot"><a href="#local-6989586621679771478"><span class="hs-identifier hs-type hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679771477"><span class="annot"><a href="#local-6989586621679771477"><span class="hs-identifier hs-type hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679771476"><span class="annot"><a href="#local-6989586621679771476"><span class="hs-identifier hs-type hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679771475"><span class="annot"><a href="#local-6989586621679771475"><span class="hs-identifier hs-type hs-type">inputEmbedDim</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Encoder.html#TEEmbedLayerNormF"><span class="hs-identifier hs-type">TEEmbedLayerNormF</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#BART"><span class="hs-identifier hs-type">BART</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771478"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771477"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771476"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771475"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span><span>
</span><span id="line-134"></span><span>  </span><span id="TEEmbedLayerNormF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Encoder.html#TEEmbedLayerNormF"><span class="hs-identifier hs-var">TEEmbedLayerNormF</span></a></span></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#Pegasus"><span class="hs-identifier hs-type">Pegasus</span></a></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="hs-special">(</span><span class="hs-special">)</span><span>
</span><span id="line-135"></span><span>  </span><span id="TEEmbedLayerNormF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Encoder.html#TEEmbedLayerNormF"><span class="hs-identifier hs-var">TEEmbedLayerNormF</span></a></span></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#BERT"><span class="hs-identifier hs-type">BERT</span></a></span><span> </span><span id="local-6989586621679771474"><span class="annot"><a href="#local-6989586621679771474"><span class="hs-identifier hs-type hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679771473"><span class="annot"><a href="#local-6989586621679771473"><span class="hs-identifier hs-type hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679771472"><span class="annot"><a href="#local-6989586621679771472"><span class="hs-identifier hs-type hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679771471"><span class="annot"><a href="#local-6989586621679771471"><span class="hs-identifier hs-type hs-type">inputEmbedDim</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Normalization.html#LayerNorm"><span class="hs-identifier hs-type">LayerNorm</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Type.html#WithBias"><span class="hs-identifier hs-type">WithBias</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771474"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771473"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771472"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Shape"><span class="hs-identifier hs-type">Shape</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="annot"><a href="#local-6989586621679771471"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span><span class="hs-special">]</span><span class="hs-special">)</span><span>
</span><span id="line-136"></span><span>  </span><span id="TEEmbedLayerNormF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Encoder.html#TEEmbedLayerNormF"><span class="hs-identifier hs-var">TEEmbedLayerNormF</span></a></span></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#RoBERTa"><span class="hs-identifier hs-type">RoBERTa</span></a></span><span> </span><span id="local-6989586621679771470"><span class="annot"><a href="#local-6989586621679771470"><span class="hs-identifier hs-type hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679771469"><span class="annot"><a href="#local-6989586621679771469"><span class="hs-identifier hs-type hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679771468"><span class="annot"><a href="#local-6989586621679771468"><span class="hs-identifier hs-type hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679771467"><span class="annot"><a href="#local-6989586621679771467"><span class="hs-identifier hs-type hs-type">inputEmbedDim</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Encoder.html#TEEmbedLayerNormF"><span class="hs-identifier hs-type">TEEmbedLayerNormF</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#BERT"><span class="hs-identifier hs-type">BERT</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771470"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771469"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771468"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771467"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span><span>
</span><span id="line-137"></span><span>
</span><span id="line-138"></span><span class="hs-keyword">type</span><span> </span><span class="hs-keyword">family</span><span>
</span><span id="line-139"></span><span>  </span><span id="TELayerNormF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Encoder.html#TELayerNormF"><span class="hs-identifier hs-var">TELayerNormF</span></a></span></span><span>
</span><span id="line-140"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679771466"><span class="annot"><a href="#local-6989586621679771466"><span class="hs-identifier hs-type">style</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#TransformerStyle"><span class="hs-identifier hs-type">TransformerStyle</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-141"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679771465"><span class="annot"><a href="#local-6989586621679771465"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#Gradient"><span class="hs-identifier hs-type">Gradient</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#RequiresGradient"><span class="hs-identifier hs-type">RequiresGradient</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-142"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679771464"><span class="annot"><a href="#local-6989586621679771464"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#Device"><span class="hs-identifier hs-type">Device</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#DeviceType"><span class="hs-identifier hs-type">DeviceType</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-143"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679771463"><span class="annot"><a href="#local-6989586621679771463"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#DataType"><span class="hs-identifier hs-type">DataType</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#DType"><span class="hs-identifier hs-type">DType</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-144"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679771462"><span class="annot"><a href="#local-6989586621679771462"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Symbol</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-145"></span><span>    </span><span class="annot"><span class="hs-identifier hs-type">Type</span></span><span>
</span><span id="line-146"></span><span>  </span><span class="hs-keyword">where</span><span>
</span><span id="line-147"></span><span>  </span><span id="TELayerNormF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Encoder.html#TELayerNormF"><span class="hs-identifier hs-var">TELayerNormF</span></a></span></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#T5"><span class="hs-identifier hs-type">T5</span></a></span><span> </span><span id="local-6989586621679771461"><span class="annot"><a href="#local-6989586621679771461"><span class="hs-identifier hs-type hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679771460"><span class="annot"><a href="#local-6989586621679771460"><span class="hs-identifier hs-type hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679771459"><span class="annot"><a href="#local-6989586621679771459"><span class="hs-identifier hs-type hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679771458"><span class="annot"><a href="#local-6989586621679771458"><span class="hs-identifier hs-type hs-type">inputEmbedDim</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Normalization.html#LayerNorm"><span class="hs-identifier hs-type">LayerNorm</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Type.html#WithoutBias"><span class="hs-identifier hs-type">WithoutBias</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771461"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771460"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771459"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Shape"><span class="hs-identifier hs-type">Shape</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="annot"><a href="#local-6989586621679771458"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span><span class="hs-special">]</span><span class="hs-special">)</span><span>
</span><span id="line-148"></span><span>  </span><span id="TELayerNormF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Encoder.html#TELayerNormF"><span class="hs-identifier hs-var">TELayerNormF</span></a></span></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#ByT5"><span class="hs-identifier hs-type">ByT5</span></a></span><span> </span><span id="local-6989586621679771457"><span class="annot"><a href="#local-6989586621679771457"><span class="hs-identifier hs-type hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679771456"><span class="annot"><a href="#local-6989586621679771456"><span class="hs-identifier hs-type hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679771455"><span class="annot"><a href="#local-6989586621679771455"><span class="hs-identifier hs-type hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679771454"><span class="annot"><a href="#local-6989586621679771454"><span class="hs-identifier hs-type hs-type">inputEmbedDim</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Encoder.html#TELayerNormF"><span class="hs-identifier hs-type">TELayerNormF</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#T5"><span class="hs-identifier hs-type">T5</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771457"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771456"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771455"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771454"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span><span>
</span><span id="line-149"></span><span>  </span><span id="TELayerNormF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Encoder.html#TELayerNormF"><span class="hs-identifier hs-var">TELayerNormF</span></a></span></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#BART"><span class="hs-identifier hs-type">BART</span></a></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="hs-special">(</span><span class="hs-special">)</span><span>
</span><span id="line-150"></span><span>  </span><span id="TELayerNormF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Encoder.html#TELayerNormF"><span class="hs-identifier hs-var">TELayerNormF</span></a></span></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#MBART"><span class="hs-identifier hs-type">MBART</span></a></span><span> </span><span id="local-6989586621679771453"><span class="annot"><a href="#local-6989586621679771453"><span class="hs-identifier hs-type hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679771452"><span class="annot"><a href="#local-6989586621679771452"><span class="hs-identifier hs-type hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679771451"><span class="annot"><a href="#local-6989586621679771451"><span class="hs-identifier hs-type hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679771450"><span class="annot"><a href="#local-6989586621679771450"><span class="hs-identifier hs-type hs-type">inputEmbedDim</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Encoder.html#TELayerNormF"><span class="hs-identifier hs-type">TELayerNormF</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#BART"><span class="hs-identifier hs-type">BART</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771453"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771452"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771451"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771450"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span><span>
</span><span id="line-151"></span><span>  </span><span id="TELayerNormF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Encoder.html#TELayerNormF"><span class="hs-identifier hs-var">TELayerNormF</span></a></span></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#Pegasus"><span class="hs-identifier hs-type">Pegasus</span></a></span><span> </span><span id="local-6989586621679771449"><span class="annot"><a href="#local-6989586621679771449"><span class="hs-identifier hs-type hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679771448"><span class="annot"><a href="#local-6989586621679771448"><span class="hs-identifier hs-type hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679771447"><span class="annot"><a href="#local-6989586621679771447"><span class="hs-identifier hs-type hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679771446"><span class="annot"><a href="#local-6989586621679771446"><span class="hs-identifier hs-type hs-type">inputEmbedDim</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Normalization.html#LayerNorm"><span class="hs-identifier hs-type">LayerNorm</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Type.html#WithBias"><span class="hs-identifier hs-type">WithBias</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771449"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771448"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771447"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Shape"><span class="hs-identifier hs-type">Shape</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="annot"><a href="#local-6989586621679771446"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span><span class="hs-special">]</span><span class="hs-special">)</span><span>
</span><span id="line-152"></span><span>  </span><span id="TELayerNormF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Encoder.html#TELayerNormF"><span class="hs-identifier hs-var">TELayerNormF</span></a></span></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#BERT"><span class="hs-identifier hs-type">BERT</span></a></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="hs-special">(</span><span class="hs-special">)</span><span>
</span><span id="line-153"></span><span>  </span><span id="TELayerNormF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Encoder.html#TELayerNormF"><span class="hs-identifier hs-var">TELayerNormF</span></a></span></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#RoBERTa"><span class="hs-identifier hs-type">RoBERTa</span></a></span><span> </span><span id="local-6989586621679771445"><span class="annot"><a href="#local-6989586621679771445"><span class="hs-identifier hs-type hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679771444"><span class="annot"><a href="#local-6989586621679771444"><span class="hs-identifier hs-type hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679771443"><span class="annot"><a href="#local-6989586621679771443"><span class="hs-identifier hs-type hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679771442"><span class="annot"><a href="#local-6989586621679771442"><span class="hs-identifier hs-type hs-type">inputEmbedDim</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Encoder.html#TELayerNormF"><span class="hs-identifier hs-type">TELayerNormF</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#BERT"><span class="hs-identifier hs-type">BERT</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771445"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771444"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771443"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771442"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span><span>
</span><span id="line-154"></span><span>
</span><span id="line-155"></span><span class="hs-keyword">type</span><span> </span><span class="hs-keyword">family</span><span>
</span><span id="line-156"></span><span>  </span><span id="TEDropoutF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Encoder.html#TEDropoutF"><span class="hs-identifier hs-var">TEDropoutF</span></a></span></span><span>
</span><span id="line-157"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679771441"><span class="annot"><a href="#local-6989586621679771441"><span class="hs-identifier hs-type">style</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#TransformerStyle"><span class="hs-identifier hs-type">TransformerStyle</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-158"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679771440"><span class="annot"><a href="#local-6989586621679771440"><span class="hs-identifier hs-type">dropoutP</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Type</span></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-159"></span><span>    </span><span class="annot"><span class="hs-identifier hs-type">Type</span></span><span>
</span><span id="line-160"></span><span>  </span><span class="hs-keyword">where</span><span>
</span><span id="line-161"></span><span>  </span><span id="TEDropoutF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Encoder.html#TEDropoutF"><span class="hs-identifier hs-var">TEDropoutF</span></a></span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span id="local-6989586621679771439"><span class="annot"><a href="#local-6989586621679771439"><span class="hs-identifier hs-type hs-type">dropoutP</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Dropout.html#Dropout"><span class="hs-identifier hs-type">Dropout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771439"><span class="hs-identifier hs-type">dropoutP</span></a></span><span>
</span><span id="line-162"></span><span>
</span><span id="line-163"></span><span class="hs-keyword">type</span><span> </span><span class="hs-keyword">family</span><span>
</span><span id="line-164"></span><span>  </span><span id="TEPosEncF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Encoder.html#TEPosEncF"><span class="hs-identifier hs-var">TEPosEncF</span></a></span></span><span>
</span><span id="line-165"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679771438"><span class="annot"><a href="#local-6989586621679771438"><span class="hs-identifier hs-type">style</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#TransformerStyle"><span class="hs-identifier hs-type">TransformerStyle</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-166"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679771437"><span class="annot"><a href="#local-6989586621679771437"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#Gradient"><span class="hs-identifier hs-type">Gradient</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#RequiresGradient"><span class="hs-identifier hs-type">RequiresGradient</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-167"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679771436"><span class="annot"><a href="#local-6989586621679771436"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#Device"><span class="hs-identifier hs-type">Device</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#DeviceType"><span class="hs-identifier hs-type">DeviceType</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-168"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679771435"><span class="annot"><a href="#local-6989586621679771435"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#DataType"><span class="hs-identifier hs-type">DataType</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#DType"><span class="hs-identifier hs-type">DType</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-169"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679771434"><span class="annot"><a href="#local-6989586621679771434"><span class="hs-identifier hs-type">headDim</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Symbol</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-170"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679771433"><span class="annot"><a href="#local-6989586621679771433"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Symbol</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-171"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679771432"><span class="annot"><a href="#local-6989586621679771432"><span class="hs-identifier hs-type">posEncDim</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Symbol</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-172"></span><span>    </span><span class="annot"><span class="hs-identifier hs-type">Type</span></span><span>
</span><span id="line-173"></span><span>  </span><span class="hs-keyword">where</span><span>
</span><span id="line-174"></span><span>  </span><span id="TEPosEncF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Encoder.html#TEPosEncF"><span class="hs-identifier hs-var">TEPosEncF</span></a></span></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#T5"><span class="hs-identifier hs-type">T5</span></a></span><span> </span><span id="local-6989586621679771431"><span class="annot"><a href="#local-6989586621679771431"><span class="hs-identifier hs-type hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679771430"><span class="annot"><a href="#local-6989586621679771430"><span class="hs-identifier hs-type hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679771429"><span class="annot"><a href="#local-6989586621679771429"><span class="hs-identifier hs-type hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679771428"><span class="annot"><a href="#local-6989586621679771428"><span class="hs-identifier hs-type hs-type">headDim</span></a></span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span id="local-6989586621679771427"><span class="annot"><a href="#local-6989586621679771427"><span class="hs-identifier hs-type hs-type">posEncDim</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Sparse.html#Embedding"><span class="hs-identifier hs-type">Embedding</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771431"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#Layout"><span class="hs-identifier hs-type">Layout</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#Dense"><span class="hs-identifier hs-type">Dense</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679771430"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771429"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771427"><span class="hs-identifier hs-type">posEncDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771428"><span class="hs-identifier hs-type">headDim</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><span class="hs-identifier hs-type">Nothing</span></span><span>
</span><span id="line-175"></span><span>  </span><span id="TEPosEncF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Encoder.html#TEPosEncF"><span class="hs-identifier hs-var">TEPosEncF</span></a></span></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#ByT5"><span class="hs-identifier hs-type">ByT5</span></a></span><span> </span><span id="local-6989586621679771426"><span class="annot"><a href="#local-6989586621679771426"><span class="hs-identifier hs-type hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679771425"><span class="annot"><a href="#local-6989586621679771425"><span class="hs-identifier hs-type hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679771424"><span class="annot"><a href="#local-6989586621679771424"><span class="hs-identifier hs-type hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679771423"><span class="annot"><a href="#local-6989586621679771423"><span class="hs-identifier hs-type hs-type">headDim</span></a></span></span><span> </span><span id="local-6989586621679771422"><span class="annot"><a href="#local-6989586621679771422"><span class="hs-identifier hs-type hs-type">inputEmbedDim</span></a></span></span><span> </span><span id="local-6989586621679771421"><span class="annot"><a href="#local-6989586621679771421"><span class="hs-identifier hs-type hs-type">posEncDim</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Encoder.html#TEPosEncF"><span class="hs-identifier hs-type">TEPosEncF</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#T5"><span class="hs-identifier hs-type">T5</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771426"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771425"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771424"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771423"><span class="hs-identifier hs-type">headDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771422"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771421"><span class="hs-identifier hs-type">posEncDim</span></a></span><span>
</span><span id="line-176"></span><span>  </span><span id="TEPosEncF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Encoder.html#TEPosEncF"><span class="hs-identifier hs-var">TEPosEncF</span></a></span></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#BART"><span class="hs-identifier hs-type">BART</span></a></span><span> </span><span id="local-6989586621679771420"><span class="annot"><a href="#local-6989586621679771420"><span class="hs-identifier hs-type hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679771419"><span class="annot"><a href="#local-6989586621679771419"><span class="hs-identifier hs-type hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679771418"><span class="annot"><a href="#local-6989586621679771418"><span class="hs-identifier hs-type hs-type">dataType</span></a></span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span id="local-6989586621679771417"><span class="annot"><a href="#local-6989586621679771417"><span class="hs-identifier hs-type hs-type">inputEmbedDim</span></a></span></span><span> </span><span id="local-6989586621679771416"><span class="annot"><a href="#local-6989586621679771416"><span class="hs-identifier hs-type hs-type">posEncDim</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Sparse.html#Embedding"><span class="hs-identifier hs-type">Embedding</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771420"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#Layout"><span class="hs-identifier hs-type">Layout</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#Dense"><span class="hs-identifier hs-type">Dense</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679771419"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771418"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771416"><span class="hs-identifier hs-type">posEncDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771417"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><span class="hs-identifier hs-type">Nothing</span></span><span>
</span><span id="line-177"></span><span>  </span><span id="TEPosEncF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Encoder.html#TEPosEncF"><span class="hs-identifier hs-var">TEPosEncF</span></a></span></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#MBART"><span class="hs-identifier hs-type">MBART</span></a></span><span> </span><span id="local-6989586621679771415"><span class="annot"><a href="#local-6989586621679771415"><span class="hs-identifier hs-type hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679771414"><span class="annot"><a href="#local-6989586621679771414"><span class="hs-identifier hs-type hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679771413"><span class="annot"><a href="#local-6989586621679771413"><span class="hs-identifier hs-type hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679771412"><span class="annot"><a href="#local-6989586621679771412"><span class="hs-identifier hs-type hs-type">headDim</span></a></span></span><span> </span><span id="local-6989586621679771411"><span class="annot"><a href="#local-6989586621679771411"><span class="hs-identifier hs-type hs-type">inputEmbedDim</span></a></span></span><span> </span><span id="local-6989586621679771410"><span class="annot"><a href="#local-6989586621679771410"><span class="hs-identifier hs-type hs-type">posEncDim</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Encoder.html#TEPosEncF"><span class="hs-identifier hs-type">TEPosEncF</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#BART"><span class="hs-identifier hs-type">BART</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771415"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771414"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771413"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771412"><span class="hs-identifier hs-type">headDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771411"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771410"><span class="hs-identifier hs-type">posEncDim</span></a></span><span>
</span><span id="line-178"></span><span>  </span><span id="TEPosEncF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Encoder.html#TEPosEncF"><span class="hs-identifier hs-var">TEPosEncF</span></a></span></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#Pegasus"><span class="hs-identifier hs-type">Pegasus</span></a></span><span> </span><span id="local-6989586621679771409"><span class="annot"><a href="#local-6989586621679771409"><span class="hs-identifier hs-type hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679771408"><span class="annot"><a href="#local-6989586621679771408"><span class="hs-identifier hs-type hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679771407"><span class="annot"><a href="#local-6989586621679771407"><span class="hs-identifier hs-type hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679771406"><span class="annot"><a href="#local-6989586621679771406"><span class="hs-identifier hs-type hs-type">headDim</span></a></span></span><span> </span><span id="local-6989586621679771405"><span class="annot"><a href="#local-6989586621679771405"><span class="hs-identifier hs-type hs-type">inputEmbedDim</span></a></span></span><span> </span><span id="local-6989586621679771404"><span class="annot"><a href="#local-6989586621679771404"><span class="hs-identifier hs-type hs-type">posEncDim</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Encoder.html#TEPosEncF"><span class="hs-identifier hs-type">TEPosEncF</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#BART"><span class="hs-identifier hs-type">BART</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771409"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771408"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771407"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771406"><span class="hs-identifier hs-type">headDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771405"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771404"><span class="hs-identifier hs-type">posEncDim</span></a></span><span>
</span><span id="line-179"></span><span>  </span><span id="TEPosEncF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Encoder.html#TEPosEncF"><span class="hs-identifier hs-var">TEPosEncF</span></a></span></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#BERT"><span class="hs-identifier hs-type">BERT</span></a></span><span> </span><span id="local-6989586621679771403"><span class="annot"><a href="#local-6989586621679771403"><span class="hs-identifier hs-type hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679771402"><span class="annot"><a href="#local-6989586621679771402"><span class="hs-identifier hs-type hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679771401"><span class="annot"><a href="#local-6989586621679771401"><span class="hs-identifier hs-type hs-type">dataType</span></a></span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span id="local-6989586621679771400"><span class="annot"><a href="#local-6989586621679771400"><span class="hs-identifier hs-type hs-type">inputEmbedDim</span></a></span></span><span> </span><span id="local-6989586621679771399"><span class="annot"><a href="#local-6989586621679771399"><span class="hs-identifier hs-type hs-type">posEncDim</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Sparse.html#Embedding"><span class="hs-identifier hs-type">Embedding</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771403"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#Layout"><span class="hs-identifier hs-type">Layout</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#Dense"><span class="hs-identifier hs-type">Dense</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679771402"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771401"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771399"><span class="hs-identifier hs-type">posEncDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771400"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><span class="hs-identifier hs-type">Nothing</span></span><span>
</span><span id="line-180"></span><span>  </span><span id="TEPosEncF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Encoder.html#TEPosEncF"><span class="hs-identifier hs-var">TEPosEncF</span></a></span></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#RoBERTa"><span class="hs-identifier hs-type">RoBERTa</span></a></span><span> </span><span id="local-6989586621679771398"><span class="annot"><a href="#local-6989586621679771398"><span class="hs-identifier hs-type hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679771397"><span class="annot"><a href="#local-6989586621679771397"><span class="hs-identifier hs-type hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679771396"><span class="annot"><a href="#local-6989586621679771396"><span class="hs-identifier hs-type hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679771395"><span class="annot"><a href="#local-6989586621679771395"><span class="hs-identifier hs-type hs-type">headDim</span></a></span></span><span> </span><span id="local-6989586621679771394"><span class="annot"><a href="#local-6989586621679771394"><span class="hs-identifier hs-type hs-type">inputEmbedDim</span></a></span></span><span> </span><span id="local-6989586621679771393"><span class="annot"><a href="#local-6989586621679771393"><span class="hs-identifier hs-type hs-type">posEncDim</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Encoder.html#TEPosEncF"><span class="hs-identifier hs-type">TEPosEncF</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#BERT"><span class="hs-identifier hs-type">BERT</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771398"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771397"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771396"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771395"><span class="hs-identifier hs-type">headDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771394"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771393"><span class="hs-identifier hs-type">posEncDim</span></a></span><span>
</span><span id="line-181"></span><span>
</span><span id="line-182"></span><span class="hs-keyword">type</span><span> </span><span class="hs-keyword">family</span><span>
</span><span id="line-183"></span><span>  </span><span id="HasInitializeTEEmbedLayerNormInputF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Encoder.html#HasInitializeTEEmbedLayerNormInputF"><span class="hs-identifier hs-var">HasInitializeTEEmbedLayerNormInputF</span></a></span></span><span>
</span><span id="line-184"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679771392"><span class="annot"><a href="#local-6989586621679771392"><span class="hs-identifier hs-type">style</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#TransformerStyle"><span class="hs-identifier hs-type">TransformerStyle</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-185"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679771391"><span class="annot"><a href="#local-6989586621679771391"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#Gradient"><span class="hs-identifier hs-type">Gradient</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#RequiresGradient"><span class="hs-identifier hs-type">RequiresGradient</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-186"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679771390"><span class="annot"><a href="#local-6989586621679771390"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#Device"><span class="hs-identifier hs-type">Device</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#DeviceType"><span class="hs-identifier hs-type">DeviceType</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-187"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679771389"><span class="annot"><a href="#local-6989586621679771389"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#DataType"><span class="hs-identifier hs-type">DataType</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#DType"><span class="hs-identifier hs-type">DType</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-188"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679771388"><span class="annot"><a href="#local-6989586621679771388"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Symbol</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-189"></span><span>    </span><span class="annot"><span class="hs-identifier hs-type">Type</span></span><span>
</span><span id="line-190"></span><span>  </span><span class="hs-keyword">where</span><span>
</span><span id="line-191"></span><span>  </span><span id="HasInitializeTEEmbedLayerNormInputF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Encoder.html#HasInitializeTEEmbedLayerNormInputF"><span class="hs-identifier hs-var">HasInitializeTEEmbedLayerNormInputF</span></a></span></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#T5"><span class="hs-identifier hs-type">T5</span></a></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="hs-special">(</span><span class="hs-special">)</span><span>
</span><span id="line-192"></span><span>  </span><span id="HasInitializeTEEmbedLayerNormInputF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Encoder.html#HasInitializeTEEmbedLayerNormInputF"><span class="hs-identifier hs-var">HasInitializeTEEmbedLayerNormInputF</span></a></span></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#ByT5"><span class="hs-identifier hs-type">ByT5</span></a></span><span> </span><span id="local-6989586621679771387"><span class="annot"><a href="#local-6989586621679771387"><span class="hs-identifier hs-type hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679771386"><span class="annot"><a href="#local-6989586621679771386"><span class="hs-identifier hs-type hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679771385"><span class="annot"><a href="#local-6989586621679771385"><span class="hs-identifier hs-type hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679771384"><span class="annot"><a href="#local-6989586621679771384"><span class="hs-identifier hs-type hs-type">inputEmbedDim</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Encoder.html#HasInitializeTEEmbedLayerNormInputF"><span class="hs-identifier hs-type">HasInitializeTEEmbedLayerNormInputF</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#T5"><span class="hs-identifier hs-type">T5</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771387"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771386"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771385"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771384"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span><span>
</span><span id="line-193"></span><span>  </span><span id="HasInitializeTEEmbedLayerNormInputF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Encoder.html#HasInitializeTEEmbedLayerNormInputF"><span class="hs-identifier hs-var">HasInitializeTEEmbedLayerNormInputF</span></a></span></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#BART"><span class="hs-identifier hs-type">BART</span></a></span><span> </span><span id="local-6989586621679771383"><span class="annot"><a href="#local-6989586621679771383"><span class="hs-identifier hs-type hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679771382"><span class="annot"><a href="#local-6989586621679771382"><span class="hs-identifier hs-type hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679771381"><span class="annot"><a href="#local-6989586621679771381"><span class="hs-identifier hs-type hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679771380"><span class="annot"><a href="#local-6989586621679771380"><span class="hs-identifier hs-type hs-type">inputEmbedDim</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#SGradient"><span class="hs-identifier hs-type">SGradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771383"><span class="hs-identifier hs-type">gradient</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#SDevice"><span class="hs-identifier hs-type">SDevice</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771382"><span class="hs-identifier hs-type">device</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#SDataType"><span class="hs-identifier hs-type">SDataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771381"><span class="hs-identifier hs-type">dataType</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SShape"><span class="hs-identifier hs-type">SShape</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Shape"><span class="hs-identifier hs-type">Shape</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="annot"><a href="#local-6989586621679771380"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span><span class="hs-special">]</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Double</span></span><span class="hs-special">)</span><span>
</span><span id="line-194"></span><span>  </span><span id="HasInitializeTEEmbedLayerNormInputF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Encoder.html#HasInitializeTEEmbedLayerNormInputF"><span class="hs-identifier hs-var">HasInitializeTEEmbedLayerNormInputF</span></a></span></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#MBART"><span class="hs-identifier hs-type">MBART</span></a></span><span> </span><span id="local-6989586621679771379"><span class="annot"><a href="#local-6989586621679771379"><span class="hs-identifier hs-type hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679771378"><span class="annot"><a href="#local-6989586621679771378"><span class="hs-identifier hs-type hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679771377"><span class="annot"><a href="#local-6989586621679771377"><span class="hs-identifier hs-type hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679771376"><span class="annot"><a href="#local-6989586621679771376"><span class="hs-identifier hs-type hs-type">inputEmbedDim</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Encoder.html#HasInitializeTEEmbedLayerNormInputF"><span class="hs-identifier hs-type">HasInitializeTEEmbedLayerNormInputF</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#BART"><span class="hs-identifier hs-type">BART</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771379"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771378"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771377"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771376"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span><span>
</span><span id="line-195"></span><span>  </span><span id="HasInitializeTEEmbedLayerNormInputF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Encoder.html#HasInitializeTEEmbedLayerNormInputF"><span class="hs-identifier hs-var">HasInitializeTEEmbedLayerNormInputF</span></a></span></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#Pegasus"><span class="hs-identifier hs-type">Pegasus</span></a></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="hs-special">(</span><span class="hs-special">)</span><span>
</span><span id="line-196"></span><span>  </span><span id="HasInitializeTEEmbedLayerNormInputF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Encoder.html#HasInitializeTEEmbedLayerNormInputF"><span class="hs-identifier hs-var">HasInitializeTEEmbedLayerNormInputF</span></a></span></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#BERT"><span class="hs-identifier hs-type">BERT</span></a></span><span> </span><span id="local-6989586621679771375"><span class="annot"><a href="#local-6989586621679771375"><span class="hs-identifier hs-type hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679771374"><span class="annot"><a href="#local-6989586621679771374"><span class="hs-identifier hs-type hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679771373"><span class="annot"><a href="#local-6989586621679771373"><span class="hs-identifier hs-type hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679771372"><span class="annot"><a href="#local-6989586621679771372"><span class="hs-identifier hs-type hs-type">inputEmbedDim</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#SGradient"><span class="hs-identifier hs-type">SGradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771375"><span class="hs-identifier hs-type">gradient</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#SDevice"><span class="hs-identifier hs-type">SDevice</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771374"><span class="hs-identifier hs-type">device</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#SDataType"><span class="hs-identifier hs-type">SDataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771373"><span class="hs-identifier hs-type">dataType</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SShape"><span class="hs-identifier hs-type">SShape</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Shape"><span class="hs-identifier hs-type">Shape</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="annot"><a href="#local-6989586621679771372"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span><span class="hs-special">]</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Double</span></span><span class="hs-special">)</span><span>
</span><span id="line-197"></span><span>  </span><span id="HasInitializeTEEmbedLayerNormInputF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Encoder.html#HasInitializeTEEmbedLayerNormInputF"><span class="hs-identifier hs-var">HasInitializeTEEmbedLayerNormInputF</span></a></span></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#RoBERTa"><span class="hs-identifier hs-type">RoBERTa</span></a></span><span> </span><span id="local-6989586621679771371"><span class="annot"><a href="#local-6989586621679771371"><span class="hs-identifier hs-type hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679771370"><span class="annot"><a href="#local-6989586621679771370"><span class="hs-identifier hs-type hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679771369"><span class="annot"><a href="#local-6989586621679771369"><span class="hs-identifier hs-type hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679771368"><span class="annot"><a href="#local-6989586621679771368"><span class="hs-identifier hs-type hs-type">inputEmbedDim</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Encoder.html#HasInitializeTEEmbedLayerNormInputF"><span class="hs-identifier hs-type">HasInitializeTEEmbedLayerNormInputF</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#BERT"><span class="hs-identifier hs-type">BERT</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771371"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771370"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771369"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771368"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span><span>
</span><span id="line-198"></span><span>
</span><span id="line-199"></span><span class="hs-keyword">type</span><span> </span><span class="hs-keyword">family</span><span>
</span><span id="line-200"></span><span>  </span><span id="HasInitializeTELayerNormInputF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Encoder.html#HasInitializeTELayerNormInputF"><span class="hs-identifier hs-var">HasInitializeTELayerNormInputF</span></a></span></span><span>
</span><span id="line-201"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679771367"><span class="annot"><a href="#local-6989586621679771367"><span class="hs-identifier hs-type">style</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#TransformerStyle"><span class="hs-identifier hs-type">TransformerStyle</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-202"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679771366"><span class="annot"><a href="#local-6989586621679771366"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#Gradient"><span class="hs-identifier hs-type">Gradient</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#RequiresGradient"><span class="hs-identifier hs-type">RequiresGradient</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-203"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679771365"><span class="annot"><a href="#local-6989586621679771365"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#Device"><span class="hs-identifier hs-type">Device</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#DeviceType"><span class="hs-identifier hs-type">DeviceType</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-204"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679771364"><span class="annot"><a href="#local-6989586621679771364"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#DataType"><span class="hs-identifier hs-type">DataType</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#DType"><span class="hs-identifier hs-type">DType</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-205"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679771363"><span class="annot"><a href="#local-6989586621679771363"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Symbol</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-206"></span><span>    </span><span class="annot"><span class="hs-identifier hs-type">Type</span></span><span>
</span><span id="line-207"></span><span>  </span><span class="hs-keyword">where</span><span>
</span><span id="line-208"></span><span>  </span><span id="HasInitializeTELayerNormInputF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Encoder.html#HasInitializeTELayerNormInputF"><span class="hs-identifier hs-var">HasInitializeTELayerNormInputF</span></a></span></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#T5"><span class="hs-identifier hs-type">T5</span></a></span><span> </span><span id="local-6989586621679771362"><span class="annot"><a href="#local-6989586621679771362"><span class="hs-identifier hs-type hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679771361"><span class="annot"><a href="#local-6989586621679771361"><span class="hs-identifier hs-type hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679771360"><span class="annot"><a href="#local-6989586621679771360"><span class="hs-identifier hs-type hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679771359"><span class="annot"><a href="#local-6989586621679771359"><span class="hs-identifier hs-type hs-type">inputEmbedDim</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#SGradient"><span class="hs-identifier hs-type">SGradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771362"><span class="hs-identifier hs-type">gradient</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#SDevice"><span class="hs-identifier hs-type">SDevice</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771361"><span class="hs-identifier hs-type">device</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#SDataType"><span class="hs-identifier hs-type">SDataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771360"><span class="hs-identifier hs-type">dataType</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SShape"><span class="hs-identifier hs-type">SShape</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Shape"><span class="hs-identifier hs-type">Shape</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="annot"><a href="#local-6989586621679771359"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span><span class="hs-special">]</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Double</span></span><span class="hs-special">)</span><span>
</span><span id="line-209"></span><span>  </span><span id="HasInitializeTELayerNormInputF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Encoder.html#HasInitializeTELayerNormInputF"><span class="hs-identifier hs-var">HasInitializeTELayerNormInputF</span></a></span></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#ByT5"><span class="hs-identifier hs-type">ByT5</span></a></span><span> </span><span id="local-6989586621679771358"><span class="annot"><a href="#local-6989586621679771358"><span class="hs-identifier hs-type hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679771357"><span class="annot"><a href="#local-6989586621679771357"><span class="hs-identifier hs-type hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679771356"><span class="annot"><a href="#local-6989586621679771356"><span class="hs-identifier hs-type hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679771355"><span class="annot"><a href="#local-6989586621679771355"><span class="hs-identifier hs-type hs-type">inputEmbedDim</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Encoder.html#HasInitializeTELayerNormInputF"><span class="hs-identifier hs-type">HasInitializeTELayerNormInputF</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#T5"><span class="hs-identifier hs-type">T5</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771358"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771357"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771356"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771355"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span><span>
</span><span id="line-210"></span><span>  </span><span id="HasInitializeTELayerNormInputF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Encoder.html#HasInitializeTELayerNormInputF"><span class="hs-identifier hs-var">HasInitializeTELayerNormInputF</span></a></span></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#BART"><span class="hs-identifier hs-type">BART</span></a></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="hs-special">(</span><span class="hs-special">)</span><span>
</span><span id="line-211"></span><span>  </span><span id="HasInitializeTELayerNormInputF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Encoder.html#HasInitializeTELayerNormInputF"><span class="hs-identifier hs-var">HasInitializeTELayerNormInputF</span></a></span></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#MBART"><span class="hs-identifier hs-type">MBART</span></a></span><span> </span><span id="local-6989586621679771354"><span class="annot"><a href="#local-6989586621679771354"><span class="hs-identifier hs-type hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679771353"><span class="annot"><a href="#local-6989586621679771353"><span class="hs-identifier hs-type hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679771352"><span class="annot"><a href="#local-6989586621679771352"><span class="hs-identifier hs-type hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679771351"><span class="annot"><a href="#local-6989586621679771351"><span class="hs-identifier hs-type hs-type">inputEmbedDim</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Encoder.html#HasInitializeTELayerNormInputF"><span class="hs-identifier hs-type">HasInitializeTELayerNormInputF</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#BART"><span class="hs-identifier hs-type">BART</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771354"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771353"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771352"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771351"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span><span>
</span><span id="line-212"></span><span>  </span><span id="HasInitializeTELayerNormInputF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Encoder.html#HasInitializeTELayerNormInputF"><span class="hs-identifier hs-var">HasInitializeTELayerNormInputF</span></a></span></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#Pegasus"><span class="hs-identifier hs-type">Pegasus</span></a></span><span> </span><span id="local-6989586621679771350"><span class="annot"><a href="#local-6989586621679771350"><span class="hs-identifier hs-type hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679771349"><span class="annot"><a href="#local-6989586621679771349"><span class="hs-identifier hs-type hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679771348"><span class="annot"><a href="#local-6989586621679771348"><span class="hs-identifier hs-type hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679771347"><span class="annot"><a href="#local-6989586621679771347"><span class="hs-identifier hs-type hs-type">inputEmbedDim</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#SGradient"><span class="hs-identifier hs-type">SGradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771350"><span class="hs-identifier hs-type">gradient</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#SDevice"><span class="hs-identifier hs-type">SDevice</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771349"><span class="hs-identifier hs-type">device</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#SDataType"><span class="hs-identifier hs-type">SDataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771348"><span class="hs-identifier hs-type">dataType</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SShape"><span class="hs-identifier hs-type">SShape</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Shape"><span class="hs-identifier hs-type">Shape</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="annot"><a href="#local-6989586621679771347"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span><span class="hs-special">]</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Double</span></span><span class="hs-special">)</span><span>
</span><span id="line-213"></span><span>  </span><span id="HasInitializeTELayerNormInputF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Encoder.html#HasInitializeTELayerNormInputF"><span class="hs-identifier hs-var">HasInitializeTELayerNormInputF</span></a></span></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#BERT"><span class="hs-identifier hs-type">BERT</span></a></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="hs-special">(</span><span class="hs-special">)</span><span>
</span><span id="line-214"></span><span>  </span><span id="HasInitializeTELayerNormInputF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Encoder.html#HasInitializeTELayerNormInputF"><span class="hs-identifier hs-var">HasInitializeTELayerNormInputF</span></a></span></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#RoBERTa"><span class="hs-identifier hs-type">RoBERTa</span></a></span><span> </span><span id="local-6989586621679771346"><span class="annot"><a href="#local-6989586621679771346"><span class="hs-identifier hs-type hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679771345"><span class="annot"><a href="#local-6989586621679771345"><span class="hs-identifier hs-type hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679771344"><span class="annot"><a href="#local-6989586621679771344"><span class="hs-identifier hs-type hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679771343"><span class="annot"><a href="#local-6989586621679771343"><span class="hs-identifier hs-type hs-type">inputEmbedDim</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Encoder.html#HasInitializeTELayerNormInputF"><span class="hs-identifier hs-type">HasInitializeTELayerNormInputF</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#BERT"><span class="hs-identifier hs-type">BERT</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771346"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771345"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771344"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771343"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span><span>
</span><span id="line-215"></span><span>
</span><span id="line-216"></span><span class="hs-keyword">type</span><span> </span><span class="hs-keyword">family</span><span>
</span><span id="line-217"></span><span>  </span><span id="HasInitializeTEPosEncInputF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Encoder.html#HasInitializeTEPosEncInputF"><span class="hs-identifier hs-var">HasInitializeTEPosEncInputF</span></a></span></span><span>
</span><span id="line-218"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679771342"><span class="annot"><a href="#local-6989586621679771342"><span class="hs-identifier hs-type">style</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#TransformerStyle"><span class="hs-identifier hs-type">TransformerStyle</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-219"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679771341"><span class="annot"><a href="#local-6989586621679771341"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#Gradient"><span class="hs-identifier hs-type">Gradient</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#RequiresGradient"><span class="hs-identifier hs-type">RequiresGradient</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-220"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679771340"><span class="annot"><a href="#local-6989586621679771340"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#Device"><span class="hs-identifier hs-type">Device</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#DeviceType"><span class="hs-identifier hs-type">DeviceType</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-221"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679771339"><span class="annot"><a href="#local-6989586621679771339"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#DataType"><span class="hs-identifier hs-type">DataType</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#DType"><span class="hs-identifier hs-type">DType</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-222"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679771338"><span class="annot"><a href="#local-6989586621679771338"><span class="hs-identifier hs-type">headDim</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Symbol</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-223"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679771337"><span class="annot"><a href="#local-6989586621679771337"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Symbol</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-224"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679771336"><span class="annot"><a href="#local-6989586621679771336"><span class="hs-identifier hs-type">posEncDim</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Symbol</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-225"></span><span>    </span><span class="annot"><span class="hs-identifier hs-type">Type</span></span><span>
</span><span id="line-226"></span><span>  </span><span class="hs-keyword">where</span><span>
</span><span id="line-227"></span><span>  </span><span id="HasInitializeTEPosEncInputF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Encoder.html#HasInitializeTEPosEncInputF"><span class="hs-identifier hs-var">HasInitializeTEPosEncInputF</span></a></span></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#T5"><span class="hs-identifier hs-type">T5</span></a></span><span> </span><span id="local-6989586621679771335"><span class="annot"><a href="#local-6989586621679771335"><span class="hs-identifier hs-type hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679771334"><span class="annot"><a href="#local-6989586621679771334"><span class="hs-identifier hs-type hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679771333"><span class="annot"><a href="#local-6989586621679771333"><span class="hs-identifier hs-type hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679771332"><span class="annot"><a href="#local-6989586621679771332"><span class="hs-identifier hs-type hs-type">headDim</span></a></span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span id="local-6989586621679771331"><span class="annot"><a href="#local-6989586621679771331"><span class="hs-identifier hs-type hs-type">posEncDim</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#SGradient"><span class="hs-identifier hs-type">SGradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771335"><span class="hs-identifier hs-type">gradient</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#SLayout"><span class="hs-identifier hs-type">SLayout</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#Layout"><span class="hs-identifier hs-type">Layout</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#Dense"><span class="hs-identifier hs-type">Dense</span></a></span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#SDevice"><span class="hs-identifier hs-type">SDevice</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771334"><span class="hs-identifier hs-type">device</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#SDataType"><span class="hs-identifier hs-type">SDataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771333"><span class="hs-identifier hs-type">dataType</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SDim"><span class="hs-identifier hs-type">SDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771331"><span class="hs-identifier hs-type">posEncDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SDim"><span class="hs-identifier hs-type">SDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771332"><span class="hs-identifier hs-type">headDim</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-228"></span><span>  </span><span id="HasInitializeTEPosEncInputF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Encoder.html#HasInitializeTEPosEncInputF"><span class="hs-identifier hs-var">HasInitializeTEPosEncInputF</span></a></span></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#ByT5"><span class="hs-identifier hs-type">ByT5</span></a></span><span> </span><span id="local-6989586621679771330"><span class="annot"><a href="#local-6989586621679771330"><span class="hs-identifier hs-type hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679771329"><span class="annot"><a href="#local-6989586621679771329"><span class="hs-identifier hs-type hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679771328"><span class="annot"><a href="#local-6989586621679771328"><span class="hs-identifier hs-type hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679771327"><span class="annot"><a href="#local-6989586621679771327"><span class="hs-identifier hs-type hs-type">headDim</span></a></span></span><span> </span><span id="local-6989586621679771326"><span class="annot"><a href="#local-6989586621679771326"><span class="hs-identifier hs-type hs-type">inputEmbedDim</span></a></span></span><span> </span><span id="local-6989586621679771325"><span class="annot"><a href="#local-6989586621679771325"><span class="hs-identifier hs-type hs-type">posEncDim</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Encoder.html#HasInitializeTEPosEncInputF"><span class="hs-identifier hs-type">HasInitializeTEPosEncInputF</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#T5"><span class="hs-identifier hs-type">T5</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771330"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771329"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771328"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771327"><span class="hs-identifier hs-type">headDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771326"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771325"><span class="hs-identifier hs-type">posEncDim</span></a></span><span>
</span><span id="line-229"></span><span>  </span><span id="HasInitializeTEPosEncInputF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Encoder.html#HasInitializeTEPosEncInputF"><span class="hs-identifier hs-var">HasInitializeTEPosEncInputF</span></a></span></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#BART"><span class="hs-identifier hs-type">BART</span></a></span><span> </span><span id="local-6989586621679771324"><span class="annot"><a href="#local-6989586621679771324"><span class="hs-identifier hs-type hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679771323"><span class="annot"><a href="#local-6989586621679771323"><span class="hs-identifier hs-type hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679771322"><span class="annot"><a href="#local-6989586621679771322"><span class="hs-identifier hs-type hs-type">dataType</span></a></span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span id="local-6989586621679771321"><span class="annot"><a href="#local-6989586621679771321"><span class="hs-identifier hs-type hs-type">inputEmbedDim</span></a></span></span><span> </span><span id="local-6989586621679771320"><span class="annot"><a href="#local-6989586621679771320"><span class="hs-identifier hs-type hs-type">posEncDim</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#SGradient"><span class="hs-identifier hs-type">SGradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771324"><span class="hs-identifier hs-type">gradient</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#SLayout"><span class="hs-identifier hs-type">SLayout</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#Layout"><span class="hs-identifier hs-type">Layout</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#Dense"><span class="hs-identifier hs-type">Dense</span></a></span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#SDevice"><span class="hs-identifier hs-type">SDevice</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771323"><span class="hs-identifier hs-type">device</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#SDataType"><span class="hs-identifier hs-type">SDataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771322"><span class="hs-identifier hs-type">dataType</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SDim"><span class="hs-identifier hs-type">SDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771320"><span class="hs-identifier hs-type">posEncDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SDim"><span class="hs-identifier hs-type">SDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771321"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-230"></span><span>  </span><span id="HasInitializeTEPosEncInputF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Encoder.html#HasInitializeTEPosEncInputF"><span class="hs-identifier hs-var">HasInitializeTEPosEncInputF</span></a></span></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#MBART"><span class="hs-identifier hs-type">MBART</span></a></span><span> </span><span id="local-6989586621679771319"><span class="annot"><a href="#local-6989586621679771319"><span class="hs-identifier hs-type hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679771318"><span class="annot"><a href="#local-6989586621679771318"><span class="hs-identifier hs-type hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679771317"><span class="annot"><a href="#local-6989586621679771317"><span class="hs-identifier hs-type hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679771316"><span class="annot"><a href="#local-6989586621679771316"><span class="hs-identifier hs-type hs-type">headDim</span></a></span></span><span> </span><span id="local-6989586621679771315"><span class="annot"><a href="#local-6989586621679771315"><span class="hs-identifier hs-type hs-type">inputEmbedDim</span></a></span></span><span> </span><span id="local-6989586621679771314"><span class="annot"><a href="#local-6989586621679771314"><span class="hs-identifier hs-type hs-type">posEncDim</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Encoder.html#HasInitializeTEPosEncInputF"><span class="hs-identifier hs-type">HasInitializeTEPosEncInputF</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#BART"><span class="hs-identifier hs-type">BART</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771319"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771318"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771317"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771316"><span class="hs-identifier hs-type">headDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771315"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771314"><span class="hs-identifier hs-type">posEncDim</span></a></span><span>
</span><span id="line-231"></span><span>  </span><span id="HasInitializeTEPosEncInputF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Encoder.html#HasInitializeTEPosEncInputF"><span class="hs-identifier hs-var">HasInitializeTEPosEncInputF</span></a></span></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#Pegasus"><span class="hs-identifier hs-type">Pegasus</span></a></span><span> </span><span id="local-6989586621679771313"><span class="annot"><a href="#local-6989586621679771313"><span class="hs-identifier hs-type hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679771312"><span class="annot"><a href="#local-6989586621679771312"><span class="hs-identifier hs-type hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679771311"><span class="annot"><a href="#local-6989586621679771311"><span class="hs-identifier hs-type hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679771310"><span class="annot"><a href="#local-6989586621679771310"><span class="hs-identifier hs-type hs-type">headDim</span></a></span></span><span> </span><span id="local-6989586621679771309"><span class="annot"><a href="#local-6989586621679771309"><span class="hs-identifier hs-type hs-type">inputEmbedDim</span></a></span></span><span> </span><span id="local-6989586621679771308"><span class="annot"><a href="#local-6989586621679771308"><span class="hs-identifier hs-type hs-type">posEncDim</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Encoder.html#HasInitializeTEPosEncInputF"><span class="hs-identifier hs-type">HasInitializeTEPosEncInputF</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#BART"><span class="hs-identifier hs-type">BART</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771313"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771312"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771311"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771310"><span class="hs-identifier hs-type">headDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771309"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771308"><span class="hs-identifier hs-type">posEncDim</span></a></span><span>
</span><span id="line-232"></span><span>  </span><span id="HasInitializeTEPosEncInputF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Encoder.html#HasInitializeTEPosEncInputF"><span class="hs-identifier hs-var">HasInitializeTEPosEncInputF</span></a></span></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#BERT"><span class="hs-identifier hs-type">BERT</span></a></span><span> </span><span id="local-6989586621679771307"><span class="annot"><a href="#local-6989586621679771307"><span class="hs-identifier hs-type hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679771306"><span class="annot"><a href="#local-6989586621679771306"><span class="hs-identifier hs-type hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679771305"><span class="annot"><a href="#local-6989586621679771305"><span class="hs-identifier hs-type hs-type">dataType</span></a></span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span id="local-6989586621679771304"><span class="annot"><a href="#local-6989586621679771304"><span class="hs-identifier hs-type hs-type">inputEmbedDim</span></a></span></span><span> </span><span id="local-6989586621679771303"><span class="annot"><a href="#local-6989586621679771303"><span class="hs-identifier hs-type hs-type">posEncDim</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#SGradient"><span class="hs-identifier hs-type">SGradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771307"><span class="hs-identifier hs-type">gradient</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#SLayout"><span class="hs-identifier hs-type">SLayout</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#Layout"><span class="hs-identifier hs-type">Layout</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#Dense"><span class="hs-identifier hs-type">Dense</span></a></span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#SDevice"><span class="hs-identifier hs-type">SDevice</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771306"><span class="hs-identifier hs-type">device</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#SDataType"><span class="hs-identifier hs-type">SDataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771305"><span class="hs-identifier hs-type">dataType</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SDim"><span class="hs-identifier hs-type">SDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771303"><span class="hs-identifier hs-type">posEncDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SDim"><span class="hs-identifier hs-type">SDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771304"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-233"></span><span>  </span><span id="HasInitializeTEPosEncInputF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Encoder.html#HasInitializeTEPosEncInputF"><span class="hs-identifier hs-var">HasInitializeTEPosEncInputF</span></a></span></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#RoBERTa"><span class="hs-identifier hs-type">RoBERTa</span></a></span><span> </span><span id="local-6989586621679771302"><span class="annot"><a href="#local-6989586621679771302"><span class="hs-identifier hs-type hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679771301"><span class="annot"><a href="#local-6989586621679771301"><span class="hs-identifier hs-type hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679771300"><span class="annot"><a href="#local-6989586621679771300"><span class="hs-identifier hs-type hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679771299"><span class="annot"><a href="#local-6989586621679771299"><span class="hs-identifier hs-type hs-type">headDim</span></a></span></span><span> </span><span id="local-6989586621679771298"><span class="annot"><a href="#local-6989586621679771298"><span class="hs-identifier hs-type hs-type">inputEmbedDim</span></a></span></span><span> </span><span id="local-6989586621679771297"><span class="annot"><a href="#local-6989586621679771297"><span class="hs-identifier hs-type hs-type">posEncDim</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Encoder.html#HasInitializeTEPosEncInputF"><span class="hs-identifier hs-type">HasInitializeTEPosEncInputF</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#BERT"><span class="hs-identifier hs-type">BERT</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771302"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771301"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771300"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771299"><span class="hs-identifier hs-type">headDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771298"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771297"><span class="hs-identifier hs-type">posEncDim</span></a></span><span>
</span><span id="line-234"></span><span>
</span><span id="line-235"></span><span id="local-6989586621679771275"><span id="local-6989586621679771276"><span id="local-6989586621679771277"><span id="local-6989586621679771278"><span id="local-6989586621679771279"><span id="local-6989586621679771280"><span id="local-6989586621679771281"><span id="local-6989586621679771282"><span id="local-6989586621679771283"><span id="local-6989586621679771284"><span id="local-6989586621679771285"><span id="local-6989586621679771286"><span id="local-6989586621679771287"><span id="local-6989586621679771288"><span id="local-6989586621679771289"><span id="local-6989586621679771290"><span id="local-6989586621679771291"><span id="local-6989586621679771292"><span id="local-6989586621679771293"><span id="local-6989586621679771294"><span id="local-6989586621679771295"><span id="local-6989586621679771296"><span class="hs-keyword">instance</span><span>
</span><span id="line-236"></span><span>  </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-type">SingI</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771296"><span class="hs-identifier hs-type">style</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-237"></span><span>    </span><span class="annot"><a href="#local-6989586621679771295"><span class="hs-identifier hs-type">stack</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Encoder.html#TEStackF"><span class="hs-identifier hs-type">TEStackF</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771296"><span class="hs-identifier hs-type">style</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771294"><span class="hs-identifier hs-type">numLayers</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771293"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771292"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771291"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771290"><span class="hs-identifier hs-type">headDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771289"><span class="hs-identifier hs-type">headEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771288"><span class="hs-identifier hs-type">embedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771287"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771286"><span class="hs-identifier hs-type">ffnDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771285"><span class="hs-identifier hs-type">dropoutP</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-238"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasInitialize"><span class="hs-identifier hs-type">HasInitialize</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771295"><span class="hs-identifier hs-type">stack</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#SGradient"><span class="hs-identifier hs-type">SGradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771293"><span class="hs-identifier hs-type">gradient</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#SDevice"><span class="hs-identifier hs-type">SDevice</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771292"><span class="hs-identifier hs-type">device</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#SDataType"><span class="hs-identifier hs-type">SDataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771291"><span class="hs-identifier hs-type">dataType</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SDim"><span class="hs-identifier hs-type">SDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771290"><span class="hs-identifier hs-type">headDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SDim"><span class="hs-identifier hs-type">SDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771289"><span class="hs-identifier hs-type">headEmbedDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SDim"><span class="hs-identifier hs-type">SDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771288"><span class="hs-identifier hs-type">embedDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SDim"><span class="hs-identifier hs-type">SDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771287"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SDim"><span class="hs-identifier hs-type">SDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771286"><span class="hs-identifier hs-type">ffnDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679771285"><span class="hs-identifier hs-type">dropoutP</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Double</span></span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679771284"><span class="hs-identifier hs-type">generator</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771283"><span class="hs-identifier hs-type">generator'</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-239"></span><span>    </span><span class="annot"><a href="#local-6989586621679771282"><span class="hs-identifier hs-type">embedLayerNorm</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Encoder.html#TEEmbedLayerNormF"><span class="hs-identifier hs-type">TEEmbedLayerNormF</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771296"><span class="hs-identifier hs-type">style</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771293"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771292"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771291"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771287"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-240"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasInitialize"><span class="hs-identifier hs-type">HasInitialize</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771282"><span class="hs-identifier hs-type">embedLayerNorm</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Encoder.html#HasInitializeTEEmbedLayerNormInputF"><span class="hs-identifier hs-type">HasInitializeTEEmbedLayerNormInputF</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771296"><span class="hs-identifier hs-type">style</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771293"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771292"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771291"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771287"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679771283"><span class="hs-identifier hs-type">generator'</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771281"><span class="hs-identifier hs-type">generator''</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-241"></span><span>    </span><span class="annot"><a href="#local-6989586621679771280"><span class="hs-identifier hs-type">layerNorm</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Encoder.html#TELayerNormF"><span class="hs-identifier hs-type">TELayerNormF</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771296"><span class="hs-identifier hs-type">style</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771293"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771292"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771291"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771287"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-242"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasInitialize"><span class="hs-identifier hs-type">HasInitialize</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771280"><span class="hs-identifier hs-type">layerNorm</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Encoder.html#HasInitializeTELayerNormInputF"><span class="hs-identifier hs-type">HasInitializeTELayerNormInputF</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771296"><span class="hs-identifier hs-type">style</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771293"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771292"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771291"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771287"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679771281"><span class="hs-identifier hs-type">generator''</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771279"><span class="hs-identifier hs-type">generator'''</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-243"></span><span>    </span><span class="annot"><a href="#local-6989586621679771278"><span class="hs-identifier hs-type">dropout</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Encoder.html#TEDropoutF"><span class="hs-identifier hs-type">TEDropoutF</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771296"><span class="hs-identifier hs-type">style</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771285"><span class="hs-identifier hs-type">dropoutP</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-244"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasInitialize"><span class="hs-identifier hs-type">HasInitialize</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771278"><span class="hs-identifier hs-type">dropout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771285"><span class="hs-identifier hs-type">dropoutP</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771279"><span class="hs-identifier hs-type">generator'''</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771279"><span class="hs-identifier hs-type">generator'''</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-245"></span><span>    </span><span class="annot"><a href="#local-6989586621679771277"><span class="hs-identifier hs-type">posEnc</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Encoder.html#TEPosEncF"><span class="hs-identifier hs-type">TEPosEncF</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771296"><span class="hs-identifier hs-type">style</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771293"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771292"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771291"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771290"><span class="hs-identifier hs-type">headDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771287"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771276"><span class="hs-identifier hs-type">posEncDim</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-246"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasInitialize"><span class="hs-identifier hs-type">HasInitialize</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771277"><span class="hs-identifier hs-type">posEnc</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Encoder.html#HasInitializeTEPosEncInputF"><span class="hs-identifier hs-type">HasInitializeTEPosEncInputF</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771296"><span class="hs-identifier hs-type">style</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771293"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771292"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771291"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771290"><span class="hs-identifier hs-type">headDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771287"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771276"><span class="hs-identifier hs-type">posEncDim</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679771279"><span class="hs-identifier hs-type">generator'''</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771275"><span class="hs-identifier hs-type">generator''''</span></a></span><span>
</span><span id="line-247"></span><span>  </span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-248"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasInitialize"><span class="hs-identifier hs-type">HasInitialize</span></a></span><span>
</span><span id="line-249"></span><span>    </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Encoder.html#TransformerEncoder"><span class="hs-identifier hs-type">TransformerEncoder</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771296"><span class="hs-identifier hs-type">style</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771294"><span class="hs-identifier hs-type">numLayers</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771293"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771292"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771291"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771290"><span class="hs-identifier hs-type">headDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771289"><span class="hs-identifier hs-type">headEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771288"><span class="hs-identifier hs-type">embedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771287"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771286"><span class="hs-identifier hs-type">ffnDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771276"><span class="hs-identifier hs-type">posEncDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771285"><span class="hs-identifier hs-type">dropoutP</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-250"></span><span>    </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#SGradient"><span class="hs-identifier hs-type">SGradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771293"><span class="hs-identifier hs-type">gradient</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#SDevice"><span class="hs-identifier hs-type">SDevice</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771292"><span class="hs-identifier hs-type">device</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#SDataType"><span class="hs-identifier hs-type">SDataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771291"><span class="hs-identifier hs-type">dataType</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SDim"><span class="hs-identifier hs-type">SDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771290"><span class="hs-identifier hs-type">headDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SDim"><span class="hs-identifier hs-type">SDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771289"><span class="hs-identifier hs-type">headEmbedDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SDim"><span class="hs-identifier hs-type">SDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771288"><span class="hs-identifier hs-type">embedDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SDim"><span class="hs-identifier hs-type">SDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771287"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SDim"><span class="hs-identifier hs-type">SDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771286"><span class="hs-identifier hs-type">ffnDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SDim"><span class="hs-identifier hs-type">SDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771276"><span class="hs-identifier hs-type">posEncDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679771285"><span class="hs-identifier hs-type">dropoutP</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Double</span></span><span class="hs-special">)</span><span>
</span><span id="line-251"></span><span>    </span><span class="annot"><a href="#local-6989586621679771284"><span class="hs-identifier hs-type">generator</span></a></span><span>
</span><span id="line-252"></span><span>    </span><span class="annot"><a href="#local-6989586621679771275"><span class="hs-identifier hs-type">generator''''</span></a></span><span>
</span><span id="line-253"></span><span>  </span><span class="hs-keyword">where</span><span>
</span><span id="line-254"></span><span>  </span><span id="local-6989586621679771272"><span class="annot"><span class="annottext">initialize :: (SGradient gradient, SDevice device, SDataType dataType,
 SDim headDim, SDim headEmbedDim, SDim embedDim, SDim inputEmbedDim,
 SDim ffnDim, SDim posEncDim, dropoutP, Double)
-&gt; generator
-&gt; (TransformerEncoder
      style
      numLayers
      gradient
      device
      dataType
      headDim
      headEmbedDim
      embedDim
      inputEmbedDim
      ffnDim
      posEncDim
      dropoutP,
    generator'''')
</span><a href="Torch.GraduallyTyped.NN.Class.html#initialize"><span class="hs-identifier hs-var hs-var hs-var hs-var">initialize</span></a></span></span><span> </span><span class="hs-special">(</span><span id="local-6989586621679771270"><span class="annot"><span class="annottext">SGradient gradient
</span><a href="#local-6989586621679771270"><span class="hs-identifier hs-var">gradient</span></a></span></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679771269"><span class="annot"><span class="annottext">SDevice device
</span><a href="#local-6989586621679771269"><span class="hs-identifier hs-var">device</span></a></span></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679771268"><span class="annot"><span class="annottext">SDataType dataType
</span><a href="#local-6989586621679771268"><span class="hs-identifier hs-var">dataType</span></a></span></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679771267"><span class="annot"><span class="annottext">SDim headDim
</span><a href="#local-6989586621679771267"><span class="hs-identifier hs-var">headDim</span></a></span></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679771266"><span class="annot"><span class="annottext">SDim headEmbedDim
</span><a href="#local-6989586621679771266"><span class="hs-identifier hs-var">headEmbedDim</span></a></span></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679771265"><span class="annot"><span class="annottext">SDim embedDim
</span><a href="#local-6989586621679771265"><span class="hs-identifier hs-var">embedDim</span></a></span></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679771264"><span class="annot"><span class="annottext">SDim inputEmbedDim
</span><a href="#local-6989586621679771264"><span class="hs-identifier hs-var">inputEmbedDim</span></a></span></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679771263"><span class="annot"><span class="annottext">SDim ffnDim
</span><a href="#local-6989586621679771263"><span class="hs-identifier hs-var">ffnDim</span></a></span></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679771262"><span class="annot"><span class="annottext">SDim posEncDim
</span><a href="#local-6989586621679771262"><span class="hs-identifier hs-var">posEncDim</span></a></span></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679771261"><span class="annot"><span class="annottext">dropoutP
</span><a href="#local-6989586621679771261"><span class="hs-identifier hs-var">dropoutP</span></a></span></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679771260"><span class="annot"><span class="annottext">Double
</span><a href="#local-6989586621679771260"><span class="hs-identifier hs-var">eps</span></a></span></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-255"></span><span>    </span><span class="hs-keyword">let</span><span> </span><span id="local-6989586621679771259"><span class="annot"><span class="annottext">stack :: IxState
  generator
  generator'
  (TransformerStack
     style
     numLayers
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     inputEmbedDim
     ffnDim
     dropoutP)
</span><a href="#local-6989586621679771259"><span class="hs-identifier hs-var hs-var">stack</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">(generator
 -&gt; (TransformerStack
       style
       numLayers
       gradient
       device
       dataType
       headDim
       headEmbedDim
       embedDim
       inputEmbedDim
       ffnDim
       dropoutP,
     generator'))
-&gt; IxState
     generator
     generator'
     (TransformerStack
        style
        numLayers
        gradient
        device
        dataType
        headDim
        headEmbedDim
        embedDim
        inputEmbedDim
        ffnDim
        dropoutP)
forall i j a. (i -&gt; (a, j)) -&gt; IxState i j a
</span><a href="../file:///nix/store/8vjaffqxij7bih93d9mlzmc7ksanlw0i-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier hs-var">IxState</span></a></span><span> </span><span class="annot"><span class="annottext">((generator
  -&gt; (TransformerStack
        style
        numLayers
        gradient
        device
        dataType
        headDim
        headEmbedDim
        embedDim
        inputEmbedDim
        ffnDim
        dropoutP,
      generator'))
 -&gt; IxState
      generator
      generator'
      (TransformerStack
         style
         numLayers
         gradient
         device
         dataType
         headDim
         headEmbedDim
         embedDim
         inputEmbedDim
         ffnDim
         dropoutP))
-&gt; ((SGradient gradient, SDevice device, SDataType dataType,
     SDim headDim, SDim headEmbedDim, SDim embedDim, SDim inputEmbedDim,
     SDim ffnDim, dropoutP, Double)
    -&gt; generator
    -&gt; (TransformerStack
          style
          numLayers
          gradient
          device
          dataType
          headDim
          headEmbedDim
          embedDim
          inputEmbedDim
          ffnDim
          dropoutP,
        generator'))
-&gt; (SGradient gradient, SDevice device, SDataType dataType,
    SDim headDim, SDim headEmbedDim, SDim embedDim, SDim inputEmbedDim,
    SDim ffnDim, dropoutP, Double)
-&gt; IxState
     generator
     generator'
     (TransformerStack
        style
        numLayers
        gradient
        device
        dataType
        headDim
        headEmbedDim
        embedDim
        inputEmbedDim
        ffnDim
        dropoutP)
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">(SGradient gradient, SDevice device, SDataType dataType,
 SDim headDim, SDim headEmbedDim, SDim embedDim, SDim inputEmbedDim,
 SDim ffnDim, dropoutP, Double)
-&gt; generator
-&gt; (TransformerStack
      style
      numLayers
      gradient
      device
      dataType
      headDim
      headEmbedDim
      embedDim
      inputEmbedDim
      ffnDim
      dropoutP,
    generator')
forall model input generator generatorOutput.
HasInitialize model input generator generatorOutput =&gt;
input -&gt; generator -&gt; (model, generatorOutput)
</span><a href="Torch.GraduallyTyped.NN.Class.html#initialize"><span class="hs-identifier hs-var">initialize</span></a></span><span> </span><span class="annot"><span class="annottext">((SGradient gradient, SDevice device, SDataType dataType,
  SDim headDim, SDim headEmbedDim, SDim embedDim, SDim inputEmbedDim,
  SDim ffnDim, dropoutP, Double)
 -&gt; IxState
      generator
      generator'
      (TransformerStack
         style
         numLayers
         gradient
         device
         dataType
         headDim
         headEmbedDim
         embedDim
         inputEmbedDim
         ffnDim
         dropoutP))
-&gt; (SGradient gradient, SDevice device, SDataType dataType,
    SDim headDim, SDim headEmbedDim, SDim embedDim, SDim inputEmbedDim,
    SDim ffnDim, dropoutP, Double)
-&gt; IxState
     generator
     generator'
     (TransformerStack
        style
        numLayers
        gradient
        device
        dataType
        headDim
        headEmbedDim
        embedDim
        inputEmbedDim
        ffnDim
        dropoutP)
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SGradient gradient
</span><a href="#local-6989586621679771270"><span class="hs-identifier hs-var">gradient</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDevice device
</span><a href="#local-6989586621679771269"><span class="hs-identifier hs-var">device</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDataType dataType
</span><a href="#local-6989586621679771268"><span class="hs-identifier hs-var">dataType</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDim headDim
</span><a href="#local-6989586621679771267"><span class="hs-identifier hs-var">headDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDim headEmbedDim
</span><a href="#local-6989586621679771266"><span class="hs-identifier hs-var">headEmbedDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDim embedDim
</span><a href="#local-6989586621679771265"><span class="hs-identifier hs-var">embedDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDim inputEmbedDim
</span><a href="#local-6989586621679771264"><span class="hs-identifier hs-var">inputEmbedDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDim ffnDim
</span><a href="#local-6989586621679771263"><span class="hs-identifier hs-var">ffnDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">dropoutP
</span><a href="#local-6989586621679771261"><span class="hs-identifier hs-var">dropoutP</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">Double
</span><a href="#local-6989586621679771260"><span class="hs-identifier hs-var">eps</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-256"></span><span>        </span><span id="local-6989586621679771256"><span class="annot"><span class="annottext">embedLayerNorm :: IxState generator' generator'' embedLayerNorm
</span><a href="#local-6989586621679771256"><span class="hs-identifier hs-var hs-var">embedLayerNorm</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">(generator' -&gt; (embedLayerNorm, generator''))
-&gt; IxState generator' generator'' embedLayerNorm
forall i j a. (i -&gt; (a, j)) -&gt; IxState i j a
</span><a href="../file:///nix/store/8vjaffqxij7bih93d9mlzmc7ksanlw0i-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier hs-var">IxState</span></a></span><span> </span><span class="annot"><span class="annottext">((generator' -&gt; (embedLayerNorm, generator''))
 -&gt; IxState generator' generator'' embedLayerNorm)
-&gt; (HasInitializeTEEmbedLayerNormInputF
      style gradient device dataType inputEmbedDim
    -&gt; generator' -&gt; (embedLayerNorm, generator''))
-&gt; HasInitializeTEEmbedLayerNormInputF
     style gradient device dataType inputEmbedDim
-&gt; IxState generator' generator'' embedLayerNorm
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">HasInitializeTEEmbedLayerNormInputF
  style gradient device dataType inputEmbedDim
-&gt; generator' -&gt; (embedLayerNorm, generator'')
forall model input generator generatorOutput.
HasInitialize model input generator generatorOutput =&gt;
input -&gt; generator -&gt; (model, generatorOutput)
</span><a href="Torch.GraduallyTyped.NN.Class.html#initialize"><span class="hs-identifier hs-var">initialize</span></a></span><span> </span><span class="annot"><span class="annottext">(HasInitializeTEEmbedLayerNormInputF
   style gradient device dataType inputEmbedDim
 -&gt; IxState generator' generator'' embedLayerNorm)
-&gt; HasInitializeTEEmbedLayerNormInputF
     style gradient device dataType inputEmbedDim
-&gt; IxState generator' generator'' embedLayerNorm
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="hs-keyword">case</span><span> </span><span class="annot"><span class="annottext">SingI style =&gt; Sing style
forall k (a :: k). SingI a =&gt; Sing a
</span><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-var">sing</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679771296"><span class="hs-identifier hs-type">style</span></a></span><span> </span><span class="hs-keyword">of</span><span>
</span><span id="line-257"></span><span>          </span><span class="annot"><span class="annottext">Sing style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#ST5"><span class="hs-identifier hs-var">ST5</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="hs-special">(</span><span class="hs-special">)</span><span>
</span><span id="line-258"></span><span>          </span><span class="annot"><span class="annottext">Sing style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SByT5"><span class="hs-identifier hs-var">SByT5</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="hs-special">(</span><span class="hs-special">)</span><span>
</span><span id="line-259"></span><span>          </span><span class="annot"><span class="annottext">Sing style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SBART"><span class="hs-identifier hs-var">SBART</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SGradient gradient
</span><a href="#local-6989586621679771270"><span class="hs-identifier hs-var">gradient</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDevice device
</span><a href="#local-6989586621679771269"><span class="hs-identifier hs-var">device</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDataType dataType
</span><a href="#local-6989586621679771268"><span class="hs-identifier hs-var">dataType</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SList '[inputEmbedDim] -&gt; SShape ('Shape '[inputEmbedDim])
forall (dims :: [Dim (Name Symbol) (Size Nat)]).
SList dims -&gt; SShape ('Shape dims)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SShape"><span class="hs-identifier hs-var">SShape</span></a></span><span> </span><span class="annot"><span class="annottext">(SList '[inputEmbedDim] -&gt; SShape ('Shape '[inputEmbedDim]))
-&gt; SList '[inputEmbedDim] -&gt; SShape ('Shape '[inputEmbedDim])
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">SDim inputEmbedDim
</span><a href="#local-6989586621679771264"><span class="hs-identifier hs-var">inputEmbedDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim inputEmbedDim -&gt; SList '[] -&gt; SList '[inputEmbedDim]
forall (dim :: Dim (Name Symbol) (Size Nat))
       (dims :: [Dim (Name Symbol) (Size Nat)]).
SDim dim -&gt; SList dims -&gt; SList (dim : dims)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%7C%3A"><span class="hs-operator hs-var">:|:</span></a></span><span> </span><span class="annot"><span class="annottext">SList '[]
forall a. SList '[]
</span><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-var">SNil</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">Double
</span><a href="#local-6989586621679771260"><span class="hs-identifier hs-var">eps</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-260"></span><span>          </span><span class="annot"><span class="annottext">Sing style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SMBART"><span class="hs-identifier hs-var">SMBART</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SGradient gradient
</span><a href="#local-6989586621679771270"><span class="hs-identifier hs-var">gradient</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDevice device
</span><a href="#local-6989586621679771269"><span class="hs-identifier hs-var">device</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDataType dataType
</span><a href="#local-6989586621679771268"><span class="hs-identifier hs-var">dataType</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SList '[inputEmbedDim] -&gt; SShape ('Shape '[inputEmbedDim])
forall (dims :: [Dim (Name Symbol) (Size Nat)]).
SList dims -&gt; SShape ('Shape dims)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SShape"><span class="hs-identifier hs-var">SShape</span></a></span><span> </span><span class="annot"><span class="annottext">(SList '[inputEmbedDim] -&gt; SShape ('Shape '[inputEmbedDim]))
-&gt; SList '[inputEmbedDim] -&gt; SShape ('Shape '[inputEmbedDim])
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">SDim inputEmbedDim
</span><a href="#local-6989586621679771264"><span class="hs-identifier hs-var">inputEmbedDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim inputEmbedDim -&gt; SList '[] -&gt; SList '[inputEmbedDim]
forall (dim :: Dim (Name Symbol) (Size Nat))
       (dims :: [Dim (Name Symbol) (Size Nat)]).
SDim dim -&gt; SList dims -&gt; SList (dim : dims)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%7C%3A"><span class="hs-operator hs-var">:|:</span></a></span><span> </span><span class="annot"><span class="annottext">SList '[]
forall a. SList '[]
</span><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-var">SNil</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">Double
</span><a href="#local-6989586621679771260"><span class="hs-identifier hs-var">eps</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-261"></span><span>          </span><span class="annot"><span class="annottext">Sing style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SPegasus"><span class="hs-identifier hs-var">SPegasus</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="hs-special">(</span><span class="hs-special">)</span><span>
</span><span id="line-262"></span><span>          </span><span class="annot"><span class="annottext">Sing style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SBERT"><span class="hs-identifier hs-var">SBERT</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SGradient gradient
</span><a href="#local-6989586621679771270"><span class="hs-identifier hs-var">gradient</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDevice device
</span><a href="#local-6989586621679771269"><span class="hs-identifier hs-var">device</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDataType dataType
</span><a href="#local-6989586621679771268"><span class="hs-identifier hs-var">dataType</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SList '[inputEmbedDim] -&gt; SShape ('Shape '[inputEmbedDim])
forall (dims :: [Dim (Name Symbol) (Size Nat)]).
SList dims -&gt; SShape ('Shape dims)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SShape"><span class="hs-identifier hs-var">SShape</span></a></span><span> </span><span class="annot"><span class="annottext">(SList '[inputEmbedDim] -&gt; SShape ('Shape '[inputEmbedDim]))
-&gt; SList '[inputEmbedDim] -&gt; SShape ('Shape '[inputEmbedDim])
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">SDim inputEmbedDim
</span><a href="#local-6989586621679771264"><span class="hs-identifier hs-var">inputEmbedDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim inputEmbedDim -&gt; SList '[] -&gt; SList '[inputEmbedDim]
forall (dim :: Dim (Name Symbol) (Size Nat))
       (dims :: [Dim (Name Symbol) (Size Nat)]).
SDim dim -&gt; SList dims -&gt; SList (dim : dims)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%7C%3A"><span class="hs-operator hs-var">:|:</span></a></span><span> </span><span class="annot"><span class="annottext">SList '[]
forall a. SList '[]
</span><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-var">SNil</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">Double
</span><a href="#local-6989586621679771260"><span class="hs-identifier hs-var">eps</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-263"></span><span>          </span><span class="annot"><span class="annottext">Sing style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SRoBERTa"><span class="hs-identifier hs-var">SRoBERTa</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SGradient gradient
</span><a href="#local-6989586621679771270"><span class="hs-identifier hs-var">gradient</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDevice device
</span><a href="#local-6989586621679771269"><span class="hs-identifier hs-var">device</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDataType dataType
</span><a href="#local-6989586621679771268"><span class="hs-identifier hs-var">dataType</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SList '[inputEmbedDim] -&gt; SShape ('Shape '[inputEmbedDim])
forall (dims :: [Dim (Name Symbol) (Size Nat)]).
SList dims -&gt; SShape ('Shape dims)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SShape"><span class="hs-identifier hs-var">SShape</span></a></span><span> </span><span class="annot"><span class="annottext">(SList '[inputEmbedDim] -&gt; SShape ('Shape '[inputEmbedDim]))
-&gt; SList '[inputEmbedDim] -&gt; SShape ('Shape '[inputEmbedDim])
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">SDim inputEmbedDim
</span><a href="#local-6989586621679771264"><span class="hs-identifier hs-var">inputEmbedDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim inputEmbedDim -&gt; SList '[] -&gt; SList '[inputEmbedDim]
forall (dim :: Dim (Name Symbol) (Size Nat))
       (dims :: [Dim (Name Symbol) (Size Nat)]).
SDim dim -&gt; SList dims -&gt; SList (dim : dims)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%7C%3A"><span class="hs-operator hs-var">:|:</span></a></span><span> </span><span class="annot"><span class="annottext">SList '[]
forall a. SList '[]
</span><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-var">SNil</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">Double
</span><a href="#local-6989586621679771260"><span class="hs-identifier hs-var">eps</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-264"></span><span>          </span><span class="annot"><span class="annottext">Sing style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SGPT2"><span class="hs-identifier hs-var">SGPT2</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><span class="annottext">HasInitializeTEEmbedLayerNormInputF
  style gradient device dataType inputEmbedDim
forall a. HasCallStack =&gt; a
</span><span class="hs-identifier hs-var">undefined</span></span><span>
</span><span id="line-265"></span><span>        </span><span id="local-6989586621679771245"><span class="annot"><span class="annottext">layerNorm :: IxState generator'' generator''' layerNorm
</span><a href="#local-6989586621679771245"><span class="hs-identifier hs-var hs-var">layerNorm</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">(generator'' -&gt; (layerNorm, generator'''))
-&gt; IxState generator'' generator''' layerNorm
forall i j a. (i -&gt; (a, j)) -&gt; IxState i j a
</span><a href="../file:///nix/store/8vjaffqxij7bih93d9mlzmc7ksanlw0i-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier hs-var">IxState</span></a></span><span> </span><span class="annot"><span class="annottext">((generator'' -&gt; (layerNorm, generator'''))
 -&gt; IxState generator'' generator''' layerNorm)
-&gt; (HasInitializeTELayerNormInputF
      style gradient device dataType inputEmbedDim
    -&gt; generator'' -&gt; (layerNorm, generator'''))
-&gt; HasInitializeTELayerNormInputF
     style gradient device dataType inputEmbedDim
-&gt; IxState generator'' generator''' layerNorm
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">HasInitializeTELayerNormInputF
  style gradient device dataType inputEmbedDim
-&gt; generator'' -&gt; (layerNorm, generator''')
forall model input generator generatorOutput.
HasInitialize model input generator generatorOutput =&gt;
input -&gt; generator -&gt; (model, generatorOutput)
</span><a href="Torch.GraduallyTyped.NN.Class.html#initialize"><span class="hs-identifier hs-var">initialize</span></a></span><span> </span><span class="annot"><span class="annottext">(HasInitializeTELayerNormInputF
   style gradient device dataType inputEmbedDim
 -&gt; IxState generator'' generator''' layerNorm)
-&gt; HasInitializeTELayerNormInputF
     style gradient device dataType inputEmbedDim
-&gt; IxState generator'' generator''' layerNorm
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="hs-keyword">case</span><span> </span><span class="annot"><span class="annottext">SingI style =&gt; Sing style
forall k (a :: k). SingI a =&gt; Sing a
</span><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-var">sing</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679771296"><span class="hs-identifier hs-type">style</span></a></span><span> </span><span class="hs-keyword">of</span><span>
</span><span id="line-266"></span><span>          </span><span class="annot"><span class="annottext">Sing style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#ST5"><span class="hs-identifier hs-var">ST5</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SGradient gradient
</span><a href="#local-6989586621679771270"><span class="hs-identifier hs-var">gradient</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDevice device
</span><a href="#local-6989586621679771269"><span class="hs-identifier hs-var">device</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDataType dataType
</span><a href="#local-6989586621679771268"><span class="hs-identifier hs-var">dataType</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SList '[inputEmbedDim] -&gt; SShape ('Shape '[inputEmbedDim])
forall (dims :: [Dim (Name Symbol) (Size Nat)]).
SList dims -&gt; SShape ('Shape dims)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SShape"><span class="hs-identifier hs-var">SShape</span></a></span><span> </span><span class="annot"><span class="annottext">(SList '[inputEmbedDim] -&gt; SShape ('Shape '[inputEmbedDim]))
-&gt; SList '[inputEmbedDim] -&gt; SShape ('Shape '[inputEmbedDim])
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">SDim inputEmbedDim
</span><a href="#local-6989586621679771264"><span class="hs-identifier hs-var">inputEmbedDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim inputEmbedDim -&gt; SList '[] -&gt; SList '[inputEmbedDim]
forall (dim :: Dim (Name Symbol) (Size Nat))
       (dims :: [Dim (Name Symbol) (Size Nat)]).
SDim dim -&gt; SList dims -&gt; SList (dim : dims)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%7C%3A"><span class="hs-operator hs-var">:|:</span></a></span><span> </span><span class="annot"><span class="annottext">SList '[]
forall a. SList '[]
</span><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-var">SNil</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">Double
</span><a href="#local-6989586621679771260"><span class="hs-identifier hs-var">eps</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-267"></span><span>          </span><span class="annot"><span class="annottext">Sing style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SByT5"><span class="hs-identifier hs-var">SByT5</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SGradient gradient
</span><a href="#local-6989586621679771270"><span class="hs-identifier hs-var">gradient</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDevice device
</span><a href="#local-6989586621679771269"><span class="hs-identifier hs-var">device</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDataType dataType
</span><a href="#local-6989586621679771268"><span class="hs-identifier hs-var">dataType</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SList '[inputEmbedDim] -&gt; SShape ('Shape '[inputEmbedDim])
forall (dims :: [Dim (Name Symbol) (Size Nat)]).
SList dims -&gt; SShape ('Shape dims)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SShape"><span class="hs-identifier hs-var">SShape</span></a></span><span> </span><span class="annot"><span class="annottext">(SList '[inputEmbedDim] -&gt; SShape ('Shape '[inputEmbedDim]))
-&gt; SList '[inputEmbedDim] -&gt; SShape ('Shape '[inputEmbedDim])
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">SDim inputEmbedDim
</span><a href="#local-6989586621679771264"><span class="hs-identifier hs-var">inputEmbedDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim inputEmbedDim -&gt; SList '[] -&gt; SList '[inputEmbedDim]
forall (dim :: Dim (Name Symbol) (Size Nat))
       (dims :: [Dim (Name Symbol) (Size Nat)]).
SDim dim -&gt; SList dims -&gt; SList (dim : dims)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%7C%3A"><span class="hs-operator hs-var">:|:</span></a></span><span> </span><span class="annot"><span class="annottext">SList '[]
forall a. SList '[]
</span><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-var">SNil</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">Double
</span><a href="#local-6989586621679771260"><span class="hs-identifier hs-var">eps</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-268"></span><span>          </span><span class="annot"><span class="annottext">Sing style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SBART"><span class="hs-identifier hs-var">SBART</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="hs-special">(</span><span class="hs-special">)</span><span>
</span><span id="line-269"></span><span>          </span><span class="annot"><span class="annottext">Sing style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SMBART"><span class="hs-identifier hs-var">SMBART</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="hs-special">(</span><span class="hs-special">)</span><span>
</span><span id="line-270"></span><span>          </span><span class="annot"><span class="annottext">Sing style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SPegasus"><span class="hs-identifier hs-var">SPegasus</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SGradient gradient
</span><a href="#local-6989586621679771270"><span class="hs-identifier hs-var">gradient</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDevice device
</span><a href="#local-6989586621679771269"><span class="hs-identifier hs-var">device</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDataType dataType
</span><a href="#local-6989586621679771268"><span class="hs-identifier hs-var">dataType</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SList '[inputEmbedDim] -&gt; SShape ('Shape '[inputEmbedDim])
forall (dims :: [Dim (Name Symbol) (Size Nat)]).
SList dims -&gt; SShape ('Shape dims)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SShape"><span class="hs-identifier hs-var">SShape</span></a></span><span> </span><span class="annot"><span class="annottext">(SList '[inputEmbedDim] -&gt; SShape ('Shape '[inputEmbedDim]))
-&gt; SList '[inputEmbedDim] -&gt; SShape ('Shape '[inputEmbedDim])
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">SDim inputEmbedDim
</span><a href="#local-6989586621679771264"><span class="hs-identifier hs-var">inputEmbedDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim inputEmbedDim -&gt; SList '[] -&gt; SList '[inputEmbedDim]
forall (dim :: Dim (Name Symbol) (Size Nat))
       (dims :: [Dim (Name Symbol) (Size Nat)]).
SDim dim -&gt; SList dims -&gt; SList (dim : dims)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%7C%3A"><span class="hs-operator hs-var">:|:</span></a></span><span> </span><span class="annot"><span class="annottext">SList '[]
forall a. SList '[]
</span><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-var">SNil</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">Double
</span><a href="#local-6989586621679771260"><span class="hs-identifier hs-var">eps</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-271"></span><span>          </span><span class="annot"><span class="annottext">Sing style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SBERT"><span class="hs-identifier hs-var">SBERT</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="hs-special">(</span><span class="hs-special">)</span><span>
</span><span id="line-272"></span><span>          </span><span class="annot"><span class="annottext">Sing style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SRoBERTa"><span class="hs-identifier hs-var">SRoBERTa</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="hs-special">(</span><span class="hs-special">)</span><span>
</span><span id="line-273"></span><span>          </span><span class="annot"><span class="annottext">Sing style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SGPT2"><span class="hs-identifier hs-var">SGPT2</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><span class="annottext">HasInitializeTELayerNormInputF
  style gradient device dataType inputEmbedDim
forall a. HasCallStack =&gt; a
</span><span class="hs-identifier hs-var">undefined</span></span><span>
</span><span id="line-274"></span><span>        </span><span id="local-6989586621679771244"><span class="annot"><span class="annottext">dropout :: IxState generator''' generator''' (Dropout dropoutP)
</span><a href="#local-6989586621679771244"><span class="hs-identifier hs-var hs-var">dropout</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">(generator''' -&gt; (Dropout dropoutP, generator'''))
-&gt; IxState generator''' generator''' (Dropout dropoutP)
forall i j a. (i -&gt; (a, j)) -&gt; IxState i j a
</span><a href="../file:///nix/store/8vjaffqxij7bih93d9mlzmc7ksanlw0i-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier hs-var">IxState</span></a></span><span> </span><span class="annot"><span class="annottext">((generator''' -&gt; (Dropout dropoutP, generator'''))
 -&gt; IxState generator''' generator''' (Dropout dropoutP))
-&gt; (dropoutP -&gt; generator''' -&gt; (Dropout dropoutP, generator'''))
-&gt; dropoutP
-&gt; IxState generator''' generator''' (Dropout dropoutP)
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">dropoutP -&gt; generator''' -&gt; (Dropout dropoutP, generator''')
forall model input generator generatorOutput.
HasInitialize model input generator generatorOutput =&gt;
input -&gt; generator -&gt; (model, generatorOutput)
</span><a href="Torch.GraduallyTyped.NN.Class.html#initialize"><span class="hs-identifier hs-var">initialize</span></a></span><span> </span><span class="annot"><span class="annottext">(dropoutP -&gt; IxState generator''' generator''' (Dropout dropoutP))
-&gt; dropoutP -&gt; IxState generator''' generator''' (Dropout dropoutP)
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">dropoutP
</span><a href="#local-6989586621679771261"><span class="hs-identifier hs-var">dropoutP</span></a></span><span>
</span><span id="line-275"></span><span>        </span><span id="local-6989586621679771243"><span class="annot"><span class="annottext">posEnc :: IxState generator''' generator'''' posEnc
</span><a href="#local-6989586621679771243"><span class="hs-identifier hs-var hs-var">posEnc</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">(generator''' -&gt; (posEnc, generator''''))
-&gt; IxState generator''' generator'''' posEnc
forall i j a. (i -&gt; (a, j)) -&gt; IxState i j a
</span><a href="../file:///nix/store/8vjaffqxij7bih93d9mlzmc7ksanlw0i-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier hs-var">IxState</span></a></span><span> </span><span class="annot"><span class="annottext">((generator''' -&gt; (posEnc, generator''''))
 -&gt; IxState generator''' generator'''' posEnc)
-&gt; (HasInitializeTEPosEncInputF
      style gradient device dataType headDim inputEmbedDim posEncDim
    -&gt; generator''' -&gt; (posEnc, generator''''))
-&gt; HasInitializeTEPosEncInputF
     style gradient device dataType headDim inputEmbedDim posEncDim
-&gt; IxState generator''' generator'''' posEnc
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">HasInitializeTEPosEncInputF
  style gradient device dataType headDim inputEmbedDim posEncDim
-&gt; generator''' -&gt; (posEnc, generator'''')
forall model input generator generatorOutput.
HasInitialize model input generator generatorOutput =&gt;
input -&gt; generator -&gt; (model, generatorOutput)
</span><a href="Torch.GraduallyTyped.NN.Class.html#initialize"><span class="hs-identifier hs-var">initialize</span></a></span><span> </span><span class="annot"><span class="annottext">(HasInitializeTEPosEncInputF
   style gradient device dataType headDim inputEmbedDim posEncDim
 -&gt; IxState generator''' generator'''' posEnc)
-&gt; HasInitializeTEPosEncInputF
     style gradient device dataType headDim inputEmbedDim posEncDim
-&gt; IxState generator''' generator'''' posEnc
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="hs-keyword">case</span><span> </span><span class="annot"><span class="annottext">SingI style =&gt; Sing style
forall k (a :: k). SingI a =&gt; Sing a
</span><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-var">sing</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679771296"><span class="hs-identifier hs-type">style</span></a></span><span> </span><span class="hs-keyword">of</span><span>
</span><span id="line-276"></span><span>          </span><span class="annot"><span class="annottext">Sing style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#ST5"><span class="hs-identifier hs-var">ST5</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SGradient gradient
</span><a href="#local-6989586621679771270"><span class="hs-identifier hs-var">gradient</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SLayoutType 'Dense -&gt; SLayout ('Layout 'Dense)
forall (layoutType :: LayoutType).
SLayoutType layoutType -&gt; SLayout ('Layout layoutType)
</span><a href="Torch.GraduallyTyped.Layout.html#SLayout"><span class="hs-identifier hs-var">SLayout</span></a></span><span> </span><span class="annot"><span class="annottext">SLayoutType 'Dense
</span><a href="Torch.GraduallyTyped.Layout.html#SDense"><span class="hs-identifier hs-var">SDense</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDevice device
</span><a href="#local-6989586621679771269"><span class="hs-identifier hs-var">device</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDataType dataType
</span><a href="#local-6989586621679771268"><span class="hs-identifier hs-var">dataType</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDim posEncDim
</span><a href="#local-6989586621679771262"><span class="hs-identifier hs-var">posEncDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDim headDim
</span><a href="#local-6989586621679771267"><span class="hs-identifier hs-var">headDim</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-277"></span><span>          </span><span class="annot"><span class="annottext">Sing style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SByT5"><span class="hs-identifier hs-var">SByT5</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SGradient gradient
</span><a href="#local-6989586621679771270"><span class="hs-identifier hs-var">gradient</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SLayoutType 'Dense -&gt; SLayout ('Layout 'Dense)
forall (layoutType :: LayoutType).
SLayoutType layoutType -&gt; SLayout ('Layout layoutType)
</span><a href="Torch.GraduallyTyped.Layout.html#SLayout"><span class="hs-identifier hs-var">SLayout</span></a></span><span> </span><span class="annot"><span class="annottext">SLayoutType 'Dense
</span><a href="Torch.GraduallyTyped.Layout.html#SDense"><span class="hs-identifier hs-var">SDense</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDevice device
</span><a href="#local-6989586621679771269"><span class="hs-identifier hs-var">device</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDataType dataType
</span><a href="#local-6989586621679771268"><span class="hs-identifier hs-var">dataType</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDim posEncDim
</span><a href="#local-6989586621679771262"><span class="hs-identifier hs-var">posEncDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDim headDim
</span><a href="#local-6989586621679771267"><span class="hs-identifier hs-var">headDim</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-278"></span><span>          </span><span class="annot"><span class="annottext">Sing style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SBART"><span class="hs-identifier hs-var">SBART</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SGradient gradient
</span><a href="#local-6989586621679771270"><span class="hs-identifier hs-var">gradient</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SLayoutType 'Dense -&gt; SLayout ('Layout 'Dense)
forall (layoutType :: LayoutType).
SLayoutType layoutType -&gt; SLayout ('Layout layoutType)
</span><a href="Torch.GraduallyTyped.Layout.html#SLayout"><span class="hs-identifier hs-var">SLayout</span></a></span><span> </span><span class="annot"><span class="annottext">SLayoutType 'Dense
</span><a href="Torch.GraduallyTyped.Layout.html#SDense"><span class="hs-identifier hs-var">SDense</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDevice device
</span><a href="#local-6989586621679771269"><span class="hs-identifier hs-var">device</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDataType dataType
</span><a href="#local-6989586621679771268"><span class="hs-identifier hs-var">dataType</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDim posEncDim
</span><a href="#local-6989586621679771262"><span class="hs-identifier hs-var">posEncDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDim inputEmbedDim
</span><a href="#local-6989586621679771264"><span class="hs-identifier hs-var">inputEmbedDim</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-279"></span><span>          </span><span class="annot"><span class="annottext">Sing style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SMBART"><span class="hs-identifier hs-var">SMBART</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SGradient gradient
</span><a href="#local-6989586621679771270"><span class="hs-identifier hs-var">gradient</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SLayoutType 'Dense -&gt; SLayout ('Layout 'Dense)
forall (layoutType :: LayoutType).
SLayoutType layoutType -&gt; SLayout ('Layout layoutType)
</span><a href="Torch.GraduallyTyped.Layout.html#SLayout"><span class="hs-identifier hs-var">SLayout</span></a></span><span> </span><span class="annot"><span class="annottext">SLayoutType 'Dense
</span><a href="Torch.GraduallyTyped.Layout.html#SDense"><span class="hs-identifier hs-var">SDense</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDevice device
</span><a href="#local-6989586621679771269"><span class="hs-identifier hs-var">device</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDataType dataType
</span><a href="#local-6989586621679771268"><span class="hs-identifier hs-var">dataType</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDim posEncDim
</span><a href="#local-6989586621679771262"><span class="hs-identifier hs-var">posEncDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDim inputEmbedDim
</span><a href="#local-6989586621679771264"><span class="hs-identifier hs-var">inputEmbedDim</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-280"></span><span>          </span><span class="annot"><span class="annottext">Sing style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SPegasus"><span class="hs-identifier hs-var">SPegasus</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SGradient gradient
</span><a href="#local-6989586621679771270"><span class="hs-identifier hs-var">gradient</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SLayoutType 'Dense -&gt; SLayout ('Layout 'Dense)
forall (layoutType :: LayoutType).
SLayoutType layoutType -&gt; SLayout ('Layout layoutType)
</span><a href="Torch.GraduallyTyped.Layout.html#SLayout"><span class="hs-identifier hs-var">SLayout</span></a></span><span> </span><span class="annot"><span class="annottext">SLayoutType 'Dense
</span><a href="Torch.GraduallyTyped.Layout.html#SDense"><span class="hs-identifier hs-var">SDense</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDevice device
</span><a href="#local-6989586621679771269"><span class="hs-identifier hs-var">device</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDataType dataType
</span><a href="#local-6989586621679771268"><span class="hs-identifier hs-var">dataType</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDim posEncDim
</span><a href="#local-6989586621679771262"><span class="hs-identifier hs-var">posEncDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDim inputEmbedDim
</span><a href="#local-6989586621679771264"><span class="hs-identifier hs-var">inputEmbedDim</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-281"></span><span>          </span><span class="annot"><span class="annottext">Sing style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SBERT"><span class="hs-identifier hs-var">SBERT</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SGradient gradient
</span><a href="#local-6989586621679771270"><span class="hs-identifier hs-var">gradient</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SLayoutType 'Dense -&gt; SLayout ('Layout 'Dense)
forall (layoutType :: LayoutType).
SLayoutType layoutType -&gt; SLayout ('Layout layoutType)
</span><a href="Torch.GraduallyTyped.Layout.html#SLayout"><span class="hs-identifier hs-var">SLayout</span></a></span><span> </span><span class="annot"><span class="annottext">SLayoutType 'Dense
</span><a href="Torch.GraduallyTyped.Layout.html#SDense"><span class="hs-identifier hs-var">SDense</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDevice device
</span><a href="#local-6989586621679771269"><span class="hs-identifier hs-var">device</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDataType dataType
</span><a href="#local-6989586621679771268"><span class="hs-identifier hs-var">dataType</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDim posEncDim
</span><a href="#local-6989586621679771262"><span class="hs-identifier hs-var">posEncDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDim inputEmbedDim
</span><a href="#local-6989586621679771264"><span class="hs-identifier hs-var">inputEmbedDim</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-282"></span><span>          </span><span class="annot"><span class="annottext">Sing style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SRoBERTa"><span class="hs-identifier hs-var">SRoBERTa</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SGradient gradient
</span><a href="#local-6989586621679771270"><span class="hs-identifier hs-var">gradient</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SLayoutType 'Dense -&gt; SLayout ('Layout 'Dense)
forall (layoutType :: LayoutType).
SLayoutType layoutType -&gt; SLayout ('Layout layoutType)
</span><a href="Torch.GraduallyTyped.Layout.html#SLayout"><span class="hs-identifier hs-var">SLayout</span></a></span><span> </span><span class="annot"><span class="annottext">SLayoutType 'Dense
</span><a href="Torch.GraduallyTyped.Layout.html#SDense"><span class="hs-identifier hs-var">SDense</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDevice device
</span><a href="#local-6989586621679771269"><span class="hs-identifier hs-var">device</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDataType dataType
</span><a href="#local-6989586621679771268"><span class="hs-identifier hs-var">dataType</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDim posEncDim
</span><a href="#local-6989586621679771262"><span class="hs-identifier hs-var">posEncDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDim inputEmbedDim
</span><a href="#local-6989586621679771264"><span class="hs-identifier hs-var">inputEmbedDim</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-283"></span><span>          </span><span class="annot"><span class="annottext">Sing style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SGPT2"><span class="hs-identifier hs-var">SGPT2</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><span class="annottext">HasInitializeTEPosEncInputF
  style gradient device dataType headDim inputEmbedDim posEncDim
forall a. HasCallStack =&gt; a
</span><span class="hs-identifier hs-var">undefined</span></span><span>
</span><span id="line-284"></span><span>     </span><span class="hs-keyword">in</span><span> </span><span class="annot"><span class="annottext">IxState
  generator
  generator''''
  (TransformerEncoder
     style
     numLayers
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     inputEmbedDim
     ffnDim
     posEncDim
     dropoutP)
-&gt; generator
-&gt; (TransformerEncoder
      style
      numLayers
      gradient
      device
      dataType
      headDim
      headEmbedDim
      embedDim
      inputEmbedDim
      ffnDim
      posEncDim
      dropoutP,
    generator'''')
forall i j a. IxState i j a -&gt; i -&gt; (a, j)
</span><a href="../file:///nix/store/8vjaffqxij7bih93d9mlzmc7ksanlw0i-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier hs-var hs-var">runIxState</span></a></span><span> </span><span class="annot"><span class="annottext">(IxState
   generator
   generator''''
   (TransformerEncoder
      style
      numLayers
      gradient
      device
      dataType
      headDim
      headEmbedDim
      embedDim
      inputEmbedDim
      ffnDim
      posEncDim
      dropoutP)
 -&gt; generator
 -&gt; (TransformerEncoder
       style
       numLayers
       gradient
       device
       dataType
       headDim
       headEmbedDim
       embedDim
       inputEmbedDim
       ffnDim
       posEncDim
       dropoutP,
     generator''''))
-&gt; IxState
     generator
     generator''''
     (TransformerEncoder
        style
        numLayers
        gradient
        device
        dataType
        headDim
        headEmbedDim
        embedDim
        inputEmbedDim
        ffnDim
        posEncDim
        dropoutP)
-&gt; generator
-&gt; (TransformerEncoder
      style
      numLayers
      gradient
      device
      dataType
      headDim
      headEmbedDim
      embedDim
      inputEmbedDim
      ffnDim
      posEncDim
      dropoutP,
    generator'''')
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span>
</span><span id="line-285"></span><span>          </span><span class="hs-special">(</span><span> </span><span class="annot"><span class="annottext">TransformerStack
  style
  numLayers
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  inputEmbedDim
  ffnDim
  dropoutP
-&gt; embedLayerNorm
-&gt; layerNorm
-&gt; Dropout dropoutP
-&gt; posEnc
-&gt; GTransformerEncoder
     (TransformerStack
        style
        numLayers
        gradient
        device
        dataType
        headDim
        headEmbedDim
        embedDim
        inputEmbedDim
        ffnDim
        dropoutP)
     embedLayerNorm
     layerNorm
     (Dropout dropoutP)
     posEnc
forall stack embedLayerNorm layerNorm dropout posEnc.
stack
-&gt; embedLayerNorm
-&gt; layerNorm
-&gt; dropout
-&gt; posEnc
-&gt; GTransformerEncoder
     stack embedLayerNorm layerNorm dropout posEnc
</span><a href="Torch.GraduallyTyped.NN.Transformer.Encoder.html#GTransformerEncoder"><span class="hs-identifier hs-var">GTransformerEncoder</span></a></span><span>
</span><span id="line-286"></span><span>              </span><span class="annot"><span class="annottext">(TransformerStack
   style
   numLayers
   gradient
   device
   dataType
   headDim
   headEmbedDim
   embedDim
   inputEmbedDim
   ffnDim
   dropoutP
 -&gt; embedLayerNorm
 -&gt; layerNorm
 -&gt; Dropout dropoutP
 -&gt; posEnc
 -&gt; GTransformerEncoder
      (TransformerStack
         style
         numLayers
         gradient
         device
         dataType
         headDim
         headEmbedDim
         embedDim
         inputEmbedDim
         ffnDim
         dropoutP)
      embedLayerNorm
      layerNorm
      (Dropout dropoutP)
      posEnc)
-&gt; IxState
     generator
     generator'
     (TransformerStack
        style
        numLayers
        gradient
        device
        dataType
        headDim
        headEmbedDim
        embedDim
        inputEmbedDim
        ffnDim
        dropoutP)
-&gt; IxState
     generator
     generator'
     (embedLayerNorm
      -&gt; layerNorm
      -&gt; Dropout dropoutP
      -&gt; posEnc
      -&gt; GTransformerEncoder
           (TransformerStack
              style
              numLayers
              gradient
              device
              dataType
              headDim
              headEmbedDim
              embedDim
              inputEmbedDim
              ffnDim
              dropoutP)
           embedLayerNorm
           layerNorm
           (Dropout dropoutP)
           posEnc)
forall k1 k2 (f :: k1 -&gt; k2 -&gt; * -&gt; *) a b (j :: k1) (k3 :: k2).
IxFunctor f =&gt;
(a -&gt; b) -&gt; f j k3 a -&gt; f j k3 b
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&lt;&lt;$&gt;&gt;</span></a></span><span> </span><span class="annot"><span class="annottext">IxState
  generator
  generator'
  (TransformerStack
     style
     numLayers
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     inputEmbedDim
     ffnDim
     dropoutP)
</span><a href="#local-6989586621679771259"><span class="hs-identifier hs-var">stack</span></a></span><span>
</span><span id="line-287"></span><span>              </span><span class="annot"><span class="annottext">IxState
  generator
  generator'
  (embedLayerNorm
   -&gt; layerNorm
   -&gt; Dropout dropoutP
   -&gt; posEnc
   -&gt; GTransformerEncoder
        (TransformerStack
           style
           numLayers
           gradient
           device
           dataType
           headDim
           headEmbedDim
           embedDim
           inputEmbedDim
           ffnDim
           dropoutP)
        embedLayerNorm
        layerNorm
        (Dropout dropoutP)
        posEnc)
-&gt; IxState generator' generator'' embedLayerNorm
-&gt; IxState
     generator
     generator''
     (layerNorm
      -&gt; Dropout dropoutP
      -&gt; posEnc
      -&gt; GTransformerEncoder
           (TransformerStack
              style
              numLayers
              gradient
              device
              dataType
              headDim
              headEmbedDim
              embedDim
              inputEmbedDim
              ffnDim
              dropoutP)
           embedLayerNorm
           layerNorm
           (Dropout dropoutP)
           posEnc)
forall k1 (f :: k1 -&gt; k1 -&gt; * -&gt; *) (i :: k1) (j :: k1) a b
       (k2 :: k1).
IxApplicative f =&gt;
f i j (a -&gt; b) -&gt; f j k2 a -&gt; f i k2 b
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&lt;&lt;*&gt;&gt;</span></a></span><span> </span><span class="annot"><span class="annottext">IxState generator' generator'' embedLayerNorm
</span><a href="#local-6989586621679771256"><span class="hs-identifier hs-var">embedLayerNorm</span></a></span><span>
</span><span id="line-288"></span><span>              </span><span class="annot"><span class="annottext">IxState
  generator
  generator''
  (layerNorm
   -&gt; Dropout dropoutP
   -&gt; posEnc
   -&gt; GTransformerEncoder
        (TransformerStack
           style
           numLayers
           gradient
           device
           dataType
           headDim
           headEmbedDim
           embedDim
           inputEmbedDim
           ffnDim
           dropoutP)
        embedLayerNorm
        layerNorm
        (Dropout dropoutP)
        posEnc)
-&gt; IxState generator'' generator''' layerNorm
-&gt; IxState
     generator
     generator'''
     (Dropout dropoutP
      -&gt; posEnc
      -&gt; GTransformerEncoder
           (TransformerStack
              style
              numLayers
              gradient
              device
              dataType
              headDim
              headEmbedDim
              embedDim
              inputEmbedDim
              ffnDim
              dropoutP)
           embedLayerNorm
           layerNorm
           (Dropout dropoutP)
           posEnc)
forall k1 (f :: k1 -&gt; k1 -&gt; * -&gt; *) (i :: k1) (j :: k1) a b
       (k2 :: k1).
IxApplicative f =&gt;
f i j (a -&gt; b) -&gt; f j k2 a -&gt; f i k2 b
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&lt;&lt;*&gt;&gt;</span></a></span><span> </span><span class="annot"><span class="annottext">IxState generator'' generator''' layerNorm
</span><a href="#local-6989586621679771245"><span class="hs-identifier hs-var">layerNorm</span></a></span><span>
</span><span id="line-289"></span><span>              </span><span class="annot"><span class="annottext">IxState
  generator
  generator'''
  (Dropout dropoutP
   -&gt; posEnc
   -&gt; GTransformerEncoder
        (TransformerStack
           style
           numLayers
           gradient
           device
           dataType
           headDim
           headEmbedDim
           embedDim
           inputEmbedDim
           ffnDim
           dropoutP)
        embedLayerNorm
        layerNorm
        (Dropout dropoutP)
        posEnc)
-&gt; IxState generator''' generator''' (Dropout dropoutP)
-&gt; IxState
     generator
     generator'''
     (posEnc
      -&gt; GTransformerEncoder
           (TransformerStack
              style
              numLayers
              gradient
              device
              dataType
              headDim
              headEmbedDim
              embedDim
              inputEmbedDim
              ffnDim
              dropoutP)
           embedLayerNorm
           layerNorm
           (Dropout dropoutP)
           posEnc)
forall k1 (f :: k1 -&gt; k1 -&gt; * -&gt; *) (i :: k1) (j :: k1) a b
       (k2 :: k1).
IxApplicative f =&gt;
f i j (a -&gt; b) -&gt; f j k2 a -&gt; f i k2 b
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&lt;&lt;*&gt;&gt;</span></a></span><span> </span><span class="annot"><span class="annottext">IxState generator''' generator''' (Dropout dropoutP)
</span><a href="#local-6989586621679771244"><span class="hs-identifier hs-var">dropout</span></a></span><span>
</span><span id="line-290"></span><span>              </span><span class="annot"><span class="annottext">IxState
  generator
  generator'''
  (posEnc
   -&gt; GTransformerEncoder
        (TransformerStack
           style
           numLayers
           gradient
           device
           dataType
           headDim
           headEmbedDim
           embedDim
           inputEmbedDim
           ffnDim
           dropoutP)
        embedLayerNorm
        layerNorm
        (Dropout dropoutP)
        posEnc)
-&gt; IxState generator''' generator'''' posEnc
-&gt; IxState
     generator
     generator''''
     (GTransformerEncoder
        (TransformerStack
           style
           numLayers
           gradient
           device
           dataType
           headDim
           headEmbedDim
           embedDim
           inputEmbedDim
           ffnDim
           dropoutP)
        embedLayerNorm
        layerNorm
        (Dropout dropoutP)
        posEnc)
forall k1 (f :: k1 -&gt; k1 -&gt; * -&gt; *) (i :: k1) (j :: k1) a b
       (k2 :: k1).
IxApplicative f =&gt;
f i j (a -&gt; b) -&gt; f j k2 a -&gt; f i k2 b
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&lt;&lt;*&gt;&gt;</span></a></span><span> </span><span class="annot"><span class="annottext">IxState generator''' generator'''' posEnc
</span><a href="#local-6989586621679771243"><span class="hs-identifier hs-var">posEnc</span></a></span><span>
</span><span id="line-291"></span><span>          </span><span class="hs-special">)</span><span>
</span><span id="line-292"></span><span>            </span><span class="annot"><span class="annottext">IxState
  generator
  generator''''
  (GTransformerEncoder
     (TransformerStack
        style
        numLayers
        gradient
        device
        dataType
        headDim
        headEmbedDim
        embedDim
        inputEmbedDim
        ffnDim
        dropoutP)
     embedLayerNorm
     layerNorm
     (Dropout dropoutP)
     posEnc)
-&gt; (GTransformerEncoder
      (TransformerStack
         style
         numLayers
         gradient
         device
         dataType
         headDim
         headEmbedDim
         embedDim
         inputEmbedDim
         ffnDim
         dropoutP)
      embedLayerNorm
      layerNorm
      (Dropout dropoutP)
      posEnc
    -&gt; IxState
         generator''''
         generator''''
         (TransformerEncoder
            style
            numLayers
            gradient
            device
            dataType
            headDim
            headEmbedDim
            embedDim
            inputEmbedDim
            ffnDim
            posEncDim
            dropoutP))
-&gt; IxState
     generator
     generator''''
     (TransformerEncoder
        style
        numLayers
        gradient
        device
        dataType
        headDim
        headEmbedDim
        embedDim
        inputEmbedDim
        ffnDim
        posEncDim
        dropoutP)
forall k1 (m :: k1 -&gt; k1 -&gt; * -&gt; *) (i :: k1) (j :: k1) a
       (k2 :: k1) b.
IxMonad m =&gt;
m i j a -&gt; (a -&gt; m j k2 b) -&gt; m i k2 b
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&gt;&gt;&gt;=</span></a></span><span> </span><span class="annot"><span class="annottext">TransformerEncoder
  style
  numLayers
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  inputEmbedDim
  ffnDim
  posEncDim
  dropoutP
-&gt; IxState
     generator''''
     generator''''
     (TransformerEncoder
        style
        numLayers
        gradient
        device
        dataType
        headDim
        headEmbedDim
        embedDim
        inputEmbedDim
        ffnDim
        posEncDim
        dropoutP)
forall k (m :: k -&gt; k -&gt; * -&gt; *) a (i :: k).
IxPointed m =&gt;
a -&gt; m i i a
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-identifier hs-var">ireturn</span></a></span><span> </span><span class="annot"><span class="annottext">(TransformerEncoder
   style
   numLayers
   gradient
   device
   dataType
   headDim
   headEmbedDim
   embedDim
   inputEmbedDim
   ffnDim
   posEncDim
   dropoutP
 -&gt; IxState
      generator''''
      generator''''
      (TransformerEncoder
         style
         numLayers
         gradient
         device
         dataType
         headDim
         headEmbedDim
         embedDim
         inputEmbedDim
         ffnDim
         posEncDim
         dropoutP))
-&gt; (GTransformerEncoder
      (TransformerStack
         style
         numLayers
         gradient
         device
         dataType
         headDim
         headEmbedDim
         embedDim
         inputEmbedDim
         ffnDim
         dropoutP)
      embedLayerNorm
      layerNorm
      (Dropout dropoutP)
      posEnc
    -&gt; TransformerEncoder
         style
         numLayers
         gradient
         device
         dataType
         headDim
         headEmbedDim
         embedDim
         inputEmbedDim
         ffnDim
         posEncDim
         dropoutP)
-&gt; GTransformerEncoder
     (TransformerStack
        style
        numLayers
        gradient
        device
        dataType
        headDim
        headEmbedDim
        embedDim
        inputEmbedDim
        ffnDim
        dropoutP)
     embedLayerNorm
     layerNorm
     (Dropout dropoutP)
     posEnc
-&gt; IxState
     generator''''
     generator''''
     (TransformerEncoder
        style
        numLayers
        gradient
        device
        dataType
        headDim
        headEmbedDim
        embedDim
        inputEmbedDim
        ffnDim
        posEncDim
        dropoutP)
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">GTransformerEncoder
  (TransformerStack
     style
     numLayers
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     inputEmbedDim
     ffnDim
     dropoutP)
  embedLayerNorm
  layerNorm
  (Dropout dropoutP)
  posEnc
-&gt; TransformerEncoder
     style
     numLayers
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     inputEmbedDim
     ffnDim
     posEncDim
     dropoutP
forall (style :: TransformerStyle) (numLayers :: Nat)
       (gradient :: Gradient RequiresGradient)
       (device :: Device (DeviceType Nat)) (dataType :: DataType DType)
       (headDim :: Dim (Name Symbol) (Size Nat))
       (headEmbedDim :: Dim (Name Symbol) (Size Nat))
       (embedDim :: Dim (Name Symbol) (Size Nat))
       (inputEmbedDim :: Dim (Name Symbol) (Size Nat))
       (ffnDim :: Dim (Name Symbol) (Size Nat))
       (posEncDim :: Dim (Name Symbol) (Size Nat)) dropoutP.
GTransformerEncoder
  (TEStackF
     style
     numLayers
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     inputEmbedDim
     ffnDim
     dropoutP)
  (TEEmbedLayerNormF style gradient device dataType inputEmbedDim)
  (TELayerNormF style gradient device dataType inputEmbedDim)
  (TEDropoutF style dropoutP)
  (TEPosEncF
     style gradient device dataType headDim inputEmbedDim posEncDim)
-&gt; TransformerEncoder
     style
     numLayers
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     inputEmbedDim
     ffnDim
     posEncDim
     dropoutP
</span><a href="Torch.GraduallyTyped.NN.Transformer.Encoder.html#TransformerEncoder"><span class="hs-identifier hs-var">TransformerEncoder</span></a></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span><span>
</span><span id="line-293"></span><span>
</span><span id="line-294"></span><span id="local-6989586621679771228"><span id="local-6989586621679771229"><span id="local-6989586621679771230"><span id="local-6989586621679771231"><span id="local-6989586621679771232"><span id="local-6989586621679771233"><span id="local-6989586621679771234"><span id="local-6989586621679771235"><span id="local-6989586621679771236"><span id="local-6989586621679771237"><span id="local-6989586621679771238"><span id="local-6989586621679771239"><span class="hs-keyword">instance</span><span>
</span><span id="line-295"></span><span>  </span><span class="hs-special">(</span><span class="annot"><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-type">SingI</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771239"><span class="hs-identifier hs-type">style</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="hs-identifier hs-type">KnownNat</span></span><span> </span><span class="annot"><a href="#local-6989586621679771238"><span class="hs-identifier hs-type">numLayers</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-296"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasStateDict"><span class="hs-identifier hs-type">HasStateDict</span></a></span><span>
</span><span id="line-297"></span><span>    </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Encoder.html#TransformerEncoder"><span class="hs-identifier hs-type">TransformerEncoder</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771239"><span class="hs-identifier hs-type">style</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771238"><span class="hs-identifier hs-type">numLayers</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771237"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771236"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771235"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771234"><span class="hs-identifier hs-type">headDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771233"><span class="hs-identifier hs-type">headEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771232"><span class="hs-identifier hs-type">embedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771231"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771230"><span class="hs-identifier hs-type">ffnDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771229"><span class="hs-identifier hs-type">posEncDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771228"><span class="hs-identifier hs-type">dropoutP</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-298"></span><span>    </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#SGradient"><span class="hs-identifier hs-type">SGradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771237"><span class="hs-identifier hs-type">gradient</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#SDevice"><span class="hs-identifier hs-type">SDevice</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771236"><span class="hs-identifier hs-type">device</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#SDataType"><span class="hs-identifier hs-type">SDataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771235"><span class="hs-identifier hs-type">dataType</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SDim"><span class="hs-identifier hs-type">SDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771234"><span class="hs-identifier hs-type">headDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SDim"><span class="hs-identifier hs-type">SDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771233"><span class="hs-identifier hs-type">headEmbedDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SDim"><span class="hs-identifier hs-type">SDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771232"><span class="hs-identifier hs-type">embedDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SDim"><span class="hs-identifier hs-type">SDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771231"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SDim"><span class="hs-identifier hs-type">SDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771230"><span class="hs-identifier hs-type">ffnDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SDim"><span class="hs-identifier hs-type">SDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771229"><span class="hs-identifier hs-type">posEncDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679771228"><span class="hs-identifier hs-type">dropoutP</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Double</span></span><span class="hs-special">)</span><span>
</span><span id="line-299"></span><span>  </span><span class="hs-keyword">where</span><span>
</span><span id="line-300"></span><span>  </span><span id="local-6989586621679771224"><span class="annot"><span class="annottext">fromStateDict :: (SGradient gradient, SDevice device, SDataType dataType,
 SDim headDim, SDim headEmbedDim, SDim embedDim, SDim inputEmbedDim,
 SDim ffnDim, SDim posEncDim, dropoutP, Double)
-&gt; StateDictKey
-&gt; m (TransformerEncoder
        style
        numLayers
        gradient
        device
        dataType
        headDim
        headEmbedDim
        embedDim
        inputEmbedDim
        ffnDim
        posEncDim
        dropoutP)
</span><a href="Torch.GraduallyTyped.NN.Class.html#fromStateDict"><span class="hs-identifier hs-var hs-var hs-var hs-var">fromStateDict</span></a></span></span><span> </span><span class="hs-special">(</span><span id="local-6989586621679771222"><span class="annot"><span class="annottext">SGradient gradient
</span><a href="#local-6989586621679771222"><span class="hs-identifier hs-var">gradient</span></a></span></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679771221"><span class="annot"><span class="annottext">SDevice device
</span><a href="#local-6989586621679771221"><span class="hs-identifier hs-var">device</span></a></span></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679771220"><span class="annot"><span class="annottext">SDataType dataType
</span><a href="#local-6989586621679771220"><span class="hs-identifier hs-var">dataType</span></a></span></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679771219"><span class="annot"><span class="annottext">SDim headDim
</span><a href="#local-6989586621679771219"><span class="hs-identifier hs-var">headDim</span></a></span></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679771218"><span class="annot"><span class="annottext">SDim headEmbedDim
</span><a href="#local-6989586621679771218"><span class="hs-identifier hs-var">headEmbedDim</span></a></span></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679771217"><span class="annot"><span class="annottext">SDim embedDim
</span><a href="#local-6989586621679771217"><span class="hs-identifier hs-var">embedDim</span></a></span></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679771216"><span class="annot"><span class="annottext">SDim inputEmbedDim
</span><a href="#local-6989586621679771216"><span class="hs-identifier hs-var">inputEmbedDim</span></a></span></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679771215"><span class="annot"><span class="annottext">SDim ffnDim
</span><a href="#local-6989586621679771215"><span class="hs-identifier hs-var">ffnDim</span></a></span></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679771214"><span class="annot"><span class="annottext">SDim posEncDim
</span><a href="#local-6989586621679771214"><span class="hs-identifier hs-var">posEncDim</span></a></span></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679771213"><span class="annot"><span class="annottext">dropoutP
</span><a href="#local-6989586621679771213"><span class="hs-identifier hs-var">dropoutP</span></a></span></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679771212"><span class="annot"><span class="annottext">Double
</span><a href="#local-6989586621679771212"><span class="hs-identifier hs-var">eps</span></a></span></span><span class="hs-special">)</span><span> </span><span id="local-6989586621679771211"><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679771211"><span class="hs-identifier hs-var">k</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-301"></span><span>    </span><span class="hs-keyword">let</span><span> </span><span id="local-6989586621679771210"><span class="annot"><span class="annottext">stack :: STransformerStyle style
-&gt; m (TransformerStack
        style
        numLayers
        gradient
        device
        dataType
        headDim
        headEmbedDim
        embedDim
        inputEmbedDim
        ffnDim
        dropoutP)
</span><a href="#local-6989586621679771210"><span class="hs-identifier hs-var hs-var">stack</span></a></span></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#ST5"><span class="hs-identifier hs-var">ST5</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">(SGradient gradient, SDevice device, SDataType dataType,
 SDim headDim, SDim headEmbedDim, SDim embedDim, SDim inputEmbedDim,
 SDim ffnDim, dropoutP, Double)
-&gt; StateDictKey
-&gt; m (TransformerStack
        'T5
        numLayers
        gradient
        device
        dataType
        headDim
        headEmbedDim
        embedDim
        inputEmbedDim
        ffnDim
        dropoutP)
forall model input (m :: * -&gt; *).
(HasStateDict model input, MonadThrow m, MonadState StateDict m) =&gt;
input -&gt; StateDictKey -&gt; m model
</span><a href="Torch.GraduallyTyped.NN.Class.html#fromStateDict"><span class="hs-identifier hs-var">fromStateDict</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SGradient gradient
</span><a href="#local-6989586621679771222"><span class="hs-identifier hs-var">gradient</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDevice device
</span><a href="#local-6989586621679771221"><span class="hs-identifier hs-var">device</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDataType dataType
</span><a href="#local-6989586621679771220"><span class="hs-identifier hs-var">dataType</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDim headDim
</span><a href="#local-6989586621679771219"><span class="hs-identifier hs-var">headDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDim headEmbedDim
</span><a href="#local-6989586621679771218"><span class="hs-identifier hs-var">headEmbedDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDim embedDim
</span><a href="#local-6989586621679771217"><span class="hs-identifier hs-var">embedDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDim inputEmbedDim
</span><a href="#local-6989586621679771216"><span class="hs-identifier hs-var">inputEmbedDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDim ffnDim
</span><a href="#local-6989586621679771215"><span class="hs-identifier hs-var">ffnDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">dropoutP
</span><a href="#local-6989586621679771213"><span class="hs-identifier hs-var">dropoutP</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">Double
</span><a href="#local-6989586621679771212"><span class="hs-identifier hs-var">eps</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679771211"><span class="hs-identifier hs-var">k</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey -&gt; StateDictKey -&gt; StateDictKey
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;block.&quot;</span></span><span class="hs-special">)</span><span>
</span><span id="line-302"></span><span>        </span><span class="annot"><a href="#local-6989586621679771210"><span class="hs-identifier hs-var">stack</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SByT5"><span class="hs-identifier hs-var">SByT5</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">(SGradient gradient, SDevice device, SDataType dataType,
 SDim headDim, SDim headEmbedDim, SDim embedDim, SDim inputEmbedDim,
 SDim ffnDim, dropoutP, Double)
-&gt; StateDictKey
-&gt; m (TransformerStack
        'ByT5
        numLayers
        gradient
        device
        dataType
        headDim
        headEmbedDim
        embedDim
        inputEmbedDim
        ffnDim
        dropoutP)
forall model input (m :: * -&gt; *).
(HasStateDict model input, MonadThrow m, MonadState StateDict m) =&gt;
input -&gt; StateDictKey -&gt; m model
</span><a href="Torch.GraduallyTyped.NN.Class.html#fromStateDict"><span class="hs-identifier hs-var">fromStateDict</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SGradient gradient
</span><a href="#local-6989586621679771222"><span class="hs-identifier hs-var">gradient</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDevice device
</span><a href="#local-6989586621679771221"><span class="hs-identifier hs-var">device</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDataType dataType
</span><a href="#local-6989586621679771220"><span class="hs-identifier hs-var">dataType</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDim headDim
</span><a href="#local-6989586621679771219"><span class="hs-identifier hs-var">headDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDim headEmbedDim
</span><a href="#local-6989586621679771218"><span class="hs-identifier hs-var">headEmbedDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDim embedDim
</span><a href="#local-6989586621679771217"><span class="hs-identifier hs-var">embedDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDim inputEmbedDim
</span><a href="#local-6989586621679771216"><span class="hs-identifier hs-var">inputEmbedDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDim ffnDim
</span><a href="#local-6989586621679771215"><span class="hs-identifier hs-var">ffnDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">dropoutP
</span><a href="#local-6989586621679771213"><span class="hs-identifier hs-var">dropoutP</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">Double
</span><a href="#local-6989586621679771212"><span class="hs-identifier hs-var">eps</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679771211"><span class="hs-identifier hs-var">k</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey -&gt; StateDictKey -&gt; StateDictKey
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;block.&quot;</span></span><span class="hs-special">)</span><span>
</span><span id="line-303"></span><span>        </span><span class="annot"><a href="#local-6989586621679771210"><span class="hs-identifier hs-var">stack</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SBART"><span class="hs-identifier hs-var">SBART</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">(SGradient gradient, SDevice device, SDataType dataType,
 SDim headDim, SDim headEmbedDim, SDim embedDim, SDim inputEmbedDim,
 SDim ffnDim, dropoutP, Double)
-&gt; StateDictKey
-&gt; m (TransformerStack
        'BART
        numLayers
        gradient
        device
        dataType
        headDim
        headEmbedDim
        embedDim
        inputEmbedDim
        ffnDim
        dropoutP)
forall model input (m :: * -&gt; *).
(HasStateDict model input, MonadThrow m, MonadState StateDict m) =&gt;
input -&gt; StateDictKey -&gt; m model
</span><a href="Torch.GraduallyTyped.NN.Class.html#fromStateDict"><span class="hs-identifier hs-var">fromStateDict</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SGradient gradient
</span><a href="#local-6989586621679771222"><span class="hs-identifier hs-var">gradient</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDevice device
</span><a href="#local-6989586621679771221"><span class="hs-identifier hs-var">device</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDataType dataType
</span><a href="#local-6989586621679771220"><span class="hs-identifier hs-var">dataType</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDim headDim
</span><a href="#local-6989586621679771219"><span class="hs-identifier hs-var">headDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDim headEmbedDim
</span><a href="#local-6989586621679771218"><span class="hs-identifier hs-var">headEmbedDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDim embedDim
</span><a href="#local-6989586621679771217"><span class="hs-identifier hs-var">embedDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDim inputEmbedDim
</span><a href="#local-6989586621679771216"><span class="hs-identifier hs-var">inputEmbedDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDim ffnDim
</span><a href="#local-6989586621679771215"><span class="hs-identifier hs-var">ffnDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">dropoutP
</span><a href="#local-6989586621679771213"><span class="hs-identifier hs-var">dropoutP</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">Double
</span><a href="#local-6989586621679771212"><span class="hs-identifier hs-var">eps</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679771211"><span class="hs-identifier hs-var">k</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey -&gt; StateDictKey -&gt; StateDictKey
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;layers.&quot;</span></span><span class="hs-special">)</span><span>
</span><span id="line-304"></span><span>        </span><span class="annot"><a href="#local-6989586621679771210"><span class="hs-identifier hs-var">stack</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SMBART"><span class="hs-identifier hs-var">SMBART</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">(SGradient gradient, SDevice device, SDataType dataType,
 SDim headDim, SDim headEmbedDim, SDim embedDim, SDim inputEmbedDim,
 SDim ffnDim, dropoutP, Double)
-&gt; StateDictKey
-&gt; m (TransformerStack
        'MBART
        numLayers
        gradient
        device
        dataType
        headDim
        headEmbedDim
        embedDim
        inputEmbedDim
        ffnDim
        dropoutP)
forall model input (m :: * -&gt; *).
(HasStateDict model input, MonadThrow m, MonadState StateDict m) =&gt;
input -&gt; StateDictKey -&gt; m model
</span><a href="Torch.GraduallyTyped.NN.Class.html#fromStateDict"><span class="hs-identifier hs-var">fromStateDict</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SGradient gradient
</span><a href="#local-6989586621679771222"><span class="hs-identifier hs-var">gradient</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDevice device
</span><a href="#local-6989586621679771221"><span class="hs-identifier hs-var">device</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDataType dataType
</span><a href="#local-6989586621679771220"><span class="hs-identifier hs-var">dataType</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDim headDim
</span><a href="#local-6989586621679771219"><span class="hs-identifier hs-var">headDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDim headEmbedDim
</span><a href="#local-6989586621679771218"><span class="hs-identifier hs-var">headEmbedDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDim embedDim
</span><a href="#local-6989586621679771217"><span class="hs-identifier hs-var">embedDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDim inputEmbedDim
</span><a href="#local-6989586621679771216"><span class="hs-identifier hs-var">inputEmbedDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDim ffnDim
</span><a href="#local-6989586621679771215"><span class="hs-identifier hs-var">ffnDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">dropoutP
</span><a href="#local-6989586621679771213"><span class="hs-identifier hs-var">dropoutP</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">Double
</span><a href="#local-6989586621679771212"><span class="hs-identifier hs-var">eps</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679771211"><span class="hs-identifier hs-var">k</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey -&gt; StateDictKey -&gt; StateDictKey
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;layers.&quot;</span></span><span class="hs-special">)</span><span>
</span><span id="line-305"></span><span>        </span><span class="annot"><a href="#local-6989586621679771210"><span class="hs-identifier hs-var">stack</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SPegasus"><span class="hs-identifier hs-var">SPegasus</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">(SGradient gradient, SDevice device, SDataType dataType,
 SDim headDim, SDim headEmbedDim, SDim embedDim, SDim inputEmbedDim,
 SDim ffnDim, dropoutP, Double)
-&gt; StateDictKey
-&gt; m (TransformerStack
        'Pegasus
        numLayers
        gradient
        device
        dataType
        headDim
        headEmbedDim
        embedDim
        inputEmbedDim
        ffnDim
        dropoutP)
forall model input (m :: * -&gt; *).
(HasStateDict model input, MonadThrow m, MonadState StateDict m) =&gt;
input -&gt; StateDictKey -&gt; m model
</span><a href="Torch.GraduallyTyped.NN.Class.html#fromStateDict"><span class="hs-identifier hs-var">fromStateDict</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SGradient gradient
</span><a href="#local-6989586621679771222"><span class="hs-identifier hs-var">gradient</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDevice device
</span><a href="#local-6989586621679771221"><span class="hs-identifier hs-var">device</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDataType dataType
</span><a href="#local-6989586621679771220"><span class="hs-identifier hs-var">dataType</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDim headDim
</span><a href="#local-6989586621679771219"><span class="hs-identifier hs-var">headDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDim headEmbedDim
</span><a href="#local-6989586621679771218"><span class="hs-identifier hs-var">headEmbedDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDim embedDim
</span><a href="#local-6989586621679771217"><span class="hs-identifier hs-var">embedDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDim inputEmbedDim
</span><a href="#local-6989586621679771216"><span class="hs-identifier hs-var">inputEmbedDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDim ffnDim
</span><a href="#local-6989586621679771215"><span class="hs-identifier hs-var">ffnDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">dropoutP
</span><a href="#local-6989586621679771213"><span class="hs-identifier hs-var">dropoutP</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">Double
</span><a href="#local-6989586621679771212"><span class="hs-identifier hs-var">eps</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679771211"><span class="hs-identifier hs-var">k</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey -&gt; StateDictKey -&gt; StateDictKey
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;layers.&quot;</span></span><span class="hs-special">)</span><span>
</span><span id="line-306"></span><span>        </span><span class="annot"><a href="#local-6989586621679771210"><span class="hs-identifier hs-var">stack</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SBERT"><span class="hs-identifier hs-var">SBERT</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">(SGradient gradient, SDevice device, SDataType dataType,
 SDim headDim, SDim headEmbedDim, SDim embedDim, SDim inputEmbedDim,
 SDim ffnDim, dropoutP, Double)
-&gt; StateDictKey
-&gt; m (TransformerStack
        'BERT
        numLayers
        gradient
        device
        dataType
        headDim
        headEmbedDim
        embedDim
        inputEmbedDim
        ffnDim
        dropoutP)
forall model input (m :: * -&gt; *).
(HasStateDict model input, MonadThrow m, MonadState StateDict m) =&gt;
input -&gt; StateDictKey -&gt; m model
</span><a href="Torch.GraduallyTyped.NN.Class.html#fromStateDict"><span class="hs-identifier hs-var">fromStateDict</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SGradient gradient
</span><a href="#local-6989586621679771222"><span class="hs-identifier hs-var">gradient</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDevice device
</span><a href="#local-6989586621679771221"><span class="hs-identifier hs-var">device</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDataType dataType
</span><a href="#local-6989586621679771220"><span class="hs-identifier hs-var">dataType</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDim headDim
</span><a href="#local-6989586621679771219"><span class="hs-identifier hs-var">headDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDim headEmbedDim
</span><a href="#local-6989586621679771218"><span class="hs-identifier hs-var">headEmbedDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDim embedDim
</span><a href="#local-6989586621679771217"><span class="hs-identifier hs-var">embedDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDim inputEmbedDim
</span><a href="#local-6989586621679771216"><span class="hs-identifier hs-var">inputEmbedDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDim ffnDim
</span><a href="#local-6989586621679771215"><span class="hs-identifier hs-var">ffnDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">dropoutP
</span><a href="#local-6989586621679771213"><span class="hs-identifier hs-var">dropoutP</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">Double
</span><a href="#local-6989586621679771212"><span class="hs-identifier hs-var">eps</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679771211"><span class="hs-identifier hs-var">k</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey -&gt; StateDictKey -&gt; StateDictKey
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;encoder.layer.&quot;</span></span><span class="hs-special">)</span><span>
</span><span id="line-307"></span><span>        </span><span class="annot"><a href="#local-6989586621679771210"><span class="hs-identifier hs-var">stack</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SRoBERTa"><span class="hs-identifier hs-var">SRoBERTa</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">(SGradient gradient, SDevice device, SDataType dataType,
 SDim headDim, SDim headEmbedDim, SDim embedDim, SDim inputEmbedDim,
 SDim ffnDim, dropoutP, Double)
-&gt; StateDictKey
-&gt; m (TransformerStack
        'RoBERTa
        numLayers
        gradient
        device
        dataType
        headDim
        headEmbedDim
        embedDim
        inputEmbedDim
        ffnDim
        dropoutP)
forall model input (m :: * -&gt; *).
(HasStateDict model input, MonadThrow m, MonadState StateDict m) =&gt;
input -&gt; StateDictKey -&gt; m model
</span><a href="Torch.GraduallyTyped.NN.Class.html#fromStateDict"><span class="hs-identifier hs-var">fromStateDict</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SGradient gradient
</span><a href="#local-6989586621679771222"><span class="hs-identifier hs-var">gradient</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDevice device
</span><a href="#local-6989586621679771221"><span class="hs-identifier hs-var">device</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDataType dataType
</span><a href="#local-6989586621679771220"><span class="hs-identifier hs-var">dataType</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDim headDim
</span><a href="#local-6989586621679771219"><span class="hs-identifier hs-var">headDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDim headEmbedDim
</span><a href="#local-6989586621679771218"><span class="hs-identifier hs-var">headEmbedDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDim embedDim
</span><a href="#local-6989586621679771217"><span class="hs-identifier hs-var">embedDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDim inputEmbedDim
</span><a href="#local-6989586621679771216"><span class="hs-identifier hs-var">inputEmbedDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDim ffnDim
</span><a href="#local-6989586621679771215"><span class="hs-identifier hs-var">ffnDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">dropoutP
</span><a href="#local-6989586621679771213"><span class="hs-identifier hs-var">dropoutP</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">Double
</span><a href="#local-6989586621679771212"><span class="hs-identifier hs-var">eps</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679771211"><span class="hs-identifier hs-var">k</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey -&gt; StateDictKey -&gt; StateDictKey
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;encoder.layer.&quot;</span></span><span class="hs-special">)</span><span>
</span><span id="line-308"></span><span>        </span><span class="annot"><a href="#local-6989586621679771210"><span class="hs-identifier hs-var">stack</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SGPT2"><span class="hs-identifier hs-var">SGPT2</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">m (TransformerStack
     style
     numLayers
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     inputEmbedDim
     ffnDim
     dropoutP)
forall a. HasCallStack =&gt; a
</span><span class="hs-identifier hs-var">undefined</span></span><span>
</span><span id="line-309"></span><span>        </span><span id="local-6989586621679771209"><span class="annot"><span class="annottext">embedLayerNorm :: STransformerStyle style
-&gt; m (TEEmbedLayerNormF
        style gradient device dataType inputEmbedDim)
</span><a href="#local-6989586621679771209"><span class="hs-identifier hs-var hs-var">embedLayerNorm</span></a></span></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#ST5"><span class="hs-identifier hs-var">ST5</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">() -&gt; StateDictKey -&gt; m ()
forall model input (m :: * -&gt; *).
(HasStateDict model input, MonadThrow m, MonadState StateDict m) =&gt;
input -&gt; StateDictKey -&gt; m model
</span><a href="Torch.GraduallyTyped.NN.Class.html#fromStateDict"><span class="hs-identifier hs-var">fromStateDict</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679771211"><span class="hs-identifier hs-var">k</span></a></span><span>
</span><span id="line-310"></span><span>        </span><span class="annot"><a href="#local-6989586621679771209"><span class="hs-identifier hs-var">embedLayerNorm</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SByT5"><span class="hs-identifier hs-var">SByT5</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">() -&gt; StateDictKey -&gt; m ()
forall model input (m :: * -&gt; *).
(HasStateDict model input, MonadThrow m, MonadState StateDict m) =&gt;
input -&gt; StateDictKey -&gt; m model
</span><a href="Torch.GraduallyTyped.NN.Class.html#fromStateDict"><span class="hs-identifier hs-var">fromStateDict</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679771211"><span class="hs-identifier hs-var">k</span></a></span><span>
</span><span id="line-311"></span><span>        </span><span class="annot"><a href="#local-6989586621679771209"><span class="hs-identifier hs-var">embedLayerNorm</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SBART"><span class="hs-identifier hs-var">SBART</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">(SGradient gradient, SDevice device, SDataType dataType,
 SShape ('Shape '[inputEmbedDim]), Double)
-&gt; StateDictKey
-&gt; m (LayerNorm
        'WithBias gradient device dataType ('Shape '[inputEmbedDim]))
forall model input (m :: * -&gt; *).
(HasStateDict model input, MonadThrow m, MonadState StateDict m) =&gt;
input -&gt; StateDictKey -&gt; m model
</span><a href="Torch.GraduallyTyped.NN.Class.html#fromStateDict"><span class="hs-identifier hs-var">fromStateDict</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SGradient gradient
</span><a href="#local-6989586621679771222"><span class="hs-identifier hs-var">gradient</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDevice device
</span><a href="#local-6989586621679771221"><span class="hs-identifier hs-var">device</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDataType dataType
</span><a href="#local-6989586621679771220"><span class="hs-identifier hs-var">dataType</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SList '[inputEmbedDim] -&gt; SShape ('Shape '[inputEmbedDim])
forall (dims :: [Dim (Name Symbol) (Size Nat)]).
SList dims -&gt; SShape ('Shape dims)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SShape"><span class="hs-identifier hs-var">SShape</span></a></span><span> </span><span class="annot"><span class="annottext">(SList '[inputEmbedDim] -&gt; SShape ('Shape '[inputEmbedDim]))
-&gt; SList '[inputEmbedDim] -&gt; SShape ('Shape '[inputEmbedDim])
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">SDim inputEmbedDim
</span><a href="#local-6989586621679771216"><span class="hs-identifier hs-var">inputEmbedDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim inputEmbedDim -&gt; SList '[] -&gt; SList '[inputEmbedDim]
forall (dim :: Dim (Name Symbol) (Size Nat))
       (dims :: [Dim (Name Symbol) (Size Nat)]).
SDim dim -&gt; SList dims -&gt; SList (dim : dims)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%7C%3A"><span class="hs-operator hs-var">:|:</span></a></span><span> </span><span class="annot"><span class="annottext">SList '[]
forall a. SList '[]
</span><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-var">SNil</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">Double
</span><a href="#local-6989586621679771212"><span class="hs-identifier hs-var">eps</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679771211"><span class="hs-identifier hs-var">k</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey -&gt; StateDictKey -&gt; StateDictKey
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;layernorm_embedding.&quot;</span></span><span class="hs-special">)</span><span>
</span><span id="line-312"></span><span>        </span><span class="annot"><a href="#local-6989586621679771209"><span class="hs-identifier hs-var">embedLayerNorm</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SMBART"><span class="hs-identifier hs-var">SMBART</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">(SGradient gradient, SDevice device, SDataType dataType,
 SShape ('Shape '[inputEmbedDim]), Double)
-&gt; StateDictKey
-&gt; m (LayerNorm
        'WithBias gradient device dataType ('Shape '[inputEmbedDim]))
forall model input (m :: * -&gt; *).
(HasStateDict model input, MonadThrow m, MonadState StateDict m) =&gt;
input -&gt; StateDictKey -&gt; m model
</span><a href="Torch.GraduallyTyped.NN.Class.html#fromStateDict"><span class="hs-identifier hs-var">fromStateDict</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SGradient gradient
</span><a href="#local-6989586621679771222"><span class="hs-identifier hs-var">gradient</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDevice device
</span><a href="#local-6989586621679771221"><span class="hs-identifier hs-var">device</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDataType dataType
</span><a href="#local-6989586621679771220"><span class="hs-identifier hs-var">dataType</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SList '[inputEmbedDim] -&gt; SShape ('Shape '[inputEmbedDim])
forall (dims :: [Dim (Name Symbol) (Size Nat)]).
SList dims -&gt; SShape ('Shape dims)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SShape"><span class="hs-identifier hs-var">SShape</span></a></span><span> </span><span class="annot"><span class="annottext">(SList '[inputEmbedDim] -&gt; SShape ('Shape '[inputEmbedDim]))
-&gt; SList '[inputEmbedDim] -&gt; SShape ('Shape '[inputEmbedDim])
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">SDim inputEmbedDim
</span><a href="#local-6989586621679771216"><span class="hs-identifier hs-var">inputEmbedDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim inputEmbedDim -&gt; SList '[] -&gt; SList '[inputEmbedDim]
forall (dim :: Dim (Name Symbol) (Size Nat))
       (dims :: [Dim (Name Symbol) (Size Nat)]).
SDim dim -&gt; SList dims -&gt; SList (dim : dims)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%7C%3A"><span class="hs-operator hs-var">:|:</span></a></span><span> </span><span class="annot"><span class="annottext">SList '[]
forall a. SList '[]
</span><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-var">SNil</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">Double
</span><a href="#local-6989586621679771212"><span class="hs-identifier hs-var">eps</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679771211"><span class="hs-identifier hs-var">k</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey -&gt; StateDictKey -&gt; StateDictKey
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;layernorm_embedding.&quot;</span></span><span class="hs-special">)</span><span>
</span><span id="line-313"></span><span>        </span><span class="annot"><a href="#local-6989586621679771209"><span class="hs-identifier hs-var">embedLayerNorm</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SPegasus"><span class="hs-identifier hs-var">SPegasus</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">() -&gt; StateDictKey -&gt; m ()
forall model input (m :: * -&gt; *).
(HasStateDict model input, MonadThrow m, MonadState StateDict m) =&gt;
input -&gt; StateDictKey -&gt; m model
</span><a href="Torch.GraduallyTyped.NN.Class.html#fromStateDict"><span class="hs-identifier hs-var">fromStateDict</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679771211"><span class="hs-identifier hs-var">k</span></a></span><span>
</span><span id="line-314"></span><span>        </span><span class="annot"><a href="#local-6989586621679771209"><span class="hs-identifier hs-var">embedLayerNorm</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SBERT"><span class="hs-identifier hs-var">SBERT</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">(SGradient gradient, SDevice device, SDataType dataType,
 SShape ('Shape '[inputEmbedDim]), Double)
-&gt; StateDictKey
-&gt; m (LayerNorm
        'WithBias gradient device dataType ('Shape '[inputEmbedDim]))
forall model input (m :: * -&gt; *).
(HasStateDict model input, MonadThrow m, MonadState StateDict m) =&gt;
input -&gt; StateDictKey -&gt; m model
</span><a href="Torch.GraduallyTyped.NN.Class.html#fromStateDict"><span class="hs-identifier hs-var">fromStateDict</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SGradient gradient
</span><a href="#local-6989586621679771222"><span class="hs-identifier hs-var">gradient</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDevice device
</span><a href="#local-6989586621679771221"><span class="hs-identifier hs-var">device</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDataType dataType
</span><a href="#local-6989586621679771220"><span class="hs-identifier hs-var">dataType</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SList '[inputEmbedDim] -&gt; SShape ('Shape '[inputEmbedDim])
forall (dims :: [Dim (Name Symbol) (Size Nat)]).
SList dims -&gt; SShape ('Shape dims)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SShape"><span class="hs-identifier hs-var">SShape</span></a></span><span> </span><span class="annot"><span class="annottext">(SList '[inputEmbedDim] -&gt; SShape ('Shape '[inputEmbedDim]))
-&gt; SList '[inputEmbedDim] -&gt; SShape ('Shape '[inputEmbedDim])
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">SDim inputEmbedDim
</span><a href="#local-6989586621679771216"><span class="hs-identifier hs-var">inputEmbedDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim inputEmbedDim -&gt; SList '[] -&gt; SList '[inputEmbedDim]
forall (dim :: Dim (Name Symbol) (Size Nat))
       (dims :: [Dim (Name Symbol) (Size Nat)]).
SDim dim -&gt; SList dims -&gt; SList (dim : dims)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%7C%3A"><span class="hs-operator hs-var">:|:</span></a></span><span> </span><span class="annot"><span class="annottext">SList '[]
forall a. SList '[]
</span><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-var">SNil</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">Double
</span><a href="#local-6989586621679771212"><span class="hs-identifier hs-var">eps</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679771211"><span class="hs-identifier hs-var">k</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey -&gt; StateDictKey -&gt; StateDictKey
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;embeddings.LayerNorm.&quot;</span></span><span class="hs-special">)</span><span>
</span><span id="line-315"></span><span>        </span><span class="annot"><a href="#local-6989586621679771209"><span class="hs-identifier hs-var">embedLayerNorm</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SRoBERTa"><span class="hs-identifier hs-var">SRoBERTa</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">(SGradient gradient, SDevice device, SDataType dataType,
 SShape ('Shape '[inputEmbedDim]), Double)
-&gt; StateDictKey
-&gt; m (LayerNorm
        'WithBias gradient device dataType ('Shape '[inputEmbedDim]))
forall model input (m :: * -&gt; *).
(HasStateDict model input, MonadThrow m, MonadState StateDict m) =&gt;
input -&gt; StateDictKey -&gt; m model
</span><a href="Torch.GraduallyTyped.NN.Class.html#fromStateDict"><span class="hs-identifier hs-var">fromStateDict</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SGradient gradient
</span><a href="#local-6989586621679771222"><span class="hs-identifier hs-var">gradient</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDevice device
</span><a href="#local-6989586621679771221"><span class="hs-identifier hs-var">device</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDataType dataType
</span><a href="#local-6989586621679771220"><span class="hs-identifier hs-var">dataType</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SList '[inputEmbedDim] -&gt; SShape ('Shape '[inputEmbedDim])
forall (dims :: [Dim (Name Symbol) (Size Nat)]).
SList dims -&gt; SShape ('Shape dims)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SShape"><span class="hs-identifier hs-var">SShape</span></a></span><span> </span><span class="annot"><span class="annottext">(SList '[inputEmbedDim] -&gt; SShape ('Shape '[inputEmbedDim]))
-&gt; SList '[inputEmbedDim] -&gt; SShape ('Shape '[inputEmbedDim])
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">SDim inputEmbedDim
</span><a href="#local-6989586621679771216"><span class="hs-identifier hs-var">inputEmbedDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim inputEmbedDim -&gt; SList '[] -&gt; SList '[inputEmbedDim]
forall (dim :: Dim (Name Symbol) (Size Nat))
       (dims :: [Dim (Name Symbol) (Size Nat)]).
SDim dim -&gt; SList dims -&gt; SList (dim : dims)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%7C%3A"><span class="hs-operator hs-var">:|:</span></a></span><span> </span><span class="annot"><span class="annottext">SList '[]
forall a. SList '[]
</span><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-var">SNil</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">Double
</span><a href="#local-6989586621679771212"><span class="hs-identifier hs-var">eps</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679771211"><span class="hs-identifier hs-var">k</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey -&gt; StateDictKey -&gt; StateDictKey
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;embeddings.LayerNorm.&quot;</span></span><span class="hs-special">)</span><span>
</span><span id="line-316"></span><span>        </span><span class="annot"><a href="#local-6989586621679771209"><span class="hs-identifier hs-var">embedLayerNorm</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SGPT2"><span class="hs-identifier hs-var">SGPT2</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">m (TEEmbedLayerNormF style gradient device dataType inputEmbedDim)
forall a. HasCallStack =&gt; a
</span><span class="hs-identifier hs-var">undefined</span></span><span>
</span><span id="line-317"></span><span>        </span><span id="local-6989586621679771208"><span class="annot"><span class="annottext">layerNorm :: STransformerStyle style
-&gt; m (TELayerNormF style gradient device dataType inputEmbedDim)
</span><a href="#local-6989586621679771208"><span class="hs-identifier hs-var hs-var">layerNorm</span></a></span></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#ST5"><span class="hs-identifier hs-var">ST5</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">(SGradient gradient, SDevice device, SDataType dataType,
 SShape ('Shape '[inputEmbedDim]), Double)
-&gt; StateDictKey
-&gt; m (LayerNorm
        'WithoutBias gradient device dataType ('Shape '[inputEmbedDim]))
forall model input (m :: * -&gt; *).
(HasStateDict model input, MonadThrow m, MonadState StateDict m) =&gt;
input -&gt; StateDictKey -&gt; m model
</span><a href="Torch.GraduallyTyped.NN.Class.html#fromStateDict"><span class="hs-identifier hs-var">fromStateDict</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SGradient gradient
</span><a href="#local-6989586621679771222"><span class="hs-identifier hs-var">gradient</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDevice device
</span><a href="#local-6989586621679771221"><span class="hs-identifier hs-var">device</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDataType dataType
</span><a href="#local-6989586621679771220"><span class="hs-identifier hs-var">dataType</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SList '[inputEmbedDim] -&gt; SShape ('Shape '[inputEmbedDim])
forall (dims :: [Dim (Name Symbol) (Size Nat)]).
SList dims -&gt; SShape ('Shape dims)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SShape"><span class="hs-identifier hs-var">SShape</span></a></span><span> </span><span class="annot"><span class="annottext">(SList '[inputEmbedDim] -&gt; SShape ('Shape '[inputEmbedDim]))
-&gt; SList '[inputEmbedDim] -&gt; SShape ('Shape '[inputEmbedDim])
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">SDim inputEmbedDim
</span><a href="#local-6989586621679771216"><span class="hs-identifier hs-var">inputEmbedDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim inputEmbedDim -&gt; SList '[] -&gt; SList '[inputEmbedDim]
forall (dim :: Dim (Name Symbol) (Size Nat))
       (dims :: [Dim (Name Symbol) (Size Nat)]).
SDim dim -&gt; SList dims -&gt; SList (dim : dims)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%7C%3A"><span class="hs-operator hs-var">:|:</span></a></span><span> </span><span class="annot"><span class="annottext">SList '[]
forall a. SList '[]
</span><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-var">SNil</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">Double
</span><a href="#local-6989586621679771212"><span class="hs-identifier hs-var">eps</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679771211"><span class="hs-identifier hs-var">k</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey -&gt; StateDictKey -&gt; StateDictKey
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;final_layer_norm.&quot;</span></span><span class="hs-special">)</span><span>
</span><span id="line-318"></span><span>        </span><span class="annot"><a href="#local-6989586621679771208"><span class="hs-identifier hs-var">layerNorm</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SByT5"><span class="hs-identifier hs-var">SByT5</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">(SGradient gradient, SDevice device, SDataType dataType,
 SShape ('Shape '[inputEmbedDim]), Double)
-&gt; StateDictKey
-&gt; m (LayerNorm
        'WithoutBias gradient device dataType ('Shape '[inputEmbedDim]))
forall model input (m :: * -&gt; *).
(HasStateDict model input, MonadThrow m, MonadState StateDict m) =&gt;
input -&gt; StateDictKey -&gt; m model
</span><a href="Torch.GraduallyTyped.NN.Class.html#fromStateDict"><span class="hs-identifier hs-var">fromStateDict</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SGradient gradient
</span><a href="#local-6989586621679771222"><span class="hs-identifier hs-var">gradient</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDevice device
</span><a href="#local-6989586621679771221"><span class="hs-identifier hs-var">device</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDataType dataType
</span><a href="#local-6989586621679771220"><span class="hs-identifier hs-var">dataType</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SList '[inputEmbedDim] -&gt; SShape ('Shape '[inputEmbedDim])
forall (dims :: [Dim (Name Symbol) (Size Nat)]).
SList dims -&gt; SShape ('Shape dims)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SShape"><span class="hs-identifier hs-var">SShape</span></a></span><span> </span><span class="annot"><span class="annottext">(SList '[inputEmbedDim] -&gt; SShape ('Shape '[inputEmbedDim]))
-&gt; SList '[inputEmbedDim] -&gt; SShape ('Shape '[inputEmbedDim])
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">SDim inputEmbedDim
</span><a href="#local-6989586621679771216"><span class="hs-identifier hs-var">inputEmbedDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim inputEmbedDim -&gt; SList '[] -&gt; SList '[inputEmbedDim]
forall (dim :: Dim (Name Symbol) (Size Nat))
       (dims :: [Dim (Name Symbol) (Size Nat)]).
SDim dim -&gt; SList dims -&gt; SList (dim : dims)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%7C%3A"><span class="hs-operator hs-var">:|:</span></a></span><span> </span><span class="annot"><span class="annottext">SList '[]
forall a. SList '[]
</span><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-var">SNil</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">Double
</span><a href="#local-6989586621679771212"><span class="hs-identifier hs-var">eps</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679771211"><span class="hs-identifier hs-var">k</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey -&gt; StateDictKey -&gt; StateDictKey
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;final_layer_norm.&quot;</span></span><span class="hs-special">)</span><span>
</span><span id="line-319"></span><span>        </span><span class="annot"><a href="#local-6989586621679771208"><span class="hs-identifier hs-var">layerNorm</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SBART"><span class="hs-identifier hs-var">SBART</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">() -&gt; StateDictKey -&gt; m ()
forall model input (m :: * -&gt; *).
(HasStateDict model input, MonadThrow m, MonadState StateDict m) =&gt;
input -&gt; StateDictKey -&gt; m model
</span><a href="Torch.GraduallyTyped.NN.Class.html#fromStateDict"><span class="hs-identifier hs-var">fromStateDict</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679771211"><span class="hs-identifier hs-var">k</span></a></span><span>
</span><span id="line-320"></span><span>        </span><span class="annot"><a href="#local-6989586621679771208"><span class="hs-identifier hs-var">layerNorm</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SMBART"><span class="hs-identifier hs-var">SMBART</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">() -&gt; StateDictKey -&gt; m ()
forall model input (m :: * -&gt; *).
(HasStateDict model input, MonadThrow m, MonadState StateDict m) =&gt;
input -&gt; StateDictKey -&gt; m model
</span><a href="Torch.GraduallyTyped.NN.Class.html#fromStateDict"><span class="hs-identifier hs-var">fromStateDict</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679771211"><span class="hs-identifier hs-var">k</span></a></span><span>
</span><span id="line-321"></span><span>        </span><span class="annot"><a href="#local-6989586621679771208"><span class="hs-identifier hs-var">layerNorm</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SPegasus"><span class="hs-identifier hs-var">SPegasus</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">(SGradient gradient, SDevice device, SDataType dataType,
 SShape ('Shape '[inputEmbedDim]), Double)
-&gt; StateDictKey
-&gt; m (LayerNorm
        'WithBias gradient device dataType ('Shape '[inputEmbedDim]))
forall model input (m :: * -&gt; *).
(HasStateDict model input, MonadThrow m, MonadState StateDict m) =&gt;
input -&gt; StateDictKey -&gt; m model
</span><a href="Torch.GraduallyTyped.NN.Class.html#fromStateDict"><span class="hs-identifier hs-var">fromStateDict</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SGradient gradient
</span><a href="#local-6989586621679771222"><span class="hs-identifier hs-var">gradient</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDevice device
</span><a href="#local-6989586621679771221"><span class="hs-identifier hs-var">device</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDataType dataType
</span><a href="#local-6989586621679771220"><span class="hs-identifier hs-var">dataType</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SList '[inputEmbedDim] -&gt; SShape ('Shape '[inputEmbedDim])
forall (dims :: [Dim (Name Symbol) (Size Nat)]).
SList dims -&gt; SShape ('Shape dims)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SShape"><span class="hs-identifier hs-var">SShape</span></a></span><span> </span><span class="annot"><span class="annottext">(SList '[inputEmbedDim] -&gt; SShape ('Shape '[inputEmbedDim]))
-&gt; SList '[inputEmbedDim] -&gt; SShape ('Shape '[inputEmbedDim])
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">SDim inputEmbedDim
</span><a href="#local-6989586621679771216"><span class="hs-identifier hs-var">inputEmbedDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim inputEmbedDim -&gt; SList '[] -&gt; SList '[inputEmbedDim]
forall (dim :: Dim (Name Symbol) (Size Nat))
       (dims :: [Dim (Name Symbol) (Size Nat)]).
SDim dim -&gt; SList dims -&gt; SList (dim : dims)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%7C%3A"><span class="hs-operator hs-var">:|:</span></a></span><span> </span><span class="annot"><span class="annottext">SList '[]
forall a. SList '[]
</span><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-var">SNil</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">Double
</span><a href="#local-6989586621679771212"><span class="hs-identifier hs-var">eps</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679771211"><span class="hs-identifier hs-var">k</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey -&gt; StateDictKey -&gt; StateDictKey
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;layer_norm.&quot;</span></span><span class="hs-special">)</span><span>
</span><span id="line-322"></span><span>        </span><span class="annot"><a href="#local-6989586621679771208"><span class="hs-identifier hs-var">layerNorm</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SBERT"><span class="hs-identifier hs-var">SBERT</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">() -&gt; StateDictKey -&gt; m ()
forall model input (m :: * -&gt; *).
(HasStateDict model input, MonadThrow m, MonadState StateDict m) =&gt;
input -&gt; StateDictKey -&gt; m model
</span><a href="Torch.GraduallyTyped.NN.Class.html#fromStateDict"><span class="hs-identifier hs-var">fromStateDict</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679771211"><span class="hs-identifier hs-var">k</span></a></span><span>
</span><span id="line-323"></span><span>        </span><span class="annot"><a href="#local-6989586621679771208"><span class="hs-identifier hs-var">layerNorm</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SRoBERTa"><span class="hs-identifier hs-var">SRoBERTa</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">() -&gt; StateDictKey -&gt; m ()
forall model input (m :: * -&gt; *).
(HasStateDict model input, MonadThrow m, MonadState StateDict m) =&gt;
input -&gt; StateDictKey -&gt; m model
</span><a href="Torch.GraduallyTyped.NN.Class.html#fromStateDict"><span class="hs-identifier hs-var">fromStateDict</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679771211"><span class="hs-identifier hs-var">k</span></a></span><span>
</span><span id="line-324"></span><span>        </span><span class="annot"><a href="#local-6989586621679771208"><span class="hs-identifier hs-var">layerNorm</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SGPT2"><span class="hs-identifier hs-var">SGPT2</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">m (TELayerNormF style gradient device dataType inputEmbedDim)
forall a. HasCallStack =&gt; a
</span><span class="hs-identifier hs-var">undefined</span></span><span>
</span><span id="line-325"></span><span>        </span><span id="local-6989586621679771207"><span class="annot"><span class="annottext">dropout :: STransformerStyle style -&gt; m (Dropout dropoutP)
</span><a href="#local-6989586621679771207"><span class="hs-identifier hs-var hs-var">dropout</span></a></span></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><span class="hs-identifier">_</span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">dropoutP -&gt; StateDictKey -&gt; m (Dropout dropoutP)
forall model input (m :: * -&gt; *).
(HasStateDict model input, MonadThrow m, MonadState StateDict m) =&gt;
input -&gt; StateDictKey -&gt; m model
</span><a href="Torch.GraduallyTyped.NN.Class.html#fromStateDict"><span class="hs-identifier hs-var">fromStateDict</span></a></span><span> </span><span class="annot"><span class="annottext">dropoutP
</span><a href="#local-6989586621679771213"><span class="hs-identifier hs-var">dropoutP</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679771211"><span class="hs-identifier hs-var">k</span></a></span><span>
</span><span id="line-326"></span><span>        </span><span id="local-6989586621679771206"><span class="annot"><span class="annottext">posEnc :: STransformerStyle style
-&gt; m (TEPosEncF
        style gradient device dataType headDim inputEmbedDim posEncDim)
</span><a href="#local-6989586621679771206"><span class="hs-identifier hs-var hs-var">posEnc</span></a></span></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#ST5"><span class="hs-identifier hs-var">ST5</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">(SGradient gradient, SLayout ('Layout 'Dense), SDevice device,
 SDataType dataType, SDim posEncDim, SDim headDim)
-&gt; StateDictKey
-&gt; m (Embedding
        gradient
        ('Layout 'Dense)
        device
        dataType
        posEncDim
        headDim
        'Nothing)
forall model input (m :: * -&gt; *).
(HasStateDict model input, MonadThrow m, MonadState StateDict m) =&gt;
input -&gt; StateDictKey -&gt; m model
</span><a href="Torch.GraduallyTyped.NN.Class.html#fromStateDict"><span class="hs-identifier hs-var">fromStateDict</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SGradient gradient
</span><a href="#local-6989586621679771222"><span class="hs-identifier hs-var">gradient</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SLayoutType 'Dense -&gt; SLayout ('Layout 'Dense)
forall (layoutType :: LayoutType).
SLayoutType layoutType -&gt; SLayout ('Layout layoutType)
</span><a href="Torch.GraduallyTyped.Layout.html#SLayout"><span class="hs-identifier hs-var">SLayout</span></a></span><span> </span><span class="annot"><span class="annottext">SLayoutType 'Dense
</span><a href="Torch.GraduallyTyped.Layout.html#SDense"><span class="hs-identifier hs-var">SDense</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDevice device
</span><a href="#local-6989586621679771221"><span class="hs-identifier hs-var">device</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDataType dataType
</span><a href="#local-6989586621679771220"><span class="hs-identifier hs-var">dataType</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDim posEncDim
</span><a href="#local-6989586621679771214"><span class="hs-identifier hs-var">posEncDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDim headDim
</span><a href="#local-6989586621679771219"><span class="hs-identifier hs-var">headDim</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679771211"><span class="hs-identifier hs-var">k</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey -&gt; StateDictKey -&gt; StateDictKey
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;block.0.layer.0.SelfAttention.relative_attention_bias.&quot;</span></span><span class="hs-special">)</span><span>
</span><span id="line-327"></span><span>        </span><span class="annot"><a href="#local-6989586621679771206"><span class="hs-identifier hs-var">posEnc</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SByT5"><span class="hs-identifier hs-var">SByT5</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">(SGradient gradient, SLayout ('Layout 'Dense), SDevice device,
 SDataType dataType, SDim posEncDim, SDim headDim)
-&gt; StateDictKey
-&gt; m (Embedding
        gradient
        ('Layout 'Dense)
        device
        dataType
        posEncDim
        headDim
        'Nothing)
forall model input (m :: * -&gt; *).
(HasStateDict model input, MonadThrow m, MonadState StateDict m) =&gt;
input -&gt; StateDictKey -&gt; m model
</span><a href="Torch.GraduallyTyped.NN.Class.html#fromStateDict"><span class="hs-identifier hs-var">fromStateDict</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SGradient gradient
</span><a href="#local-6989586621679771222"><span class="hs-identifier hs-var">gradient</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SLayoutType 'Dense -&gt; SLayout ('Layout 'Dense)
forall (layoutType :: LayoutType).
SLayoutType layoutType -&gt; SLayout ('Layout layoutType)
</span><a href="Torch.GraduallyTyped.Layout.html#SLayout"><span class="hs-identifier hs-var">SLayout</span></a></span><span> </span><span class="annot"><span class="annottext">SLayoutType 'Dense
</span><a href="Torch.GraduallyTyped.Layout.html#SDense"><span class="hs-identifier hs-var">SDense</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDevice device
</span><a href="#local-6989586621679771221"><span class="hs-identifier hs-var">device</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDataType dataType
</span><a href="#local-6989586621679771220"><span class="hs-identifier hs-var">dataType</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDim posEncDim
</span><a href="#local-6989586621679771214"><span class="hs-identifier hs-var">posEncDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDim headDim
</span><a href="#local-6989586621679771219"><span class="hs-identifier hs-var">headDim</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679771211"><span class="hs-identifier hs-var">k</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey -&gt; StateDictKey -&gt; StateDictKey
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;block.0.layer.0.SelfAttention.relative_attention_bias.&quot;</span></span><span class="hs-special">)</span><span>
</span><span id="line-328"></span><span>        </span><span class="annot"><a href="#local-6989586621679771206"><span class="hs-identifier hs-var">posEnc</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SBART"><span class="hs-identifier hs-var">SBART</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">(SGradient gradient, SLayout ('Layout 'Dense), SDevice device,
 SDataType dataType, SDim posEncDim, SDim inputEmbedDim)
-&gt; StateDictKey
-&gt; m (Embedding
        gradient
        ('Layout 'Dense)
        device
        dataType
        posEncDim
        inputEmbedDim
        'Nothing)
forall model input (m :: * -&gt; *).
(HasStateDict model input, MonadThrow m, MonadState StateDict m) =&gt;
input -&gt; StateDictKey -&gt; m model
</span><a href="Torch.GraduallyTyped.NN.Class.html#fromStateDict"><span class="hs-identifier hs-var">fromStateDict</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SGradient gradient
</span><a href="#local-6989586621679771222"><span class="hs-identifier hs-var">gradient</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SLayoutType 'Dense -&gt; SLayout ('Layout 'Dense)
forall (layoutType :: LayoutType).
SLayoutType layoutType -&gt; SLayout ('Layout layoutType)
</span><a href="Torch.GraduallyTyped.Layout.html#SLayout"><span class="hs-identifier hs-var">SLayout</span></a></span><span> </span><span class="annot"><span class="annottext">SLayoutType 'Dense
</span><a href="Torch.GraduallyTyped.Layout.html#SDense"><span class="hs-identifier hs-var">SDense</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDevice device
</span><a href="#local-6989586621679771221"><span class="hs-identifier hs-var">device</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDataType dataType
</span><a href="#local-6989586621679771220"><span class="hs-identifier hs-var">dataType</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDim posEncDim
</span><a href="#local-6989586621679771214"><span class="hs-identifier hs-var">posEncDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDim inputEmbedDim
</span><a href="#local-6989586621679771216"><span class="hs-identifier hs-var">inputEmbedDim</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679771211"><span class="hs-identifier hs-var">k</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey -&gt; StateDictKey -&gt; StateDictKey
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;embed_positions.&quot;</span></span><span class="hs-special">)</span><span>
</span><span id="line-329"></span><span>        </span><span class="annot"><a href="#local-6989586621679771206"><span class="hs-identifier hs-var">posEnc</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SMBART"><span class="hs-identifier hs-var">SMBART</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">(SGradient gradient, SLayout ('Layout 'Dense), SDevice device,
 SDataType dataType, SDim posEncDim, SDim inputEmbedDim)
-&gt; StateDictKey
-&gt; m (Embedding
        gradient
        ('Layout 'Dense)
        device
        dataType
        posEncDim
        inputEmbedDim
        'Nothing)
forall model input (m :: * -&gt; *).
(HasStateDict model input, MonadThrow m, MonadState StateDict m) =&gt;
input -&gt; StateDictKey -&gt; m model
</span><a href="Torch.GraduallyTyped.NN.Class.html#fromStateDict"><span class="hs-identifier hs-var">fromStateDict</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SGradient gradient
</span><a href="#local-6989586621679771222"><span class="hs-identifier hs-var">gradient</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SLayoutType 'Dense -&gt; SLayout ('Layout 'Dense)
forall (layoutType :: LayoutType).
SLayoutType layoutType -&gt; SLayout ('Layout layoutType)
</span><a href="Torch.GraduallyTyped.Layout.html#SLayout"><span class="hs-identifier hs-var">SLayout</span></a></span><span> </span><span class="annot"><span class="annottext">SLayoutType 'Dense
</span><a href="Torch.GraduallyTyped.Layout.html#SDense"><span class="hs-identifier hs-var">SDense</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDevice device
</span><a href="#local-6989586621679771221"><span class="hs-identifier hs-var">device</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDataType dataType
</span><a href="#local-6989586621679771220"><span class="hs-identifier hs-var">dataType</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDim posEncDim
</span><a href="#local-6989586621679771214"><span class="hs-identifier hs-var">posEncDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDim inputEmbedDim
</span><a href="#local-6989586621679771216"><span class="hs-identifier hs-var">inputEmbedDim</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679771211"><span class="hs-identifier hs-var">k</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey -&gt; StateDictKey -&gt; StateDictKey
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;embed_positions.&quot;</span></span><span class="hs-special">)</span><span>
</span><span id="line-330"></span><span>        </span><span class="annot"><a href="#local-6989586621679771206"><span class="hs-identifier hs-var">posEnc</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SPegasus"><span class="hs-identifier hs-var">SPegasus</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">(SGradient gradient, SLayout ('Layout 'Dense), SDevice device,
 SDataType dataType, SDim posEncDim, SDim inputEmbedDim)
-&gt; StateDictKey
-&gt; m (Embedding
        gradient
        ('Layout 'Dense)
        device
        dataType
        posEncDim
        inputEmbedDim
        'Nothing)
forall model input (m :: * -&gt; *).
(HasStateDict model input, MonadThrow m, MonadState StateDict m) =&gt;
input -&gt; StateDictKey -&gt; m model
</span><a href="Torch.GraduallyTyped.NN.Class.html#fromStateDict"><span class="hs-identifier hs-var">fromStateDict</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SGradient gradient
</span><a href="#local-6989586621679771222"><span class="hs-identifier hs-var">gradient</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SLayoutType 'Dense -&gt; SLayout ('Layout 'Dense)
forall (layoutType :: LayoutType).
SLayoutType layoutType -&gt; SLayout ('Layout layoutType)
</span><a href="Torch.GraduallyTyped.Layout.html#SLayout"><span class="hs-identifier hs-var">SLayout</span></a></span><span> </span><span class="annot"><span class="annottext">SLayoutType 'Dense
</span><a href="Torch.GraduallyTyped.Layout.html#SDense"><span class="hs-identifier hs-var">SDense</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDevice device
</span><a href="#local-6989586621679771221"><span class="hs-identifier hs-var">device</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDataType dataType
</span><a href="#local-6989586621679771220"><span class="hs-identifier hs-var">dataType</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDim posEncDim
</span><a href="#local-6989586621679771214"><span class="hs-identifier hs-var">posEncDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDim inputEmbedDim
</span><a href="#local-6989586621679771216"><span class="hs-identifier hs-var">inputEmbedDim</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679771211"><span class="hs-identifier hs-var">k</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey -&gt; StateDictKey -&gt; StateDictKey
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;embed_positions.&quot;</span></span><span class="hs-special">)</span><span>
</span><span id="line-331"></span><span>        </span><span class="annot"><a href="#local-6989586621679771206"><span class="hs-identifier hs-var">posEnc</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SBERT"><span class="hs-identifier hs-var">SBERT</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">(SGradient gradient, SLayout ('Layout 'Dense), SDevice device,
 SDataType dataType, SDim posEncDim, SDim inputEmbedDim)
-&gt; StateDictKey
-&gt; m (Embedding
        gradient
        ('Layout 'Dense)
        device
        dataType
        posEncDim
        inputEmbedDim
        'Nothing)
forall model input (m :: * -&gt; *).
(HasStateDict model input, MonadThrow m, MonadState StateDict m) =&gt;
input -&gt; StateDictKey -&gt; m model
</span><a href="Torch.GraduallyTyped.NN.Class.html#fromStateDict"><span class="hs-identifier hs-var">fromStateDict</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SGradient gradient
</span><a href="#local-6989586621679771222"><span class="hs-identifier hs-var">gradient</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SLayoutType 'Dense -&gt; SLayout ('Layout 'Dense)
forall (layoutType :: LayoutType).
SLayoutType layoutType -&gt; SLayout ('Layout layoutType)
</span><a href="Torch.GraduallyTyped.Layout.html#SLayout"><span class="hs-identifier hs-var">SLayout</span></a></span><span> </span><span class="annot"><span class="annottext">SLayoutType 'Dense
</span><a href="Torch.GraduallyTyped.Layout.html#SDense"><span class="hs-identifier hs-var">SDense</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDevice device
</span><a href="#local-6989586621679771221"><span class="hs-identifier hs-var">device</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDataType dataType
</span><a href="#local-6989586621679771220"><span class="hs-identifier hs-var">dataType</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDim posEncDim
</span><a href="#local-6989586621679771214"><span class="hs-identifier hs-var">posEncDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDim inputEmbedDim
</span><a href="#local-6989586621679771216"><span class="hs-identifier hs-var">inputEmbedDim</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679771211"><span class="hs-identifier hs-var">k</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey -&gt; StateDictKey -&gt; StateDictKey
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;embeddings.position_embeddings.&quot;</span></span><span class="hs-special">)</span><span>
</span><span id="line-332"></span><span>        </span><span class="annot"><a href="#local-6989586621679771206"><span class="hs-identifier hs-var">posEnc</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SRoBERTa"><span class="hs-identifier hs-var">SRoBERTa</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">(SGradient gradient, SLayout ('Layout 'Dense), SDevice device,
 SDataType dataType, SDim posEncDim, SDim inputEmbedDim)
-&gt; StateDictKey
-&gt; m (Embedding
        gradient
        ('Layout 'Dense)
        device
        dataType
        posEncDim
        inputEmbedDim
        'Nothing)
forall model input (m :: * -&gt; *).
(HasStateDict model input, MonadThrow m, MonadState StateDict m) =&gt;
input -&gt; StateDictKey -&gt; m model
</span><a href="Torch.GraduallyTyped.NN.Class.html#fromStateDict"><span class="hs-identifier hs-var">fromStateDict</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SGradient gradient
</span><a href="#local-6989586621679771222"><span class="hs-identifier hs-var">gradient</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SLayoutType 'Dense -&gt; SLayout ('Layout 'Dense)
forall (layoutType :: LayoutType).
SLayoutType layoutType -&gt; SLayout ('Layout layoutType)
</span><a href="Torch.GraduallyTyped.Layout.html#SLayout"><span class="hs-identifier hs-var">SLayout</span></a></span><span> </span><span class="annot"><span class="annottext">SLayoutType 'Dense
</span><a href="Torch.GraduallyTyped.Layout.html#SDense"><span class="hs-identifier hs-var">SDense</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDevice device
</span><a href="#local-6989586621679771221"><span class="hs-identifier hs-var">device</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDataType dataType
</span><a href="#local-6989586621679771220"><span class="hs-identifier hs-var">dataType</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDim posEncDim
</span><a href="#local-6989586621679771214"><span class="hs-identifier hs-var">posEncDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDim inputEmbedDim
</span><a href="#local-6989586621679771216"><span class="hs-identifier hs-var">inputEmbedDim</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679771211"><span class="hs-identifier hs-var">k</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey -&gt; StateDictKey -&gt; StateDictKey
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;embeddings.position_embeddings.&quot;</span></span><span class="hs-special">)</span><span>
</span><span id="line-333"></span><span>        </span><span class="annot"><a href="#local-6989586621679771206"><span class="hs-identifier hs-var">posEnc</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SGPT2"><span class="hs-identifier hs-var">SGPT2</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">m (TEPosEncF
     style gradient device dataType headDim inputEmbedDim posEncDim)
forall a. HasCallStack =&gt; a
</span><span class="hs-identifier hs-var">undefined</span></span><span>
</span><span id="line-334"></span><span>     </span><span class="hs-keyword">in</span><span> </span><span class="annot"><span class="annottext">GTransformerEncoder
  (TransformerStack
     style
     numLayers
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     inputEmbedDim
     ffnDim
     dropoutP)
  (TEEmbedLayerNormF style gradient device dataType inputEmbedDim)
  (TELayerNormF style gradient device dataType inputEmbedDim)
  (Dropout dropoutP)
  (TEPosEncF
     style gradient device dataType headDim inputEmbedDim posEncDim)
-&gt; TransformerEncoder
     style
     numLayers
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     inputEmbedDim
     ffnDim
     posEncDim
     dropoutP
forall (style :: TransformerStyle) (numLayers :: Nat)
       (gradient :: Gradient RequiresGradient)
       (device :: Device (DeviceType Nat)) (dataType :: DataType DType)
       (headDim :: Dim (Name Symbol) (Size Nat))
       (headEmbedDim :: Dim (Name Symbol) (Size Nat))
       (embedDim :: Dim (Name Symbol) (Size Nat))
       (inputEmbedDim :: Dim (Name Symbol) (Size Nat))
       (ffnDim :: Dim (Name Symbol) (Size Nat))
       (posEncDim :: Dim (Name Symbol) (Size Nat)) dropoutP.
GTransformerEncoder
  (TEStackF
     style
     numLayers
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     inputEmbedDim
     ffnDim
     dropoutP)
  (TEEmbedLayerNormF style gradient device dataType inputEmbedDim)
  (TELayerNormF style gradient device dataType inputEmbedDim)
  (TEDropoutF style dropoutP)
  (TEPosEncF
     style gradient device dataType headDim inputEmbedDim posEncDim)
-&gt; TransformerEncoder
     style
     numLayers
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     inputEmbedDim
     ffnDim
     posEncDim
     dropoutP
</span><a href="Torch.GraduallyTyped.NN.Transformer.Encoder.html#TransformerEncoder"><span class="hs-identifier hs-var">TransformerEncoder</span></a></span><span>
</span><span id="line-335"></span><span>          </span><span class="annot"><span class="annottext">(GTransformerEncoder
   (TransformerStack
      style
      numLayers
      gradient
      device
      dataType
      headDim
      headEmbedDim
      embedDim
      inputEmbedDim
      ffnDim
      dropoutP)
   (TEEmbedLayerNormF style gradient device dataType inputEmbedDim)
   (TELayerNormF style gradient device dataType inputEmbedDim)
   (Dropout dropoutP)
   (TEPosEncF
      style gradient device dataType headDim inputEmbedDim posEncDim)
 -&gt; TransformerEncoder
      style
      numLayers
      gradient
      device
      dataType
      headDim
      headEmbedDim
      embedDim
      inputEmbedDim
      ffnDim
      posEncDim
      dropoutP)
-&gt; m (GTransformerEncoder
        (TransformerStack
           style
           numLayers
           gradient
           device
           dataType
           headDim
           headEmbedDim
           embedDim
           inputEmbedDim
           ffnDim
           dropoutP)
        (TEEmbedLayerNormF style gradient device dataType inputEmbedDim)
        (TELayerNormF style gradient device dataType inputEmbedDim)
        (Dropout dropoutP)
        (TEPosEncF
           style gradient device dataType headDim inputEmbedDim posEncDim))
-&gt; m (TransformerEncoder
        style
        numLayers
        gradient
        device
        dataType
        headDim
        headEmbedDim
        embedDim
        inputEmbedDim
        ffnDim
        posEncDim
        dropoutP)
forall (f :: * -&gt; *) a b. Functor f =&gt; (a -&gt; b) -&gt; f a -&gt; f b
</span><span class="hs-operator hs-var">&lt;$&gt;</span></span><span> </span><span class="hs-special">(</span><span> </span><span class="annot"><span class="annottext">TransformerStack
  style
  numLayers
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  inputEmbedDim
  ffnDim
  dropoutP
-&gt; TEEmbedLayerNormF style gradient device dataType inputEmbedDim
-&gt; TELayerNormF style gradient device dataType inputEmbedDim
-&gt; Dropout dropoutP
-&gt; TEPosEncF
     style gradient device dataType headDim inputEmbedDim posEncDim
-&gt; GTransformerEncoder
     (TransformerStack
        style
        numLayers
        gradient
        device
        dataType
        headDim
        headEmbedDim
        embedDim
        inputEmbedDim
        ffnDim
        dropoutP)
     (TEEmbedLayerNormF style gradient device dataType inputEmbedDim)
     (TELayerNormF style gradient device dataType inputEmbedDim)
     (Dropout dropoutP)
     (TEPosEncF
        style gradient device dataType headDim inputEmbedDim posEncDim)
forall stack embedLayerNorm layerNorm dropout posEnc.
stack
-&gt; embedLayerNorm
-&gt; layerNorm
-&gt; dropout
-&gt; posEnc
-&gt; GTransformerEncoder
     stack embedLayerNorm layerNorm dropout posEnc
</span><a href="Torch.GraduallyTyped.NN.Transformer.Encoder.html#GTransformerEncoder"><span class="hs-identifier hs-var">GTransformerEncoder</span></a></span><span>
</span><span id="line-336"></span><span>                  </span><span class="annot"><span class="annottext">(TransformerStack
   style
   numLayers
   gradient
   device
   dataType
   headDim
   headEmbedDim
   embedDim
   inputEmbedDim
   ffnDim
   dropoutP
 -&gt; TEEmbedLayerNormF style gradient device dataType inputEmbedDim
 -&gt; TELayerNormF style gradient device dataType inputEmbedDim
 -&gt; Dropout dropoutP
 -&gt; TEPosEncF
      style gradient device dataType headDim inputEmbedDim posEncDim
 -&gt; GTransformerEncoder
      (TransformerStack
         style
         numLayers
         gradient
         device
         dataType
         headDim
         headEmbedDim
         embedDim
         inputEmbedDim
         ffnDim
         dropoutP)
      (TEEmbedLayerNormF style gradient device dataType inputEmbedDim)
      (TELayerNormF style gradient device dataType inputEmbedDim)
      (Dropout dropoutP)
      (TEPosEncF
         style gradient device dataType headDim inputEmbedDim posEncDim))
-&gt; m (TransformerStack
        style
        numLayers
        gradient
        device
        dataType
        headDim
        headEmbedDim
        embedDim
        inputEmbedDim
        ffnDim
        dropoutP)
-&gt; m (TEEmbedLayerNormF
        style gradient device dataType inputEmbedDim
      -&gt; TELayerNormF style gradient device dataType inputEmbedDim
      -&gt; Dropout dropoutP
      -&gt; TEPosEncF
           style gradient device dataType headDim inputEmbedDim posEncDim
      -&gt; GTransformerEncoder
           (TransformerStack
              style
              numLayers
              gradient
              device
              dataType
              headDim
              headEmbedDim
              embedDim
              inputEmbedDim
              ffnDim
              dropoutP)
           (TEEmbedLayerNormF style gradient device dataType inputEmbedDim)
           (TELayerNormF style gradient device dataType inputEmbedDim)
           (Dropout dropoutP)
           (TEPosEncF
              style gradient device dataType headDim inputEmbedDim posEncDim))
forall (f :: * -&gt; *) a b. Functor f =&gt; (a -&gt; b) -&gt; f a -&gt; f b
</span><span class="hs-operator hs-var">&lt;$&gt;</span></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
-&gt; m (TransformerStack
        style
        numLayers
        gradient
        device
        dataType
        headDim
        headEmbedDim
        embedDim
        inputEmbedDim
        ffnDim
        dropoutP)
</span><a href="#local-6989586621679771210"><span class="hs-identifier hs-var">stack</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SingI style =&gt; Sing style
forall k (a :: k). SingI a =&gt; Sing a
</span><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-var">sing</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679771239"><span class="hs-identifier hs-type">style</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-337"></span><span>                  </span><span class="annot"><span class="annottext">m (TEEmbedLayerNormF style gradient device dataType inputEmbedDim
   -&gt; TELayerNormF style gradient device dataType inputEmbedDim
   -&gt; Dropout dropoutP
   -&gt; TEPosEncF
        style gradient device dataType headDim inputEmbedDim posEncDim
   -&gt; GTransformerEncoder
        (TransformerStack
           style
           numLayers
           gradient
           device
           dataType
           headDim
           headEmbedDim
           embedDim
           inputEmbedDim
           ffnDim
           dropoutP)
        (TEEmbedLayerNormF style gradient device dataType inputEmbedDim)
        (TELayerNormF style gradient device dataType inputEmbedDim)
        (Dropout dropoutP)
        (TEPosEncF
           style gradient device dataType headDim inputEmbedDim posEncDim))
-&gt; m (TEEmbedLayerNormF
        style gradient device dataType inputEmbedDim)
-&gt; m (TELayerNormF style gradient device dataType inputEmbedDim
      -&gt; Dropout dropoutP
      -&gt; TEPosEncF
           style gradient device dataType headDim inputEmbedDim posEncDim
      -&gt; GTransformerEncoder
           (TransformerStack
              style
              numLayers
              gradient
              device
              dataType
              headDim
              headEmbedDim
              embedDim
              inputEmbedDim
              ffnDim
              dropoutP)
           (TEEmbedLayerNormF style gradient device dataType inputEmbedDim)
           (TELayerNormF style gradient device dataType inputEmbedDim)
           (Dropout dropoutP)
           (TEPosEncF
              style gradient device dataType headDim inputEmbedDim posEncDim))
forall (f :: * -&gt; *) a b. Applicative f =&gt; f (a -&gt; b) -&gt; f a -&gt; f b
</span><span class="hs-operator hs-var">&lt;*&gt;</span></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
-&gt; m (TEEmbedLayerNormF
        style gradient device dataType inputEmbedDim)
</span><a href="#local-6989586621679771209"><span class="hs-identifier hs-var">embedLayerNorm</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SingI style =&gt; Sing style
forall k (a :: k). SingI a =&gt; Sing a
</span><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-var">sing</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679771239"><span class="hs-identifier hs-type">style</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-338"></span><span>                  </span><span class="annot"><span class="annottext">m (TELayerNormF style gradient device dataType inputEmbedDim
   -&gt; Dropout dropoutP
   -&gt; TEPosEncF
        style gradient device dataType headDim inputEmbedDim posEncDim
   -&gt; GTransformerEncoder
        (TransformerStack
           style
           numLayers
           gradient
           device
           dataType
           headDim
           headEmbedDim
           embedDim
           inputEmbedDim
           ffnDim
           dropoutP)
        (TEEmbedLayerNormF style gradient device dataType inputEmbedDim)
        (TELayerNormF style gradient device dataType inputEmbedDim)
        (Dropout dropoutP)
        (TEPosEncF
           style gradient device dataType headDim inputEmbedDim posEncDim))
-&gt; m (TELayerNormF style gradient device dataType inputEmbedDim)
-&gt; m (Dropout dropoutP
      -&gt; TEPosEncF
           style gradient device dataType headDim inputEmbedDim posEncDim
      -&gt; GTransformerEncoder
           (TransformerStack
              style
              numLayers
              gradient
              device
              dataType
              headDim
              headEmbedDim
              embedDim
              inputEmbedDim
              ffnDim
              dropoutP)
           (TEEmbedLayerNormF style gradient device dataType inputEmbedDim)
           (TELayerNormF style gradient device dataType inputEmbedDim)
           (Dropout dropoutP)
           (TEPosEncF
              style gradient device dataType headDim inputEmbedDim posEncDim))
forall (f :: * -&gt; *) a b. Applicative f =&gt; f (a -&gt; b) -&gt; f a -&gt; f b
</span><span class="hs-operator hs-var">&lt;*&gt;</span></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
-&gt; m (TELayerNormF style gradient device dataType inputEmbedDim)
</span><a href="#local-6989586621679771208"><span class="hs-identifier hs-var">layerNorm</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SingI style =&gt; Sing style
forall k (a :: k). SingI a =&gt; Sing a
</span><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-var">sing</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679771239"><span class="hs-identifier hs-type">style</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-339"></span><span>                  </span><span class="annot"><span class="annottext">m (Dropout dropoutP
   -&gt; TEPosEncF
        style gradient device dataType headDim inputEmbedDim posEncDim
   -&gt; GTransformerEncoder
        (TransformerStack
           style
           numLayers
           gradient
           device
           dataType
           headDim
           headEmbedDim
           embedDim
           inputEmbedDim
           ffnDim
           dropoutP)
        (TEEmbedLayerNormF style gradient device dataType inputEmbedDim)
        (TELayerNormF style gradient device dataType inputEmbedDim)
        (Dropout dropoutP)
        (TEPosEncF
           style gradient device dataType headDim inputEmbedDim posEncDim))
-&gt; m (Dropout dropoutP)
-&gt; m (TEPosEncF
        style gradient device dataType headDim inputEmbedDim posEncDim
      -&gt; GTransformerEncoder
           (TransformerStack
              style
              numLayers
              gradient
              device
              dataType
              headDim
              headEmbedDim
              embedDim
              inputEmbedDim
              ffnDim
              dropoutP)
           (TEEmbedLayerNormF style gradient device dataType inputEmbedDim)
           (TELayerNormF style gradient device dataType inputEmbedDim)
           (Dropout dropoutP)
           (TEPosEncF
              style gradient device dataType headDim inputEmbedDim posEncDim))
forall (f :: * -&gt; *) a b. Applicative f =&gt; f (a -&gt; b) -&gt; f a -&gt; f b
</span><span class="hs-operator hs-var">&lt;*&gt;</span></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style -&gt; m (Dropout dropoutP)
</span><a href="#local-6989586621679771207"><span class="hs-identifier hs-var">dropout</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SingI style =&gt; Sing style
forall k (a :: k). SingI a =&gt; Sing a
</span><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-var">sing</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679771239"><span class="hs-identifier hs-type">style</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-340"></span><span>                  </span><span class="annot"><span class="annottext">m (TEPosEncF
     style gradient device dataType headDim inputEmbedDim posEncDim
   -&gt; GTransformerEncoder
        (TransformerStack
           style
           numLayers
           gradient
           device
           dataType
           headDim
           headEmbedDim
           embedDim
           inputEmbedDim
           ffnDim
           dropoutP)
        (TEEmbedLayerNormF style gradient device dataType inputEmbedDim)
        (TELayerNormF style gradient device dataType inputEmbedDim)
        (Dropout dropoutP)
        (TEPosEncF
           style gradient device dataType headDim inputEmbedDim posEncDim))
-&gt; m (TEPosEncF
        style gradient device dataType headDim inputEmbedDim posEncDim)
-&gt; m (GTransformerEncoder
        (TransformerStack
           style
           numLayers
           gradient
           device
           dataType
           headDim
           headEmbedDim
           embedDim
           inputEmbedDim
           ffnDim
           dropoutP)
        (TEEmbedLayerNormF style gradient device dataType inputEmbedDim)
        (TELayerNormF style gradient device dataType inputEmbedDim)
        (Dropout dropoutP)
        (TEPosEncF
           style gradient device dataType headDim inputEmbedDim posEncDim))
forall (f :: * -&gt; *) a b. Applicative f =&gt; f (a -&gt; b) -&gt; f a -&gt; f b
</span><span class="hs-operator hs-var">&lt;*&gt;</span></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
-&gt; m (TEPosEncF
        style gradient device dataType headDim inputEmbedDim posEncDim)
</span><a href="#local-6989586621679771206"><span class="hs-identifier hs-var">posEnc</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SingI style =&gt; Sing style
forall k (a :: k). SingI a =&gt; Sing a
</span><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-var">sing</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679771239"><span class="hs-identifier hs-type">style</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-341"></span><span>              </span><span class="hs-special">)</span><span>
</span><span id="line-342"></span><span>  </span><span id="local-6989586621679771204"><span class="annot"><span class="annottext">toStateDict :: StateDictKey
-&gt; TransformerEncoder
     style
     numLayers
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     inputEmbedDim
     ffnDim
     posEncDim
     dropoutP
-&gt; m ()
</span><a href="Torch.GraduallyTyped.NN.Class.html#toStateDict"><span class="hs-identifier hs-var hs-var hs-var hs-var">toStateDict</span></a></span></span><span> </span><span id="local-6989586621679771202"><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679771202"><span class="hs-identifier hs-var">k</span></a></span></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Encoder.html#TransformerEncoder"><span class="hs-identifier hs-type">TransformerEncoder</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Encoder.html#GTransformerEncoder"><span class="hs-identifier hs-type">GTransformerEncoder</span></a></span><span> </span><span class="hs-special">{</span><span id="local-6989586621679771197"><span id="local-6989586621679771198"><span id="local-6989586621679771199"><span id="local-6989586621679771200"><span id="local-6989586621679771201"><span class="annot"><span class="annottext">TEPosEncF
  style gradient device dataType headDim inputEmbedDim posEncDim
TEDropoutF style dropoutP
TELayerNormF style gradient device dataType inputEmbedDim
TEEmbedLayerNormF style gradient device dataType inputEmbedDim
TEStackF
  style
  numLayers
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  inputEmbedDim
  ffnDim
  dropoutP
tePosEnc :: TEPosEncF
  style gradient device dataType headDim inputEmbedDim posEncDim
teDropout :: TEDropoutF style dropoutP
teLayerNorm :: TELayerNormF style gradient device dataType inputEmbedDim
teEmbedLayerNorm :: TEEmbedLayerNormF style gradient device dataType inputEmbedDim
teStack :: TEStackF
  style
  numLayers
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  inputEmbedDim
  ffnDim
  dropoutP
tePosEnc :: forall stack embedLayerNorm layerNorm dropout posEnc.
GTransformerEncoder stack embedLayerNorm layerNorm dropout posEnc
-&gt; posEnc
teDropout :: forall stack embedLayerNorm layerNorm dropout posEnc.
GTransformerEncoder stack embedLayerNorm layerNorm dropout posEnc
-&gt; dropout
teLayerNorm :: forall stack embedLayerNorm layerNorm dropout posEnc.
GTransformerEncoder stack embedLayerNorm layerNorm dropout posEnc
-&gt; layerNorm
teEmbedLayerNorm :: forall stack embedLayerNorm layerNorm dropout posEnc.
GTransformerEncoder stack embedLayerNorm layerNorm dropout posEnc
-&gt; embedLayerNorm
teStack :: forall stack embedLayerNorm layerNorm dropout posEnc.
GTransformerEncoder stack embedLayerNorm layerNorm dropout posEnc
-&gt; stack
</span><a href="#local-6989586621679771197"><span class="hs-glyph hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var">..</span></a></span></span></span></span></span></span><span class="hs-special">}</span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-343"></span><span>    </span><span class="hs-keyword">let</span><span> </span><span id="local-6989586621679771196"><span class="annot"><span class="annottext">stack :: STransformerStyle style
-&gt; TransformerStack
     style
     numLayers
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     inputEmbedDim
     ffnDim
     dropoutP
-&gt; m ()
</span><a href="#local-6989586621679771196"><span class="hs-identifier hs-var hs-var">stack</span></a></span></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#ST5"><span class="hs-identifier hs-var">ST5</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">StateDictKey
-&gt; TransformerStack
     'T5
     numLayers
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     inputEmbedDim
     ffnDim
     dropoutP
-&gt; m ()
forall model input (m :: * -&gt; *).
(HasStateDict model input, MonadThrow m, MonadState StateDict m) =&gt;
StateDictKey -&gt; model -&gt; m ()
</span><a href="Torch.GraduallyTyped.NN.Class.html#toStateDict"><span class="hs-identifier hs-var">toStateDict</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679771202"><span class="hs-identifier hs-var">k</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey -&gt; StateDictKey -&gt; StateDictKey
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;block.&quot;</span></span><span class="hs-special">)</span><span>
</span><span id="line-344"></span><span>        </span><span class="annot"><a href="#local-6989586621679771196"><span class="hs-identifier hs-var">stack</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SByT5"><span class="hs-identifier hs-var">SByT5</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">StateDictKey
-&gt; TransformerStack
     'ByT5
     numLayers
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     inputEmbedDim
     ffnDim
     dropoutP
-&gt; m ()
forall model input (m :: * -&gt; *).
(HasStateDict model input, MonadThrow m, MonadState StateDict m) =&gt;
StateDictKey -&gt; model -&gt; m ()
</span><a href="Torch.GraduallyTyped.NN.Class.html#toStateDict"><span class="hs-identifier hs-var">toStateDict</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679771202"><span class="hs-identifier hs-var">k</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey -&gt; StateDictKey -&gt; StateDictKey
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;block.&quot;</span></span><span class="hs-special">)</span><span>
</span><span id="line-345"></span><span>        </span><span class="annot"><a href="#local-6989586621679771196"><span class="hs-identifier hs-var">stack</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SBART"><span class="hs-identifier hs-var">SBART</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">StateDictKey
-&gt; TransformerStack
     'BART
     numLayers
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     inputEmbedDim
     ffnDim
     dropoutP
-&gt; m ()
forall model input (m :: * -&gt; *).
(HasStateDict model input, MonadThrow m, MonadState StateDict m) =&gt;
StateDictKey -&gt; model -&gt; m ()
</span><a href="Torch.GraduallyTyped.NN.Class.html#toStateDict"><span class="hs-identifier hs-var">toStateDict</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679771202"><span class="hs-identifier hs-var">k</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey -&gt; StateDictKey -&gt; StateDictKey
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;layers.&quot;</span></span><span class="hs-special">)</span><span>
</span><span id="line-346"></span><span>        </span><span class="annot"><a href="#local-6989586621679771196"><span class="hs-identifier hs-var">stack</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SMBART"><span class="hs-identifier hs-var">SMBART</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">StateDictKey
-&gt; TransformerStack
     'MBART
     numLayers
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     inputEmbedDim
     ffnDim
     dropoutP
-&gt; m ()
forall model input (m :: * -&gt; *).
(HasStateDict model input, MonadThrow m, MonadState StateDict m) =&gt;
StateDictKey -&gt; model -&gt; m ()
</span><a href="Torch.GraduallyTyped.NN.Class.html#toStateDict"><span class="hs-identifier hs-var">toStateDict</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679771202"><span class="hs-identifier hs-var">k</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey -&gt; StateDictKey -&gt; StateDictKey
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;layers.&quot;</span></span><span class="hs-special">)</span><span>
</span><span id="line-347"></span><span>        </span><span class="annot"><a href="#local-6989586621679771196"><span class="hs-identifier hs-var">stack</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SPegasus"><span class="hs-identifier hs-var">SPegasus</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">StateDictKey
-&gt; TransformerStack
     'Pegasus
     numLayers
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     inputEmbedDim
     ffnDim
     dropoutP
-&gt; m ()
forall model input (m :: * -&gt; *).
(HasStateDict model input, MonadThrow m, MonadState StateDict m) =&gt;
StateDictKey -&gt; model -&gt; m ()
</span><a href="Torch.GraduallyTyped.NN.Class.html#toStateDict"><span class="hs-identifier hs-var">toStateDict</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679771202"><span class="hs-identifier hs-var">k</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey -&gt; StateDictKey -&gt; StateDictKey
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;layers.&quot;</span></span><span class="hs-special">)</span><span>
</span><span id="line-348"></span><span>        </span><span class="annot"><a href="#local-6989586621679771196"><span class="hs-identifier hs-var">stack</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SBERT"><span class="hs-identifier hs-var">SBERT</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">StateDictKey
-&gt; TransformerStack
     'BERT
     numLayers
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     inputEmbedDim
     ffnDim
     dropoutP
-&gt; m ()
forall model input (m :: * -&gt; *).
(HasStateDict model input, MonadThrow m, MonadState StateDict m) =&gt;
StateDictKey -&gt; model -&gt; m ()
</span><a href="Torch.GraduallyTyped.NN.Class.html#toStateDict"><span class="hs-identifier hs-var">toStateDict</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679771202"><span class="hs-identifier hs-var">k</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey -&gt; StateDictKey -&gt; StateDictKey
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;encoder.layer.&quot;</span></span><span class="hs-special">)</span><span>
</span><span id="line-349"></span><span>        </span><span class="annot"><a href="#local-6989586621679771196"><span class="hs-identifier hs-var">stack</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SRoBERTa"><span class="hs-identifier hs-var">SRoBERTa</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">StateDictKey
-&gt; TransformerStack
     'RoBERTa
     numLayers
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     inputEmbedDim
     ffnDim
     dropoutP
-&gt; m ()
forall model input (m :: * -&gt; *).
(HasStateDict model input, MonadThrow m, MonadState StateDict m) =&gt;
StateDictKey -&gt; model -&gt; m ()
</span><a href="Torch.GraduallyTyped.NN.Class.html#toStateDict"><span class="hs-identifier hs-var">toStateDict</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679771202"><span class="hs-identifier hs-var">k</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey -&gt; StateDictKey -&gt; StateDictKey
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;encoder.layer.&quot;</span></span><span class="hs-special">)</span><span>
</span><span id="line-350"></span><span>        </span><span class="annot"><a href="#local-6989586621679771196"><span class="hs-identifier hs-var">stack</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SGPT2"><span class="hs-identifier hs-var">SGPT2</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">TransformerStack
  style
  numLayers
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  inputEmbedDim
  ffnDim
  dropoutP
-&gt; m ()
forall a. HasCallStack =&gt; a
</span><span class="hs-identifier hs-var">undefined</span></span><span>
</span><span id="line-351"></span><span>        </span><span id="local-6989586621679771195"><span class="annot"><span class="annottext">embedLayerNorm :: STransformerStyle style
-&gt; TEEmbedLayerNormF style gradient device dataType inputEmbedDim
-&gt; m ()
</span><a href="#local-6989586621679771195"><span class="hs-identifier hs-var hs-var">embedLayerNorm</span></a></span></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#ST5"><span class="hs-identifier hs-var">ST5</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">StateDictKey -&gt; () -&gt; m ()
forall model input (m :: * -&gt; *).
(HasStateDict model input, MonadThrow m, MonadState StateDict m) =&gt;
StateDictKey -&gt; model -&gt; m ()
</span><a href="Torch.GraduallyTyped.NN.Class.html#toStateDict"><span class="hs-identifier hs-var">toStateDict</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679771202"><span class="hs-identifier hs-var">k</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey -&gt; StateDictKey -&gt; StateDictKey
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;layernorm_embedding.&quot;</span></span><span class="hs-special">)</span><span>
</span><span id="line-352"></span><span>        </span><span class="annot"><a href="#local-6989586621679771195"><span class="hs-identifier hs-var">embedLayerNorm</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SByT5"><span class="hs-identifier hs-var">SByT5</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">StateDictKey -&gt; () -&gt; m ()
forall model input (m :: * -&gt; *).
(HasStateDict model input, MonadThrow m, MonadState StateDict m) =&gt;
StateDictKey -&gt; model -&gt; m ()
</span><a href="Torch.GraduallyTyped.NN.Class.html#toStateDict"><span class="hs-identifier hs-var">toStateDict</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679771202"><span class="hs-identifier hs-var">k</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey -&gt; StateDictKey -&gt; StateDictKey
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;layernorm_embedding.&quot;</span></span><span class="hs-special">)</span><span>
</span><span id="line-353"></span><span>        </span><span class="annot"><a href="#local-6989586621679771195"><span class="hs-identifier hs-var">embedLayerNorm</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SBART"><span class="hs-identifier hs-var">SBART</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">StateDictKey
-&gt; LayerNorm
     'WithBias gradient device dataType ('Shape '[inputEmbedDim])
-&gt; m ()
forall model input (m :: * -&gt; *).
(HasStateDict model input, MonadThrow m, MonadState StateDict m) =&gt;
StateDictKey -&gt; model -&gt; m ()
</span><a href="Torch.GraduallyTyped.NN.Class.html#toStateDict"><span class="hs-identifier hs-var">toStateDict</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679771202"><span class="hs-identifier hs-var">k</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey -&gt; StateDictKey -&gt; StateDictKey
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;layernorm_embedding.&quot;</span></span><span class="hs-special">)</span><span>
</span><span id="line-354"></span><span>        </span><span class="annot"><a href="#local-6989586621679771195"><span class="hs-identifier hs-var">embedLayerNorm</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SMBART"><span class="hs-identifier hs-var">SMBART</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">StateDictKey
-&gt; LayerNorm
     'WithBias gradient device dataType ('Shape '[inputEmbedDim])
-&gt; m ()
forall model input (m :: * -&gt; *).
(HasStateDict model input, MonadThrow m, MonadState StateDict m) =&gt;
StateDictKey -&gt; model -&gt; m ()
</span><a href="Torch.GraduallyTyped.NN.Class.html#toStateDict"><span class="hs-identifier hs-var">toStateDict</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679771202"><span class="hs-identifier hs-var">k</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey -&gt; StateDictKey -&gt; StateDictKey
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;layernorm_embedding.&quot;</span></span><span class="hs-special">)</span><span>
</span><span id="line-355"></span><span>        </span><span class="annot"><a href="#local-6989586621679771195"><span class="hs-identifier hs-var">embedLayerNorm</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SPegasus"><span class="hs-identifier hs-var">SPegasus</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">StateDictKey -&gt; () -&gt; m ()
forall model input (m :: * -&gt; *).
(HasStateDict model input, MonadThrow m, MonadState StateDict m) =&gt;
StateDictKey -&gt; model -&gt; m ()
</span><a href="Torch.GraduallyTyped.NN.Class.html#toStateDict"><span class="hs-identifier hs-var">toStateDict</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679771202"><span class="hs-identifier hs-var">k</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey -&gt; StateDictKey -&gt; StateDictKey
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;layernorm_embedding.&quot;</span></span><span class="hs-special">)</span><span>
</span><span id="line-356"></span><span>        </span><span class="annot"><a href="#local-6989586621679771195"><span class="hs-identifier hs-var">embedLayerNorm</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SBERT"><span class="hs-identifier hs-var">SBERT</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">StateDictKey
-&gt; LayerNorm
     'WithBias gradient device dataType ('Shape '[inputEmbedDim])
-&gt; m ()
forall model input (m :: * -&gt; *).
(HasStateDict model input, MonadThrow m, MonadState StateDict m) =&gt;
StateDictKey -&gt; model -&gt; m ()
</span><a href="Torch.GraduallyTyped.NN.Class.html#toStateDict"><span class="hs-identifier hs-var">toStateDict</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679771202"><span class="hs-identifier hs-var">k</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey -&gt; StateDictKey -&gt; StateDictKey
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;embeddings.LayerNorm.&quot;</span></span><span class="hs-special">)</span><span>
</span><span id="line-357"></span><span>        </span><span class="annot"><a href="#local-6989586621679771195"><span class="hs-identifier hs-var">embedLayerNorm</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SRoBERTa"><span class="hs-identifier hs-var">SRoBERTa</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">StateDictKey
-&gt; LayerNorm
     'WithBias gradient device dataType ('Shape '[inputEmbedDim])
-&gt; m ()
forall model input (m :: * -&gt; *).
(HasStateDict model input, MonadThrow m, MonadState StateDict m) =&gt;
StateDictKey -&gt; model -&gt; m ()
</span><a href="Torch.GraduallyTyped.NN.Class.html#toStateDict"><span class="hs-identifier hs-var">toStateDict</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679771202"><span class="hs-identifier hs-var">k</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey -&gt; StateDictKey -&gt; StateDictKey
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;embeddings.LayerNorm.&quot;</span></span><span class="hs-special">)</span><span>
</span><span id="line-358"></span><span>        </span><span class="annot"><a href="#local-6989586621679771195"><span class="hs-identifier hs-var">embedLayerNorm</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SGPT2"><span class="hs-identifier hs-var">SGPT2</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">TEEmbedLayerNormF style gradient device dataType inputEmbedDim
-&gt; m ()
forall a. HasCallStack =&gt; a
</span><span class="hs-identifier hs-var">undefined</span></span><span>
</span><span id="line-359"></span><span>        </span><span id="local-6989586621679771194"><span class="annot"><span class="annottext">layerNorm :: STransformerStyle style
-&gt; TELayerNormF style gradient device dataType inputEmbedDim
-&gt; m ()
</span><a href="#local-6989586621679771194"><span class="hs-identifier hs-var hs-var">layerNorm</span></a></span></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#ST5"><span class="hs-identifier hs-var">ST5</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">StateDictKey
-&gt; LayerNorm
     'WithoutBias gradient device dataType ('Shape '[inputEmbedDim])
-&gt; m ()
forall model input (m :: * -&gt; *).
(HasStateDict model input, MonadThrow m, MonadState StateDict m) =&gt;
StateDictKey -&gt; model -&gt; m ()
</span><a href="Torch.GraduallyTyped.NN.Class.html#toStateDict"><span class="hs-identifier hs-var">toStateDict</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679771202"><span class="hs-identifier hs-var">k</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey -&gt; StateDictKey -&gt; StateDictKey
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;final_layer_norm.&quot;</span></span><span class="hs-special">)</span><span>
</span><span id="line-360"></span><span>        </span><span class="annot"><a href="#local-6989586621679771194"><span class="hs-identifier hs-var">layerNorm</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SByT5"><span class="hs-identifier hs-var">SByT5</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">StateDictKey
-&gt; LayerNorm
     'WithoutBias gradient device dataType ('Shape '[inputEmbedDim])
-&gt; m ()
forall model input (m :: * -&gt; *).
(HasStateDict model input, MonadThrow m, MonadState StateDict m) =&gt;
StateDictKey -&gt; model -&gt; m ()
</span><a href="Torch.GraduallyTyped.NN.Class.html#toStateDict"><span class="hs-identifier hs-var">toStateDict</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679771202"><span class="hs-identifier hs-var">k</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey -&gt; StateDictKey -&gt; StateDictKey
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;final_layer_norm.&quot;</span></span><span class="hs-special">)</span><span>
</span><span id="line-361"></span><span>        </span><span class="annot"><a href="#local-6989586621679771194"><span class="hs-identifier hs-var">layerNorm</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SBART"><span class="hs-identifier hs-var">SBART</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">StateDictKey -&gt; () -&gt; m ()
forall model input (m :: * -&gt; *).
(HasStateDict model input, MonadThrow m, MonadState StateDict m) =&gt;
StateDictKey -&gt; model -&gt; m ()
</span><a href="Torch.GraduallyTyped.NN.Class.html#toStateDict"><span class="hs-identifier hs-var">toStateDict</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679771202"><span class="hs-identifier hs-var">k</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey -&gt; StateDictKey -&gt; StateDictKey
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;final_layer_norm.&quot;</span></span><span class="hs-special">)</span><span>
</span><span id="line-362"></span><span>        </span><span class="annot"><a href="#local-6989586621679771194"><span class="hs-identifier hs-var">layerNorm</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SMBART"><span class="hs-identifier hs-var">SMBART</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">StateDictKey -&gt; () -&gt; m ()
forall model input (m :: * -&gt; *).
(HasStateDict model input, MonadThrow m, MonadState StateDict m) =&gt;
StateDictKey -&gt; model -&gt; m ()
</span><a href="Torch.GraduallyTyped.NN.Class.html#toStateDict"><span class="hs-identifier hs-var">toStateDict</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679771202"><span class="hs-identifier hs-var">k</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey -&gt; StateDictKey -&gt; StateDictKey
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;final_layer_norm.&quot;</span></span><span class="hs-special">)</span><span>
</span><span id="line-363"></span><span>        </span><span class="annot"><a href="#local-6989586621679771194"><span class="hs-identifier hs-var">layerNorm</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SPegasus"><span class="hs-identifier hs-var">SPegasus</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">StateDictKey
-&gt; LayerNorm
     'WithBias gradient device dataType ('Shape '[inputEmbedDim])
-&gt; m ()
forall model input (m :: * -&gt; *).
(HasStateDict model input, MonadThrow m, MonadState StateDict m) =&gt;
StateDictKey -&gt; model -&gt; m ()
</span><a href="Torch.GraduallyTyped.NN.Class.html#toStateDict"><span class="hs-identifier hs-var">toStateDict</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679771202"><span class="hs-identifier hs-var">k</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey -&gt; StateDictKey -&gt; StateDictKey
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;layernorm_embedding.&quot;</span></span><span class="hs-special">)</span><span>
</span><span id="line-364"></span><span>        </span><span class="annot"><a href="#local-6989586621679771194"><span class="hs-identifier hs-var">layerNorm</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SBERT"><span class="hs-identifier hs-var">SBERT</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">StateDictKey -&gt; () -&gt; m ()
forall model input (m :: * -&gt; *).
(HasStateDict model input, MonadThrow m, MonadState StateDict m) =&gt;
StateDictKey -&gt; model -&gt; m ()
</span><a href="Torch.GraduallyTyped.NN.Class.html#toStateDict"><span class="hs-identifier hs-var">toStateDict</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679771202"><span class="hs-identifier hs-var">k</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey -&gt; StateDictKey -&gt; StateDictKey
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;layernorm_embedding.&quot;</span></span><span class="hs-special">)</span><span>
</span><span id="line-365"></span><span>        </span><span class="annot"><a href="#local-6989586621679771194"><span class="hs-identifier hs-var">layerNorm</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SRoBERTa"><span class="hs-identifier hs-var">SRoBERTa</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">StateDictKey -&gt; () -&gt; m ()
forall model input (m :: * -&gt; *).
(HasStateDict model input, MonadThrow m, MonadState StateDict m) =&gt;
StateDictKey -&gt; model -&gt; m ()
</span><a href="Torch.GraduallyTyped.NN.Class.html#toStateDict"><span class="hs-identifier hs-var">toStateDict</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679771202"><span class="hs-identifier hs-var">k</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey -&gt; StateDictKey -&gt; StateDictKey
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;layernorm_embedding.&quot;</span></span><span class="hs-special">)</span><span>
</span><span id="line-366"></span><span>        </span><span class="annot"><a href="#local-6989586621679771194"><span class="hs-identifier hs-var">layerNorm</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SGPT2"><span class="hs-identifier hs-var">SGPT2</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">TELayerNormF style gradient device dataType inputEmbedDim -&gt; m ()
forall a. HasCallStack =&gt; a
</span><span class="hs-identifier hs-var">undefined</span></span><span>
</span><span id="line-367"></span><span>        </span><span id="local-6989586621679771193"><span class="annot"><span class="annottext">dropout :: STransformerStyle style -&gt; Dropout dropoutP -&gt; m ()
</span><a href="#local-6989586621679771193"><span class="hs-identifier hs-var hs-var">dropout</span></a></span></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><span class="hs-identifier">_</span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">StateDictKey -&gt; Dropout dropoutP -&gt; m ()
forall model input (m :: * -&gt; *).
(HasStateDict model input, MonadThrow m, MonadState StateDict m) =&gt;
StateDictKey -&gt; model -&gt; m ()
</span><a href="Torch.GraduallyTyped.NN.Class.html#toStateDict"><span class="hs-identifier hs-var">toStateDict</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679771202"><span class="hs-identifier hs-var">k</span></a></span><span>
</span><span id="line-368"></span><span>        </span><span id="local-6989586621679771192"><span class="annot"><span class="annottext">posEnc :: STransformerStyle style
-&gt; TEPosEncF
     style gradient device dataType headDim inputEmbedDim posEncDim
-&gt; m ()
</span><a href="#local-6989586621679771192"><span class="hs-identifier hs-var hs-var">posEnc</span></a></span></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#ST5"><span class="hs-identifier hs-var">ST5</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">StateDictKey
-&gt; Embedding
     gradient
     ('Layout 'Dense)
     device
     dataType
     posEncDim
     headDim
     'Nothing
-&gt; m ()
forall model input (m :: * -&gt; *).
(HasStateDict model input, MonadThrow m, MonadState StateDict m) =&gt;
StateDictKey -&gt; model -&gt; m ()
</span><a href="Torch.GraduallyTyped.NN.Class.html#toStateDict"><span class="hs-identifier hs-var">toStateDict</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679771202"><span class="hs-identifier hs-var">k</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey -&gt; StateDictKey -&gt; StateDictKey
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;block.0.layer.0.SelfAttention.relative_attention_bias.&quot;</span></span><span class="hs-special">)</span><span>
</span><span id="line-369"></span><span>        </span><span class="annot"><a href="#local-6989586621679771192"><span class="hs-identifier hs-var">posEnc</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SByT5"><span class="hs-identifier hs-var">SByT5</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">StateDictKey
-&gt; Embedding
     gradient
     ('Layout 'Dense)
     device
     dataType
     posEncDim
     headDim
     'Nothing
-&gt; m ()
forall model input (m :: * -&gt; *).
(HasStateDict model input, MonadThrow m, MonadState StateDict m) =&gt;
StateDictKey -&gt; model -&gt; m ()
</span><a href="Torch.GraduallyTyped.NN.Class.html#toStateDict"><span class="hs-identifier hs-var">toStateDict</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679771202"><span class="hs-identifier hs-var">k</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey -&gt; StateDictKey -&gt; StateDictKey
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;block.0.layer.0.SelfAttention.relative_attention_bias.&quot;</span></span><span class="hs-special">)</span><span>
</span><span id="line-370"></span><span>        </span><span class="annot"><a href="#local-6989586621679771192"><span class="hs-identifier hs-var">posEnc</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SBART"><span class="hs-identifier hs-var">SBART</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">StateDictKey
-&gt; Embedding
     gradient
     ('Layout 'Dense)
     device
     dataType
     posEncDim
     inputEmbedDim
     'Nothing
-&gt; m ()
forall model input (m :: * -&gt; *).
(HasStateDict model input, MonadThrow m, MonadState StateDict m) =&gt;
StateDictKey -&gt; model -&gt; m ()
</span><a href="Torch.GraduallyTyped.NN.Class.html#toStateDict"><span class="hs-identifier hs-var">toStateDict</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679771202"><span class="hs-identifier hs-var">k</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey -&gt; StateDictKey -&gt; StateDictKey
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;embed_positions.&quot;</span></span><span class="hs-special">)</span><span>
</span><span id="line-371"></span><span>        </span><span class="annot"><a href="#local-6989586621679771192"><span class="hs-identifier hs-var">posEnc</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SMBART"><span class="hs-identifier hs-var">SMBART</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">StateDictKey
-&gt; Embedding
     gradient
     ('Layout 'Dense)
     device
     dataType
     posEncDim
     inputEmbedDim
     'Nothing
-&gt; m ()
forall model input (m :: * -&gt; *).
(HasStateDict model input, MonadThrow m, MonadState StateDict m) =&gt;
StateDictKey -&gt; model -&gt; m ()
</span><a href="Torch.GraduallyTyped.NN.Class.html#toStateDict"><span class="hs-identifier hs-var">toStateDict</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679771202"><span class="hs-identifier hs-var">k</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey -&gt; StateDictKey -&gt; StateDictKey
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;embed_positions.&quot;</span></span><span class="hs-special">)</span><span>
</span><span id="line-372"></span><span>        </span><span class="annot"><a href="#local-6989586621679771192"><span class="hs-identifier hs-var">posEnc</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SPegasus"><span class="hs-identifier hs-var">SPegasus</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">StateDictKey
-&gt; Embedding
     gradient
     ('Layout 'Dense)
     device
     dataType
     posEncDim
     inputEmbedDim
     'Nothing
-&gt; m ()
forall model input (m :: * -&gt; *).
(HasStateDict model input, MonadThrow m, MonadState StateDict m) =&gt;
StateDictKey -&gt; model -&gt; m ()
</span><a href="Torch.GraduallyTyped.NN.Class.html#toStateDict"><span class="hs-identifier hs-var">toStateDict</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679771202"><span class="hs-identifier hs-var">k</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey -&gt; StateDictKey -&gt; StateDictKey
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;embed_positions.&quot;</span></span><span class="hs-special">)</span><span>
</span><span id="line-373"></span><span>        </span><span class="annot"><a href="#local-6989586621679771192"><span class="hs-identifier hs-var">posEnc</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SBERT"><span class="hs-identifier hs-var">SBERT</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">StateDictKey
-&gt; Embedding
     gradient
     ('Layout 'Dense)
     device
     dataType
     posEncDim
     inputEmbedDim
     'Nothing
-&gt; m ()
forall model input (m :: * -&gt; *).
(HasStateDict model input, MonadThrow m, MonadState StateDict m) =&gt;
StateDictKey -&gt; model -&gt; m ()
</span><a href="Torch.GraduallyTyped.NN.Class.html#toStateDict"><span class="hs-identifier hs-var">toStateDict</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679771202"><span class="hs-identifier hs-var">k</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey -&gt; StateDictKey -&gt; StateDictKey
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;embeddings.position_embeddings.&quot;</span></span><span class="hs-special">)</span><span>
</span><span id="line-374"></span><span>        </span><span class="annot"><a href="#local-6989586621679771192"><span class="hs-identifier hs-var">posEnc</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SRoBERTa"><span class="hs-identifier hs-var">SRoBERTa</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">StateDictKey
-&gt; Embedding
     gradient
     ('Layout 'Dense)
     device
     dataType
     posEncDim
     inputEmbedDim
     'Nothing
-&gt; m ()
forall model input (m :: * -&gt; *).
(HasStateDict model input, MonadThrow m, MonadState StateDict m) =&gt;
StateDictKey -&gt; model -&gt; m ()
</span><a href="Torch.GraduallyTyped.NN.Class.html#toStateDict"><span class="hs-identifier hs-var">toStateDict</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679771202"><span class="hs-identifier hs-var">k</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey -&gt; StateDictKey -&gt; StateDictKey
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;embeddings.position_embeddings.&quot;</span></span><span class="hs-special">)</span><span>
</span><span id="line-375"></span><span>        </span><span class="annot"><a href="#local-6989586621679771192"><span class="hs-identifier hs-var">posEnc</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SGPT2"><span class="hs-identifier hs-var">SGPT2</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">TEPosEncF
  style gradient device dataType headDim inputEmbedDim posEncDim
-&gt; m ()
forall a. HasCallStack =&gt; a
</span><span class="hs-identifier hs-var">undefined</span></span><span>
</span><span id="line-376"></span><span>     </span><span class="hs-keyword">in</span><span> </span><span class="hs-keyword">do</span><span>
</span><span id="line-377"></span><span>          </span><span class="hs-special">(</span><span class="hs-special">)</span><span> </span><span class="hs-glyph">&lt;-</span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
-&gt; TransformerStack
     style
     numLayers
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     inputEmbedDim
     ffnDim
     dropoutP
-&gt; m ()
</span><a href="#local-6989586621679771196"><span class="hs-identifier hs-var">stack</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SingI style =&gt; Sing style
forall k (a :: k). SingI a =&gt; Sing a
</span><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-var">sing</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679771239"><span class="hs-identifier hs-type">style</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">TransformerStack
  style
  numLayers
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  inputEmbedDim
  ffnDim
  dropoutP
TEStackF
  style
  numLayers
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  inputEmbedDim
  ffnDim
  dropoutP
</span><a href="#local-6989586621679771201"><span class="hs-identifier hs-var">teStack</span></a></span><span>
</span><span id="line-378"></span><span>          </span><span class="hs-special">(</span><span class="hs-special">)</span><span> </span><span class="hs-glyph">&lt;-</span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
-&gt; TEEmbedLayerNormF style gradient device dataType inputEmbedDim
-&gt; m ()
</span><a href="#local-6989586621679771195"><span class="hs-identifier hs-var">embedLayerNorm</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SingI style =&gt; Sing style
forall k (a :: k). SingI a =&gt; Sing a
</span><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-var">sing</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679771239"><span class="hs-identifier hs-type">style</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">TEEmbedLayerNormF style gradient device dataType inputEmbedDim
</span><a href="#local-6989586621679771200"><span class="hs-identifier hs-var">teEmbedLayerNorm</span></a></span><span>
</span><span id="line-379"></span><span>          </span><span class="hs-special">(</span><span class="hs-special">)</span><span> </span><span class="hs-glyph">&lt;-</span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
-&gt; TELayerNormF style gradient device dataType inputEmbedDim
-&gt; m ()
</span><a href="#local-6989586621679771194"><span class="hs-identifier hs-var">layerNorm</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SingI style =&gt; Sing style
forall k (a :: k). SingI a =&gt; Sing a
</span><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-var">sing</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679771239"><span class="hs-identifier hs-type">style</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">TELayerNormF style gradient device dataType inputEmbedDim
</span><a href="#local-6989586621679771199"><span class="hs-identifier hs-var">teLayerNorm</span></a></span><span>
</span><span id="line-380"></span><span>          </span><span class="hs-special">(</span><span class="hs-special">)</span><span> </span><span class="hs-glyph">&lt;-</span><span> </span><span class="annot"><span class="annottext">STransformerStyle style -&gt; Dropout dropoutP -&gt; m ()
</span><a href="#local-6989586621679771193"><span class="hs-identifier hs-var">dropout</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SingI style =&gt; Sing style
forall k (a :: k). SingI a =&gt; Sing a
</span><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-var">sing</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679771239"><span class="hs-identifier hs-type">style</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">Dropout dropoutP
TEDropoutF style dropoutP
</span><a href="#local-6989586621679771198"><span class="hs-identifier hs-var">teDropout</span></a></span><span>
</span><span id="line-381"></span><span>          </span><span class="hs-special">(</span><span class="hs-special">)</span><span> </span><span class="hs-glyph">&lt;-</span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
-&gt; TEPosEncF
     style gradient device dataType headDim inputEmbedDim posEncDim
-&gt; m ()
</span><a href="#local-6989586621679771192"><span class="hs-identifier hs-var">posEnc</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SingI style =&gt; Sing style
forall k (a :: k). SingI a =&gt; Sing a
</span><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-var">sing</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679771239"><span class="hs-identifier hs-type">style</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">TEPosEncF
  style gradient device dataType headDim inputEmbedDim posEncDim
</span><a href="#local-6989586621679771197"><span class="hs-identifier hs-var">tePosEnc</span></a></span><span>
</span><span id="line-382"></span><span>          </span><span class="annot"><span class="annottext">() -&gt; m ()
forall (f :: * -&gt; *) a. Applicative f =&gt; a -&gt; f a
</span><span class="hs-identifier hs-var">pure</span></span><span> </span><span class="hs-special">(</span><span class="hs-special">)</span></span></span></span></span></span></span></span></span></span></span></span></span><span>
</span><span id="line-383"></span><span>
</span><span id="line-384"></span><span class="hs-comment">-- | 'HasForward' instance for @TransformerEncoder numLayers 'T5@.</span><span>
</span><span id="line-385"></span><span class="hs-comment">--</span><span>
</span><span id="line-386"></span><span class="hs-comment">-- @</span><span>
</span><span id="line-387"></span><span class="hs-comment">--  &#9484;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9488;  &#9484;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9488;  &#9484;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9488;</span><span>
</span><span id="line-388"></span><span class="hs-comment">--  &#9474; input &#9474;  &#9474; relPos &#9474;  &#9474; attentionMask &#9474;</span><span>
</span><span id="line-389"></span><span class="hs-comment">--  &#9492;&#9472;&#9472;&#9472;&#9516;&#9472;&#9472;&#9472;&#9496;  &#9492;&#9472;&#9472;&#9472;&#9516;&#9472;&#9472;&#9472;&#9472;&#9496;  &#9492;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9516;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9496;</span><span>
</span><span id="line-390"></span><span class="hs-comment">--      &#9474;          &#9474;               &#9474;</span><span>
</span><span id="line-391"></span><span class="hs-comment">--      &#9474;          &#9660;               &#9474;</span><span>
</span><span id="line-392"></span><span class="hs-comment">--      &#9474;      tePosEnc            &#9474;</span><span>
</span><span id="line-393"></span><span class="hs-comment">--      &#9474;          &#9660;               &#9474;</span><span>
</span><span id="line-394"></span><span class="hs-comment">--      &#9474;      transpose           &#9474;</span><span>
</span><span id="line-395"></span><span class="hs-comment">--      &#9474;          &#9660;               &#9660;</span><span>
</span><span id="line-396"></span><span class="hs-comment">--      &#9474;      transpose       unsqueeze</span><span>
</span><span id="line-397"></span><span class="hs-comment">--      &#9660;          &#9474;               &#9474;</span><span>
</span><span id="line-398"></span><span class="hs-comment">--  teDropout      &#9492;&#9472;&#9472;&#9472;&#9472;&#9472;&#9658;add&#9668;&#9472;&#9472;&#9472;&#9472;&#9472;&#9496;</span><span>
</span><span id="line-399"></span><span class="hs-comment">--      &#9660;                  &#9474;</span><span>
</span><span id="line-400"></span><span class="hs-comment">--   teStack&#9668;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9496;</span><span>
</span><span id="line-401"></span><span class="hs-comment">--      &#9660;</span><span>
</span><span id="line-402"></span><span class="hs-comment">-- teLayerNorm</span><span>
</span><span id="line-403"></span><span class="hs-comment">--      &#9660;</span><span>
</span><span id="line-404"></span><span class="hs-comment">--  teDropout</span><span>
</span><span id="line-405"></span><span class="hs-comment">--      &#9474;</span><span>
</span><span id="line-406"></span><span class="hs-comment">--      &#9660;</span><span>
</span><span id="line-407"></span><span class="hs-comment">--  &#9484;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9488;</span><span>
</span><span id="line-408"></span><span class="hs-comment">--  &#9474; output &#9474;</span><span>
</span><span id="line-409"></span><span class="hs-comment">--  &#9492;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9496;</span><span>
</span><span id="line-410"></span><span class="hs-comment">-- @</span><span>
</span><span id="line-411"></span><span id="local-6989586621679771161"><span id="local-6989586621679771162"><span id="local-6989586621679771163"><span id="local-6989586621679771164"><span id="local-6989586621679771165"><span id="local-6989586621679771166"><span id="local-6989586621679771167"><span id="local-6989586621679771168"><span id="local-6989586621679771169"><span id="local-6989586621679771170"><span id="local-6989586621679771171"><span id="local-6989586621679771172"><span id="local-6989586621679771173"><span id="local-6989586621679771174"><span id="local-6989586621679771175"><span id="local-6989586621679771176"><span id="local-6989586621679771177"><span id="local-6989586621679771178"><span id="local-6989586621679771179"><span id="local-6989586621679771180"><span id="local-6989586621679771181"><span id="local-6989586621679771182"><span id="local-6989586621679771183"><span id="local-6989586621679771184"><span id="local-6989586621679771185"><span id="local-6989586621679771186"><span id="local-6989586621679771187"><span id="local-6989586621679771188"><span id="local-6989586621679771189"><span id="local-6989586621679771190"><span id="local-6989586621679771191"><span class="hs-keyword">instance</span><span>
</span><span id="line-412"></span><span>  </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasForward"><span class="hs-identifier hs-type">HasForward</span></a></span><span>
</span><span id="line-413"></span><span>      </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Encoder.html#TEDropoutF"><span class="hs-identifier hs-type">TEDropoutF</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#T5"><span class="hs-identifier hs-type">T5</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771191"><span class="hs-identifier hs-type">dropoutP</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-414"></span><span>      </span><span class="annot"><a href="#local-6989586621679771190"><span class="hs-identifier hs-type">input</span></a></span><span>
</span><span id="line-415"></span><span>      </span><span class="annot"><a href="#local-6989586621679771189"><span class="hs-identifier hs-type">generator</span></a></span><span>
</span><span id="line-416"></span><span>      </span><span class="annot"><a href="#local-6989586621679771188"><span class="hs-identifier hs-type">dropoutOutput</span></a></span><span>
</span><span id="line-417"></span><span>      </span><span class="annot"><a href="#local-6989586621679771187"><span class="hs-identifier hs-type">dropoutGeneratorOutput</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-418"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasForward"><span class="hs-identifier hs-type">HasForward</span></a></span><span>
</span><span id="line-419"></span><span>      </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Encoder.html#TEStackF"><span class="hs-identifier hs-type">TEStackF</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#T5"><span class="hs-identifier hs-type">T5</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771186"><span class="hs-identifier hs-type">numLayers</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771185"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771184"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771183"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771182"><span class="hs-identifier hs-type">headDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771181"><span class="hs-identifier hs-type">headEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771180"><span class="hs-identifier hs-type">embedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771179"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771178"><span class="hs-identifier hs-type">ffnDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771191"><span class="hs-identifier hs-type">dropoutP</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-420"></span><span>      </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="#local-6989586621679771188"><span class="hs-identifier hs-type">dropoutOutput</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-421"></span><span>        </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span>
</span><span id="line-422"></span><span>          </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679771185"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%7C%3E"><span class="hs-operator hs-type">&lt;|&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771177"><span class="hs-identifier hs-type">relPosGradient</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%7C%3E"><span class="hs-operator hs-type">&lt;|&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771176"><span class="hs-identifier hs-type">attentionMaskGradient</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-423"></span><span>          </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#Layout"><span class="hs-identifier hs-type">Layout</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#Dense"><span class="hs-identifier hs-type">Dense</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771175"><span class="hs-identifier hs-type">relPosLayout</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771174"><span class="hs-identifier hs-type">attentionMaskLayout</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-424"></span><span>          </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679771184"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771173"><span class="hs-identifier hs-type">relPosDevice</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771172"><span class="hs-identifier hs-type">attentionMaskDevice</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-425"></span><span>          </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Prelude.html#Seq"><span class="hs-identifier hs-type">Seq</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679771171"><span class="hs-identifier hs-type">relPosDataType</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#DataType"><span class="hs-identifier hs-type">DataType</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#Int64"><span class="hs-identifier hs-type">Int64</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679771183"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771170"><span class="hs-identifier hs-type">attentionMaskDataType</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-426"></span><span>          </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Class.html#BroadcastShapesF"><span class="hs-identifier hs-type">BroadcastShapesF</span></a></span><span>
</span><span id="line-427"></span><span>              </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.IndexingSlicingJoining.html#TransposeF"><span class="hs-identifier hs-type">TransposeF</span></a></span><span>
</span><span id="line-428"></span><span>                  </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SelectDim"><span class="hs-identifier hs-type">SelectDim</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#ByIndex"><span class="hs-identifier hs-type">ByIndex</span></a></span><span> </span><span class="annot"><span class="hs-number">1</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-429"></span><span>                  </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SelectDim"><span class="hs-identifier hs-type">SelectDim</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#ByIndex"><span class="hs-identifier hs-type">ByIndex</span></a></span><span> </span><span class="annot"><span class="hs-number">2</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-430"></span><span>                  </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.IndexingSlicingJoining.html#TransposeF"><span class="hs-identifier hs-type">TransposeF</span></a></span><span>
</span><span id="line-431"></span><span>                      </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SelectDim"><span class="hs-identifier hs-type">SelectDim</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#ByIndex"><span class="hs-identifier hs-type">ByIndex</span></a></span><span> </span><span class="annot"><span class="hs-number">2</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-432"></span><span>                      </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SelectDim"><span class="hs-identifier hs-type">SelectDim</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#ByIndex"><span class="hs-identifier hs-type">ByIndex</span></a></span><span> </span><span class="annot"><span class="hs-number">3</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-433"></span><span>                      </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Functional.Sparse.html#EmbeddingF"><span class="hs-identifier hs-type">EmbeddingF</span></a></span><span>
</span><span id="line-434"></span><span>                          </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Shape"><span class="hs-identifier hs-type">Shape</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="annot"><a href="#local-6989586621679771169"><span class="hs-identifier hs-type">posEncDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679771182"><span class="hs-identifier hs-type">headDim</span></a></span><span class="hs-special">]</span><span class="hs-special">)</span><span>
</span><span id="line-435"></span><span>                          </span><span class="annot"><a href="#local-6989586621679771168"><span class="hs-identifier hs-type">relPosShape</span></a></span><span>
</span><span id="line-436"></span><span>                      </span><span class="hs-special">)</span><span>
</span><span id="line-437"></span><span>                  </span><span class="hs-special">)</span><span>
</span><span id="line-438"></span><span>              </span><span class="hs-special">)</span><span>
</span><span id="line-439"></span><span>              </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.IndexingSlicingJoining.html#UnsqueezeF"><span class="hs-identifier hs-type">UnsqueezeF</span></a></span><span>
</span><span id="line-440"></span><span>                  </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SelectDim"><span class="hs-identifier hs-type">SelectDim</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#ByIndex"><span class="hs-identifier hs-type">ByIndex</span></a></span><span> </span><span class="annot"><span class="hs-number">1</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-441"></span><span>                  </span><span class="annot"><a href="#local-6989586621679771167"><span class="hs-identifier hs-type">attentionMaskShape</span></a></span><span>
</span><span id="line-442"></span><span>              </span><span class="hs-special">)</span><span>
</span><span id="line-443"></span><span>          </span><span class="hs-special">)</span><span>
</span><span id="line-444"></span><span>      </span><span class="hs-special">)</span><span>
</span><span id="line-445"></span><span>      </span><span class="annot"><a href="#local-6989586621679771187"><span class="hs-identifier hs-type">dropoutGeneratorOutput</span></a></span><span>
</span><span id="line-446"></span><span>      </span><span class="annot"><a href="#local-6989586621679771166"><span class="hs-identifier hs-type">stackOutput</span></a></span><span>
</span><span id="line-447"></span><span>      </span><span class="annot"><a href="#local-6989586621679771165"><span class="hs-identifier hs-type">stackGeneratorOutput</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-448"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasForward"><span class="hs-identifier hs-type">HasForward</span></a></span><span>
</span><span id="line-449"></span><span>      </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Encoder.html#TELayerNormF"><span class="hs-identifier hs-type">TELayerNormF</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#T5"><span class="hs-identifier hs-type">T5</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771185"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771184"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771183"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771179"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-450"></span><span>      </span><span class="annot"><a href="#local-6989586621679771166"><span class="hs-identifier hs-type">stackOutput</span></a></span><span>
</span><span id="line-451"></span><span>      </span><span class="annot"><a href="#local-6989586621679771165"><span class="hs-identifier hs-type">stackGeneratorOutput</span></a></span><span>
</span><span id="line-452"></span><span>      </span><span class="annot"><a href="#local-6989586621679771164"><span class="hs-identifier hs-type">layerNormOutput</span></a></span><span>
</span><span id="line-453"></span><span>      </span><span class="annot"><a href="#local-6989586621679771163"><span class="hs-identifier hs-type">layerNormGeneratorOutput</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-454"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasForward"><span class="hs-identifier hs-type">HasForward</span></a></span><span>
</span><span id="line-455"></span><span>      </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Encoder.html#TEDropoutF"><span class="hs-identifier hs-type">TEDropoutF</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#T5"><span class="hs-identifier hs-type">T5</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771191"><span class="hs-identifier hs-type">dropoutP</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-456"></span><span>      </span><span class="annot"><a href="#local-6989586621679771164"><span class="hs-identifier hs-type">layerNormOutput</span></a></span><span>
</span><span id="line-457"></span><span>      </span><span class="annot"><a href="#local-6989586621679771163"><span class="hs-identifier hs-type">layerNormGeneratorOutput</span></a></span><span>
</span><span id="line-458"></span><span>      </span><span class="annot"><a href="#local-6989586621679771162"><span class="hs-identifier hs-type">output</span></a></span><span>
</span><span id="line-459"></span><span>      </span><span class="annot"><a href="#local-6989586621679771161"><span class="hs-identifier hs-type">generatorOutput</span></a></span><span>
</span><span id="line-460"></span><span>  </span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-461"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasForward"><span class="hs-identifier hs-type">HasForward</span></a></span><span>
</span><span id="line-462"></span><span>    </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Encoder.html#TransformerEncoder"><span class="hs-identifier hs-type">TransformerEncoder</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#T5"><span class="hs-identifier hs-type">T5</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771186"><span class="hs-identifier hs-type">numLayers</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771185"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771184"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771183"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771182"><span class="hs-identifier hs-type">headDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771181"><span class="hs-identifier hs-type">headEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771180"><span class="hs-identifier hs-type">embedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771179"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771178"><span class="hs-identifier hs-type">ffnDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771169"><span class="hs-identifier hs-type">posEncDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771191"><span class="hs-identifier hs-type">dropoutP</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-463"></span><span>    </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="#local-6989586621679771190"><span class="hs-identifier hs-type">input</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-464"></span><span>      </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771177"><span class="hs-identifier hs-type">relPosGradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771175"><span class="hs-identifier hs-type">relPosLayout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771173"><span class="hs-identifier hs-type">relPosDevice</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771171"><span class="hs-identifier hs-type">relPosDataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771168"><span class="hs-identifier hs-type">relPosShape</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-465"></span><span>      </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771176"><span class="hs-identifier hs-type">attentionMaskGradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771174"><span class="hs-identifier hs-type">attentionMaskLayout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771172"><span class="hs-identifier hs-type">attentionMaskDevice</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771170"><span class="hs-identifier hs-type">attentionMaskDataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771167"><span class="hs-identifier hs-type">attentionMaskShape</span></a></span><span>
</span><span id="line-466"></span><span>    </span><span class="hs-special">)</span><span>
</span><span id="line-467"></span><span>    </span><span class="annot"><a href="#local-6989586621679771189"><span class="hs-identifier hs-type">generator</span></a></span><span>
</span><span id="line-468"></span><span>    </span><span class="annot"><a href="#local-6989586621679771162"><span class="hs-identifier hs-type">output</span></a></span><span>
</span><span id="line-469"></span><span>    </span><span class="annot"><a href="#local-6989586621679771161"><span class="hs-identifier hs-type">generatorOutput</span></a></span><span>
</span><span id="line-470"></span><span>  </span><span class="hs-keyword">where</span><span>
</span><span id="line-471"></span><span>  </span><span id="local-6989586621679771158"><span class="annot"><span class="annottext">forward :: TransformerEncoder
  'T5
  numLayers
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  inputEmbedDim
  ffnDim
  posEncDim
  dropoutP
-&gt; (input,
    Tensor
      relPosGradient
      relPosLayout
      relPosDevice
      relPosDataType
      relPosShape,
    Tensor
      attentionMaskGradient
      attentionMaskLayout
      attentionMaskDevice
      attentionMaskDataType
      attentionMaskShape)
-&gt; generator
-&gt; m (output, generatorOutput)
</span><a href="Torch.GraduallyTyped.NN.Class.html#forward"><span class="hs-identifier hs-var hs-var hs-var hs-var">forward</span></a></span></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Encoder.html#TransformerEncoder"><span class="hs-identifier hs-type">TransformerEncoder</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Encoder.html#GTransformerEncoder"><span class="hs-identifier hs-type">GTransformerEncoder</span></a></span><span> </span><span class="hs-special">{</span><span id="local-6989586621679771152"><span id="local-6989586621679771153"><span id="local-6989586621679771154"><span id="local-6989586621679771155"><span id="local-6989586621679771156"><span class="annot"><span class="annottext">TEPosEncF
  'T5 gradient device dataType headDim inputEmbedDim posEncDim
TEDropoutF 'T5 dropoutP
TELayerNormF 'T5 gradient device dataType inputEmbedDim
TEEmbedLayerNormF 'T5 gradient device dataType inputEmbedDim
TEStackF
  'T5
  numLayers
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  inputEmbedDim
  ffnDim
  dropoutP
tePosEnc :: TEPosEncF
  'T5 gradient device dataType headDim inputEmbedDim posEncDim
teDropout :: TEDropoutF 'T5 dropoutP
teLayerNorm :: TELayerNormF 'T5 gradient device dataType inputEmbedDim
teEmbedLayerNorm :: TEEmbedLayerNormF 'T5 gradient device dataType inputEmbedDim
teStack :: TEStackF
  'T5
  numLayers
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  inputEmbedDim
  ffnDim
  dropoutP
tePosEnc :: forall stack embedLayerNorm layerNorm dropout posEnc.
GTransformerEncoder stack embedLayerNorm layerNorm dropout posEnc
-&gt; posEnc
teDropout :: forall stack embedLayerNorm layerNorm dropout posEnc.
GTransformerEncoder stack embedLayerNorm layerNorm dropout posEnc
-&gt; dropout
teLayerNorm :: forall stack embedLayerNorm layerNorm dropout posEnc.
GTransformerEncoder stack embedLayerNorm layerNorm dropout posEnc
-&gt; layerNorm
teEmbedLayerNorm :: forall stack embedLayerNorm layerNorm dropout posEnc.
GTransformerEncoder stack embedLayerNorm layerNorm dropout posEnc
-&gt; embedLayerNorm
teStack :: forall stack embedLayerNorm layerNorm dropout posEnc.
GTransformerEncoder stack embedLayerNorm layerNorm dropout posEnc
-&gt; stack
</span><a href="#local-6989586621679771152"><span class="hs-glyph hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var">..</span></a></span></span></span></span></span></span><span class="hs-special">}</span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span id="local-6989586621679771151"><span class="annot"><span class="annottext">input
</span><a href="#local-6989586621679771151"><span class="hs-identifier hs-var">input</span></a></span></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679771150"><span class="annot"><span class="annottext">Tensor
  relPosGradient relPosLayout relPosDevice relPosDataType relPosShape
</span><a href="#local-6989586621679771150"><span class="hs-identifier hs-var">relPos</span></a></span></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679771149"><span class="annot"><span class="annottext">Tensor
  attentionMaskGradient
  attentionMaskLayout
  attentionMaskDevice
  attentionMaskDataType
  attentionMaskShape
</span><a href="#local-6989586621679771149"><span class="hs-identifier hs-var">attentionMask</span></a></span></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-472"></span><span>    </span><span class="hs-keyword">let</span><span> </span><span id="local-6989586621679771148"><span class="annot"><span class="annottext">relPosBias :: IxStateT
  m
  dropoutGeneratorOutput
  dropoutGeneratorOutput
  (Tensor
     (Or (Gradient RequiresGradient) gradient relPosGradient)
     (Unify (Layout LayoutType) ('Layout 'Dense) relPosLayout)
     (Unify (Device (DeviceType Nat)) device relPosDevice)
     (Seq
        (Unify (DataType DType) relPosDataType ('DataType 'Int64))
        dataType)
     (TransposeF
        ('SelectDim ('ByIndex 1))
        ('SelectDim ('ByIndex 2))
        (TransposeF
           ('SelectDim ('ByIndex 2))
           ('SelectDim ('ByIndex 3))
           (EmbeddingF ('Shape '[posEncDim, headDim]) relPosShape))))
</span><a href="#local-6989586621679771148"><span class="hs-identifier hs-var hs-var">relPosBias</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-473"></span><span>          </span><span class="annot"><span class="annottext">Tensor
  relPosGradient relPosLayout relPosDevice relPosDataType relPosShape
-&gt; IxStateT
     m
     dropoutGeneratorOutput
     dropoutGeneratorOutput
     (Tensor
        relPosGradient
        relPosLayout
        relPosDevice
        relPosDataType
        relPosShape)
forall k (m :: k -&gt; k -&gt; * -&gt; *) a (i :: k).
IxPointed m =&gt;
a -&gt; m i i a
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-identifier hs-var">ireturn</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor
  relPosGradient relPosLayout relPosDevice relPosDataType relPosShape
</span><a href="#local-6989586621679771150"><span class="hs-identifier hs-var">relPos</span></a></span><span>
</span><span id="line-474"></span><span>            </span><span class="annot"><span class="annottext">IxStateT
  m
  dropoutGeneratorOutput
  dropoutGeneratorOutput
  (Tensor
     relPosGradient
     relPosLayout
     relPosDevice
     relPosDataType
     relPosShape)
-&gt; (Tensor
      relPosGradient relPosLayout relPosDevice relPosDataType relPosShape
    -&gt; IxStateT
         m
         dropoutGeneratorOutput
         dropoutGeneratorOutput
         (Tensor
            (Or (Gradient RequiresGradient) gradient relPosGradient)
            (Unify (Layout LayoutType) ('Layout 'Dense) relPosLayout)
            (Unify (Device (DeviceType Nat)) device relPosDevice)
            (Seq
               (Unify (DataType DType) relPosDataType ('DataType 'Int64))
               dataType)
            (EmbeddingF ('Shape '[posEncDim, headDim]) relPosShape)))
-&gt; IxStateT
     m
     dropoutGeneratorOutput
     dropoutGeneratorOutput
     (Tensor
        (Or (Gradient RequiresGradient) gradient relPosGradient)
        (Unify (Layout LayoutType) ('Layout 'Dense) relPosLayout)
        (Unify (Device (DeviceType Nat)) device relPosDevice)
        (Seq
           (Unify (DataType DType) relPosDataType ('DataType 'Int64))
           dataType)
        (EmbeddingF ('Shape '[posEncDim, headDim]) relPosShape))
forall k1 (m :: k1 -&gt; k1 -&gt; * -&gt; *) (i :: k1) (j :: k1) a
       (k2 :: k1) b.
IxMonad m =&gt;
m i j a -&gt; (a -&gt; m j k2 b) -&gt; m i k2 b
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&gt;&gt;&gt;=</span></a></span><span> </span><span class="annot"><span class="annottext">(dropoutGeneratorOutput
 -&gt; m (Tensor
         (Or (Gradient RequiresGradient) gradient relPosGradient)
         (Unify (Layout LayoutType) ('Layout 'Dense) relPosLayout)
         (Unify (Device (DeviceType Nat)) device relPosDevice)
         (Seq
            (Unify (DataType DType) relPosDataType ('DataType 'Int64))
            dataType)
         (EmbeddingF ('Shape '[posEncDim, headDim]) relPosShape),
       dropoutGeneratorOutput))
-&gt; IxStateT
     m
     dropoutGeneratorOutput
     dropoutGeneratorOutput
     (Tensor
        (Or (Gradient RequiresGradient) gradient relPosGradient)
        (Unify (Layout LayoutType) ('Layout 'Dense) relPosLayout)
        (Unify (Device (DeviceType Nat)) device relPosDevice)
        (Seq
           (Unify (DataType DType) relPosDataType ('DataType 'Int64))
           dataType)
        (EmbeddingF ('Shape '[posEncDim, headDim]) relPosShape))
forall (m :: * -&gt; *) i j a. (i -&gt; m (a, j)) -&gt; IxStateT m i j a
</span><a href="../file:///nix/store/8vjaffqxij7bih93d9mlzmc7ksanlw0i-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier hs-var">IxStateT</span></a></span><span> </span><span class="annot"><span class="annottext">((dropoutGeneratorOutput
  -&gt; m (Tensor
          (Or (Gradient RequiresGradient) gradient relPosGradient)
          (Unify (Layout LayoutType) ('Layout 'Dense) relPosLayout)
          (Unify (Device (DeviceType Nat)) device relPosDevice)
          (Seq
             (Unify (DataType DType) relPosDataType ('DataType 'Int64))
             dataType)
          (EmbeddingF ('Shape '[posEncDim, headDim]) relPosShape),
        dropoutGeneratorOutput))
 -&gt; IxStateT
      m
      dropoutGeneratorOutput
      dropoutGeneratorOutput
      (Tensor
         (Or (Gradient RequiresGradient) gradient relPosGradient)
         (Unify (Layout LayoutType) ('Layout 'Dense) relPosLayout)
         (Unify (Device (DeviceType Nat)) device relPosDevice)
         (Seq
            (Unify (DataType DType) relPosDataType ('DataType 'Int64))
            dataType)
         (EmbeddingF ('Shape '[posEncDim, headDim]) relPosShape)))
-&gt; (Tensor
      relPosGradient relPosLayout relPosDevice relPosDataType relPosShape
    -&gt; dropoutGeneratorOutput
    -&gt; m (Tensor
            (Or (Gradient RequiresGradient) gradient relPosGradient)
            (Unify (Layout LayoutType) ('Layout 'Dense) relPosLayout)
            (Unify (Device (DeviceType Nat)) device relPosDevice)
            (Seq
               (Unify (DataType DType) relPosDataType ('DataType 'Int64))
               dataType)
            (EmbeddingF ('Shape '[posEncDim, headDim]) relPosShape),
          dropoutGeneratorOutput))
-&gt; Tensor
     relPosGradient relPosLayout relPosDevice relPosDataType relPosShape
-&gt; IxStateT
     m
     dropoutGeneratorOutput
     dropoutGeneratorOutput
     (Tensor
        (Or (Gradient RequiresGradient) gradient relPosGradient)
        (Unify (Layout LayoutType) ('Layout 'Dense) relPosLayout)
        (Unify (Device (DeviceType Nat)) device relPosDevice)
        (Seq
           (Unify (DataType DType) relPosDataType ('DataType 'Int64))
           dataType)
        (EmbeddingF ('Shape '[posEncDim, headDim]) relPosShape))
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">Embedding
  gradient
  ('Layout 'Dense)
  device
  dataType
  posEncDim
  headDim
  'Nothing
-&gt; Tensor
     relPosGradient relPosLayout relPosDevice relPosDataType relPosShape
-&gt; dropoutGeneratorOutput
-&gt; m (Tensor
        (Or (Gradient RequiresGradient) gradient relPosGradient)
        (Unify (Layout LayoutType) ('Layout 'Dense) relPosLayout)
        (Unify (Device (DeviceType Nat)) device relPosDevice)
        (Seq
           (Unify (DataType DType) relPosDataType ('DataType 'Int64))
           dataType)
        (EmbeddingF ('Shape '[posEncDim, headDim]) relPosShape),
      dropoutGeneratorOutput)
forall model input generator output generatorOutput (m :: * -&gt; *).
(HasForward model input generator output generatorOutput,
 MonadThrow m) =&gt;
model -&gt; input -&gt; generator -&gt; m (output, generatorOutput)
</span><a href="Torch.GraduallyTyped.NN.Class.html#forward"><span class="hs-identifier hs-var">forward</span></a></span><span> </span><span class="annot"><span class="annottext">Embedding
  gradient
  ('Layout 'Dense)
  device
  dataType
  posEncDim
  headDim
  'Nothing
TEPosEncF
  'T5 gradient device dataType headDim inputEmbedDim posEncDim
</span><a href="#local-6989586621679771152"><span class="hs-identifier hs-var">tePosEnc</span></a></span><span>
</span><span id="line-475"></span><span>            </span><span class="annot"><span class="annottext">IxStateT
  m
  dropoutGeneratorOutput
  dropoutGeneratorOutput
  (Tensor
     (Or (Gradient RequiresGradient) gradient relPosGradient)
     (Unify (Layout LayoutType) ('Layout 'Dense) relPosLayout)
     (Unify (Device (DeviceType Nat)) device relPosDevice)
     (Seq
        (Unify (DataType DType) relPosDataType ('DataType 'Int64))
        dataType)
     (EmbeddingF ('Shape '[posEncDim, headDim]) relPosShape))
-&gt; (Tensor
      (Or (Gradient RequiresGradient) gradient relPosGradient)
      (Unify (Layout LayoutType) ('Layout 'Dense) relPosLayout)
      (Unify (Device (DeviceType Nat)) device relPosDevice)
      (Seq
         (Unify (DataType DType) relPosDataType ('DataType 'Int64))
         dataType)
      (EmbeddingF ('Shape '[posEncDim, headDim]) relPosShape)
    -&gt; IxStateT
         m
         dropoutGeneratorOutput
         dropoutGeneratorOutput
         (Tensor
            (Or (Gradient RequiresGradient) gradient relPosGradient)
            (Unify (Layout LayoutType) ('Layout 'Dense) relPosLayout)
            (Unify (Device (DeviceType Nat)) device relPosDevice)
            (Seq
               (Unify (DataType DType) relPosDataType ('DataType 'Int64))
               dataType)
            (TransposeF
               ('SelectDim ('ByIndex 2))
               ('SelectDim ('ByIndex 3))
               (EmbeddingF ('Shape '[posEncDim, headDim]) relPosShape))))
-&gt; IxStateT
     m
     dropoutGeneratorOutput
     dropoutGeneratorOutput
     (Tensor
        (Or (Gradient RequiresGradient) gradient relPosGradient)
        (Unify (Layout LayoutType) ('Layout 'Dense) relPosLayout)
        (Unify (Device (DeviceType Nat)) device relPosDevice)
        (Seq
           (Unify (DataType DType) relPosDataType ('DataType 'Int64))
           dataType)
        (TransposeF
           ('SelectDim ('ByIndex 2))
           ('SelectDim ('ByIndex 3))
           (EmbeddingF ('Shape '[posEncDim, headDim]) relPosShape)))
forall k1 (m :: k1 -&gt; k1 -&gt; * -&gt; *) (i :: k1) (j :: k1) a
       (k2 :: k1) b.
IxMonad m =&gt;
m i j a -&gt; (a -&gt; m j k2 b) -&gt; m i k2 b
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&gt;&gt;&gt;=</span></a></span><span> </span><span class="annot"><span class="annottext">m (Tensor
     (Or (Gradient RequiresGradient) gradient relPosGradient)
     (Unify (Layout LayoutType) ('Layout 'Dense) relPosLayout)
     (Unify (Device (DeviceType Nat)) device relPosDevice)
     (Seq
        (Unify (DataType DType) relPosDataType ('DataType 'Int64))
        dataType)
     (TransposeF
        ('SelectDim ('ByIndex 2))
        ('SelectDim ('ByIndex 3))
        (EmbeddingF ('Shape '[posEncDim, headDim]) relPosShape)))
-&gt; IxStateT
     m
     dropoutGeneratorOutput
     dropoutGeneratorOutput
     (Tensor
        (Or (Gradient RequiresGradient) gradient relPosGradient)
        (Unify (Layout LayoutType) ('Layout 'Dense) relPosLayout)
        (Unify (Device (DeviceType Nat)) device relPosDevice)
        (Seq
           (Unify (DataType DType) relPosDataType ('DataType 'Int64))
           dataType)
        (TransposeF
           ('SelectDim ('ByIndex 2))
           ('SelectDim ('ByIndex 3))
           (EmbeddingF ('Shape '[posEncDim, headDim]) relPosShape)))
forall k (t :: (* -&gt; *) -&gt; k -&gt; k -&gt; * -&gt; *) (m :: * -&gt; *) a
       (i :: k).
(IxMonadTrans t, Monad m) =&gt;
m a -&gt; t m i i a
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-identifier hs-var">ilift</span></a></span><span> </span><span class="annot"><span class="annottext">(m (Tensor
      (Or (Gradient RequiresGradient) gradient relPosGradient)
      (Unify (Layout LayoutType) ('Layout 'Dense) relPosLayout)
      (Unify (Device (DeviceType Nat)) device relPosDevice)
      (Seq
         (Unify (DataType DType) relPosDataType ('DataType 'Int64))
         dataType)
      (TransposeF
         ('SelectDim ('ByIndex 2))
         ('SelectDim ('ByIndex 3))
         (EmbeddingF ('Shape '[posEncDim, headDim]) relPosShape)))
 -&gt; IxStateT
      m
      dropoutGeneratorOutput
      dropoutGeneratorOutput
      (Tensor
         (Or (Gradient RequiresGradient) gradient relPosGradient)
         (Unify (Layout LayoutType) ('Layout 'Dense) relPosLayout)
         (Unify (Device (DeviceType Nat)) device relPosDevice)
         (Seq
            (Unify (DataType DType) relPosDataType ('DataType 'Int64))
            dataType)
         (TransposeF
            ('SelectDim ('ByIndex 2))
            ('SelectDim ('ByIndex 3))
            (EmbeddingF ('Shape '[posEncDim, headDim]) relPosShape))))
-&gt; (Tensor
      (Or (Gradient RequiresGradient) gradient relPosGradient)
      (Unify (Layout LayoutType) ('Layout 'Dense) relPosLayout)
      (Unify (Device (DeviceType Nat)) device relPosDevice)
      (Seq
         (Unify (DataType DType) relPosDataType ('DataType 'Int64))
         dataType)
      (EmbeddingF ('Shape '[posEncDim, headDim]) relPosShape)
    -&gt; m (Tensor
            (Or (Gradient RequiresGradient) gradient relPosGradient)
            (Unify (Layout LayoutType) ('Layout 'Dense) relPosLayout)
            (Unify (Device (DeviceType Nat)) device relPosDevice)
            (Seq
               (Unify (DataType DType) relPosDataType ('DataType 'Int64))
               dataType)
            (TransposeF
               ('SelectDim ('ByIndex 2))
               ('SelectDim ('ByIndex 3))
               (EmbeddingF ('Shape '[posEncDim, headDim]) relPosShape))))
-&gt; Tensor
     (Or (Gradient RequiresGradient) gradient relPosGradient)
     (Unify (Layout LayoutType) ('Layout 'Dense) relPosLayout)
     (Unify (Device (DeviceType Nat)) device relPosDevice)
     (Seq
        (Unify (DataType DType) relPosDataType ('DataType 'Int64))
        dataType)
     (EmbeddingF ('Shape '[posEncDim, headDim]) relPosShape)
-&gt; IxStateT
     m
     dropoutGeneratorOutput
     dropoutGeneratorOutput
     (Tensor
        (Or (Gradient RequiresGradient) gradient relPosGradient)
        (Unify (Layout LayoutType) ('Layout 'Dense) relPosLayout)
        (Unify (Device (DeviceType Nat)) device relPosDevice)
        (Seq
           (Unify (DataType DType) relPosDataType ('DataType 'Int64))
           dataType)
        (TransposeF
           ('SelectDim ('ByIndex 2))
           ('SelectDim ('ByIndex 3))
           (EmbeddingF ('Shape '[posEncDim, headDim]) relPosShape)))
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">forall (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)])
       (shape' :: Shape [Dim (Name Symbol) (Size Nat)]) (m :: * -&gt; *).
(shape'
 ~ TransposeF
     ('SelectDim ('ByIndex 2)) ('SelectDim ('ByIndex 3)) shape,
 SingI ('SelectDim ('ByIndex 2)), SingI ('SelectDim ('ByIndex 3)),
 MonadThrow m) =&gt;
Tensor gradient layout device dataType shape
-&gt; m (Tensor gradient layout device dataType shape')
forall (selectDim0 :: SelectDim (By Symbol Nat))
       (selectDim1 :: SelectDim (By Symbol Nat))
       (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)])
       (shape' :: Shape [Dim (Name Symbol) (Size Nat)]) (m :: * -&gt; *).
(shape' ~ TransposeF selectDim0 selectDim1 shape, SingI selectDim0,
 SingI selectDim1, MonadThrow m) =&gt;
Tensor gradient layout device dataType shape
-&gt; m (Tensor gradient layout device dataType shape')
</span><a href="Torch.GraduallyTyped.Tensor.IndexingSlicingJoining.html#transpose"><span class="hs-identifier hs-var">transpose</span></a></span><span> </span><span class="hs-glyph">@</span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SelectDim"><span class="hs-identifier hs-type">SelectDim</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#ByIndex"><span class="hs-identifier hs-type">ByIndex</span></a></span><span> </span><span class="annot"><span class="hs-number">2</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span> </span><span class="hs-glyph">@</span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SelectDim"><span class="hs-identifier hs-type">SelectDim</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#ByIndex"><span class="hs-identifier hs-type">ByIndex</span></a></span><span> </span><span class="annot"><span class="hs-number">3</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-476"></span><span>            </span><span class="annot"><span class="annottext">IxStateT
  m
  dropoutGeneratorOutput
  dropoutGeneratorOutput
  (Tensor
     (Or (Gradient RequiresGradient) gradient relPosGradient)
     (Unify (Layout LayoutType) ('Layout 'Dense) relPosLayout)
     (Unify (Device (DeviceType Nat)) device relPosDevice)
     (Seq
        (Unify (DataType DType) relPosDataType ('DataType 'Int64))
        dataType)
     (TransposeF
        ('SelectDim ('ByIndex 2))
        ('SelectDim ('ByIndex 3))
        (EmbeddingF ('Shape '[posEncDim, headDim]) relPosShape)))
-&gt; (Tensor
      (Or (Gradient RequiresGradient) gradient relPosGradient)
      (Unify (Layout LayoutType) ('Layout 'Dense) relPosLayout)
      (Unify (Device (DeviceType Nat)) device relPosDevice)
      (Seq
         (Unify (DataType DType) relPosDataType ('DataType 'Int64))
         dataType)
      (TransposeF
         ('SelectDim ('ByIndex 2))
         ('SelectDim ('ByIndex 3))
         (EmbeddingF ('Shape '[posEncDim, headDim]) relPosShape))
    -&gt; IxStateT
         m
         dropoutGeneratorOutput
         dropoutGeneratorOutput
         (Tensor
            (Or (Gradient RequiresGradient) gradient relPosGradient)
            (Unify (Layout LayoutType) ('Layout 'Dense) relPosLayout)
            (Unify (Device (DeviceType Nat)) device relPosDevice)
            (Seq
               (Unify (DataType DType) relPosDataType ('DataType 'Int64))
               dataType)
            (TransposeF
               ('SelectDim ('ByIndex 1))
               ('SelectDim ('ByIndex 2))
               (TransposeF
                  ('SelectDim ('ByIndex 2))
                  ('SelectDim ('ByIndex 3))
                  (EmbeddingF ('Shape '[posEncDim, headDim]) relPosShape)))))
-&gt; IxStateT
     m
     dropoutGeneratorOutput
     dropoutGeneratorOutput
     (Tensor
        (Or (Gradient RequiresGradient) gradient relPosGradient)
        (Unify (Layout LayoutType) ('Layout 'Dense) relPosLayout)
        (Unify (Device (DeviceType Nat)) device relPosDevice)
        (Seq
           (Unify (DataType DType) relPosDataType ('DataType 'Int64))
           dataType)
        (TransposeF
           ('SelectDim ('ByIndex 1))
           ('SelectDim ('ByIndex 2))
           (TransposeF
              ('SelectDim ('ByIndex 2))
              ('SelectDim ('ByIndex 3))
              (EmbeddingF ('Shape '[posEncDim, headDim]) relPosShape))))
forall k1 (m :: k1 -&gt; k1 -&gt; * -&gt; *) (i :: k1) (j :: k1) a
       (k2 :: k1) b.
IxMonad m =&gt;
m i j a -&gt; (a -&gt; m j k2 b) -&gt; m i k2 b
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&gt;&gt;&gt;=</span></a></span><span> </span><span class="annot"><span class="annottext">m (Tensor
     (Or (Gradient RequiresGradient) gradient relPosGradient)
     (Unify (Layout LayoutType) ('Layout 'Dense) relPosLayout)
     (Unify (Device (DeviceType Nat)) device relPosDevice)
     (Seq
        (Unify (DataType DType) relPosDataType ('DataType 'Int64))
        dataType)
     (TransposeF
        ('SelectDim ('ByIndex 1))
        ('SelectDim ('ByIndex 2))
        (TransposeF
           ('SelectDim ('ByIndex 2))
           ('SelectDim ('ByIndex 3))
           (EmbeddingF ('Shape '[posEncDim, headDim]) relPosShape))))
-&gt; IxStateT
     m
     dropoutGeneratorOutput
     dropoutGeneratorOutput
     (Tensor
        (Or (Gradient RequiresGradient) gradient relPosGradient)
        (Unify (Layout LayoutType) ('Layout 'Dense) relPosLayout)
        (Unify (Device (DeviceType Nat)) device relPosDevice)
        (Seq
           (Unify (DataType DType) relPosDataType ('DataType 'Int64))
           dataType)
        (TransposeF
           ('SelectDim ('ByIndex 1))
           ('SelectDim ('ByIndex 2))
           (TransposeF
              ('SelectDim ('ByIndex 2))
              ('SelectDim ('ByIndex 3))
              (EmbeddingF ('Shape '[posEncDim, headDim]) relPosShape))))
forall k (t :: (* -&gt; *) -&gt; k -&gt; k -&gt; * -&gt; *) (m :: * -&gt; *) a
       (i :: k).
(IxMonadTrans t, Monad m) =&gt;
m a -&gt; t m i i a
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-identifier hs-var">ilift</span></a></span><span> </span><span class="annot"><span class="annottext">(m (Tensor
      (Or (Gradient RequiresGradient) gradient relPosGradient)
      (Unify (Layout LayoutType) ('Layout 'Dense) relPosLayout)
      (Unify (Device (DeviceType Nat)) device relPosDevice)
      (Seq
         (Unify (DataType DType) relPosDataType ('DataType 'Int64))
         dataType)
      (TransposeF
         ('SelectDim ('ByIndex 1))
         ('SelectDim ('ByIndex 2))
         (TransposeF
            ('SelectDim ('ByIndex 2))
            ('SelectDim ('ByIndex 3))
            (EmbeddingF ('Shape '[posEncDim, headDim]) relPosShape))))
 -&gt; IxStateT
      m
      dropoutGeneratorOutput
      dropoutGeneratorOutput
      (Tensor
         (Or (Gradient RequiresGradient) gradient relPosGradient)
         (Unify (Layout LayoutType) ('Layout 'Dense) relPosLayout)
         (Unify (Device (DeviceType Nat)) device relPosDevice)
         (Seq
            (Unify (DataType DType) relPosDataType ('DataType 'Int64))
            dataType)
         (TransposeF
            ('SelectDim ('ByIndex 1))
            ('SelectDim ('ByIndex 2))
            (TransposeF
               ('SelectDim ('ByIndex 2))
               ('SelectDim ('ByIndex 3))
               (EmbeddingF ('Shape '[posEncDim, headDim]) relPosShape)))))
-&gt; (Tensor
      (Or (Gradient RequiresGradient) gradient relPosGradient)
      (Unify (Layout LayoutType) ('Layout 'Dense) relPosLayout)
      (Unify (Device (DeviceType Nat)) device relPosDevice)
      (Seq
         (Unify (DataType DType) relPosDataType ('DataType 'Int64))
         dataType)
      (TransposeF
         ('SelectDim ('ByIndex 2))
         ('SelectDim ('ByIndex 3))
         (EmbeddingF ('Shape '[posEncDim, headDim]) relPosShape))
    -&gt; m (Tensor
            (Or (Gradient RequiresGradient) gradient relPosGradient)
            (Unify (Layout LayoutType) ('Layout 'Dense) relPosLayout)
            (Unify (Device (DeviceType Nat)) device relPosDevice)
            (Seq
               (Unify (DataType DType) relPosDataType ('DataType 'Int64))
               dataType)
            (TransposeF
               ('SelectDim ('ByIndex 1))
               ('SelectDim ('ByIndex 2))
               (TransposeF
                  ('SelectDim ('ByIndex 2))
                  ('SelectDim ('ByIndex 3))
                  (EmbeddingF ('Shape '[posEncDim, headDim]) relPosShape)))))
-&gt; Tensor
     (Or (Gradient RequiresGradient) gradient relPosGradient)
     (Unify (Layout LayoutType) ('Layout 'Dense) relPosLayout)
     (Unify (Device (DeviceType Nat)) device relPosDevice)
     (Seq
        (Unify (DataType DType) relPosDataType ('DataType 'Int64))
        dataType)
     (TransposeF
        ('SelectDim ('ByIndex 2))
        ('SelectDim ('ByIndex 3))
        (EmbeddingF ('Shape '[posEncDim, headDim]) relPosShape))
-&gt; IxStateT
     m
     dropoutGeneratorOutput
     dropoutGeneratorOutput
     (Tensor
        (Or (Gradient RequiresGradient) gradient relPosGradient)
        (Unify (Layout LayoutType) ('Layout 'Dense) relPosLayout)
        (Unify (Device (DeviceType Nat)) device relPosDevice)
        (Seq
           (Unify (DataType DType) relPosDataType ('DataType 'Int64))
           dataType)
        (TransposeF
           ('SelectDim ('ByIndex 1))
           ('SelectDim ('ByIndex 2))
           (TransposeF
              ('SelectDim ('ByIndex 2))
              ('SelectDim ('ByIndex 3))
              (EmbeddingF ('Shape '[posEncDim, headDim]) relPosShape))))
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">forall (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)])
       (shape' :: Shape [Dim (Name Symbol) (Size Nat)]) (m :: * -&gt; *).
(shape'
 ~ TransposeF
     ('SelectDim ('ByIndex 1)) ('SelectDim ('ByIndex 2)) shape,
 SingI ('SelectDim ('ByIndex 1)), SingI ('SelectDim ('ByIndex 2)),
 MonadThrow m) =&gt;
Tensor gradient layout device dataType shape
-&gt; m (Tensor gradient layout device dataType shape')
forall (selectDim0 :: SelectDim (By Symbol Nat))
       (selectDim1 :: SelectDim (By Symbol Nat))
       (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)])
       (shape' :: Shape [Dim (Name Symbol) (Size Nat)]) (m :: * -&gt; *).
(shape' ~ TransposeF selectDim0 selectDim1 shape, SingI selectDim0,
 SingI selectDim1, MonadThrow m) =&gt;
Tensor gradient layout device dataType shape
-&gt; m (Tensor gradient layout device dataType shape')
</span><a href="Torch.GraduallyTyped.Tensor.IndexingSlicingJoining.html#transpose"><span class="hs-identifier hs-var">transpose</span></a></span><span> </span><span class="hs-glyph">@</span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SelectDim"><span class="hs-identifier hs-type">SelectDim</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#ByIndex"><span class="hs-identifier hs-type">ByIndex</span></a></span><span> </span><span class="annot"><span class="hs-number">1</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span> </span><span class="hs-glyph">@</span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SelectDim"><span class="hs-identifier hs-type">SelectDim</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#ByIndex"><span class="hs-identifier hs-type">ByIndex</span></a></span><span> </span><span class="annot"><span class="hs-number">2</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-477"></span><span>        </span><span id="local-6989586621679771146"><span class="annot"><span class="annottext">attentionBias :: IxStateT
  m
  dropoutGeneratorOutput
  dropoutGeneratorOutput
  (Tensor
     (Or
        (Gradient RequiresGradient)
        (Or (Gradient RequiresGradient) gradient relPosGradient)
        attentionMaskGradient)
     (Unify
        (Layout LayoutType)
        (Unify (Layout LayoutType) ('Layout 'Dense) relPosLayout)
        attentionMaskLayout)
     (Unify
        (Device (DeviceType Nat))
        (Unify (Device (DeviceType Nat)) device relPosDevice)
        attentionMaskDevice)
     (Unify
        (DataType DType)
        (Seq
           (Unify (DataType DType) relPosDataType ('DataType 'Int64))
           dataType)
        attentionMaskDataType)
     (BroadcastShapesF
        (TransposeF
           ('SelectDim ('ByIndex 1))
           ('SelectDim ('ByIndex 2))
           (TransposeF
              ('SelectDim ('ByIndex 2))
              ('SelectDim ('ByIndex 3))
              (EmbeddingF ('Shape '[posEncDim, headDim]) relPosShape)))
        (UnsqueezeF ('SelectDim ('ByIndex 1)) attentionMaskShape)))
</span><a href="#local-6989586621679771146"><span class="hs-identifier hs-var hs-var">attentionBias</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-478"></span><span>          </span><span class="annot"><span class="annottext">IxStateT
  m
  dropoutGeneratorOutput
  dropoutGeneratorOutput
  (Tensor
     (Or (Gradient RequiresGradient) gradient relPosGradient)
     (Unify (Layout LayoutType) ('Layout 'Dense) relPosLayout)
     (Unify (Device (DeviceType Nat)) device relPosDevice)
     (Seq
        (Unify (DataType DType) relPosDataType ('DataType 'Int64))
        dataType)
     (TransposeF
        ('SelectDim ('ByIndex 1))
        ('SelectDim ('ByIndex 2))
        (TransposeF
           ('SelectDim ('ByIndex 2))
           ('SelectDim ('ByIndex 3))
           (EmbeddingF ('Shape '[posEncDim, headDim]) relPosShape))))
</span><a href="#local-6989586621679771148"><span class="hs-identifier hs-var">relPosBias</span></a></span><span>
</span><span id="line-479"></span><span>            </span><span class="annot"><span class="annottext">IxStateT
  m
  dropoutGeneratorOutput
  dropoutGeneratorOutput
  (Tensor
     (Or (Gradient RequiresGradient) gradient relPosGradient)
     (Unify (Layout LayoutType) ('Layout 'Dense) relPosLayout)
     (Unify (Device (DeviceType Nat)) device relPosDevice)
     (Seq
        (Unify (DataType DType) relPosDataType ('DataType 'Int64))
        dataType)
     (TransposeF
        ('SelectDim ('ByIndex 1))
        ('SelectDim ('ByIndex 2))
        (TransposeF
           ('SelectDim ('ByIndex 2))
           ('SelectDim ('ByIndex 3))
           (EmbeddingF ('Shape '[posEncDim, headDim]) relPosShape))))
-&gt; (Tensor
      (Or (Gradient RequiresGradient) gradient relPosGradient)
      (Unify (Layout LayoutType) ('Layout 'Dense) relPosLayout)
      (Unify (Device (DeviceType Nat)) device relPosDevice)
      (Seq
         (Unify (DataType DType) relPosDataType ('DataType 'Int64))
         dataType)
      (TransposeF
         ('SelectDim ('ByIndex 1))
         ('SelectDim ('ByIndex 2))
         (TransposeF
            ('SelectDim ('ByIndex 2))
            ('SelectDim ('ByIndex 3))
            (EmbeddingF ('Shape '[posEncDim, headDim]) relPosShape)))
    -&gt; IxStateT
         m
         dropoutGeneratorOutput
         dropoutGeneratorOutput
         (Tensor
            (Or
               (Gradient RequiresGradient)
               (Or (Gradient RequiresGradient) gradient relPosGradient)
               attentionMaskGradient)
            (Unify
               (Layout LayoutType)
               (Unify (Layout LayoutType) ('Layout 'Dense) relPosLayout)
               attentionMaskLayout)
            (Unify
               (Device (DeviceType Nat))
               (Unify (Device (DeviceType Nat)) device relPosDevice)
               attentionMaskDevice)
            (Unify
               (DataType DType)
               (Seq
                  (Unify (DataType DType) relPosDataType ('DataType 'Int64))
                  dataType)
               attentionMaskDataType)
            (BroadcastShapesF
               (TransposeF
                  ('SelectDim ('ByIndex 1))
                  ('SelectDim ('ByIndex 2))
                  (TransposeF
                     ('SelectDim ('ByIndex 2))
                     ('SelectDim ('ByIndex 3))
                     (EmbeddingF ('Shape '[posEncDim, headDim]) relPosShape)))
               (UnsqueezeF ('SelectDim ('ByIndex 1)) attentionMaskShape))))
-&gt; IxStateT
     m
     dropoutGeneratorOutput
     dropoutGeneratorOutput
     (Tensor
        (Or
           (Gradient RequiresGradient)
           (Or (Gradient RequiresGradient) gradient relPosGradient)
           attentionMaskGradient)
        (Unify
           (Layout LayoutType)
           (Unify (Layout LayoutType) ('Layout 'Dense) relPosLayout)
           attentionMaskLayout)
        (Unify
           (Device (DeviceType Nat))
           (Unify (Device (DeviceType Nat)) device relPosDevice)
           attentionMaskDevice)
        (Unify
           (DataType DType)
           (Seq
              (Unify (DataType DType) relPosDataType ('DataType 'Int64))
              dataType)
           attentionMaskDataType)
        (BroadcastShapesF
           (TransposeF
              ('SelectDim ('ByIndex 1))
              ('SelectDim ('ByIndex 2))
              (TransposeF
                 ('SelectDim ('ByIndex 2))
                 ('SelectDim ('ByIndex 3))
                 (EmbeddingF ('Shape '[posEncDim, headDim]) relPosShape)))
           (UnsqueezeF ('SelectDim ('ByIndex 1)) attentionMaskShape)))
forall k1 (m :: k1 -&gt; k1 -&gt; * -&gt; *) (i :: k1) (j :: k1) a
       (k2 :: k1) b.
IxMonad m =&gt;
m i j a -&gt; (a -&gt; m j k2 b) -&gt; m i k2 b
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&gt;&gt;&gt;=</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor
  (Or
     (Gradient RequiresGradient)
     (Or (Gradient RequiresGradient) gradient relPosGradient)
     attentionMaskGradient)
  (Unify
     (Layout LayoutType)
     (Unify (Layout LayoutType) ('Layout 'Dense) relPosLayout)
     attentionMaskLayout)
  (Unify
     (Device (DeviceType Nat))
     (Unify (Device (DeviceType Nat)) device relPosDevice)
     attentionMaskDevice)
  (Unify
     (DataType DType)
     (Seq
        (Unify (DataType DType) relPosDataType ('DataType 'Int64))
        dataType)
     attentionMaskDataType)
  (BroadcastShapesF
     (TransposeF
        ('SelectDim ('ByIndex 1))
        ('SelectDim ('ByIndex 2))
        (TransposeF
           ('SelectDim ('ByIndex 2))
           ('SelectDim ('ByIndex 3))
           (EmbeddingF ('Shape '[posEncDim, headDim]) relPosShape)))
     (UnsqueezeF ('SelectDim ('ByIndex 1)) attentionMaskShape))
-&gt; IxStateT
     m
     dropoutGeneratorOutput
     dropoutGeneratorOutput
     (Tensor
        (Or
           (Gradient RequiresGradient)
           (Or (Gradient RequiresGradient) gradient relPosGradient)
           attentionMaskGradient)
        (Unify
           (Layout LayoutType)
           (Unify (Layout LayoutType) ('Layout 'Dense) relPosLayout)
           attentionMaskLayout)
        (Unify
           (Device (DeviceType Nat))
           (Unify (Device (DeviceType Nat)) device relPosDevice)
           attentionMaskDevice)
        (Unify
           (DataType DType)
           (Seq
              (Unify (DataType DType) relPosDataType ('DataType 'Int64))
              dataType)
           attentionMaskDataType)
        (BroadcastShapesF
           (TransposeF
              ('SelectDim ('ByIndex 1))
              ('SelectDim ('ByIndex 2))
              (TransposeF
                 ('SelectDim ('ByIndex 2))
                 ('SelectDim ('ByIndex 3))
                 (EmbeddingF ('Shape '[posEncDim, headDim]) relPosShape)))
           (UnsqueezeF ('SelectDim ('ByIndex 1)) attentionMaskShape)))
forall k (m :: k -&gt; k -&gt; * -&gt; *) a (i :: k).
IxPointed m =&gt;
a -&gt; m i i a
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-identifier hs-var">ireturn</span></a></span><span> </span><span class="annot"><span class="annottext">(Tensor
   (Or
      (Gradient RequiresGradient)
      (Or (Gradient RequiresGradient) gradient relPosGradient)
      attentionMaskGradient)
   (Unify
      (Layout LayoutType)
      (Unify (Layout LayoutType) ('Layout 'Dense) relPosLayout)
      attentionMaskLayout)
   (Unify
      (Device (DeviceType Nat))
      (Unify (Device (DeviceType Nat)) device relPosDevice)
      attentionMaskDevice)
   (Unify
      (DataType DType)
      (Seq
         (Unify (DataType DType) relPosDataType ('DataType 'Int64))
         dataType)
      attentionMaskDataType)
   (BroadcastShapesF
      (TransposeF
         ('SelectDim ('ByIndex 1))
         ('SelectDim ('ByIndex 2))
         (TransposeF
            ('SelectDim ('ByIndex 2))
            ('SelectDim ('ByIndex 3))
            (EmbeddingF ('Shape '[posEncDim, headDim]) relPosShape)))
      (UnsqueezeF ('SelectDim ('ByIndex 1)) attentionMaskShape))
 -&gt; IxStateT
      m
      dropoutGeneratorOutput
      dropoutGeneratorOutput
      (Tensor
         (Or
            (Gradient RequiresGradient)
            (Or (Gradient RequiresGradient) gradient relPosGradient)
            attentionMaskGradient)
         (Unify
            (Layout LayoutType)
            (Unify (Layout LayoutType) ('Layout 'Dense) relPosLayout)
            attentionMaskLayout)
         (Unify
            (Device (DeviceType Nat))
            (Unify (Device (DeviceType Nat)) device relPosDevice)
            attentionMaskDevice)
         (Unify
            (DataType DType)
            (Seq
               (Unify (DataType DType) relPosDataType ('DataType 'Int64))
               dataType)
            attentionMaskDataType)
         (BroadcastShapesF
            (TransposeF
               ('SelectDim ('ByIndex 1))
               ('SelectDim ('ByIndex 2))
               (TransposeF
                  ('SelectDim ('ByIndex 2))
                  ('SelectDim ('ByIndex 3))
                  (EmbeddingF ('Shape '[posEncDim, headDim]) relPosShape)))
            (UnsqueezeF ('SelectDim ('ByIndex 1)) attentionMaskShape))))
-&gt; (Tensor
      (Or (Gradient RequiresGradient) gradient relPosGradient)
      (Unify (Layout LayoutType) ('Layout 'Dense) relPosLayout)
      (Unify (Device (DeviceType Nat)) device relPosDevice)
      (Seq
         (Unify (DataType DType) relPosDataType ('DataType 'Int64))
         dataType)
      (TransposeF
         ('SelectDim ('ByIndex 1))
         ('SelectDim ('ByIndex 2))
         (TransposeF
            ('SelectDim ('ByIndex 2))
            ('SelectDim ('ByIndex 3))
            (EmbeddingF ('Shape '[posEncDim, headDim]) relPosShape)))
    -&gt; Tensor
         (Or
            (Gradient RequiresGradient)
            (Or (Gradient RequiresGradient) gradient relPosGradient)
            attentionMaskGradient)
         (Unify
            (Layout LayoutType)
            (Unify (Layout LayoutType) ('Layout 'Dense) relPosLayout)
            attentionMaskLayout)
         (Unify
            (Device (DeviceType Nat))
            (Unify (Device (DeviceType Nat)) device relPosDevice)
            attentionMaskDevice)
         (Unify
            (DataType DType)
            (Seq
               (Unify (DataType DType) relPosDataType ('DataType 'Int64))
               dataType)
            attentionMaskDataType)
         (BroadcastShapesF
            (TransposeF
               ('SelectDim ('ByIndex 1))
               ('SelectDim ('ByIndex 2))
               (TransposeF
                  ('SelectDim ('ByIndex 2))
                  ('SelectDim ('ByIndex 3))
                  (EmbeddingF ('Shape '[posEncDim, headDim]) relPosShape)))
            (UnsqueezeF ('SelectDim ('ByIndex 1)) attentionMaskShape)))
-&gt; Tensor
     (Or (Gradient RequiresGradient) gradient relPosGradient)
     (Unify (Layout LayoutType) ('Layout 'Dense) relPosLayout)
     (Unify (Device (DeviceType Nat)) device relPosDevice)
     (Seq
        (Unify (DataType DType) relPosDataType ('DataType 'Int64))
        dataType)
     (TransposeF
        ('SelectDim ('ByIndex 1))
        ('SelectDim ('ByIndex 2))
        (TransposeF
           ('SelectDim ('ByIndex 2))
           ('SelectDim ('ByIndex 3))
           (EmbeddingF ('Shape '[posEncDim, headDim]) relPosShape)))
-&gt; IxStateT
     m
     dropoutGeneratorOutput
     dropoutGeneratorOutput
     (Tensor
        (Or
           (Gradient RequiresGradient)
           (Or (Gradient RequiresGradient) gradient relPosGradient)
           attentionMaskGradient)
        (Unify
           (Layout LayoutType)
           (Unify (Layout LayoutType) ('Layout 'Dense) relPosLayout)
           attentionMaskLayout)
        (Unify
           (Device (DeviceType Nat))
           (Unify (Device (DeviceType Nat)) device relPosDevice)
           attentionMaskDevice)
        (Unify
           (DataType DType)
           (Seq
              (Unify (DataType DType) relPosDataType ('DataType 'Int64))
              dataType)
           attentionMaskDataType)
        (BroadcastShapesF
           (TransposeF
              ('SelectDim ('ByIndex 1))
              ('SelectDim ('ByIndex 2))
              (TransposeF
                 ('SelectDim ('ByIndex 2))
                 ('SelectDim ('ByIndex 3))
                 (EmbeddingF ('Shape '[posEncDim, headDim]) relPosShape)))
           (UnsqueezeF ('SelectDim ('ByIndex 1)) attentionMaskShape)))
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">Tensor
  (Or (Gradient RequiresGradient) gradient relPosGradient)
  (Unify (Layout LayoutType) ('Layout 'Dense) relPosLayout)
  (Unify (Device (DeviceType Nat)) device relPosDevice)
  (Seq
     (Unify (DataType DType) relPosDataType ('DataType 'Int64))
     dataType)
  (TransposeF
     ('SelectDim ('ByIndex 1))
     ('SelectDim ('ByIndex 2))
     (TransposeF
        ('SelectDim ('ByIndex 2))
        ('SelectDim ('ByIndex 3))
        (EmbeddingF ('Shape '[posEncDim, headDim]) relPosShape)))
-&gt; Tensor
     attentionMaskGradient
     attentionMaskLayout
     attentionMaskDevice
     attentionMaskDataType
     (UnsqueezeF ('SelectDim ('ByIndex 1)) attentionMaskShape)
-&gt; Tensor
     (Or (Gradient RequiresGradient) gradient relPosGradient
      &lt;|&gt; attentionMaskGradient)
     (Unify (Layout LayoutType) ('Layout 'Dense) relPosLayout
      &lt;+&gt; attentionMaskLayout)
     (Unify (Device (DeviceType Nat)) device relPosDevice
      &lt;+&gt; attentionMaskDevice)
     (Seq
        (Unify (DataType DType) relPosDataType ('DataType 'Int64)) dataType
      &lt;+&gt; attentionMaskDataType)
     (BroadcastShapesF
        (TransposeF
           ('SelectDim ('ByIndex 1))
           ('SelectDim ('ByIndex 2))
           (TransposeF
              ('SelectDim ('ByIndex 2))
              ('SelectDim ('ByIndex 3))
              (EmbeddingF ('Shape '[posEncDim, headDim]) relPosShape)))
        (UnsqueezeF ('SelectDim ('ByIndex 1)) attentionMaskShape))
forall (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)])
       (gradient' :: Gradient RequiresGradient)
       (layout' :: Layout LayoutType) (device' :: Device (DeviceType Nat))
       (dataType' :: DataType DType)
       (shape' :: Shape [Dim (Name Symbol) (Size Nat)]).
Tensor gradient layout device dataType shape
-&gt; Tensor gradient' layout' device' dataType' shape'
-&gt; Tensor
     (gradient &lt;|&gt; gradient')
     (layout &lt;+&gt; layout')
     (device &lt;+&gt; device')
     (dataType &lt;+&gt; dataType')
     (BroadcastShapesF shape shape')
</span><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#add"><span class="hs-operator hs-var">`add`</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor
  attentionMaskGradient
  attentionMaskLayout
  attentionMaskDevice
  attentionMaskDataType
  attentionMaskShape
-&gt; Tensor
     attentionMaskGradient
     attentionMaskLayout
     attentionMaskDevice
     attentionMaskDataType
     (UnsqueezeF ('SelectDim ('ByIndex 1)) attentionMaskShape)
forall (selectDim :: SelectDim (By Symbol Nat))
       (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)])
       (shape' :: Shape [Dim (Name Symbol) (Size Nat)]).
(shape' ~ UnsqueezeF selectDim shape, SingI selectDim) =&gt;
Tensor gradient layout device dataType shape
-&gt; Tensor gradient layout device dataType shape'
</span><a href="Torch.GraduallyTyped.Tensor.IndexingSlicingJoining.html#unsqueeze"><span class="hs-identifier hs-var">unsqueeze</span></a></span><span> </span><span class="hs-glyph">@</span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SelectDim"><span class="hs-identifier hs-type">SelectDim</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#ByIndex"><span class="hs-identifier hs-type">ByIndex</span></a></span><span> </span><span class="annot"><span class="hs-number">1</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">Tensor
  attentionMaskGradient
  attentionMaskLayout
  attentionMaskDevice
  attentionMaskDataType
  attentionMaskShape
</span><a href="#local-6989586621679771149"><span class="hs-identifier hs-var">attentionMask</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-480"></span><span>     </span><span class="hs-keyword">in</span><span> </span><span class="annot"><span class="annottext">IxStateT m generator generatorOutput output
-&gt; generator -&gt; m (output, generatorOutput)
forall (m :: * -&gt; *) i j a. IxStateT m i j a -&gt; i -&gt; m (a, j)
</span><a href="../file:///nix/store/8vjaffqxij7bih93d9mlzmc7ksanlw0i-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier hs-var hs-var">runIxStateT</span></a></span><span> </span><span class="annot"><span class="annottext">(IxStateT m generator generatorOutput output
 -&gt; generator -&gt; m (output, generatorOutput))
-&gt; IxStateT m generator generatorOutput output
-&gt; generator
-&gt; m (output, generatorOutput)
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span>
</span><span id="line-481"></span><span>          </span><span class="annot"><span class="annottext">input -&gt; IxStateT m generator generator input
forall k (m :: k -&gt; k -&gt; * -&gt; *) a (i :: k).
IxPointed m =&gt;
a -&gt; m i i a
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-identifier hs-var">ireturn</span></a></span><span> </span><span class="annot"><span class="annottext">input
</span><a href="#local-6989586621679771151"><span class="hs-identifier hs-var">input</span></a></span><span>
</span><span id="line-482"></span><span>            </span><span class="annot"><span class="annottext">IxStateT m generator generator input
-&gt; (input
    -&gt; IxStateT m generator dropoutGeneratorOutput dropoutOutput)
-&gt; IxStateT m generator dropoutGeneratorOutput dropoutOutput
forall k1 (m :: k1 -&gt; k1 -&gt; * -&gt; *) (i :: k1) (j :: k1) a
       (k2 :: k1) b.
IxMonad m =&gt;
m i j a -&gt; (a -&gt; m j k2 b) -&gt; m i k2 b
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&gt;&gt;&gt;=</span></a></span><span> </span><span class="annot"><span class="annottext">(generator -&gt; m (dropoutOutput, dropoutGeneratorOutput))
-&gt; IxStateT m generator dropoutGeneratorOutput dropoutOutput
forall (m :: * -&gt; *) i j a. (i -&gt; m (a, j)) -&gt; IxStateT m i j a
</span><a href="../file:///nix/store/8vjaffqxij7bih93d9mlzmc7ksanlw0i-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier hs-var">IxStateT</span></a></span><span> </span><span class="annot"><span class="annottext">((generator -&gt; m (dropoutOutput, dropoutGeneratorOutput))
 -&gt; IxStateT m generator dropoutGeneratorOutput dropoutOutput)
-&gt; (input
    -&gt; generator -&gt; m (dropoutOutput, dropoutGeneratorOutput))
-&gt; input
-&gt; IxStateT m generator dropoutGeneratorOutput dropoutOutput
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">Dropout dropoutP
-&gt; input -&gt; generator -&gt; m (dropoutOutput, dropoutGeneratorOutput)
forall model input generator output generatorOutput (m :: * -&gt; *).
(HasForward model input generator output generatorOutput,
 MonadThrow m) =&gt;
model -&gt; input -&gt; generator -&gt; m (output, generatorOutput)
</span><a href="Torch.GraduallyTyped.NN.Class.html#forward"><span class="hs-identifier hs-var">forward</span></a></span><span> </span><span class="annot"><span class="annottext">Dropout dropoutP
TEDropoutF 'T5 dropoutP
</span><a href="#local-6989586621679771153"><span class="hs-identifier hs-var">teDropout</span></a></span><span>
</span><span id="line-483"></span><span>            </span><span class="annot"><span class="annottext">IxStateT m generator dropoutGeneratorOutput dropoutOutput
-&gt; (dropoutOutput
    -&gt; IxStateT
         m dropoutGeneratorOutput stackGeneratorOutput stackOutput)
-&gt; IxStateT m generator stackGeneratorOutput stackOutput
forall k1 (m :: k1 -&gt; k1 -&gt; * -&gt; *) (i :: k1) (j :: k1) a
       (k2 :: k1) b.
IxMonad m =&gt;
m i j a -&gt; (a -&gt; m j k2 b) -&gt; m i k2 b
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&gt;&gt;&gt;=</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">\</span><span id="local-6989586621679771144"><span class="annot"><span class="annottext">dropoutOutput
</span><a href="#local-6989586621679771144"><span class="hs-identifier hs-var">input'</span></a></span></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><span class="annottext">IxStateT
  m
  dropoutGeneratorOutput
  dropoutGeneratorOutput
  (Tensor
     (Or
        (Gradient RequiresGradient)
        (Or (Gradient RequiresGradient) gradient relPosGradient)
        attentionMaskGradient)
     (Unify
        (Layout LayoutType)
        (Unify (Layout LayoutType) ('Layout 'Dense) relPosLayout)
        attentionMaskLayout)
     (Unify
        (Device (DeviceType Nat))
        (Unify (Device (DeviceType Nat)) device relPosDevice)
        attentionMaskDevice)
     (Unify
        (DataType DType)
        (Seq
           (Unify (DataType DType) relPosDataType ('DataType 'Int64))
           dataType)
        attentionMaskDataType)
     (BroadcastShapesF
        (TransposeF
           ('SelectDim ('ByIndex 1))
           ('SelectDim ('ByIndex 2))
           (TransposeF
              ('SelectDim ('ByIndex 2))
              ('SelectDim ('ByIndex 3))
              (EmbeddingF ('Shape '[posEncDim, headDim]) relPosShape)))
        (UnsqueezeF ('SelectDim ('ByIndex 1)) attentionMaskShape)))
</span><a href="#local-6989586621679771146"><span class="hs-identifier hs-var">attentionBias</span></a></span><span> </span><span class="annot"><span class="annottext">IxStateT
  m
  dropoutGeneratorOutput
  dropoutGeneratorOutput
  (Tensor
     (Or
        (Gradient RequiresGradient)
        (Or (Gradient RequiresGradient) gradient relPosGradient)
        attentionMaskGradient)
     (Unify
        (Layout LayoutType)
        (Unify (Layout LayoutType) ('Layout 'Dense) relPosLayout)
        attentionMaskLayout)
     (Unify
        (Device (DeviceType Nat))
        (Unify (Device (DeviceType Nat)) device relPosDevice)
        attentionMaskDevice)
     (Unify
        (DataType DType)
        (Seq
           (Unify (DataType DType) relPosDataType ('DataType 'Int64))
           dataType)
        attentionMaskDataType)
     (BroadcastShapesF
        (TransposeF
           ('SelectDim ('ByIndex 1))
           ('SelectDim ('ByIndex 2))
           (TransposeF
              ('SelectDim ('ByIndex 2))
              ('SelectDim ('ByIndex 3))
              (EmbeddingF ('Shape '[posEncDim, headDim]) relPosShape)))
        (UnsqueezeF ('SelectDim ('ByIndex 1)) attentionMaskShape)))
-&gt; (Tensor
      (Or
         (Gradient RequiresGradient)
         (Or (Gradient RequiresGradient) gradient relPosGradient)
         attentionMaskGradient)
      (Unify
         (Layout LayoutType)
         (Unify (Layout LayoutType) ('Layout 'Dense) relPosLayout)
         attentionMaskLayout)
      (Unify
         (Device (DeviceType Nat))
         (Unify (Device (DeviceType Nat)) device relPosDevice)
         attentionMaskDevice)
      (Unify
         (DataType DType)
         (Seq
            (Unify (DataType DType) relPosDataType ('DataType 'Int64))
            dataType)
         attentionMaskDataType)
      (BroadcastShapesF
         (TransposeF
            ('SelectDim ('ByIndex 1))
            ('SelectDim ('ByIndex 2))
            (TransposeF
               ('SelectDim ('ByIndex 2))
               ('SelectDim ('ByIndex 3))
               (EmbeddingF ('Shape '[posEncDim, headDim]) relPosShape)))
         (UnsqueezeF ('SelectDim ('ByIndex 1)) attentionMaskShape))
    -&gt; IxStateT
         m dropoutGeneratorOutput stackGeneratorOutput stackOutput)
-&gt; IxStateT
     m dropoutGeneratorOutput stackGeneratorOutput stackOutput
forall k1 (m :: k1 -&gt; k1 -&gt; * -&gt; *) (i :: k1) (j :: k1) a
       (k2 :: k1) b.
IxMonad m =&gt;
m i j a -&gt; (a -&gt; m j k2 b) -&gt; m i k2 b
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&gt;&gt;&gt;=</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">\</span><span id="local-6989586621679771143"><span class="annot"><span class="annottext">Tensor
  (Or
     (Gradient RequiresGradient)
     (Or (Gradient RequiresGradient) gradient relPosGradient)
     attentionMaskGradient)
  (Unify
     (Layout LayoutType)
     (Unify (Layout LayoutType) ('Layout 'Dense) relPosLayout)
     attentionMaskLayout)
  (Unify
     (Device (DeviceType Nat))
     (Unify (Device (DeviceType Nat)) device relPosDevice)
     attentionMaskDevice)
  (Unify
     (DataType DType)
     (Seq
        (Unify (DataType DType) relPosDataType ('DataType 'Int64))
        dataType)
     attentionMaskDataType)
  (BroadcastShapesF
     (TransposeF
        ('SelectDim ('ByIndex 1))
        ('SelectDim ('ByIndex 2))
        (TransposeF
           ('SelectDim ('ByIndex 2))
           ('SelectDim ('ByIndex 3))
           (EmbeddingF ('Shape '[posEncDim, headDim]) relPosShape)))
     (UnsqueezeF ('SelectDim ('ByIndex 1)) attentionMaskShape))
</span><a href="#local-6989586621679771143"><span class="hs-identifier hs-var">attentionBias'</span></a></span></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><span class="annottext">(dropoutGeneratorOutput -&gt; m (stackOutput, stackGeneratorOutput))
-&gt; IxStateT
     m dropoutGeneratorOutput stackGeneratorOutput stackOutput
forall (m :: * -&gt; *) i j a. (i -&gt; m (a, j)) -&gt; IxStateT m i j a
</span><a href="../file:///nix/store/8vjaffqxij7bih93d9mlzmc7ksanlw0i-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier hs-var">IxStateT</span></a></span><span> </span><span class="annot"><span class="annottext">((dropoutGeneratorOutput -&gt; m (stackOutput, stackGeneratorOutput))
 -&gt; IxStateT
      m dropoutGeneratorOutput stackGeneratorOutput stackOutput)
-&gt; (dropoutGeneratorOutput
    -&gt; m (stackOutput, stackGeneratorOutput))
-&gt; IxStateT
     m dropoutGeneratorOutput stackGeneratorOutput stackOutput
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">TransformerStack
  'T5
  numLayers
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  inputEmbedDim
  ffnDim
  dropoutP
-&gt; (dropoutOutput,
    Tensor
      (Or
         (Gradient RequiresGradient)
         (Or (Gradient RequiresGradient) gradient relPosGradient)
         attentionMaskGradient)
      (Unify
         (Layout LayoutType)
         (Unify (Layout LayoutType) ('Layout 'Dense) relPosLayout)
         attentionMaskLayout)
      (Unify
         (Device (DeviceType Nat))
         (Unify (Device (DeviceType Nat)) device relPosDevice)
         attentionMaskDevice)
      (Unify
         (DataType DType)
         (Seq
            (Unify (DataType DType) relPosDataType ('DataType 'Int64))
            dataType)
         attentionMaskDataType)
      (BroadcastShapesF
         (TransposeF
            ('SelectDim ('ByIndex 1))
            ('SelectDim ('ByIndex 2))
            (TransposeF
               ('SelectDim ('ByIndex 2))
               ('SelectDim ('ByIndex 3))
               (EmbeddingF ('Shape '[posEncDim, headDim]) relPosShape)))
         (UnsqueezeF ('SelectDim ('ByIndex 1)) attentionMaskShape)))
-&gt; dropoutGeneratorOutput
-&gt; m (stackOutput, stackGeneratorOutput)
forall model input generator output generatorOutput (m :: * -&gt; *).
(HasForward model input generator output generatorOutput,
 MonadThrow m) =&gt;
model -&gt; input -&gt; generator -&gt; m (output, generatorOutput)
</span><a href="Torch.GraduallyTyped.NN.Class.html#forward"><span class="hs-identifier hs-var">forward</span></a></span><span> </span><span class="annot"><span class="annottext">TransformerStack
  'T5
  numLayers
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  inputEmbedDim
  ffnDim
  dropoutP
TEStackF
  'T5
  numLayers
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  inputEmbedDim
  ffnDim
  dropoutP
</span><a href="#local-6989586621679771156"><span class="hs-identifier hs-var">teStack</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">dropoutOutput
</span><a href="#local-6989586621679771144"><span class="hs-identifier hs-var">input'</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">Tensor
  (Or
     (Gradient RequiresGradient)
     (Or (Gradient RequiresGradient) gradient relPosGradient)
     attentionMaskGradient)
  (Unify
     (Layout LayoutType)
     (Unify (Layout LayoutType) ('Layout 'Dense) relPosLayout)
     attentionMaskLayout)
  (Unify
     (Device (DeviceType Nat))
     (Unify (Device (DeviceType Nat)) device relPosDevice)
     attentionMaskDevice)
  (Unify
     (DataType DType)
     (Seq
        (Unify (DataType DType) relPosDataType ('DataType 'Int64))
        dataType)
     attentionMaskDataType)
  (BroadcastShapesF
     (TransposeF
        ('SelectDim ('ByIndex 1))
        ('SelectDim ('ByIndex 2))
        (TransposeF
           ('SelectDim ('ByIndex 2))
           ('SelectDim ('ByIndex 3))
           (EmbeddingF ('Shape '[posEncDim, headDim]) relPosShape)))
     (UnsqueezeF ('SelectDim ('ByIndex 1)) attentionMaskShape))
</span><a href="#local-6989586621679771143"><span class="hs-identifier hs-var">attentionBias'</span></a></span><span class="hs-special">)</span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-484"></span><span>            </span><span class="annot"><span class="annottext">IxStateT m generator stackGeneratorOutput stackOutput
-&gt; (stackOutput
    -&gt; IxStateT
         m stackGeneratorOutput layerNormGeneratorOutput layerNormOutput)
-&gt; IxStateT m generator layerNormGeneratorOutput layerNormOutput
forall k1 (m :: k1 -&gt; k1 -&gt; * -&gt; *) (i :: k1) (j :: k1) a
       (k2 :: k1) b.
IxMonad m =&gt;
m i j a -&gt; (a -&gt; m j k2 b) -&gt; m i k2 b
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&gt;&gt;&gt;=</span></a></span><span> </span><span class="annot"><span class="annottext">(stackGeneratorOutput
 -&gt; m (layerNormOutput, layerNormGeneratorOutput))
-&gt; IxStateT
     m stackGeneratorOutput layerNormGeneratorOutput layerNormOutput
forall (m :: * -&gt; *) i j a. (i -&gt; m (a, j)) -&gt; IxStateT m i j a
</span><a href="../file:///nix/store/8vjaffqxij7bih93d9mlzmc7ksanlw0i-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier hs-var">IxStateT</span></a></span><span> </span><span class="annot"><span class="annottext">((stackGeneratorOutput
  -&gt; m (layerNormOutput, layerNormGeneratorOutput))
 -&gt; IxStateT
      m stackGeneratorOutput layerNormGeneratorOutput layerNormOutput)
-&gt; (stackOutput
    -&gt; stackGeneratorOutput
    -&gt; m (layerNormOutput, layerNormGeneratorOutput))
-&gt; stackOutput
-&gt; IxStateT
     m stackGeneratorOutput layerNormGeneratorOutput layerNormOutput
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">LayerNorm
  'WithoutBias gradient device dataType ('Shape '[inputEmbedDim])
-&gt; stackOutput
-&gt; stackGeneratorOutput
-&gt; m (layerNormOutput, layerNormGeneratorOutput)
forall model input generator output generatorOutput (m :: * -&gt; *).
(HasForward model input generator output generatorOutput,
 MonadThrow m) =&gt;
model -&gt; input -&gt; generator -&gt; m (output, generatorOutput)
</span><a href="Torch.GraduallyTyped.NN.Class.html#forward"><span class="hs-identifier hs-var">forward</span></a></span><span> </span><span class="annot"><span class="annottext">LayerNorm
  'WithoutBias gradient device dataType ('Shape '[inputEmbedDim])
TELayerNormF 'T5 gradient device dataType inputEmbedDim
</span><a href="#local-6989586621679771154"><span class="hs-identifier hs-var">teLayerNorm</span></a></span><span>
</span><span id="line-485"></span><span>            </span><span class="annot"><span class="annottext">IxStateT m generator layerNormGeneratorOutput layerNormOutput
-&gt; (layerNormOutput
    -&gt; IxStateT m layerNormGeneratorOutput generatorOutput output)
-&gt; IxStateT m generator generatorOutput output
forall k1 (m :: k1 -&gt; k1 -&gt; * -&gt; *) (i :: k1) (j :: k1) a
       (k2 :: k1) b.
IxMonad m =&gt;
m i j a -&gt; (a -&gt; m j k2 b) -&gt; m i k2 b
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&gt;&gt;&gt;=</span></a></span><span> </span><span class="annot"><span class="annottext">(layerNormGeneratorOutput -&gt; m (output, generatorOutput))
-&gt; IxStateT m layerNormGeneratorOutput generatorOutput output
forall (m :: * -&gt; *) i j a. (i -&gt; m (a, j)) -&gt; IxStateT m i j a
</span><a href="../file:///nix/store/8vjaffqxij7bih93d9mlzmc7ksanlw0i-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier hs-var">IxStateT</span></a></span><span> </span><span class="annot"><span class="annottext">((layerNormGeneratorOutput -&gt; m (output, generatorOutput))
 -&gt; IxStateT m layerNormGeneratorOutput generatorOutput output)
-&gt; (layerNormOutput
    -&gt; layerNormGeneratorOutput -&gt; m (output, generatorOutput))
-&gt; layerNormOutput
-&gt; IxStateT m layerNormGeneratorOutput generatorOutput output
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">Dropout dropoutP
-&gt; layerNormOutput
-&gt; layerNormGeneratorOutput
-&gt; m (output, generatorOutput)
forall model input generator output generatorOutput (m :: * -&gt; *).
(HasForward model input generator output generatorOutput,
 MonadThrow m) =&gt;
model -&gt; input -&gt; generator -&gt; m (output, generatorOutput)
</span><a href="Torch.GraduallyTyped.NN.Class.html#forward"><span class="hs-identifier hs-var">forward</span></a></span><span> </span><span class="annot"><span class="annottext">Dropout dropoutP
TEDropoutF 'T5 dropoutP
</span><a href="#local-6989586621679771153"><span class="hs-identifier hs-var">teDropout</span></a></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span><span>
</span><span id="line-486"></span><span>
</span><span id="line-487"></span><span id="testEncoder"><span class="annot"><span class="annottext">testEncoder :: IO
  (Tensor
     ('Gradient 'WithGradient)
     ('Layout 'Dense)
     ('Device 'CPU)
     ('DataType 'Float)
     ('Shape
        '[ 'Dim ('Name &quot;*&quot;) ('Size 3), 'Dim ('Name &quot;*&quot;) ('Size 13),
           'Dim ('Name &quot;*&quot;) ('Size 512)]))
</span><a href="Torch.GraduallyTyped.NN.Transformer.Encoder.html#testEncoder"><span class="hs-identifier hs-var hs-var">testEncoder</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="hs-keyword">do</span><span>
</span><span id="line-488"></span><span>  </span><span class="hs-keyword">let</span><span> </span><span id="local-6989586621679771141"><span class="annot"><span class="annottext">gradient :: SGradient ('Gradient 'WithGradient)
</span><a href="#local-6989586621679771141"><span class="hs-identifier hs-var hs-var">gradient</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">SRequiresGradient 'WithGradient
-&gt; SGradient ('Gradient 'WithGradient)
forall (requiresGradient :: RequiresGradient).
SRequiresGradient requiresGradient
-&gt; SGradient ('Gradient requiresGradient)
</span><a href="Torch.GraduallyTyped.RequiresGradient.html#SGradient"><span class="hs-identifier hs-var">SGradient</span></a></span><span> </span><span class="annot"><span class="annottext">SRequiresGradient 'WithGradient
</span><a href="Torch.GraduallyTyped.RequiresGradient.html#SWithGradient"><span class="hs-identifier hs-var">SWithGradient</span></a></span><span>
</span><span id="line-489"></span><span>      </span><span id="local-6989586621679771138"><span class="annot"><span class="annottext">device :: SDevice ('Device 'CPU)
</span><a href="#local-6989586621679771138"><span class="hs-identifier hs-var hs-var">device</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">SDeviceType 'CPU -&gt; SDevice ('Device 'CPU)
forall (deviceType :: DeviceType Nat).
SDeviceType deviceType -&gt; SDevice ('Device deviceType)
</span><a href="Torch.GraduallyTyped.Device.html#SDevice"><span class="hs-identifier hs-var">SDevice</span></a></span><span> </span><span class="annot"><span class="annottext">SDeviceType 'CPU
</span><a href="Torch.GraduallyTyped.Device.html#SCPU"><span class="hs-identifier hs-var">SCPU</span></a></span><span>
</span><span id="line-490"></span><span>      </span><span id="local-6989586621679771135"><span class="annot"><span class="annottext">dataType :: SDataType ('DataType 'Float)
</span><a href="#local-6989586621679771135"><span class="hs-identifier hs-var hs-var">dataType</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">SDType 'Float -&gt; SDataType ('DataType 'Float)
forall (dType :: DType).
SDType dType -&gt; SDataType ('DataType dType)
</span><a href="Torch.GraduallyTyped.DType.html#SDataType"><span class="hs-identifier hs-var">SDataType</span></a></span><span> </span><span class="annot"><span class="annottext">SDType 'Float
</span><a href="Torch.GraduallyTyped.DType.html#SFloat"><span class="hs-identifier hs-var">SFloat</span></a></span><span>
</span><span id="line-491"></span><span>      </span><span id="local-6989586621679771132"><span class="annot"><span class="annottext">headDim :: SDim ('Dim ('Name &quot;*&quot;) ('Size 8))
</span><a href="#local-6989586621679771132"><span class="hs-identifier hs-var hs-var">headDim</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">KnownSymbol &quot;*&quot; =&gt; SName ('Name &quot;*&quot;)
forall (name :: Symbol). KnownSymbol name =&gt; SName ('Name name)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SName"><span class="hs-identifier hs-var">SName</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><span class="hs-string">&quot;*&quot;</span></span><span> </span><span class="annot"><span class="annottext">SName ('Name &quot;*&quot;)
-&gt; SSize ('Size 8) -&gt; SDim ('Dim ('Name &quot;*&quot;) ('Size 8))
forall (name :: Name Symbol) (size :: Size Nat).
SName name -&gt; SSize size -&gt; SDim ('Dim name size)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%26%3A"><span class="hs-operator hs-var">:&amp;:</span></a></span><span> </span><span class="annot"><span class="annottext">KnownNat 8 =&gt; SSize ('Size 8)
forall (size :: Nat). KnownNat size =&gt; SSize ('Size size)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SSize"><span class="hs-identifier hs-var">SSize</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><span class="hs-number">8</span></span><span>
</span><span id="line-492"></span><span>      </span><span id="local-6989586621679771129"><span class="annot"><span class="annottext">headEmbedDim :: SDim ('Dim ('Name &quot;*&quot;) ('Size 64))
</span><a href="#local-6989586621679771129"><span class="hs-identifier hs-var hs-var">headEmbedDim</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">KnownSymbol &quot;*&quot; =&gt; SName ('Name &quot;*&quot;)
forall (name :: Symbol). KnownSymbol name =&gt; SName ('Name name)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SName"><span class="hs-identifier hs-var">SName</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><span class="hs-string">&quot;*&quot;</span></span><span> </span><span class="annot"><span class="annottext">SName ('Name &quot;*&quot;)
-&gt; SSize ('Size 64) -&gt; SDim ('Dim ('Name &quot;*&quot;) ('Size 64))
forall (name :: Name Symbol) (size :: Size Nat).
SName name -&gt; SSize size -&gt; SDim ('Dim name size)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%26%3A"><span class="hs-operator hs-var">:&amp;:</span></a></span><span> </span><span class="annot"><span class="annottext">KnownNat 64 =&gt; SSize ('Size 64)
forall (size :: Nat). KnownNat size =&gt; SSize ('Size size)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SSize"><span class="hs-identifier hs-var">SSize</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><span class="hs-number">64</span></span><span>
</span><span id="line-493"></span><span>      </span><span id="local-6989586621679771128"><span class="annot"><span class="annottext">embedDim :: SDim ('Dim ('Name &quot;*&quot;) ('Size 512))
</span><a href="#local-6989586621679771128"><span class="hs-identifier hs-var hs-var">embedDim</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">KnownSymbol &quot;*&quot; =&gt; SName ('Name &quot;*&quot;)
forall (name :: Symbol). KnownSymbol name =&gt; SName ('Name name)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SName"><span class="hs-identifier hs-var">SName</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><span class="hs-string">&quot;*&quot;</span></span><span> </span><span class="annot"><span class="annottext">SName ('Name &quot;*&quot;)
-&gt; SSize ('Size 512) -&gt; SDim ('Dim ('Name &quot;*&quot;) ('Size 512))
forall (name :: Name Symbol) (size :: Size Nat).
SName name -&gt; SSize size -&gt; SDim ('Dim name size)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%26%3A"><span class="hs-operator hs-var">:&amp;:</span></a></span><span> </span><span class="annot"><span class="annottext">KnownNat 512 =&gt; SSize ('Size 512)
forall (size :: Nat). KnownNat size =&gt; SSize ('Size size)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SSize"><span class="hs-identifier hs-var">SSize</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><span class="hs-number">512</span></span><span>
</span><span id="line-494"></span><span>      </span><span id="local-6989586621679771127"><span class="annot"><span class="annottext">inputEmbedDim :: SDim ('Dim ('Name &quot;*&quot;) ('Size 512))
</span><a href="#local-6989586621679771127"><span class="hs-identifier hs-var hs-var">inputEmbedDim</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">KnownSymbol &quot;*&quot; =&gt; SName ('Name &quot;*&quot;)
forall (name :: Symbol). KnownSymbol name =&gt; SName ('Name name)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SName"><span class="hs-identifier hs-var">SName</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><span class="hs-string">&quot;*&quot;</span></span><span> </span><span class="annot"><span class="annottext">SName ('Name &quot;*&quot;)
-&gt; SSize ('Size 512) -&gt; SDim ('Dim ('Name &quot;*&quot;) ('Size 512))
forall (name :: Name Symbol) (size :: Size Nat).
SName name -&gt; SSize size -&gt; SDim ('Dim name size)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%26%3A"><span class="hs-operator hs-var">:&amp;:</span></a></span><span> </span><span class="annot"><span class="annottext">KnownNat 512 =&gt; SSize ('Size 512)
forall (size :: Nat). KnownNat size =&gt; SSize ('Size size)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SSize"><span class="hs-identifier hs-var">SSize</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><span class="hs-number">512</span></span><span>
</span><span id="line-495"></span><span>      </span><span id="local-6989586621679771126"><span class="annot"><span class="annottext">ffnDim :: SDim ('Dim ('Name &quot;*&quot;) ('Size 2048))
</span><a href="#local-6989586621679771126"><span class="hs-identifier hs-var hs-var">ffnDim</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">KnownSymbol &quot;*&quot; =&gt; SName ('Name &quot;*&quot;)
forall (name :: Symbol). KnownSymbol name =&gt; SName ('Name name)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SName"><span class="hs-identifier hs-var">SName</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><span class="hs-string">&quot;*&quot;</span></span><span> </span><span class="annot"><span class="annottext">SName ('Name &quot;*&quot;)
-&gt; SSize ('Size 2048) -&gt; SDim ('Dim ('Name &quot;*&quot;) ('Size 2048))
forall (name :: Name Symbol) (size :: Size Nat).
SName name -&gt; SSize size -&gt; SDim ('Dim name size)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%26%3A"><span class="hs-operator hs-var">:&amp;:</span></a></span><span> </span><span class="annot"><span class="annottext">KnownNat 2048 =&gt; SSize ('Size 2048)
forall (size :: Nat). KnownNat size =&gt; SSize ('Size size)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SSize"><span class="hs-identifier hs-var">SSize</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><span class="hs-number">2048</span></span><span>
</span><span id="line-496"></span><span>      </span><span id="local-6989586621679771125"><span class="annot"><span class="annottext">posEncDim :: SDim ('Dim ('Name &quot;*&quot;) ('Size 32))
</span><a href="#local-6989586621679771125"><span class="hs-identifier hs-var hs-var">posEncDim</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">KnownSymbol &quot;*&quot; =&gt; SName ('Name &quot;*&quot;)
forall (name :: Symbol). KnownSymbol name =&gt; SName ('Name name)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SName"><span class="hs-identifier hs-var">SName</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><span class="hs-string">&quot;*&quot;</span></span><span> </span><span class="annot"><span class="annottext">SName ('Name &quot;*&quot;)
-&gt; SSize ('Size 32) -&gt; SDim ('Dim ('Name &quot;*&quot;) ('Size 32))
forall (name :: Name Symbol) (size :: Size Nat).
SName name -&gt; SSize size -&gt; SDim ('Dim name size)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%26%3A"><span class="hs-operator hs-var">:&amp;:</span></a></span><span> </span><span class="annot"><span class="annottext">KnownNat 32 =&gt; SSize ('Size 32)
forall (size :: Nat). KnownNat size =&gt; SSize ('Size size)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SSize"><span class="hs-identifier hs-var">SSize</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><span class="hs-number">32</span></span><span>
</span><span id="line-497"></span><span>      </span><span id="local-6989586621679771124"><span class="annot"><span class="annottext">Float
</span><a href="#local-6989586621679771124"><span class="hs-identifier hs-var">dropoutP</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Float</span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Float
</span><span class="hs-number">0.0</span></span><span>
</span><span id="line-498"></span><span>      </span><span id="local-6989586621679771123"><span class="annot"><span class="annottext">eps :: Double
</span><a href="#local-6989586621679771123"><span class="hs-identifier hs-var hs-var">eps</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Double
</span><span class="hs-number">1e-6</span></span><span>
</span><span id="line-499"></span><span>  </span><span id="local-6989586621679771122"><span class="annot"><span class="annottext">Generator ('Device 'CPU)
</span><a href="#local-6989586621679771122"><span class="hs-identifier hs-var">g</span></a></span></span><span> </span><span class="hs-glyph">&lt;-</span><span> </span><span class="annot"><span class="annottext">SDevice ('Device 'CPU) -&gt; Word64 -&gt; IO (Generator ('Device 'CPU))
forall (device :: Device (DeviceType Nat)).
SDevice device -&gt; Word64 -&gt; IO (Generator device)
</span><a href="Torch.GraduallyTyped.Random.html#sMkGenerator"><span class="hs-identifier hs-var">sMkGenerator</span></a></span><span> </span><span class="annot"><span class="annottext">SDevice ('Device 'CPU)
</span><a href="#local-6989586621679771138"><span class="hs-identifier hs-var">device</span></a></span><span> </span><span class="annot"><span class="annottext">Word64
</span><span class="hs-number">0</span></span><span>
</span><span id="line-500"></span><span>  </span><span class="hs-keyword">let</span><span> </span><span class="hs-special">(</span><span id="local-6989586621679771121"><span class="annot"><span class="annottext">TransformerEncoder
  'T5
  10
  ('Gradient 'WithGradient)
  ('Device 'CPU)
  ('DataType 'Float)
  ('Dim ('Name &quot;*&quot;) ('Size 8))
  ('Dim ('Name &quot;*&quot;) ('Size 64))
  ('Dim ('Name &quot;*&quot;) ('Size 512))
  ('Dim ('Name &quot;*&quot;) ('Size 512))
  ('Dim ('Name &quot;*&quot;) ('Size 2048))
  ('Dim ('Name &quot;*&quot;) ('Size 32))
  Float
</span><a href="#local-6989586621679771121"><span class="hs-identifier hs-var">encoder</span></a></span></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679771120"><span class="annot"><span class="annottext">Generator ('Device 'CPU)
</span><a href="#local-6989586621679771120"><span class="hs-identifier hs-var">g'</span></a></span></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">(SGradient ('Gradient 'WithGradient), SDevice ('Device 'CPU),
 SDataType ('DataType 'Float), SDim ('Dim ('Name &quot;*&quot;) ('Size 8)),
 SDim ('Dim ('Name &quot;*&quot;) ('Size 64)),
 SDim ('Dim ('Name &quot;*&quot;) ('Size 512)),
 SDim ('Dim ('Name &quot;*&quot;) ('Size 512)),
 SDim ('Dim ('Name &quot;*&quot;) ('Size 2048)),
 SDim ('Dim ('Name &quot;*&quot;) ('Size 32)), Float, Double)
-&gt; Generator ('Device 'CPU)
-&gt; (TransformerEncoder
      'T5
      10
      ('Gradient 'WithGradient)
      ('Device 'CPU)
      ('DataType 'Float)
      ('Dim ('Name &quot;*&quot;) ('Size 8))
      ('Dim ('Name &quot;*&quot;) ('Size 64))
      ('Dim ('Name &quot;*&quot;) ('Size 512))
      ('Dim ('Name &quot;*&quot;) ('Size 512))
      ('Dim ('Name &quot;*&quot;) ('Size 2048))
      ('Dim ('Name &quot;*&quot;) ('Size 32))
      Float,
    Generator ('Device 'CPU))
forall model input generator generatorOutput.
HasInitialize model input generator generatorOutput =&gt;
input -&gt; generator -&gt; (model, generatorOutput)
</span><a href="Torch.GraduallyTyped.NN.Class.html#initialize"><span class="hs-identifier hs-var">initialize</span></a></span><span> </span><span class="hs-glyph">@</span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Encoder.html#TransformerEncoder"><span class="hs-identifier hs-type">TransformerEncoder</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#T5"><span class="hs-identifier hs-type">T5</span></a></span><span> </span><span class="annot"><span class="hs-number">10</span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SGradient ('Gradient 'WithGradient)
</span><a href="#local-6989586621679771141"><span class="hs-identifier hs-var">gradient</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDevice ('Device 'CPU)
</span><a href="#local-6989586621679771138"><span class="hs-identifier hs-var">device</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDataType ('DataType 'Float)
</span><a href="#local-6989586621679771135"><span class="hs-identifier hs-var">dataType</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDim ('Dim ('Name &quot;*&quot;) ('Size 8))
</span><a href="#local-6989586621679771132"><span class="hs-identifier hs-var">headDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDim ('Dim ('Name &quot;*&quot;) ('Size 64))
</span><a href="#local-6989586621679771129"><span class="hs-identifier hs-var">headEmbedDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDim ('Dim ('Name &quot;*&quot;) ('Size 512))
</span><a href="#local-6989586621679771128"><span class="hs-identifier hs-var">embedDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDim ('Dim ('Name &quot;*&quot;) ('Size 512))
</span><a href="#local-6989586621679771127"><span class="hs-identifier hs-var">inputEmbedDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDim ('Dim ('Name &quot;*&quot;) ('Size 2048))
</span><a href="#local-6989586621679771126"><span class="hs-identifier hs-var">ffnDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDim ('Dim ('Name &quot;*&quot;) ('Size 32))
</span><a href="#local-6989586621679771125"><span class="hs-identifier hs-var">posEncDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">Float
</span><a href="#local-6989586621679771124"><span class="hs-identifier hs-var">dropoutP</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">Double
</span><a href="#local-6989586621679771123"><span class="hs-identifier hs-var">eps</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">Generator ('Device 'CPU)
</span><a href="#local-6989586621679771122"><span class="hs-identifier hs-var">g</span></a></span><span>
</span><span id="line-501"></span><span>      </span><span id="local-6989586621679771119"><span class="annot"><span class="annottext">batchDim :: SDim ('Dim ('Name &quot;*&quot;) ('Size 3))
</span><a href="#local-6989586621679771119"><span class="hs-identifier hs-var hs-var">batchDim</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">KnownSymbol &quot;*&quot; =&gt; SName ('Name &quot;*&quot;)
forall (name :: Symbol). KnownSymbol name =&gt; SName ('Name name)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SName"><span class="hs-identifier hs-var">SName</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><span class="hs-string">&quot;*&quot;</span></span><span> </span><span class="annot"><span class="annottext">SName ('Name &quot;*&quot;)
-&gt; SSize ('Size 3) -&gt; SDim ('Dim ('Name &quot;*&quot;) ('Size 3))
forall (name :: Name Symbol) (size :: Size Nat).
SName name -&gt; SSize size -&gt; SDim ('Dim name size)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%26%3A"><span class="hs-operator hs-var">:&amp;:</span></a></span><span> </span><span class="annot"><span class="annottext">KnownNat 3 =&gt; SSize ('Size 3)
forall (size :: Nat). KnownNat size =&gt; SSize ('Size size)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SSize"><span class="hs-identifier hs-var">SSize</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><span class="hs-number">3</span></span><span>
</span><span id="line-502"></span><span>      </span><span id="local-6989586621679771118"><span class="annot"><span class="annottext">seqDim :: SDim ('Dim ('Name &quot;*&quot;) ('Size 13))
</span><a href="#local-6989586621679771118"><span class="hs-identifier hs-var hs-var">seqDim</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">KnownSymbol &quot;*&quot; =&gt; SName ('Name &quot;*&quot;)
forall (name :: Symbol). KnownSymbol name =&gt; SName ('Name name)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SName"><span class="hs-identifier hs-var">SName</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><span class="hs-string">&quot;*&quot;</span></span><span> </span><span class="annot"><span class="annottext">SName ('Name &quot;*&quot;)
-&gt; SSize ('Size 13) -&gt; SDim ('Dim ('Name &quot;*&quot;) ('Size 13))
forall (name :: Name Symbol) (size :: Size Nat).
SName name -&gt; SSize size -&gt; SDim ('Dim name size)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%26%3A"><span class="hs-operator hs-var">:&amp;:</span></a></span><span> </span><span class="annot"><span class="annottext">KnownNat 13 =&gt; SSize ('Size 13)
forall (size :: Nat). KnownNat size =&gt; SSize ('Size size)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SSize"><span class="hs-identifier hs-var">SSize</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><span class="hs-number">13</span></span><span>
</span><span id="line-503"></span><span>      </span><span id="local-6989586621679771117"><span class="annot"><span class="annottext">sOnes' :: SDataType dataType
-&gt; SShape shape
-&gt; Tensor
     ('Gradient 'WithoutGradient)
     ('Layout 'Dense)
     ('Device 'CPU)
     dataType
     shape
</span><a href="#local-6989586621679771117"><span class="hs-identifier hs-var hs-var">sOnes'</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">SGradient ('Gradient 'WithoutGradient)
-&gt; SLayout ('Layout 'Dense)
-&gt; SDevice ('Device 'CPU)
-&gt; SDataType dataType
-&gt; SShape shape
-&gt; Tensor
     ('Gradient 'WithoutGradient)
     ('Layout 'Dense)
     ('Device 'CPU)
     dataType
     shape
forall (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)]).
SGradient gradient
-&gt; SLayout layout
-&gt; SDevice device
-&gt; SDataType dataType
-&gt; SShape shape
-&gt; Tensor gradient layout device dataType shape
</span><a href="Torch.GraduallyTyped.Tensor.Creation.html#sOnes"><span class="hs-identifier hs-var">sOnes</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SRequiresGradient 'WithoutGradient
-&gt; SGradient ('Gradient 'WithoutGradient)
forall (requiresGradient :: RequiresGradient).
SRequiresGradient requiresGradient
-&gt; SGradient ('Gradient requiresGradient)
</span><a href="Torch.GraduallyTyped.RequiresGradient.html#SGradient"><span class="hs-identifier hs-var">SGradient</span></a></span><span> </span><span class="annot"><span class="annottext">SRequiresGradient 'WithoutGradient
</span><a href="Torch.GraduallyTyped.RequiresGradient.html#SWithoutGradient"><span class="hs-identifier hs-var">SWithoutGradient</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SLayoutType 'Dense -&gt; SLayout ('Layout 'Dense)
forall (layoutType :: LayoutType).
SLayoutType layoutType -&gt; SLayout ('Layout layoutType)
</span><a href="Torch.GraduallyTyped.Layout.html#SLayout"><span class="hs-identifier hs-var">SLayout</span></a></span><span> </span><span class="annot"><span class="annottext">SLayoutType 'Dense
</span><a href="Torch.GraduallyTyped.Layout.html#SDense"><span class="hs-identifier hs-var">SDense</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">SDevice ('Device 'CPU)
</span><a href="#local-6989586621679771138"><span class="hs-identifier hs-var">device</span></a></span><span>
</span><span id="line-504"></span><span>      </span><span id="local-6989586621679771115"><span class="annot"><span class="annottext">input :: Tensor
  ('Gradient 'WithoutGradient)
  ('Layout 'Dense)
  ('Device 'CPU)
  ('DataType 'Float)
  ('Shape
     '[ 'Dim ('Name &quot;*&quot;) ('Size 3), 'Dim ('Name &quot;*&quot;) ('Size 13),
        'Dim ('Name &quot;*&quot;) ('Size 512)])
</span><a href="#local-6989586621679771115"><span class="hs-identifier hs-var hs-var">input</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">SDataType ('DataType 'Float)
-&gt; SShape
     ('Shape
        '[ 'Dim ('Name &quot;*&quot;) ('Size 3), 'Dim ('Name &quot;*&quot;) ('Size 13),
           'Dim ('Name &quot;*&quot;) ('Size 512)])
-&gt; Tensor
     ('Gradient 'WithoutGradient)
     ('Layout 'Dense)
     ('Device 'CPU)
     ('DataType 'Float)
     ('Shape
        '[ 'Dim ('Name &quot;*&quot;) ('Size 3), 'Dim ('Name &quot;*&quot;) ('Size 13),
           'Dim ('Name &quot;*&quot;) ('Size 512)])
forall (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)]).
SDataType dataType
-&gt; SShape shape
-&gt; Tensor
     ('Gradient 'WithoutGradient)
     ('Layout 'Dense)
     ('Device 'CPU)
     dataType
     shape
</span><a href="#local-6989586621679771117"><span class="hs-identifier hs-var">sOnes'</span></a></span><span> </span><span class="annot"><span class="annottext">SDataType ('DataType 'Float)
</span><a href="#local-6989586621679771135"><span class="hs-identifier hs-var">dataType</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SList
  '[ 'Dim ('Name &quot;*&quot;) ('Size 3), 'Dim ('Name &quot;*&quot;) ('Size 13),
     'Dim ('Name &quot;*&quot;) ('Size 512)]
-&gt; SShape
     ('Shape
        '[ 'Dim ('Name &quot;*&quot;) ('Size 3), 'Dim ('Name &quot;*&quot;) ('Size 13),
           'Dim ('Name &quot;*&quot;) ('Size 512)])
forall (dims :: [Dim (Name Symbol) (Size Nat)]).
SList dims -&gt; SShape ('Shape dims)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SShape"><span class="hs-identifier hs-var">SShape</span></a></span><span> </span><span class="annot"><span class="annottext">(SList
   '[ 'Dim ('Name &quot;*&quot;) ('Size 3), 'Dim ('Name &quot;*&quot;) ('Size 13),
      'Dim ('Name &quot;*&quot;) ('Size 512)]
 -&gt; SShape
      ('Shape
         '[ 'Dim ('Name &quot;*&quot;) ('Size 3), 'Dim ('Name &quot;*&quot;) ('Size 13),
            'Dim ('Name &quot;*&quot;) ('Size 512)]))
-&gt; SList
     '[ 'Dim ('Name &quot;*&quot;) ('Size 3), 'Dim ('Name &quot;*&quot;) ('Size 13),
        'Dim ('Name &quot;*&quot;) ('Size 512)]
-&gt; SShape
     ('Shape
        '[ 'Dim ('Name &quot;*&quot;) ('Size 3), 'Dim ('Name &quot;*&quot;) ('Size 13),
           'Dim ('Name &quot;*&quot;) ('Size 512)])
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">SDim ('Dim ('Name &quot;*&quot;) ('Size 3))
</span><a href="#local-6989586621679771119"><span class="hs-identifier hs-var">batchDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim ('Dim ('Name &quot;*&quot;) ('Size 3))
-&gt; SList
     '[ 'Dim ('Name &quot;*&quot;) ('Size 13), 'Dim ('Name &quot;*&quot;) ('Size 512)]
-&gt; SList
     '[ 'Dim ('Name &quot;*&quot;) ('Size 3), 'Dim ('Name &quot;*&quot;) ('Size 13),
        'Dim ('Name &quot;*&quot;) ('Size 512)]
forall (dim :: Dim (Name Symbol) (Size Nat))
       (dims :: [Dim (Name Symbol) (Size Nat)]).
SDim dim -&gt; SList dims -&gt; SList (dim : dims)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%7C%3A"><span class="hs-operator hs-var">:|:</span></a></span><span> </span><span class="annot"><span class="annottext">SDim ('Dim ('Name &quot;*&quot;) ('Size 13))
</span><a href="#local-6989586621679771118"><span class="hs-identifier hs-var">seqDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim ('Dim ('Name &quot;*&quot;) ('Size 13))
-&gt; SList '[ 'Dim ('Name &quot;*&quot;) ('Size 512)]
-&gt; SList
     '[ 'Dim ('Name &quot;*&quot;) ('Size 13), 'Dim ('Name &quot;*&quot;) ('Size 512)]
forall (dim :: Dim (Name Symbol) (Size Nat))
       (dims :: [Dim (Name Symbol) (Size Nat)]).
SDim dim -&gt; SList dims -&gt; SList (dim : dims)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%7C%3A"><span class="hs-operator hs-var">:|:</span></a></span><span> </span><span class="annot"><span class="annottext">SDim ('Dim ('Name &quot;*&quot;) ('Size 512))
</span><a href="#local-6989586621679771127"><span class="hs-identifier hs-var">inputEmbedDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim ('Dim ('Name &quot;*&quot;) ('Size 512))
-&gt; SList '[] -&gt; SList '[ 'Dim ('Name &quot;*&quot;) ('Size 512)]
forall (dim :: Dim (Name Symbol) (Size Nat))
       (dims :: [Dim (Name Symbol) (Size Nat)]).
SDim dim -&gt; SList dims -&gt; SList (dim : dims)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%7C%3A"><span class="hs-operator hs-var">:|:</span></a></span><span> </span><span class="annot"><span class="annottext">SList '[]
forall a. SList '[]
</span><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-var">SNil</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-505"></span><span>      </span><span id="local-6989586621679771114"><span class="annot"><span class="annottext">relPos :: Tensor
  ('Gradient 'WithoutGradient)
  ('Layout 'Dense)
  ('Device 'CPU)
  ('DataType 'Int64)
  ('Shape
     '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) ('Size 13),
        'Dim ('Name &quot;*&quot;) ('Size 13)])
</span><a href="#local-6989586621679771114"><span class="hs-identifier hs-var hs-var">relPos</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">SDataType ('DataType 'Int64)
-&gt; SShape
     ('Shape
        '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) ('Size 13),
           'Dim ('Name &quot;*&quot;) ('Size 13)])
-&gt; Tensor
     ('Gradient 'WithoutGradient)
     ('Layout 'Dense)
     ('Device 'CPU)
     ('DataType 'Int64)
     ('Shape
        '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) ('Size 13),
           'Dim ('Name &quot;*&quot;) ('Size 13)])
forall (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)]).
SDataType dataType
-&gt; SShape shape
-&gt; Tensor
     ('Gradient 'WithoutGradient)
     ('Layout 'Dense)
     ('Device 'CPU)
     dataType
     shape
</span><a href="#local-6989586621679771117"><span class="hs-identifier hs-var">sOnes'</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SDType 'Int64 -&gt; SDataType ('DataType 'Int64)
forall (dType :: DType).
SDType dType -&gt; SDataType ('DataType dType)
</span><a href="Torch.GraduallyTyped.DType.html#SDataType"><span class="hs-identifier hs-var">SDataType</span></a></span><span> </span><span class="annot"><span class="annottext">SDType 'Int64
</span><a href="Torch.GraduallyTyped.DType.html#SInt64"><span class="hs-identifier hs-var">SInt64</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SList
  '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) ('Size 13),
     'Dim ('Name &quot;*&quot;) ('Size 13)]
-&gt; SShape
     ('Shape
        '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) ('Size 13),
           'Dim ('Name &quot;*&quot;) ('Size 13)])
forall (dims :: [Dim (Name Symbol) (Size Nat)]).
SList dims -&gt; SShape ('Shape dims)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SShape"><span class="hs-identifier hs-var">SShape</span></a></span><span> </span><span class="annot"><span class="annottext">(SList
   '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) ('Size 13),
      'Dim ('Name &quot;*&quot;) ('Size 13)]
 -&gt; SShape
      ('Shape
         '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) ('Size 13),
            'Dim ('Name &quot;*&quot;) ('Size 13)]))
-&gt; SList
     '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) ('Size 13),
        'Dim ('Name &quot;*&quot;) ('Size 13)]
-&gt; SShape
     ('Shape
        '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) ('Size 13),
           'Dim ('Name &quot;*&quot;) ('Size 13)])
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">KnownSymbol &quot;*&quot; =&gt; SName ('Name &quot;*&quot;)
forall (name :: Symbol). KnownSymbol name =&gt; SName ('Name name)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SName"><span class="hs-identifier hs-var">SName</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><span class="hs-string">&quot;*&quot;</span></span><span> </span><span class="annot"><span class="annottext">SName ('Name &quot;*&quot;)
-&gt; SSize ('Size 1) -&gt; SDim ('Dim ('Name &quot;*&quot;) ('Size 1))
forall (name :: Name Symbol) (size :: Size Nat).
SName name -&gt; SSize size -&gt; SDim ('Dim name size)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%26%3A"><span class="hs-operator hs-var">:&amp;:</span></a></span><span> </span><span class="annot"><span class="annottext">KnownNat 1 =&gt; SSize ('Size 1)
forall (size :: Nat). KnownNat size =&gt; SSize ('Size size)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SSize"><span class="hs-identifier hs-var">SSize</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><span class="hs-number">1</span></span><span> </span><span class="annot"><span class="annottext">SDim ('Dim ('Name &quot;*&quot;) ('Size 1))
-&gt; SList
     '[ 'Dim ('Name &quot;*&quot;) ('Size 13), 'Dim ('Name &quot;*&quot;) ('Size 13)]
-&gt; SList
     '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) ('Size 13),
        'Dim ('Name &quot;*&quot;) ('Size 13)]
forall (dim :: Dim (Name Symbol) (Size Nat))
       (dims :: [Dim (Name Symbol) (Size Nat)]).
SDim dim -&gt; SList dims -&gt; SList (dim : dims)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%7C%3A"><span class="hs-operator hs-var">:|:</span></a></span><span> </span><span class="annot"><span class="annottext">SDim ('Dim ('Name &quot;*&quot;) ('Size 13))
</span><a href="#local-6989586621679771118"><span class="hs-identifier hs-var">seqDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim ('Dim ('Name &quot;*&quot;) ('Size 13))
-&gt; SList '[ 'Dim ('Name &quot;*&quot;) ('Size 13)]
-&gt; SList
     '[ 'Dim ('Name &quot;*&quot;) ('Size 13), 'Dim ('Name &quot;*&quot;) ('Size 13)]
forall (dim :: Dim (Name Symbol) (Size Nat))
       (dims :: [Dim (Name Symbol) (Size Nat)]).
SDim dim -&gt; SList dims -&gt; SList (dim : dims)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%7C%3A"><span class="hs-operator hs-var">:|:</span></a></span><span> </span><span class="annot"><span class="annottext">SDim ('Dim ('Name &quot;*&quot;) ('Size 13))
</span><a href="#local-6989586621679771118"><span class="hs-identifier hs-var">seqDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim ('Dim ('Name &quot;*&quot;) ('Size 13))
-&gt; SList '[] -&gt; SList '[ 'Dim ('Name &quot;*&quot;) ('Size 13)]
forall (dim :: Dim (Name Symbol) (Size Nat))
       (dims :: [Dim (Name Symbol) (Size Nat)]).
SDim dim -&gt; SList dims -&gt; SList (dim : dims)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%7C%3A"><span class="hs-operator hs-var">:|:</span></a></span><span> </span><span class="annot"><span class="annottext">SList '[]
forall a. SList '[]
</span><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-var">SNil</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-506"></span><span>      </span><span id="local-6989586621679771112"><span class="annot"><span class="annottext">attentionMask :: Tensor
  ('Gradient 'WithoutGradient)
  ('Layout 'Dense)
  ('Device 'CPU)
  ('DataType 'Float)
  ('Shape
     '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) ('Size 13),
        'Dim ('Name &quot;*&quot;) ('Size 13)])
</span><a href="#local-6989586621679771112"><span class="hs-identifier hs-var hs-var">attentionMask</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">SDataType ('DataType 'Float)
-&gt; SShape
     ('Shape
        '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) ('Size 13),
           'Dim ('Name &quot;*&quot;) ('Size 13)])
-&gt; Tensor
     ('Gradient 'WithoutGradient)
     ('Layout 'Dense)
     ('Device 'CPU)
     ('DataType 'Float)
     ('Shape
        '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) ('Size 13),
           'Dim ('Name &quot;*&quot;) ('Size 13)])
forall (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)]).
SDataType dataType
-&gt; SShape shape
-&gt; Tensor
     ('Gradient 'WithoutGradient)
     ('Layout 'Dense)
     ('Device 'CPU)
     dataType
     shape
</span><a href="#local-6989586621679771117"><span class="hs-identifier hs-var">sOnes'</span></a></span><span> </span><span class="annot"><span class="annottext">SDataType ('DataType 'Float)
</span><a href="#local-6989586621679771135"><span class="hs-identifier hs-var">dataType</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SList
  '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) ('Size 13),
     'Dim ('Name &quot;*&quot;) ('Size 13)]
-&gt; SShape
     ('Shape
        '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) ('Size 13),
           'Dim ('Name &quot;*&quot;) ('Size 13)])
forall (dims :: [Dim (Name Symbol) (Size Nat)]).
SList dims -&gt; SShape ('Shape dims)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SShape"><span class="hs-identifier hs-var">SShape</span></a></span><span> </span><span class="annot"><span class="annottext">(SList
   '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) ('Size 13),
      'Dim ('Name &quot;*&quot;) ('Size 13)]
 -&gt; SShape
      ('Shape
         '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) ('Size 13),
            'Dim ('Name &quot;*&quot;) ('Size 13)]))
-&gt; SList
     '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) ('Size 13),
        'Dim ('Name &quot;*&quot;) ('Size 13)]
-&gt; SShape
     ('Shape
        '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) ('Size 13),
           'Dim ('Name &quot;*&quot;) ('Size 13)])
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">KnownSymbol &quot;*&quot; =&gt; SName ('Name &quot;*&quot;)
forall (name :: Symbol). KnownSymbol name =&gt; SName ('Name name)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SName"><span class="hs-identifier hs-var">SName</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><span class="hs-string">&quot;*&quot;</span></span><span> </span><span class="annot"><span class="annottext">SName ('Name &quot;*&quot;)
-&gt; SSize ('Size 1) -&gt; SDim ('Dim ('Name &quot;*&quot;) ('Size 1))
forall (name :: Name Symbol) (size :: Size Nat).
SName name -&gt; SSize size -&gt; SDim ('Dim name size)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%26%3A"><span class="hs-operator hs-var">:&amp;:</span></a></span><span> </span><span class="annot"><span class="annottext">KnownNat 1 =&gt; SSize ('Size 1)
forall (size :: Nat). KnownNat size =&gt; SSize ('Size size)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SSize"><span class="hs-identifier hs-var">SSize</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><span class="hs-number">1</span></span><span> </span><span class="annot"><span class="annottext">SDim ('Dim ('Name &quot;*&quot;) ('Size 1))
-&gt; SList
     '[ 'Dim ('Name &quot;*&quot;) ('Size 13), 'Dim ('Name &quot;*&quot;) ('Size 13)]
-&gt; SList
     '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) ('Size 13),
        'Dim ('Name &quot;*&quot;) ('Size 13)]
forall (dim :: Dim (Name Symbol) (Size Nat))
       (dims :: [Dim (Name Symbol) (Size Nat)]).
SDim dim -&gt; SList dims -&gt; SList (dim : dims)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%7C%3A"><span class="hs-operator hs-var">:|:</span></a></span><span> </span><span class="annot"><span class="annottext">SDim ('Dim ('Name &quot;*&quot;) ('Size 13))
</span><a href="#local-6989586621679771118"><span class="hs-identifier hs-var">seqDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim ('Dim ('Name &quot;*&quot;) ('Size 13))
-&gt; SList '[ 'Dim ('Name &quot;*&quot;) ('Size 13)]
-&gt; SList
     '[ 'Dim ('Name &quot;*&quot;) ('Size 13), 'Dim ('Name &quot;*&quot;) ('Size 13)]
forall (dim :: Dim (Name Symbol) (Size Nat))
       (dims :: [Dim (Name Symbol) (Size Nat)]).
SDim dim -&gt; SList dims -&gt; SList (dim : dims)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%7C%3A"><span class="hs-operator hs-var">:|:</span></a></span><span> </span><span class="annot"><span class="annottext">SDim ('Dim ('Name &quot;*&quot;) ('Size 13))
</span><a href="#local-6989586621679771118"><span class="hs-identifier hs-var">seqDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim ('Dim ('Name &quot;*&quot;) ('Size 13))
-&gt; SList '[] -&gt; SList '[ 'Dim ('Name &quot;*&quot;) ('Size 13)]
forall (dim :: Dim (Name Symbol) (Size Nat))
       (dims :: [Dim (Name Symbol) (Size Nat)]).
SDim dim -&gt; SList dims -&gt; SList (dim : dims)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%7C%3A"><span class="hs-operator hs-var">:|:</span></a></span><span> </span><span class="annot"><span class="annottext">SList '[]
forall a. SList '[]
</span><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-var">SNil</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-507"></span><span>  </span><span class="hs-special">(</span><span id="local-6989586621679771111"><span class="annot"><span class="annottext">Tensor
  ('Gradient 'WithGradient)
  ('Layout 'Dense)
  ('Device 'CPU)
  ('DataType 'Float)
  ('Shape
     '[ 'Dim ('Name &quot;*&quot;) ('Size 3), 'Dim ('Name &quot;*&quot;) ('Size 13),
        'Dim ('Name &quot;*&quot;) ('Size 512)])
</span><a href="#local-6989586621679771111"><span class="hs-identifier hs-var">output</span></a></span></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">Generator ('Device 'CPU)
</span><span class="hs-identifier">_</span></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">&lt;-</span><span> </span><span class="annot"><span class="annottext">TransformerEncoder
  'T5
  10
  ('Gradient 'WithGradient)
  ('Device 'CPU)
  ('DataType 'Float)
  ('Dim ('Name &quot;*&quot;) ('Size 8))
  ('Dim ('Name &quot;*&quot;) ('Size 64))
  ('Dim ('Name &quot;*&quot;) ('Size 512))
  ('Dim ('Name &quot;*&quot;) ('Size 512))
  ('Dim ('Name &quot;*&quot;) ('Size 2048))
  ('Dim ('Name &quot;*&quot;) ('Size 32))
  Float
-&gt; (Tensor
      ('Gradient 'WithoutGradient)
      ('Layout 'Dense)
      ('Device 'CPU)
      ('DataType 'Float)
      ('Shape
         '[ 'Dim ('Name &quot;*&quot;) ('Size 3), 'Dim ('Name &quot;*&quot;) ('Size 13),
            'Dim ('Name &quot;*&quot;) ('Size 512)]),
    Tensor
      ('Gradient 'WithoutGradient)
      ('Layout 'Dense)
      ('Device 'CPU)
      ('DataType 'Int64)
      ('Shape
         '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) ('Size 13),
            'Dim ('Name &quot;*&quot;) ('Size 13)]),
    Tensor
      ('Gradient 'WithoutGradient)
      ('Layout 'Dense)
      ('Device 'CPU)
      ('DataType 'Float)
      ('Shape
         '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) ('Size 13),
            'Dim ('Name &quot;*&quot;) ('Size 13)]))
-&gt; Generator ('Device 'CPU)
-&gt; IO
     (Tensor
        ('Gradient 'WithGradient)
        ('Layout 'Dense)
        ('Device 'CPU)
        ('DataType 'Float)
        ('Shape
           '[ 'Dim ('Name &quot;*&quot;) ('Size 3), 'Dim ('Name &quot;*&quot;) ('Size 13),
              'Dim ('Name &quot;*&quot;) ('Size 512)]),
      Generator ('Device 'CPU))
forall model input generator output generatorOutput (m :: * -&gt; *).
(HasForward model input generator output generatorOutput,
 MonadThrow m) =&gt;
model -&gt; input -&gt; generator -&gt; m (output, generatorOutput)
</span><a href="Torch.GraduallyTyped.NN.Class.html#forward"><span class="hs-identifier hs-var">forward</span></a></span><span> </span><span class="annot"><span class="annottext">TransformerEncoder
  'T5
  10
  ('Gradient 'WithGradient)
  ('Device 'CPU)
  ('DataType 'Float)
  ('Dim ('Name &quot;*&quot;) ('Size 8))
  ('Dim ('Name &quot;*&quot;) ('Size 64))
  ('Dim ('Name &quot;*&quot;) ('Size 512))
  ('Dim ('Name &quot;*&quot;) ('Size 512))
  ('Dim ('Name &quot;*&quot;) ('Size 2048))
  ('Dim ('Name &quot;*&quot;) ('Size 32))
  Float
</span><a href="#local-6989586621679771121"><span class="hs-identifier hs-var">encoder</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">Tensor
  ('Gradient 'WithoutGradient)
  ('Layout 'Dense)
  ('Device 'CPU)
  ('DataType 'Float)
  ('Shape
     '[ 'Dim ('Name &quot;*&quot;) ('Size 3), 'Dim ('Name &quot;*&quot;) ('Size 13),
        'Dim ('Name &quot;*&quot;) ('Size 512)])
</span><a href="#local-6989586621679771115"><span class="hs-identifier hs-var">input</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">Tensor
  ('Gradient 'WithoutGradient)
  ('Layout 'Dense)
  ('Device 'CPU)
  ('DataType 'Int64)
  ('Shape
     '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) ('Size 13),
        'Dim ('Name &quot;*&quot;) ('Size 13)])
</span><a href="#local-6989586621679771114"><span class="hs-identifier hs-var">relPos</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">Tensor
  ('Gradient 'WithoutGradient)
  ('Layout 'Dense)
  ('Device 'CPU)
  ('DataType 'Float)
  ('Shape
     '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) ('Size 13),
        'Dim ('Name &quot;*&quot;) ('Size 13)])
</span><a href="#local-6989586621679771112"><span class="hs-identifier hs-var">attentionMask</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">Generator ('Device 'CPU)
</span><a href="#local-6989586621679771120"><span class="hs-identifier hs-var">g'</span></a></span><span>
</span><span id="line-508"></span><span>  </span><span class="annot"><span class="annottext">Tensor
  ('Gradient 'WithGradient)
  ('Layout 'Dense)
  ('Device 'CPU)
  ('DataType 'Float)
  ('Shape
     '[ 'Dim ('Name &quot;*&quot;) ('Size 3), 'Dim ('Name &quot;*&quot;) ('Size 13),
        'Dim ('Name &quot;*&quot;) ('Size 512)])
-&gt; IO
     (Tensor
        ('Gradient 'WithGradient)
        ('Layout 'Dense)
        ('Device 'CPU)
        ('DataType 'Float)
        ('Shape
           '[ 'Dim ('Name &quot;*&quot;) ('Size 3), 'Dim ('Name &quot;*&quot;) ('Size 13),
              'Dim ('Name &quot;*&quot;) ('Size 512)]))
forall (f :: * -&gt; *) a. Applicative f =&gt; a -&gt; f a
</span><span class="hs-identifier hs-var">pure</span></span><span> </span><span class="annot"><span class="annottext">Tensor
  ('Gradient 'WithGradient)
  ('Layout 'Dense)
  ('Device 'CPU)
  ('DataType 'Float)
  ('Shape
     '[ 'Dim ('Name &quot;*&quot;) ('Size 3), 'Dim ('Name &quot;*&quot;) ('Size 13),
        'Dim ('Name &quot;*&quot;) ('Size 512)])
</span><a href="#local-6989586621679771111"><span class="hs-identifier hs-var">output</span></a></span><span>
</span><span id="line-509"></span><span>
</span><span id="line-510"></span><span class="hs-comment">-- | 'HasForward' instance for @TransformerEncoder numLayers 'ByT5@.</span><span>
</span><span id="line-511"></span><span class="hs-comment">--</span><span>
</span><span id="line-512"></span><span class="hs-comment">-- @</span><span>
</span><span id="line-513"></span><span class="hs-comment">--  &#9484;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9488;  &#9484;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9488;  &#9484;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9488;</span><span>
</span><span id="line-514"></span><span class="hs-comment">--  &#9474; input &#9474;  &#9474; relPos &#9474;  &#9474; attentionMask &#9474;</span><span>
</span><span id="line-515"></span><span class="hs-comment">--  &#9492;&#9472;&#9472;&#9472;&#9516;&#9472;&#9472;&#9472;&#9496;  &#9492;&#9472;&#9472;&#9472;&#9516;&#9472;&#9472;&#9472;&#9472;&#9496;  &#9492;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9516;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9496;</span><span>
</span><span id="line-516"></span><span class="hs-comment">--      &#9474;          &#9474;               &#9474;</span><span>
</span><span id="line-517"></span><span class="hs-comment">--      &#9474;          &#9660;               &#9474;</span><span>
</span><span id="line-518"></span><span class="hs-comment">--      &#9474;      tePosEnc            &#9474;</span><span>
</span><span id="line-519"></span><span class="hs-comment">--      &#9474;          &#9660;               &#9474;</span><span>
</span><span id="line-520"></span><span class="hs-comment">--      &#9474;      transpose           &#9474;</span><span>
</span><span id="line-521"></span><span class="hs-comment">--      &#9474;          &#9660;               &#9660;</span><span>
</span><span id="line-522"></span><span class="hs-comment">--      &#9474;      transpose       unsqueeze</span><span>
</span><span id="line-523"></span><span class="hs-comment">--      &#9660;          &#9474;               &#9474;</span><span>
</span><span id="line-524"></span><span class="hs-comment">--  teDropout      &#9492;&#9472;&#9472;&#9472;&#9472;&#9472;&#9658;add&#9668;&#9472;&#9472;&#9472;&#9472;&#9472;&#9496;</span><span>
</span><span id="line-525"></span><span class="hs-comment">--      &#9660;                  &#9474;</span><span>
</span><span id="line-526"></span><span class="hs-comment">--   teStack&#9668;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9496;</span><span>
</span><span id="line-527"></span><span class="hs-comment">--      &#9660;</span><span>
</span><span id="line-528"></span><span class="hs-comment">-- teLayerNorm</span><span>
</span><span id="line-529"></span><span class="hs-comment">--      &#9660;</span><span>
</span><span id="line-530"></span><span class="hs-comment">--  teDropout</span><span>
</span><span id="line-531"></span><span class="hs-comment">--      &#9474;</span><span>
</span><span id="line-532"></span><span class="hs-comment">--      &#9660;</span><span>
</span><span id="line-533"></span><span class="hs-comment">--  &#9484;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9488;</span><span>
</span><span id="line-534"></span><span class="hs-comment">--  &#9474; output &#9474;</span><span>
</span><span id="line-535"></span><span class="hs-comment">--  &#9492;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9496;</span><span>
</span><span id="line-536"></span><span class="hs-comment">-- @</span><span>
</span><span id="line-537"></span><span id="local-6989586621679771080"><span id="local-6989586621679771081"><span id="local-6989586621679771082"><span id="local-6989586621679771083"><span id="local-6989586621679771084"><span id="local-6989586621679771085"><span id="local-6989586621679771086"><span id="local-6989586621679771087"><span id="local-6989586621679771088"><span id="local-6989586621679771089"><span id="local-6989586621679771090"><span id="local-6989586621679771091"><span id="local-6989586621679771092"><span id="local-6989586621679771093"><span id="local-6989586621679771094"><span id="local-6989586621679771095"><span id="local-6989586621679771096"><span id="local-6989586621679771097"><span id="local-6989586621679771098"><span id="local-6989586621679771099"><span id="local-6989586621679771100"><span id="local-6989586621679771101"><span id="local-6989586621679771102"><span id="local-6989586621679771103"><span id="local-6989586621679771104"><span id="local-6989586621679771105"><span id="local-6989586621679771106"><span id="local-6989586621679771107"><span id="local-6989586621679771108"><span id="local-6989586621679771109"><span id="local-6989586621679771110"><span class="hs-keyword">instance</span><span>
</span><span id="line-538"></span><span>  </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasForward"><span class="hs-identifier hs-type">HasForward</span></a></span><span>
</span><span id="line-539"></span><span>      </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Encoder.html#TEDropoutF"><span class="hs-identifier hs-type">TEDropoutF</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#ByT5"><span class="hs-identifier hs-type">ByT5</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771110"><span class="hs-identifier hs-type">dropoutP</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-540"></span><span>      </span><span class="annot"><a href="#local-6989586621679771109"><span class="hs-identifier hs-type">input</span></a></span><span>
</span><span id="line-541"></span><span>      </span><span class="annot"><a href="#local-6989586621679771108"><span class="hs-identifier hs-type">generator</span></a></span><span>
</span><span id="line-542"></span><span>      </span><span class="annot"><a href="#local-6989586621679771107"><span class="hs-identifier hs-type">dropoutOutput</span></a></span><span>
</span><span id="line-543"></span><span>      </span><span class="annot"><a href="#local-6989586621679771106"><span class="hs-identifier hs-type">dropoutGeneratorOutput</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-544"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasForward"><span class="hs-identifier hs-type">HasForward</span></a></span><span>
</span><span id="line-545"></span><span>      </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Encoder.html#TEStackF"><span class="hs-identifier hs-type">TEStackF</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#ByT5"><span class="hs-identifier hs-type">ByT5</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771105"><span class="hs-identifier hs-type">numLayers</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771104"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771103"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771102"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771101"><span class="hs-identifier hs-type">headDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771100"><span class="hs-identifier hs-type">headEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771099"><span class="hs-identifier hs-type">embedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771098"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771097"><span class="hs-identifier hs-type">ffnDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771110"><span class="hs-identifier hs-type">dropoutP</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-546"></span><span>      </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="#local-6989586621679771107"><span class="hs-identifier hs-type">dropoutOutput</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-547"></span><span>        </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span>
</span><span id="line-548"></span><span>          </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679771104"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%7C%3E"><span class="hs-operator hs-type">&lt;|&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771096"><span class="hs-identifier hs-type">relPosGradient</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%7C%3E"><span class="hs-operator hs-type">&lt;|&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771095"><span class="hs-identifier hs-type">attentionMaskGradient</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-549"></span><span>          </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#Layout"><span class="hs-identifier hs-type">Layout</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#Dense"><span class="hs-identifier hs-type">Dense</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771094"><span class="hs-identifier hs-type">relPosLayout</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771093"><span class="hs-identifier hs-type">attentionMaskLayout</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-550"></span><span>          </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679771103"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771092"><span class="hs-identifier hs-type">relPosDevice</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771091"><span class="hs-identifier hs-type">attentionMaskDevice</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-551"></span><span>          </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Prelude.html#Seq"><span class="hs-identifier hs-type">Seq</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679771090"><span class="hs-identifier hs-type">relPosDataType</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#DataType"><span class="hs-identifier hs-type">DataType</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#Int64"><span class="hs-identifier hs-type">Int64</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679771102"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771089"><span class="hs-identifier hs-type">attentionMaskDataType</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-552"></span><span>          </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Class.html#BroadcastShapesF"><span class="hs-identifier hs-type">BroadcastShapesF</span></a></span><span>
</span><span id="line-553"></span><span>              </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.IndexingSlicingJoining.html#TransposeF"><span class="hs-identifier hs-type">TransposeF</span></a></span><span>
</span><span id="line-554"></span><span>                  </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SelectDim"><span class="hs-identifier hs-type">SelectDim</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#ByIndex"><span class="hs-identifier hs-type">ByIndex</span></a></span><span> </span><span class="annot"><span class="hs-number">1</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-555"></span><span>                  </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SelectDim"><span class="hs-identifier hs-type">SelectDim</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#ByIndex"><span class="hs-identifier hs-type">ByIndex</span></a></span><span> </span><span class="annot"><span class="hs-number">2</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-556"></span><span>                  </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.IndexingSlicingJoining.html#TransposeF"><span class="hs-identifier hs-type">TransposeF</span></a></span><span>
</span><span id="line-557"></span><span>                      </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SelectDim"><span class="hs-identifier hs-type">SelectDim</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#ByIndex"><span class="hs-identifier hs-type">ByIndex</span></a></span><span> </span><span class="annot"><span class="hs-number">2</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-558"></span><span>                      </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SelectDim"><span class="hs-identifier hs-type">SelectDim</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#ByIndex"><span class="hs-identifier hs-type">ByIndex</span></a></span><span> </span><span class="annot"><span class="hs-number">3</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-559"></span><span>                      </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Functional.Sparse.html#EmbeddingF"><span class="hs-identifier hs-type">EmbeddingF</span></a></span><span>
</span><span id="line-560"></span><span>                          </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Shape"><span class="hs-identifier hs-type">Shape</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="annot"><a href="#local-6989586621679771088"><span class="hs-identifier hs-type">posEncDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679771101"><span class="hs-identifier hs-type">headDim</span></a></span><span class="hs-special">]</span><span class="hs-special">)</span><span>
</span><span id="line-561"></span><span>                          </span><span class="annot"><a href="#local-6989586621679771087"><span class="hs-identifier hs-type">relPosShape</span></a></span><span>
</span><span id="line-562"></span><span>                      </span><span class="hs-special">)</span><span>
</span><span id="line-563"></span><span>                  </span><span class="hs-special">)</span><span>
</span><span id="line-564"></span><span>              </span><span class="hs-special">)</span><span>
</span><span id="line-565"></span><span>              </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.IndexingSlicingJoining.html#UnsqueezeF"><span class="hs-identifier hs-type">UnsqueezeF</span></a></span><span>
</span><span id="line-566"></span><span>                  </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SelectDim"><span class="hs-identifier hs-type">SelectDim</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#ByIndex"><span class="hs-identifier hs-type">ByIndex</span></a></span><span> </span><span class="annot"><span class="hs-number">1</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-567"></span><span>                  </span><span class="annot"><a href="#local-6989586621679771086"><span class="hs-identifier hs-type">attentionMaskShape</span></a></span><span>
</span><span id="line-568"></span><span>              </span><span class="hs-special">)</span><span>
</span><span id="line-569"></span><span>          </span><span class="hs-special">)</span><span>
</span><span id="line-570"></span><span>      </span><span class="hs-special">)</span><span>
</span><span id="line-571"></span><span>      </span><span class="annot"><a href="#local-6989586621679771106"><span class="hs-identifier hs-type">dropoutGeneratorOutput</span></a></span><span>
</span><span id="line-572"></span><span>      </span><span class="annot"><a href="#local-6989586621679771085"><span class="hs-identifier hs-type">stackOutput</span></a></span><span>
</span><span id="line-573"></span><span>      </span><span class="annot"><a href="#local-6989586621679771084"><span class="hs-identifier hs-type">stackGeneratorOutput</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-574"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasForward"><span class="hs-identifier hs-type">HasForward</span></a></span><span>
</span><span id="line-575"></span><span>      </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Encoder.html#TELayerNormF"><span class="hs-identifier hs-type">TELayerNormF</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#ByT5"><span class="hs-identifier hs-type">ByT5</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771104"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771103"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771102"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771098"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-576"></span><span>      </span><span class="annot"><a href="#local-6989586621679771085"><span class="hs-identifier hs-type">stackOutput</span></a></span><span>
</span><span id="line-577"></span><span>      </span><span class="annot"><a href="#local-6989586621679771084"><span class="hs-identifier hs-type">stackGeneratorOutput</span></a></span><span>
</span><span id="line-578"></span><span>      </span><span class="annot"><a href="#local-6989586621679771083"><span class="hs-identifier hs-type">layerNormOutput</span></a></span><span>
</span><span id="line-579"></span><span>      </span><span class="annot"><a href="#local-6989586621679771082"><span class="hs-identifier hs-type">layerNormGeneratorOutput</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-580"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasForward"><span class="hs-identifier hs-type">HasForward</span></a></span><span>
</span><span id="line-581"></span><span>      </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Encoder.html#TEDropoutF"><span class="hs-identifier hs-type">TEDropoutF</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#ByT5"><span class="hs-identifier hs-type">ByT5</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771110"><span class="hs-identifier hs-type">dropoutP</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-582"></span><span>      </span><span class="annot"><a href="#local-6989586621679771083"><span class="hs-identifier hs-type">layerNormOutput</span></a></span><span>
</span><span id="line-583"></span><span>      </span><span class="annot"><a href="#local-6989586621679771082"><span class="hs-identifier hs-type">layerNormGeneratorOutput</span></a></span><span>
</span><span id="line-584"></span><span>      </span><span class="annot"><a href="#local-6989586621679771081"><span class="hs-identifier hs-type">output</span></a></span><span>
</span><span id="line-585"></span><span>      </span><span class="annot"><a href="#local-6989586621679771080"><span class="hs-identifier hs-type">generatorOutput</span></a></span><span>
</span><span id="line-586"></span><span>  </span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-587"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasForward"><span class="hs-identifier hs-type">HasForward</span></a></span><span>
</span><span id="line-588"></span><span>    </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Encoder.html#TransformerEncoder"><span class="hs-identifier hs-type">TransformerEncoder</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#ByT5"><span class="hs-identifier hs-type">ByT5</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771105"><span class="hs-identifier hs-type">numLayers</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771104"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771103"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771102"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771101"><span class="hs-identifier hs-type">headDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771100"><span class="hs-identifier hs-type">headEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771099"><span class="hs-identifier hs-type">embedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771098"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771097"><span class="hs-identifier hs-type">ffnDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771088"><span class="hs-identifier hs-type">posEncDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771110"><span class="hs-identifier hs-type">dropoutP</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-589"></span><span>    </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="#local-6989586621679771109"><span class="hs-identifier hs-type">input</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-590"></span><span>      </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771096"><span class="hs-identifier hs-type">relPosGradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771094"><span class="hs-identifier hs-type">relPosLayout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771092"><span class="hs-identifier hs-type">relPosDevice</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771090"><span class="hs-identifier hs-type">relPosDataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771087"><span class="hs-identifier hs-type">relPosShape</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-591"></span><span>      </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771095"><span class="hs-identifier hs-type">attentionMaskGradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771093"><span class="hs-identifier hs-type">attentionMaskLayout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771091"><span class="hs-identifier hs-type">attentionMaskDevice</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771089"><span class="hs-identifier hs-type">attentionMaskDataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771086"><span class="hs-identifier hs-type">attentionMaskShape</span></a></span><span>
</span><span id="line-592"></span><span>    </span><span class="hs-special">)</span><span>
</span><span id="line-593"></span><span>    </span><span class="annot"><a href="#local-6989586621679771108"><span class="hs-identifier hs-type">generator</span></a></span><span>
</span><span id="line-594"></span><span>    </span><span class="annot"><a href="#local-6989586621679771081"><span class="hs-identifier hs-type">output</span></a></span><span>
</span><span id="line-595"></span><span>    </span><span class="annot"><a href="#local-6989586621679771080"><span class="hs-identifier hs-type">generatorOutput</span></a></span><span>
</span><span id="line-596"></span><span>  </span><span class="hs-keyword">where</span><span>
</span><span id="line-597"></span><span>  </span><span id="local-6989586621679771078"><span class="annot"><span class="annottext">forward :: TransformerEncoder
  'ByT5
  numLayers
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  inputEmbedDim
  ffnDim
  posEncDim
  dropoutP
-&gt; (input,
    Tensor
      relPosGradient
      relPosLayout
      relPosDevice
      relPosDataType
      relPosShape,
    Tensor
      attentionMaskGradient
      attentionMaskLayout
      attentionMaskDevice
      attentionMaskDataType
      attentionMaskShape)
-&gt; generator
-&gt; m (output, generatorOutput)
</span><a href="#local-6989586621679771078"><span class="hs-identifier hs-var hs-var hs-var hs-var">forward</span></a></span></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Encoder.html#TransformerEncoder"><span class="hs-identifier hs-type">TransformerEncoder</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Encoder.html#GTransformerEncoder"><span class="hs-identifier hs-type">GTransformerEncoder</span></a></span><span> </span><span class="hs-special">{</span><span id="local-6989586621679771073"><span id="local-6989586621679771074"><span id="local-6989586621679771075"><span id="local-6989586621679771076"><span id="local-6989586621679771077"><span class="annot"><span class="annottext">TEPosEncF
  'ByT5 gradient device dataType headDim inputEmbedDim posEncDim
TEDropoutF 'ByT5 dropoutP
TELayerNormF 'ByT5 gradient device dataType inputEmbedDim
TEEmbedLayerNormF 'ByT5 gradient device dataType inputEmbedDim
TEStackF
  'ByT5
  numLayers
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  inputEmbedDim
  ffnDim
  dropoutP
tePosEnc :: TEPosEncF
  'ByT5 gradient device dataType headDim inputEmbedDim posEncDim
teDropout :: TEDropoutF 'ByT5 dropoutP
teLayerNorm :: TELayerNormF 'ByT5 gradient device dataType inputEmbedDim
teEmbedLayerNorm :: TEEmbedLayerNormF 'ByT5 gradient device dataType inputEmbedDim
teStack :: TEStackF
  'ByT5
  numLayers
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  inputEmbedDim
  ffnDim
  dropoutP
tePosEnc :: forall stack embedLayerNorm layerNorm dropout posEnc.
GTransformerEncoder stack embedLayerNorm layerNorm dropout posEnc
-&gt; posEnc
teDropout :: forall stack embedLayerNorm layerNorm dropout posEnc.
GTransformerEncoder stack embedLayerNorm layerNorm dropout posEnc
-&gt; dropout
teLayerNorm :: forall stack embedLayerNorm layerNorm dropout posEnc.
GTransformerEncoder stack embedLayerNorm layerNorm dropout posEnc
-&gt; layerNorm
teEmbedLayerNorm :: forall stack embedLayerNorm layerNorm dropout posEnc.
GTransformerEncoder stack embedLayerNorm layerNorm dropout posEnc
-&gt; embedLayerNorm
teStack :: forall stack embedLayerNorm layerNorm dropout posEnc.
GTransformerEncoder stack embedLayerNorm layerNorm dropout posEnc
-&gt; stack
</span><a href="#local-6989586621679771073"><span class="hs-glyph hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var">..</span></a></span></span></span></span></span></span><span class="hs-special">}</span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span id="local-6989586621679771072"><span class="annot"><span class="annottext">input
</span><a href="#local-6989586621679771072"><span class="hs-identifier hs-var">input</span></a></span></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679771071"><span class="annot"><span class="annottext">Tensor
  relPosGradient relPosLayout relPosDevice relPosDataType relPosShape
</span><a href="#local-6989586621679771071"><span class="hs-identifier hs-var">relPos</span></a></span></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679771070"><span class="annot"><span class="annottext">Tensor
  attentionMaskGradient
  attentionMaskLayout
  attentionMaskDevice
  attentionMaskDataType
  attentionMaskShape
</span><a href="#local-6989586621679771070"><span class="hs-identifier hs-var">attentionMask</span></a></span></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-598"></span><span>    </span><span class="hs-keyword">let</span><span> </span><span id="local-6989586621679771069"><span class="annot"><span class="annottext">relPosBias :: IxStateT
  m
  dropoutGeneratorOutput
  dropoutGeneratorOutput
  (Tensor
     (Or (Gradient RequiresGradient) gradient relPosGradient)
     (Unify (Layout LayoutType) ('Layout 'Dense) relPosLayout)
     (Unify (Device (DeviceType Nat)) device relPosDevice)
     (Seq
        (Unify (DataType DType) relPosDataType ('DataType 'Int64))
        dataType)
     (TransposeF
        ('SelectDim ('ByIndex 1))
        ('SelectDim ('ByIndex 2))
        (TransposeF
           ('SelectDim ('ByIndex 2))
           ('SelectDim ('ByIndex 3))
           (EmbeddingF ('Shape '[posEncDim, headDim]) relPosShape))))
</span><a href="#local-6989586621679771069"><span class="hs-identifier hs-var hs-var">relPosBias</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-599"></span><span>          </span><span class="annot"><span class="annottext">Tensor
  relPosGradient relPosLayout relPosDevice relPosDataType relPosShape
-&gt; IxStateT
     m
     dropoutGeneratorOutput
     dropoutGeneratorOutput
     (Tensor
        relPosGradient
        relPosLayout
        relPosDevice
        relPosDataType
        relPosShape)
forall k (m :: k -&gt; k -&gt; * -&gt; *) a (i :: k).
IxPointed m =&gt;
a -&gt; m i i a
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-identifier hs-var">ireturn</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor
  relPosGradient relPosLayout relPosDevice relPosDataType relPosShape
</span><a href="#local-6989586621679771071"><span class="hs-identifier hs-var">relPos</span></a></span><span>
</span><span id="line-600"></span><span>            </span><span class="annot"><span class="annottext">IxStateT
  m
  dropoutGeneratorOutput
  dropoutGeneratorOutput
  (Tensor
     relPosGradient
     relPosLayout
     relPosDevice
     relPosDataType
     relPosShape)
-&gt; (Tensor
      relPosGradient relPosLayout relPosDevice relPosDataType relPosShape
    -&gt; IxStateT
         m
         dropoutGeneratorOutput
         dropoutGeneratorOutput
         (Tensor
            (Or (Gradient RequiresGradient) gradient relPosGradient)
            (Unify (Layout LayoutType) ('Layout 'Dense) relPosLayout)
            (Unify (Device (DeviceType Nat)) device relPosDevice)
            (Seq
               (Unify (DataType DType) relPosDataType ('DataType 'Int64))
               dataType)
            (EmbeddingF ('Shape '[posEncDim, headDim]) relPosShape)))
-&gt; IxStateT
     m
     dropoutGeneratorOutput
     dropoutGeneratorOutput
     (Tensor
        (Or (Gradient RequiresGradient) gradient relPosGradient)
        (Unify (Layout LayoutType) ('Layout 'Dense) relPosLayout)
        (Unify (Device (DeviceType Nat)) device relPosDevice)
        (Seq
           (Unify (DataType DType) relPosDataType ('DataType 'Int64))
           dataType)
        (EmbeddingF ('Shape '[posEncDim, headDim]) relPosShape))
forall k1 (m :: k1 -&gt; k1 -&gt; * -&gt; *) (i :: k1) (j :: k1) a
       (k2 :: k1) b.
IxMonad m =&gt;
m i j a -&gt; (a -&gt; m j k2 b) -&gt; m i k2 b
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&gt;&gt;&gt;=</span></a></span><span> </span><span class="annot"><span class="annottext">(dropoutGeneratorOutput
 -&gt; m (Tensor
         (Or (Gradient RequiresGradient) gradient relPosGradient)
         (Unify (Layout LayoutType) ('Layout 'Dense) relPosLayout)
         (Unify (Device (DeviceType Nat)) device relPosDevice)
         (Seq
            (Unify (DataType DType) relPosDataType ('DataType 'Int64))
            dataType)
         (EmbeddingF ('Shape '[posEncDim, headDim]) relPosShape),
       dropoutGeneratorOutput))
-&gt; IxStateT
     m
     dropoutGeneratorOutput
     dropoutGeneratorOutput
     (Tensor
        (Or (Gradient RequiresGradient) gradient relPosGradient)
        (Unify (Layout LayoutType) ('Layout 'Dense) relPosLayout)
        (Unify (Device (DeviceType Nat)) device relPosDevice)
        (Seq
           (Unify (DataType DType) relPosDataType ('DataType 'Int64))
           dataType)
        (EmbeddingF ('Shape '[posEncDim, headDim]) relPosShape))
forall (m :: * -&gt; *) i j a. (i -&gt; m (a, j)) -&gt; IxStateT m i j a
</span><a href="../file:///nix/store/8vjaffqxij7bih93d9mlzmc7ksanlw0i-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier hs-var">IxStateT</span></a></span><span> </span><span class="annot"><span class="annottext">((dropoutGeneratorOutput
  -&gt; m (Tensor
          (Or (Gradient RequiresGradient) gradient relPosGradient)
          (Unify (Layout LayoutType) ('Layout 'Dense) relPosLayout)
          (Unify (Device (DeviceType Nat)) device relPosDevice)
          (Seq
             (Unify (DataType DType) relPosDataType ('DataType 'Int64))
             dataType)
          (EmbeddingF ('Shape '[posEncDim, headDim]) relPosShape),
        dropoutGeneratorOutput))
 -&gt; IxStateT
      m
      dropoutGeneratorOutput
      dropoutGeneratorOutput
      (Tensor
         (Or (Gradient RequiresGradient) gradient relPosGradient)
         (Unify (Layout LayoutType) ('Layout 'Dense) relPosLayout)
         (Unify (Device (DeviceType Nat)) device relPosDevice)
         (Seq
            (Unify (DataType DType) relPosDataType ('DataType 'Int64))
            dataType)
         (EmbeddingF ('Shape '[posEncDim, headDim]) relPosShape)))
-&gt; (Tensor
      relPosGradient relPosLayout relPosDevice relPosDataType relPosShape
    -&gt; dropoutGeneratorOutput
    -&gt; m (Tensor
            (Or (Gradient RequiresGradient) gradient relPosGradient)
            (Unify (Layout LayoutType) ('Layout 'Dense) relPosLayout)
            (Unify (Device (DeviceType Nat)) device relPosDevice)
            (Seq
               (Unify (DataType DType) relPosDataType ('DataType 'Int64))
               dataType)
            (EmbeddingF ('Shape '[posEncDim, headDim]) relPosShape),
          dropoutGeneratorOutput))
-&gt; Tensor
     relPosGradient relPosLayout relPosDevice relPosDataType relPosShape
-&gt; IxStateT
     m
     dropoutGeneratorOutput
     dropoutGeneratorOutput
     (Tensor
        (Or (Gradient RequiresGradient) gradient relPosGradient)
        (Unify (Layout LayoutType) ('Layout 'Dense) relPosLayout)
        (Unify (Device (DeviceType Nat)) device relPosDevice)
        (Seq
           (Unify (DataType DType) relPosDataType ('DataType 'Int64))
           dataType)
        (EmbeddingF ('Shape '[posEncDim, headDim]) relPosShape))
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">Embedding
  gradient
  ('Layout 'Dense)
  device
  dataType
  posEncDim
  headDim
  'Nothing
-&gt; Tensor
     relPosGradient relPosLayout relPosDevice relPosDataType relPosShape
-&gt; dropoutGeneratorOutput
-&gt; m (Tensor
        (Or (Gradient RequiresGradient) gradient relPosGradient)
        (Unify (Layout LayoutType) ('Layout 'Dense) relPosLayout)
        (Unify (Device (DeviceType Nat)) device relPosDevice)
        (Seq
           (Unify (DataType DType) relPosDataType ('DataType 'Int64))
           dataType)
        (EmbeddingF ('Shape '[posEncDim, headDim]) relPosShape),
      dropoutGeneratorOutput)
forall model input generator output generatorOutput (m :: * -&gt; *).
(HasForward model input generator output generatorOutput,
 MonadThrow m) =&gt;
model -&gt; input -&gt; generator -&gt; m (output, generatorOutput)
</span><a href="Torch.GraduallyTyped.NN.Class.html#forward"><span class="hs-identifier hs-var">forward</span></a></span><span> </span><span class="annot"><span class="annottext">Embedding
  gradient
  ('Layout 'Dense)
  device
  dataType
  posEncDim
  headDim
  'Nothing
TEPosEncF
  'ByT5 gradient device dataType headDim inputEmbedDim posEncDim
</span><a href="#local-6989586621679771073"><span class="hs-identifier hs-var">tePosEnc</span></a></span><span>
</span><span id="line-601"></span><span>            </span><span class="annot"><span class="annottext">IxStateT
  m
  dropoutGeneratorOutput
  dropoutGeneratorOutput
  (Tensor
     (Or (Gradient RequiresGradient) gradient relPosGradient)
     (Unify (Layout LayoutType) ('Layout 'Dense) relPosLayout)
     (Unify (Device (DeviceType Nat)) device relPosDevice)
     (Seq
        (Unify (DataType DType) relPosDataType ('DataType 'Int64))
        dataType)
     (EmbeddingF ('Shape '[posEncDim, headDim]) relPosShape))
-&gt; (Tensor
      (Or (Gradient RequiresGradient) gradient relPosGradient)
      (Unify (Layout LayoutType) ('Layout 'Dense) relPosLayout)
      (Unify (Device (DeviceType Nat)) device relPosDevice)
      (Seq
         (Unify (DataType DType) relPosDataType ('DataType 'Int64))
         dataType)
      (EmbeddingF ('Shape '[posEncDim, headDim]) relPosShape)
    -&gt; IxStateT
         m
         dropoutGeneratorOutput
         dropoutGeneratorOutput
         (Tensor
            (Or (Gradient RequiresGradient) gradient relPosGradient)
            (Unify (Layout LayoutType) ('Layout 'Dense) relPosLayout)
            (Unify (Device (DeviceType Nat)) device relPosDevice)
            (Seq
               (Unify (DataType DType) relPosDataType ('DataType 'Int64))
               dataType)
            (TransposeF
               ('SelectDim ('ByIndex 2))
               ('SelectDim ('ByIndex 3))
               (EmbeddingF ('Shape '[posEncDim, headDim]) relPosShape))))
-&gt; IxStateT
     m
     dropoutGeneratorOutput
     dropoutGeneratorOutput
     (Tensor
        (Or (Gradient RequiresGradient) gradient relPosGradient)
        (Unify (Layout LayoutType) ('Layout 'Dense) relPosLayout)
        (Unify (Device (DeviceType Nat)) device relPosDevice)
        (Seq
           (Unify (DataType DType) relPosDataType ('DataType 'Int64))
           dataType)
        (TransposeF
           ('SelectDim ('ByIndex 2))
           ('SelectDim ('ByIndex 3))
           (EmbeddingF ('Shape '[posEncDim, headDim]) relPosShape)))
forall k1 (m :: k1 -&gt; k1 -&gt; * -&gt; *) (i :: k1) (j :: k1) a
       (k2 :: k1) b.
IxMonad m =&gt;
m i j a -&gt; (a -&gt; m j k2 b) -&gt; m i k2 b
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&gt;&gt;&gt;=</span></a></span><span> </span><span class="annot"><span class="annottext">m (Tensor
     (Or (Gradient RequiresGradient) gradient relPosGradient)
     (Unify (Layout LayoutType) ('Layout 'Dense) relPosLayout)
     (Unify (Device (DeviceType Nat)) device relPosDevice)
     (Seq
        (Unify (DataType DType) relPosDataType ('DataType 'Int64))
        dataType)
     (TransposeF
        ('SelectDim ('ByIndex 2))
        ('SelectDim ('ByIndex 3))
        (EmbeddingF ('Shape '[posEncDim, headDim]) relPosShape)))
-&gt; IxStateT
     m
     dropoutGeneratorOutput
     dropoutGeneratorOutput
     (Tensor
        (Or (Gradient RequiresGradient) gradient relPosGradient)
        (Unify (Layout LayoutType) ('Layout 'Dense) relPosLayout)
        (Unify (Device (DeviceType Nat)) device relPosDevice)
        (Seq
           (Unify (DataType DType) relPosDataType ('DataType 'Int64))
           dataType)
        (TransposeF
           ('SelectDim ('ByIndex 2))
           ('SelectDim ('ByIndex 3))
           (EmbeddingF ('Shape '[posEncDim, headDim]) relPosShape)))
forall k (t :: (* -&gt; *) -&gt; k -&gt; k -&gt; * -&gt; *) (m :: * -&gt; *) a
       (i :: k).
(IxMonadTrans t, Monad m) =&gt;
m a -&gt; t m i i a
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-identifier hs-var">ilift</span></a></span><span> </span><span class="annot"><span class="annottext">(m (Tensor
      (Or (Gradient RequiresGradient) gradient relPosGradient)
      (Unify (Layout LayoutType) ('Layout 'Dense) relPosLayout)
      (Unify (Device (DeviceType Nat)) device relPosDevice)
      (Seq
         (Unify (DataType DType) relPosDataType ('DataType 'Int64))
         dataType)
      (TransposeF
         ('SelectDim ('ByIndex 2))
         ('SelectDim ('ByIndex 3))
         (EmbeddingF ('Shape '[posEncDim, headDim]) relPosShape)))
 -&gt; IxStateT
      m
      dropoutGeneratorOutput
      dropoutGeneratorOutput
      (Tensor
         (Or (Gradient RequiresGradient) gradient relPosGradient)
         (Unify (Layout LayoutType) ('Layout 'Dense) relPosLayout)
         (Unify (Device (DeviceType Nat)) device relPosDevice)
         (Seq
            (Unify (DataType DType) relPosDataType ('DataType 'Int64))
            dataType)
         (TransposeF
            ('SelectDim ('ByIndex 2))
            ('SelectDim ('ByIndex 3))
            (EmbeddingF ('Shape '[posEncDim, headDim]) relPosShape))))
-&gt; (Tensor
      (Or (Gradient RequiresGradient) gradient relPosGradient)
      (Unify (Layout LayoutType) ('Layout 'Dense) relPosLayout)
      (Unify (Device (DeviceType Nat)) device relPosDevice)
      (Seq
         (Unify (DataType DType) relPosDataType ('DataType 'Int64))
         dataType)
      (EmbeddingF ('Shape '[posEncDim, headDim]) relPosShape)
    -&gt; m (Tensor
            (Or (Gradient RequiresGradient) gradient relPosGradient)
            (Unify (Layout LayoutType) ('Layout 'Dense) relPosLayout)
            (Unify (Device (DeviceType Nat)) device relPosDevice)
            (Seq
               (Unify (DataType DType) relPosDataType ('DataType 'Int64))
               dataType)
            (TransposeF
               ('SelectDim ('ByIndex 2))
               ('SelectDim ('ByIndex 3))
               (EmbeddingF ('Shape '[posEncDim, headDim]) relPosShape))))
-&gt; Tensor
     (Or (Gradient RequiresGradient) gradient relPosGradient)
     (Unify (Layout LayoutType) ('Layout 'Dense) relPosLayout)
     (Unify (Device (DeviceType Nat)) device relPosDevice)
     (Seq
        (Unify (DataType DType) relPosDataType ('DataType 'Int64))
        dataType)
     (EmbeddingF ('Shape '[posEncDim, headDim]) relPosShape)
-&gt; IxStateT
     m
     dropoutGeneratorOutput
     dropoutGeneratorOutput
     (Tensor
        (Or (Gradient RequiresGradient) gradient relPosGradient)
        (Unify (Layout LayoutType) ('Layout 'Dense) relPosLayout)
        (Unify (Device (DeviceType Nat)) device relPosDevice)
        (Seq
           (Unify (DataType DType) relPosDataType ('DataType 'Int64))
           dataType)
        (TransposeF
           ('SelectDim ('ByIndex 2))
           ('SelectDim ('ByIndex 3))
           (EmbeddingF ('Shape '[posEncDim, headDim]) relPosShape)))
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">forall (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)])
       (shape' :: Shape [Dim (Name Symbol) (Size Nat)]) (m :: * -&gt; *).
(shape'
 ~ TransposeF
     ('SelectDim ('ByIndex 2)) ('SelectDim ('ByIndex 3)) shape,
 SingI ('SelectDim ('ByIndex 2)), SingI ('SelectDim ('ByIndex 3)),
 MonadThrow m) =&gt;
Tensor gradient layout device dataType shape
-&gt; m (Tensor gradient layout device dataType shape')
forall (selectDim0 :: SelectDim (By Symbol Nat))
       (selectDim1 :: SelectDim (By Symbol Nat))
       (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)])
       (shape' :: Shape [Dim (Name Symbol) (Size Nat)]) (m :: * -&gt; *).
(shape' ~ TransposeF selectDim0 selectDim1 shape, SingI selectDim0,
 SingI selectDim1, MonadThrow m) =&gt;
Tensor gradient layout device dataType shape
-&gt; m (Tensor gradient layout device dataType shape')
</span><a href="Torch.GraduallyTyped.Tensor.IndexingSlicingJoining.html#transpose"><span class="hs-identifier hs-var">transpose</span></a></span><span> </span><span class="hs-glyph">@</span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SelectDim"><span class="hs-identifier hs-type">SelectDim</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#ByIndex"><span class="hs-identifier hs-type">ByIndex</span></a></span><span> </span><span class="annot"><span class="hs-number">2</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span> </span><span class="hs-glyph">@</span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SelectDim"><span class="hs-identifier hs-type">SelectDim</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#ByIndex"><span class="hs-identifier hs-type">ByIndex</span></a></span><span> </span><span class="annot"><span class="hs-number">3</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-602"></span><span>            </span><span class="annot"><span class="annottext">IxStateT
  m
  dropoutGeneratorOutput
  dropoutGeneratorOutput
  (Tensor
     (Or (Gradient RequiresGradient) gradient relPosGradient)
     (Unify (Layout LayoutType) ('Layout 'Dense) relPosLayout)
     (Unify (Device (DeviceType Nat)) device relPosDevice)
     (Seq
        (Unify (DataType DType) relPosDataType ('DataType 'Int64))
        dataType)
     (TransposeF
        ('SelectDim ('ByIndex 2))
        ('SelectDim ('ByIndex 3))
        (EmbeddingF ('Shape '[posEncDim, headDim]) relPosShape)))
-&gt; (Tensor
      (Or (Gradient RequiresGradient) gradient relPosGradient)
      (Unify (Layout LayoutType) ('Layout 'Dense) relPosLayout)
      (Unify (Device (DeviceType Nat)) device relPosDevice)
      (Seq
         (Unify (DataType DType) relPosDataType ('DataType 'Int64))
         dataType)
      (TransposeF
         ('SelectDim ('ByIndex 2))
         ('SelectDim ('ByIndex 3))
         (EmbeddingF ('Shape '[posEncDim, headDim]) relPosShape))
    -&gt; IxStateT
         m
         dropoutGeneratorOutput
         dropoutGeneratorOutput
         (Tensor
            (Or (Gradient RequiresGradient) gradient relPosGradient)
            (Unify (Layout LayoutType) ('Layout 'Dense) relPosLayout)
            (Unify (Device (DeviceType Nat)) device relPosDevice)
            (Seq
               (Unify (DataType DType) relPosDataType ('DataType 'Int64))
               dataType)
            (TransposeF
               ('SelectDim ('ByIndex 1))
               ('SelectDim ('ByIndex 2))
               (TransposeF
                  ('SelectDim ('ByIndex 2))
                  ('SelectDim ('ByIndex 3))
                  (EmbeddingF ('Shape '[posEncDim, headDim]) relPosShape)))))
-&gt; IxStateT
     m
     dropoutGeneratorOutput
     dropoutGeneratorOutput
     (Tensor
        (Or (Gradient RequiresGradient) gradient relPosGradient)
        (Unify (Layout LayoutType) ('Layout 'Dense) relPosLayout)
        (Unify (Device (DeviceType Nat)) device relPosDevice)
        (Seq
           (Unify (DataType DType) relPosDataType ('DataType 'Int64))
           dataType)
        (TransposeF
           ('SelectDim ('ByIndex 1))
           ('SelectDim ('ByIndex 2))
           (TransposeF
              ('SelectDim ('ByIndex 2))
              ('SelectDim ('ByIndex 3))
              (EmbeddingF ('Shape '[posEncDim, headDim]) relPosShape))))
forall k1 (m :: k1 -&gt; k1 -&gt; * -&gt; *) (i :: k1) (j :: k1) a
       (k2 :: k1) b.
IxMonad m =&gt;
m i j a -&gt; (a -&gt; m j k2 b) -&gt; m i k2 b
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&gt;&gt;&gt;=</span></a></span><span> </span><span class="annot"><span class="annottext">m (Tensor
     (Or (Gradient RequiresGradient) gradient relPosGradient)
     (Unify (Layout LayoutType) ('Layout 'Dense) relPosLayout)
     (Unify (Device (DeviceType Nat)) device relPosDevice)
     (Seq
        (Unify (DataType DType) relPosDataType ('DataType 'Int64))
        dataType)
     (TransposeF
        ('SelectDim ('ByIndex 1))
        ('SelectDim ('ByIndex 2))
        (TransposeF
           ('SelectDim ('ByIndex 2))
           ('SelectDim ('ByIndex 3))
           (EmbeddingF ('Shape '[posEncDim, headDim]) relPosShape))))
-&gt; IxStateT
     m
     dropoutGeneratorOutput
     dropoutGeneratorOutput
     (Tensor
        (Or (Gradient RequiresGradient) gradient relPosGradient)
        (Unify (Layout LayoutType) ('Layout 'Dense) relPosLayout)
        (Unify (Device (DeviceType Nat)) device relPosDevice)
        (Seq
           (Unify (DataType DType) relPosDataType ('DataType 'Int64))
           dataType)
        (TransposeF
           ('SelectDim ('ByIndex 1))
           ('SelectDim ('ByIndex 2))
           (TransposeF
              ('SelectDim ('ByIndex 2))
              ('SelectDim ('ByIndex 3))
              (EmbeddingF ('Shape '[posEncDim, headDim]) relPosShape))))
forall k (t :: (* -&gt; *) -&gt; k -&gt; k -&gt; * -&gt; *) (m :: * -&gt; *) a
       (i :: k).
(IxMonadTrans t, Monad m) =&gt;
m a -&gt; t m i i a
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-identifier hs-var">ilift</span></a></span><span> </span><span class="annot"><span class="annottext">(m (Tensor
      (Or (Gradient RequiresGradient) gradient relPosGradient)
      (Unify (Layout LayoutType) ('Layout 'Dense) relPosLayout)
      (Unify (Device (DeviceType Nat)) device relPosDevice)
      (Seq
         (Unify (DataType DType) relPosDataType ('DataType 'Int64))
         dataType)
      (TransposeF
         ('SelectDim ('ByIndex 1))
         ('SelectDim ('ByIndex 2))
         (TransposeF
            ('SelectDim ('ByIndex 2))
            ('SelectDim ('ByIndex 3))
            (EmbeddingF ('Shape '[posEncDim, headDim]) relPosShape))))
 -&gt; IxStateT
      m
      dropoutGeneratorOutput
      dropoutGeneratorOutput
      (Tensor
         (Or (Gradient RequiresGradient) gradient relPosGradient)
         (Unify (Layout LayoutType) ('Layout 'Dense) relPosLayout)
         (Unify (Device (DeviceType Nat)) device relPosDevice)
         (Seq
            (Unify (DataType DType) relPosDataType ('DataType 'Int64))
            dataType)
         (TransposeF
            ('SelectDim ('ByIndex 1))
            ('SelectDim ('ByIndex 2))
            (TransposeF
               ('SelectDim ('ByIndex 2))
               ('SelectDim ('ByIndex 3))
               (EmbeddingF ('Shape '[posEncDim, headDim]) relPosShape)))))
-&gt; (Tensor
      (Or (Gradient RequiresGradient) gradient relPosGradient)
      (Unify (Layout LayoutType) ('Layout 'Dense) relPosLayout)
      (Unify (Device (DeviceType Nat)) device relPosDevice)
      (Seq
         (Unify (DataType DType) relPosDataType ('DataType 'Int64))
         dataType)
      (TransposeF
         ('SelectDim ('ByIndex 2))
         ('SelectDim ('ByIndex 3))
         (EmbeddingF ('Shape '[posEncDim, headDim]) relPosShape))
    -&gt; m (Tensor
            (Or (Gradient RequiresGradient) gradient relPosGradient)
            (Unify (Layout LayoutType) ('Layout 'Dense) relPosLayout)
            (Unify (Device (DeviceType Nat)) device relPosDevice)
            (Seq
               (Unify (DataType DType) relPosDataType ('DataType 'Int64))
               dataType)
            (TransposeF
               ('SelectDim ('ByIndex 1))
               ('SelectDim ('ByIndex 2))
               (TransposeF
                  ('SelectDim ('ByIndex 2))
                  ('SelectDim ('ByIndex 3))
                  (EmbeddingF ('Shape '[posEncDim, headDim]) relPosShape)))))
-&gt; Tensor
     (Or (Gradient RequiresGradient) gradient relPosGradient)
     (Unify (Layout LayoutType) ('Layout 'Dense) relPosLayout)
     (Unify (Device (DeviceType Nat)) device relPosDevice)
     (Seq
        (Unify (DataType DType) relPosDataType ('DataType 'Int64))
        dataType)
     (TransposeF
        ('SelectDim ('ByIndex 2))
        ('SelectDim ('ByIndex 3))
        (EmbeddingF ('Shape '[posEncDim, headDim]) relPosShape))
-&gt; IxStateT
     m
     dropoutGeneratorOutput
     dropoutGeneratorOutput
     (Tensor
        (Or (Gradient RequiresGradient) gradient relPosGradient)
        (Unify (Layout LayoutType) ('Layout 'Dense) relPosLayout)
        (Unify (Device (DeviceType Nat)) device relPosDevice)
        (Seq
           (Unify (DataType DType) relPosDataType ('DataType 'Int64))
           dataType)
        (TransposeF
           ('SelectDim ('ByIndex 1))
           ('SelectDim ('ByIndex 2))
           (TransposeF
              ('SelectDim ('ByIndex 2))
              ('SelectDim ('ByIndex 3))
              (EmbeddingF ('Shape '[posEncDim, headDim]) relPosShape))))
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">forall (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)])
       (shape' :: Shape [Dim (Name Symbol) (Size Nat)]) (m :: * -&gt; *).
(shape'
 ~ TransposeF
     ('SelectDim ('ByIndex 1)) ('SelectDim ('ByIndex 2)) shape,
 SingI ('SelectDim ('ByIndex 1)), SingI ('SelectDim ('ByIndex 2)),
 MonadThrow m) =&gt;
Tensor gradient layout device dataType shape
-&gt; m (Tensor gradient layout device dataType shape')
forall (selectDim0 :: SelectDim (By Symbol Nat))
       (selectDim1 :: SelectDim (By Symbol Nat))
       (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)])
       (shape' :: Shape [Dim (Name Symbol) (Size Nat)]) (m :: * -&gt; *).
(shape' ~ TransposeF selectDim0 selectDim1 shape, SingI selectDim0,
 SingI selectDim1, MonadThrow m) =&gt;
Tensor gradient layout device dataType shape
-&gt; m (Tensor gradient layout device dataType shape')
</span><a href="Torch.GraduallyTyped.Tensor.IndexingSlicingJoining.html#transpose"><span class="hs-identifier hs-var">transpose</span></a></span><span> </span><span class="hs-glyph">@</span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SelectDim"><span class="hs-identifier hs-type">SelectDim</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#ByIndex"><span class="hs-identifier hs-type">ByIndex</span></a></span><span> </span><span class="annot"><span class="hs-number">1</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span> </span><span class="hs-glyph">@</span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SelectDim"><span class="hs-identifier hs-type">SelectDim</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#ByIndex"><span class="hs-identifier hs-type">ByIndex</span></a></span><span> </span><span class="annot"><span class="hs-number">2</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-603"></span><span>        </span><span id="local-6989586621679771068"><span class="annot"><span class="annottext">attentionBias :: IxStateT
  m
  dropoutGeneratorOutput
  dropoutGeneratorOutput
  (Tensor
     (Or
        (Gradient RequiresGradient)
        (Or (Gradient RequiresGradient) gradient relPosGradient)
        attentionMaskGradient)
     (Unify
        (Layout LayoutType)
        (Unify (Layout LayoutType) ('Layout 'Dense) relPosLayout)
        attentionMaskLayout)
     (Unify
        (Device (DeviceType Nat))
        (Unify (Device (DeviceType Nat)) device relPosDevice)
        attentionMaskDevice)
     (Unify
        (DataType DType)
        (Seq
           (Unify (DataType DType) relPosDataType ('DataType 'Int64))
           dataType)
        attentionMaskDataType)
     (BroadcastShapesF
        (TransposeF
           ('SelectDim ('ByIndex 1))
           ('SelectDim ('ByIndex 2))
           (TransposeF
              ('SelectDim ('ByIndex 2))
              ('SelectDim ('ByIndex 3))
              (EmbeddingF ('Shape '[posEncDim, headDim]) relPosShape)))
        (UnsqueezeF ('SelectDim ('ByIndex 1)) attentionMaskShape)))
</span><a href="#local-6989586621679771068"><span class="hs-identifier hs-var hs-var">attentionBias</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-604"></span><span>          </span><span class="annot"><span class="annottext">IxStateT
  m
  dropoutGeneratorOutput
  dropoutGeneratorOutput
  (Tensor
     (Or (Gradient RequiresGradient) gradient relPosGradient)
     (Unify (Layout LayoutType) ('Layout 'Dense) relPosLayout)
     (Unify (Device (DeviceType Nat)) device relPosDevice)
     (Seq
        (Unify (DataType DType) relPosDataType ('DataType 'Int64))
        dataType)
     (TransposeF
        ('SelectDim ('ByIndex 1))
        ('SelectDim ('ByIndex 2))
        (TransposeF
           ('SelectDim ('ByIndex 2))
           ('SelectDim ('ByIndex 3))
           (EmbeddingF ('Shape '[posEncDim, headDim]) relPosShape))))
</span><a href="#local-6989586621679771069"><span class="hs-identifier hs-var">relPosBias</span></a></span><span>
</span><span id="line-605"></span><span>            </span><span class="annot"><span class="annottext">IxStateT
  m
  dropoutGeneratorOutput
  dropoutGeneratorOutput
  (Tensor
     (Or (Gradient RequiresGradient) gradient relPosGradient)
     (Unify (Layout LayoutType) ('Layout 'Dense) relPosLayout)
     (Unify (Device (DeviceType Nat)) device relPosDevice)
     (Seq
        (Unify (DataType DType) relPosDataType ('DataType 'Int64))
        dataType)
     (TransposeF
        ('SelectDim ('ByIndex 1))
        ('SelectDim ('ByIndex 2))
        (TransposeF
           ('SelectDim ('ByIndex 2))
           ('SelectDim ('ByIndex 3))
           (EmbeddingF ('Shape '[posEncDim, headDim]) relPosShape))))
-&gt; (Tensor
      (Or (Gradient RequiresGradient) gradient relPosGradient)
      (Unify (Layout LayoutType) ('Layout 'Dense) relPosLayout)
      (Unify (Device (DeviceType Nat)) device relPosDevice)
      (Seq
         (Unify (DataType DType) relPosDataType ('DataType 'Int64))
         dataType)
      (TransposeF
         ('SelectDim ('ByIndex 1))
         ('SelectDim ('ByIndex 2))
         (TransposeF
            ('SelectDim ('ByIndex 2))
            ('SelectDim ('ByIndex 3))
            (EmbeddingF ('Shape '[posEncDim, headDim]) relPosShape)))
    -&gt; IxStateT
         m
         dropoutGeneratorOutput
         dropoutGeneratorOutput
         (Tensor
            (Or
               (Gradient RequiresGradient)
               (Or (Gradient RequiresGradient) gradient relPosGradient)
               attentionMaskGradient)
            (Unify
               (Layout LayoutType)
               (Unify (Layout LayoutType) ('Layout 'Dense) relPosLayout)
               attentionMaskLayout)
            (Unify
               (Device (DeviceType Nat))
               (Unify (Device (DeviceType Nat)) device relPosDevice)
               attentionMaskDevice)
            (Unify
               (DataType DType)
               (Seq
                  (Unify (DataType DType) relPosDataType ('DataType 'Int64))
                  dataType)
               attentionMaskDataType)
            (BroadcastShapesF
               (TransposeF
                  ('SelectDim ('ByIndex 1))
                  ('SelectDim ('ByIndex 2))
                  (TransposeF
                     ('SelectDim ('ByIndex 2))
                     ('SelectDim ('ByIndex 3))
                     (EmbeddingF ('Shape '[posEncDim, headDim]) relPosShape)))
               (UnsqueezeF ('SelectDim ('ByIndex 1)) attentionMaskShape))))
-&gt; IxStateT
     m
     dropoutGeneratorOutput
     dropoutGeneratorOutput
     (Tensor
        (Or
           (Gradient RequiresGradient)
           (Or (Gradient RequiresGradient) gradient relPosGradient)
           attentionMaskGradient)
        (Unify
           (Layout LayoutType)
           (Unify (Layout LayoutType) ('Layout 'Dense) relPosLayout)
           attentionMaskLayout)
        (Unify
           (Device (DeviceType Nat))
           (Unify (Device (DeviceType Nat)) device relPosDevice)
           attentionMaskDevice)
        (Unify
           (DataType DType)
           (Seq
              (Unify (DataType DType) relPosDataType ('DataType 'Int64))
              dataType)
           attentionMaskDataType)
        (BroadcastShapesF
           (TransposeF
              ('SelectDim ('ByIndex 1))
              ('SelectDim ('ByIndex 2))
              (TransposeF
                 ('SelectDim ('ByIndex 2))
                 ('SelectDim ('ByIndex 3))
                 (EmbeddingF ('Shape '[posEncDim, headDim]) relPosShape)))
           (UnsqueezeF ('SelectDim ('ByIndex 1)) attentionMaskShape)))
forall k1 (m :: k1 -&gt; k1 -&gt; * -&gt; *) (i :: k1) (j :: k1) a
       (k2 :: k1) b.
IxMonad m =&gt;
m i j a -&gt; (a -&gt; m j k2 b) -&gt; m i k2 b
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&gt;&gt;&gt;=</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor
  (Or
     (Gradient RequiresGradient)
     (Or (Gradient RequiresGradient) gradient relPosGradient)
     attentionMaskGradient)
  (Unify
     (Layout LayoutType)
     (Unify (Layout LayoutType) ('Layout 'Dense) relPosLayout)
     attentionMaskLayout)
  (Unify
     (Device (DeviceType Nat))
     (Unify (Device (DeviceType Nat)) device relPosDevice)
     attentionMaskDevice)
  (Unify
     (DataType DType)
     (Seq
        (Unify (DataType DType) relPosDataType ('DataType 'Int64))
        dataType)
     attentionMaskDataType)
  (BroadcastShapesF
     (TransposeF
        ('SelectDim ('ByIndex 1))
        ('SelectDim ('ByIndex 2))
        (TransposeF
           ('SelectDim ('ByIndex 2))
           ('SelectDim ('ByIndex 3))
           (EmbeddingF ('Shape '[posEncDim, headDim]) relPosShape)))
     (UnsqueezeF ('SelectDim ('ByIndex 1)) attentionMaskShape))
-&gt; IxStateT
     m
     dropoutGeneratorOutput
     dropoutGeneratorOutput
     (Tensor
        (Or
           (Gradient RequiresGradient)
           (Or (Gradient RequiresGradient) gradient relPosGradient)
           attentionMaskGradient)
        (Unify
           (Layout LayoutType)
           (Unify (Layout LayoutType) ('Layout 'Dense) relPosLayout)
           attentionMaskLayout)
        (Unify
           (Device (DeviceType Nat))
           (Unify (Device (DeviceType Nat)) device relPosDevice)
           attentionMaskDevice)
        (Unify
           (DataType DType)
           (Seq
              (Unify (DataType DType) relPosDataType ('DataType 'Int64))
              dataType)
           attentionMaskDataType)
        (BroadcastShapesF
           (TransposeF
              ('SelectDim ('ByIndex 1))
              ('SelectDim ('ByIndex 2))
              (TransposeF
                 ('SelectDim ('ByIndex 2))
                 ('SelectDim ('ByIndex 3))
                 (EmbeddingF ('Shape '[posEncDim, headDim]) relPosShape)))
           (UnsqueezeF ('SelectDim ('ByIndex 1)) attentionMaskShape)))
forall k (m :: k -&gt; k -&gt; * -&gt; *) a (i :: k).
IxPointed m =&gt;
a -&gt; m i i a
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-identifier hs-var">ireturn</span></a></span><span> </span><span class="annot"><span class="annottext">(Tensor
   (Or
      (Gradient RequiresGradient)
      (Or (Gradient RequiresGradient) gradient relPosGradient)
      attentionMaskGradient)
   (Unify
      (Layout LayoutType)
      (Unify (Layout LayoutType) ('Layout 'Dense) relPosLayout)
      attentionMaskLayout)
   (Unify
      (Device (DeviceType Nat))
      (Unify (Device (DeviceType Nat)) device relPosDevice)
      attentionMaskDevice)
   (Unify
      (DataType DType)
      (Seq
         (Unify (DataType DType) relPosDataType ('DataType 'Int64))
         dataType)
      attentionMaskDataType)
   (BroadcastShapesF
      (TransposeF
         ('SelectDim ('ByIndex 1))
         ('SelectDim ('ByIndex 2))
         (TransposeF
            ('SelectDim ('ByIndex 2))
            ('SelectDim ('ByIndex 3))
            (EmbeddingF ('Shape '[posEncDim, headDim]) relPosShape)))
      (UnsqueezeF ('SelectDim ('ByIndex 1)) attentionMaskShape))
 -&gt; IxStateT
      m
      dropoutGeneratorOutput
      dropoutGeneratorOutput
      (Tensor
         (Or
            (Gradient RequiresGradient)
            (Or (Gradient RequiresGradient) gradient relPosGradient)
            attentionMaskGradient)
         (Unify
            (Layout LayoutType)
            (Unify (Layout LayoutType) ('Layout 'Dense) relPosLayout)
            attentionMaskLayout)
         (Unify
            (Device (DeviceType Nat))
            (Unify (Device (DeviceType Nat)) device relPosDevice)
            attentionMaskDevice)
         (Unify
            (DataType DType)
            (Seq
               (Unify (DataType DType) relPosDataType ('DataType 'Int64))
               dataType)
            attentionMaskDataType)
         (BroadcastShapesF
            (TransposeF
               ('SelectDim ('ByIndex 1))
               ('SelectDim ('ByIndex 2))
               (TransposeF
                  ('SelectDim ('ByIndex 2))
                  ('SelectDim ('ByIndex 3))
                  (EmbeddingF ('Shape '[posEncDim, headDim]) relPosShape)))
            (UnsqueezeF ('SelectDim ('ByIndex 1)) attentionMaskShape))))
-&gt; (Tensor
      (Or (Gradient RequiresGradient) gradient relPosGradient)
      (Unify (Layout LayoutType) ('Layout 'Dense) relPosLayout)
      (Unify (Device (DeviceType Nat)) device relPosDevice)
      (Seq
         (Unify (DataType DType) relPosDataType ('DataType 'Int64))
         dataType)
      (TransposeF
         ('SelectDim ('ByIndex 1))
         ('SelectDim ('ByIndex 2))
         (TransposeF
            ('SelectDim ('ByIndex 2))
            ('SelectDim ('ByIndex 3))
            (EmbeddingF ('Shape '[posEncDim, headDim]) relPosShape)))
    -&gt; Tensor
         (Or
            (Gradient RequiresGradient)
            (Or (Gradient RequiresGradient) gradient relPosGradient)
            attentionMaskGradient)
         (Unify
            (Layout LayoutType)
            (Unify (Layout LayoutType) ('Layout 'Dense) relPosLayout)
            attentionMaskLayout)
         (Unify
            (Device (DeviceType Nat))
            (Unify (Device (DeviceType Nat)) device relPosDevice)
            attentionMaskDevice)
         (Unify
            (DataType DType)
            (Seq
               (Unify (DataType DType) relPosDataType ('DataType 'Int64))
               dataType)
            attentionMaskDataType)
         (BroadcastShapesF
            (TransposeF
               ('SelectDim ('ByIndex 1))
               ('SelectDim ('ByIndex 2))
               (TransposeF
                  ('SelectDim ('ByIndex 2))
                  ('SelectDim ('ByIndex 3))
                  (EmbeddingF ('Shape '[posEncDim, headDim]) relPosShape)))
            (UnsqueezeF ('SelectDim ('ByIndex 1)) attentionMaskShape)))
-&gt; Tensor
     (Or (Gradient RequiresGradient) gradient relPosGradient)
     (Unify (Layout LayoutType) ('Layout 'Dense) relPosLayout)
     (Unify (Device (DeviceType Nat)) device relPosDevice)
     (Seq
        (Unify (DataType DType) relPosDataType ('DataType 'Int64))
        dataType)
     (TransposeF
        ('SelectDim ('ByIndex 1))
        ('SelectDim ('ByIndex 2))
        (TransposeF
           ('SelectDim ('ByIndex 2))
           ('SelectDim ('ByIndex 3))
           (EmbeddingF ('Shape '[posEncDim, headDim]) relPosShape)))
-&gt; IxStateT
     m
     dropoutGeneratorOutput
     dropoutGeneratorOutput
     (Tensor
        (Or
           (Gradient RequiresGradient)
           (Or (Gradient RequiresGradient) gradient relPosGradient)
           attentionMaskGradient)
        (Unify
           (Layout LayoutType)
           (Unify (Layout LayoutType) ('Layout 'Dense) relPosLayout)
           attentionMaskLayout)
        (Unify
           (Device (DeviceType Nat))
           (Unify (Device (DeviceType Nat)) device relPosDevice)
           attentionMaskDevice)
        (Unify
           (DataType DType)
           (Seq
              (Unify (DataType DType) relPosDataType ('DataType 'Int64))
              dataType)
           attentionMaskDataType)
        (BroadcastShapesF
           (TransposeF
              ('SelectDim ('ByIndex 1))
              ('SelectDim ('ByIndex 2))
              (TransposeF
                 ('SelectDim ('ByIndex 2))
                 ('SelectDim ('ByIndex 3))
                 (EmbeddingF ('Shape '[posEncDim, headDim]) relPosShape)))
           (UnsqueezeF ('SelectDim ('ByIndex 1)) attentionMaskShape)))
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">Tensor
  (Or (Gradient RequiresGradient) gradient relPosGradient)
  (Unify (Layout LayoutType) ('Layout 'Dense) relPosLayout)
  (Unify (Device (DeviceType Nat)) device relPosDevice)
  (Seq
     (Unify (DataType DType) relPosDataType ('DataType 'Int64))
     dataType)
  (TransposeF
     ('SelectDim ('ByIndex 1))
     ('SelectDim ('ByIndex 2))
     (TransposeF
        ('SelectDim ('ByIndex 2))
        ('SelectDim ('ByIndex 3))
        (EmbeddingF ('Shape '[posEncDim, headDim]) relPosShape)))
-&gt; Tensor
     attentionMaskGradient
     attentionMaskLayout
     attentionMaskDevice
     attentionMaskDataType
     (UnsqueezeF ('SelectDim ('ByIndex 1)) attentionMaskShape)
-&gt; Tensor
     (Or (Gradient RequiresGradient) gradient relPosGradient
      &lt;|&gt; attentionMaskGradient)
     (Unify (Layout LayoutType) ('Layout 'Dense) relPosLayout
      &lt;+&gt; attentionMaskLayout)
     (Unify (Device (DeviceType Nat)) device relPosDevice
      &lt;+&gt; attentionMaskDevice)
     (Seq
        (Unify (DataType DType) relPosDataType ('DataType 'Int64)) dataType
      &lt;+&gt; attentionMaskDataType)
     (BroadcastShapesF
        (TransposeF
           ('SelectDim ('ByIndex 1))
           ('SelectDim ('ByIndex 2))
           (TransposeF
              ('SelectDim ('ByIndex 2))
              ('SelectDim ('ByIndex 3))
              (EmbeddingF ('Shape '[posEncDim, headDim]) relPosShape)))
        (UnsqueezeF ('SelectDim ('ByIndex 1)) attentionMaskShape))
forall (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)])
       (gradient' :: Gradient RequiresGradient)
       (layout' :: Layout LayoutType) (device' :: Device (DeviceType Nat))
       (dataType' :: DataType DType)
       (shape' :: Shape [Dim (Name Symbol) (Size Nat)]).
Tensor gradient layout device dataType shape
-&gt; Tensor gradient' layout' device' dataType' shape'
-&gt; Tensor
     (gradient &lt;|&gt; gradient')
     (layout &lt;+&gt; layout')
     (device &lt;+&gt; device')
     (dataType &lt;+&gt; dataType')
     (BroadcastShapesF shape shape')
</span><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#add"><span class="hs-operator hs-var">`add`</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor
  attentionMaskGradient
  attentionMaskLayout
  attentionMaskDevice
  attentionMaskDataType
  attentionMaskShape
-&gt; Tensor
     attentionMaskGradient
     attentionMaskLayout
     attentionMaskDevice
     attentionMaskDataType
     (UnsqueezeF ('SelectDim ('ByIndex 1)) attentionMaskShape)
forall (selectDim :: SelectDim (By Symbol Nat))
       (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)])
       (shape' :: Shape [Dim (Name Symbol) (Size Nat)]).
(shape' ~ UnsqueezeF selectDim shape, SingI selectDim) =&gt;
Tensor gradient layout device dataType shape
-&gt; Tensor gradient layout device dataType shape'
</span><a href="Torch.GraduallyTyped.Tensor.IndexingSlicingJoining.html#unsqueeze"><span class="hs-identifier hs-var">unsqueeze</span></a></span><span> </span><span class="hs-glyph">@</span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SelectDim"><span class="hs-identifier hs-type">SelectDim</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#ByIndex"><span class="hs-identifier hs-type">ByIndex</span></a></span><span> </span><span class="annot"><span class="hs-number">1</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">Tensor
  attentionMaskGradient
  attentionMaskLayout
  attentionMaskDevice
  attentionMaskDataType
  attentionMaskShape
</span><a href="#local-6989586621679771070"><span class="hs-identifier hs-var">attentionMask</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-606"></span><span>     </span><span class="hs-keyword">in</span><span> </span><span class="annot"><span class="annottext">IxStateT m generator generatorOutput output
-&gt; generator -&gt; m (output, generatorOutput)
forall (m :: * -&gt; *) i j a. IxStateT m i j a -&gt; i -&gt; m (a, j)
</span><a href="../file:///nix/store/8vjaffqxij7bih93d9mlzmc7ksanlw0i-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier hs-var hs-var">runIxStateT</span></a></span><span> </span><span class="annot"><span class="annottext">(IxStateT m generator generatorOutput output
 -&gt; generator -&gt; m (output, generatorOutput))
-&gt; IxStateT m generator generatorOutput output
-&gt; generator
-&gt; m (output, generatorOutput)
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span>
</span><span id="line-607"></span><span>          </span><span class="annot"><span class="annottext">input -&gt; IxStateT m generator generator input
forall k (m :: k -&gt; k -&gt; * -&gt; *) a (i :: k).
IxPointed m =&gt;
a -&gt; m i i a
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-identifier hs-var">ireturn</span></a></span><span> </span><span class="annot"><span class="annottext">input
</span><a href="#local-6989586621679771072"><span class="hs-identifier hs-var">input</span></a></span><span>
</span><span id="line-608"></span><span>            </span><span class="annot"><span class="annottext">IxStateT m generator generator input
-&gt; (input
    -&gt; IxStateT m generator dropoutGeneratorOutput dropoutOutput)
-&gt; IxStateT m generator dropoutGeneratorOutput dropoutOutput
forall k1 (m :: k1 -&gt; k1 -&gt; * -&gt; *) (i :: k1) (j :: k1) a
       (k2 :: k1) b.
IxMonad m =&gt;
m i j a -&gt; (a -&gt; m j k2 b) -&gt; m i k2 b
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&gt;&gt;&gt;=</span></a></span><span> </span><span class="annot"><span class="annottext">(generator -&gt; m (dropoutOutput, dropoutGeneratorOutput))
-&gt; IxStateT m generator dropoutGeneratorOutput dropoutOutput
forall (m :: * -&gt; *) i j a. (i -&gt; m (a, j)) -&gt; IxStateT m i j a
</span><a href="../file:///nix/store/8vjaffqxij7bih93d9mlzmc7ksanlw0i-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier hs-var">IxStateT</span></a></span><span> </span><span class="annot"><span class="annottext">((generator -&gt; m (dropoutOutput, dropoutGeneratorOutput))
 -&gt; IxStateT m generator dropoutGeneratorOutput dropoutOutput)
-&gt; (input
    -&gt; generator -&gt; m (dropoutOutput, dropoutGeneratorOutput))
-&gt; input
-&gt; IxStateT m generator dropoutGeneratorOutput dropoutOutput
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">Dropout dropoutP
-&gt; input -&gt; generator -&gt; m (dropoutOutput, dropoutGeneratorOutput)
forall model input generator output generatorOutput (m :: * -&gt; *).
(HasForward model input generator output generatorOutput,
 MonadThrow m) =&gt;
model -&gt; input -&gt; generator -&gt; m (output, generatorOutput)
</span><a href="Torch.GraduallyTyped.NN.Class.html#forward"><span class="hs-identifier hs-var">forward</span></a></span><span> </span><span class="annot"><span class="annottext">Dropout dropoutP
TEDropoutF 'ByT5 dropoutP
</span><a href="#local-6989586621679771074"><span class="hs-identifier hs-var">teDropout</span></a></span><span>
</span><span id="line-609"></span><span>            </span><span class="annot"><span class="annottext">IxStateT m generator dropoutGeneratorOutput dropoutOutput
-&gt; (dropoutOutput
    -&gt; IxStateT
         m dropoutGeneratorOutput stackGeneratorOutput stackOutput)
-&gt; IxStateT m generator stackGeneratorOutput stackOutput
forall k1 (m :: k1 -&gt; k1 -&gt; * -&gt; *) (i :: k1) (j :: k1) a
       (k2 :: k1) b.
IxMonad m =&gt;
m i j a -&gt; (a -&gt; m j k2 b) -&gt; m i k2 b
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&gt;&gt;&gt;=</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">\</span><span id="local-6989586621679771067"><span class="annot"><span class="annottext">dropoutOutput
</span><a href="#local-6989586621679771067"><span class="hs-identifier hs-var">input'</span></a></span></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><span class="annottext">IxStateT
  m
  dropoutGeneratorOutput
  dropoutGeneratorOutput
  (Tensor
     (Or
        (Gradient RequiresGradient)
        (Or (Gradient RequiresGradient) gradient relPosGradient)
        attentionMaskGradient)
     (Unify
        (Layout LayoutType)
        (Unify (Layout LayoutType) ('Layout 'Dense) relPosLayout)
        attentionMaskLayout)
     (Unify
        (Device (DeviceType Nat))
        (Unify (Device (DeviceType Nat)) device relPosDevice)
        attentionMaskDevice)
     (Unify
        (DataType DType)
        (Seq
           (Unify (DataType DType) relPosDataType ('DataType 'Int64))
           dataType)
        attentionMaskDataType)
     (BroadcastShapesF
        (TransposeF
           ('SelectDim ('ByIndex 1))
           ('SelectDim ('ByIndex 2))
           (TransposeF
              ('SelectDim ('ByIndex 2))
              ('SelectDim ('ByIndex 3))
              (EmbeddingF ('Shape '[posEncDim, headDim]) relPosShape)))
        (UnsqueezeF ('SelectDim ('ByIndex 1)) attentionMaskShape)))
</span><a href="#local-6989586621679771068"><span class="hs-identifier hs-var">attentionBias</span></a></span><span> </span><span class="annot"><span class="annottext">IxStateT
  m
  dropoutGeneratorOutput
  dropoutGeneratorOutput
  (Tensor
     (Or
        (Gradient RequiresGradient)
        (Or (Gradient RequiresGradient) gradient relPosGradient)
        attentionMaskGradient)
     (Unify
        (Layout LayoutType)
        (Unify (Layout LayoutType) ('Layout 'Dense) relPosLayout)
        attentionMaskLayout)
     (Unify
        (Device (DeviceType Nat))
        (Unify (Device (DeviceType Nat)) device relPosDevice)
        attentionMaskDevice)
     (Unify
        (DataType DType)
        (Seq
           (Unify (DataType DType) relPosDataType ('DataType 'Int64))
           dataType)
        attentionMaskDataType)
     (BroadcastShapesF
        (TransposeF
           ('SelectDim ('ByIndex 1))
           ('SelectDim ('ByIndex 2))
           (TransposeF
              ('SelectDim ('ByIndex 2))
              ('SelectDim ('ByIndex 3))
              (EmbeddingF ('Shape '[posEncDim, headDim]) relPosShape)))
        (UnsqueezeF ('SelectDim ('ByIndex 1)) attentionMaskShape)))
-&gt; (Tensor
      (Or
         (Gradient RequiresGradient)
         (Or (Gradient RequiresGradient) gradient relPosGradient)
         attentionMaskGradient)
      (Unify
         (Layout LayoutType)
         (Unify (Layout LayoutType) ('Layout 'Dense) relPosLayout)
         attentionMaskLayout)
      (Unify
         (Device (DeviceType Nat))
         (Unify (Device (DeviceType Nat)) device relPosDevice)
         attentionMaskDevice)
      (Unify
         (DataType DType)
         (Seq
            (Unify (DataType DType) relPosDataType ('DataType 'Int64))
            dataType)
         attentionMaskDataType)
      (BroadcastShapesF
         (TransposeF
            ('SelectDim ('ByIndex 1))
            ('SelectDim ('ByIndex 2))
            (TransposeF
               ('SelectDim ('ByIndex 2))
               ('SelectDim ('ByIndex 3))
               (EmbeddingF ('Shape '[posEncDim, headDim]) relPosShape)))
         (UnsqueezeF ('SelectDim ('ByIndex 1)) attentionMaskShape))
    -&gt; IxStateT
         m dropoutGeneratorOutput stackGeneratorOutput stackOutput)
-&gt; IxStateT
     m dropoutGeneratorOutput stackGeneratorOutput stackOutput
forall k1 (m :: k1 -&gt; k1 -&gt; * -&gt; *) (i :: k1) (j :: k1) a
       (k2 :: k1) b.
IxMonad m =&gt;
m i j a -&gt; (a -&gt; m j k2 b) -&gt; m i k2 b
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&gt;&gt;&gt;=</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">\</span><span id="local-6989586621679771066"><span class="annot"><span class="annottext">Tensor
  (Or
     (Gradient RequiresGradient)
     (Or (Gradient RequiresGradient) gradient relPosGradient)
     attentionMaskGradient)
  (Unify
     (Layout LayoutType)
     (Unify (Layout LayoutType) ('Layout 'Dense) relPosLayout)
     attentionMaskLayout)
  (Unify
     (Device (DeviceType Nat))
     (Unify (Device (DeviceType Nat)) device relPosDevice)
     attentionMaskDevice)
  (Unify
     (DataType DType)
     (Seq
        (Unify (DataType DType) relPosDataType ('DataType 'Int64))
        dataType)
     attentionMaskDataType)
  (BroadcastShapesF
     (TransposeF
        ('SelectDim ('ByIndex 1))
        ('SelectDim ('ByIndex 2))
        (TransposeF
           ('SelectDim ('ByIndex 2))
           ('SelectDim ('ByIndex 3))
           (EmbeddingF ('Shape '[posEncDim, headDim]) relPosShape)))
     (UnsqueezeF ('SelectDim ('ByIndex 1)) attentionMaskShape))
</span><a href="#local-6989586621679771066"><span class="hs-identifier hs-var">attentionBias'</span></a></span></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><span class="annottext">(dropoutGeneratorOutput -&gt; m (stackOutput, stackGeneratorOutput))
-&gt; IxStateT
     m dropoutGeneratorOutput stackGeneratorOutput stackOutput
forall (m :: * -&gt; *) i j a. (i -&gt; m (a, j)) -&gt; IxStateT m i j a
</span><a href="../file:///nix/store/8vjaffqxij7bih93d9mlzmc7ksanlw0i-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier hs-var">IxStateT</span></a></span><span> </span><span class="annot"><span class="annottext">((dropoutGeneratorOutput -&gt; m (stackOutput, stackGeneratorOutput))
 -&gt; IxStateT
      m dropoutGeneratorOutput stackGeneratorOutput stackOutput)
-&gt; (dropoutGeneratorOutput
    -&gt; m (stackOutput, stackGeneratorOutput))
-&gt; IxStateT
     m dropoutGeneratorOutput stackGeneratorOutput stackOutput
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">TransformerStack
  'ByT5
  numLayers
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  inputEmbedDim
  ffnDim
  dropoutP
-&gt; (dropoutOutput,
    Tensor
      (Or
         (Gradient RequiresGradient)
         (Or (Gradient RequiresGradient) gradient relPosGradient)
         attentionMaskGradient)
      (Unify
         (Layout LayoutType)
         (Unify (Layout LayoutType) ('Layout 'Dense) relPosLayout)
         attentionMaskLayout)
      (Unify
         (Device (DeviceType Nat))
         (Unify (Device (DeviceType Nat)) device relPosDevice)
         attentionMaskDevice)
      (Unify
         (DataType DType)
         (Seq
            (Unify (DataType DType) relPosDataType ('DataType 'Int64))
            dataType)
         attentionMaskDataType)
      (BroadcastShapesF
         (TransposeF
            ('SelectDim ('ByIndex 1))
            ('SelectDim ('ByIndex 2))
            (TransposeF
               ('SelectDim ('ByIndex 2))
               ('SelectDim ('ByIndex 3))
               (EmbeddingF ('Shape '[posEncDim, headDim]) relPosShape)))
         (UnsqueezeF ('SelectDim ('ByIndex 1)) attentionMaskShape)))
-&gt; dropoutGeneratorOutput
-&gt; m (stackOutput, stackGeneratorOutput)
forall model input generator output generatorOutput (m :: * -&gt; *).
(HasForward model input generator output generatorOutput,
 MonadThrow m) =&gt;
model -&gt; input -&gt; generator -&gt; m (output, generatorOutput)
</span><a href="Torch.GraduallyTyped.NN.Class.html#forward"><span class="hs-identifier hs-var">forward</span></a></span><span> </span><span class="annot"><span class="annottext">TransformerStack
  'ByT5
  numLayers
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  inputEmbedDim
  ffnDim
  dropoutP
TEStackF
  'ByT5
  numLayers
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  inputEmbedDim
  ffnDim
  dropoutP
</span><a href="#local-6989586621679771077"><span class="hs-identifier hs-var">teStack</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">dropoutOutput
</span><a href="#local-6989586621679771067"><span class="hs-identifier hs-var">input'</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">Tensor
  (Or
     (Gradient RequiresGradient)
     (Or (Gradient RequiresGradient) gradient relPosGradient)
     attentionMaskGradient)
  (Unify
     (Layout LayoutType)
     (Unify (Layout LayoutType) ('Layout 'Dense) relPosLayout)
     attentionMaskLayout)
  (Unify
     (Device (DeviceType Nat))
     (Unify (Device (DeviceType Nat)) device relPosDevice)
     attentionMaskDevice)
  (Unify
     (DataType DType)
     (Seq
        (Unify (DataType DType) relPosDataType ('DataType 'Int64))
        dataType)
     attentionMaskDataType)
  (BroadcastShapesF
     (TransposeF
        ('SelectDim ('ByIndex 1))
        ('SelectDim ('ByIndex 2))
        (TransposeF
           ('SelectDim ('ByIndex 2))
           ('SelectDim ('ByIndex 3))
           (EmbeddingF ('Shape '[posEncDim, headDim]) relPosShape)))
     (UnsqueezeF ('SelectDim ('ByIndex 1)) attentionMaskShape))
</span><a href="#local-6989586621679771066"><span class="hs-identifier hs-var">attentionBias'</span></a></span><span class="hs-special">)</span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-610"></span><span>            </span><span class="annot"><span class="annottext">IxStateT m generator stackGeneratorOutput stackOutput
-&gt; (stackOutput
    -&gt; IxStateT
         m stackGeneratorOutput layerNormGeneratorOutput layerNormOutput)
-&gt; IxStateT m generator layerNormGeneratorOutput layerNormOutput
forall k1 (m :: k1 -&gt; k1 -&gt; * -&gt; *) (i :: k1) (j :: k1) a
       (k2 :: k1) b.
IxMonad m =&gt;
m i j a -&gt; (a -&gt; m j k2 b) -&gt; m i k2 b
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&gt;&gt;&gt;=</span></a></span><span> </span><span class="annot"><span class="annottext">(stackGeneratorOutput
 -&gt; m (layerNormOutput, layerNormGeneratorOutput))
-&gt; IxStateT
     m stackGeneratorOutput layerNormGeneratorOutput layerNormOutput
forall (m :: * -&gt; *) i j a. (i -&gt; m (a, j)) -&gt; IxStateT m i j a
</span><a href="../file:///nix/store/8vjaffqxij7bih93d9mlzmc7ksanlw0i-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier hs-var">IxStateT</span></a></span><span> </span><span class="annot"><span class="annottext">((stackGeneratorOutput
  -&gt; m (layerNormOutput, layerNormGeneratorOutput))
 -&gt; IxStateT
      m stackGeneratorOutput layerNormGeneratorOutput layerNormOutput)
-&gt; (stackOutput
    -&gt; stackGeneratorOutput
    -&gt; m (layerNormOutput, layerNormGeneratorOutput))
-&gt; stackOutput
-&gt; IxStateT
     m stackGeneratorOutput layerNormGeneratorOutput layerNormOutput
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">LayerNorm
  'WithoutBias gradient device dataType ('Shape '[inputEmbedDim])
-&gt; stackOutput
-&gt; stackGeneratorOutput
-&gt; m (layerNormOutput, layerNormGeneratorOutput)
forall model input generator output generatorOutput (m :: * -&gt; *).
(HasForward model input generator output generatorOutput,
 MonadThrow m) =&gt;
model -&gt; input -&gt; generator -&gt; m (output, generatorOutput)
</span><a href="Torch.GraduallyTyped.NN.Class.html#forward"><span class="hs-identifier hs-var">forward</span></a></span><span> </span><span class="annot"><span class="annottext">LayerNorm
  'WithoutBias gradient device dataType ('Shape '[inputEmbedDim])
TELayerNormF 'ByT5 gradient device dataType inputEmbedDim
</span><a href="#local-6989586621679771075"><span class="hs-identifier hs-var">teLayerNorm</span></a></span><span>
</span><span id="line-611"></span><span>            </span><span class="annot"><span class="annottext">IxStateT m generator layerNormGeneratorOutput layerNormOutput
-&gt; (layerNormOutput
    -&gt; IxStateT m layerNormGeneratorOutput generatorOutput output)
-&gt; IxStateT m generator generatorOutput output
forall k1 (m :: k1 -&gt; k1 -&gt; * -&gt; *) (i :: k1) (j :: k1) a
       (k2 :: k1) b.
IxMonad m =&gt;
m i j a -&gt; (a -&gt; m j k2 b) -&gt; m i k2 b
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&gt;&gt;&gt;=</span></a></span><span> </span><span class="annot"><span class="annottext">(layerNormGeneratorOutput -&gt; m (output, generatorOutput))
-&gt; IxStateT m layerNormGeneratorOutput generatorOutput output
forall (m :: * -&gt; *) i j a. (i -&gt; m (a, j)) -&gt; IxStateT m i j a
</span><a href="../file:///nix/store/8vjaffqxij7bih93d9mlzmc7ksanlw0i-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier hs-var">IxStateT</span></a></span><span> </span><span class="annot"><span class="annottext">((layerNormGeneratorOutput -&gt; m (output, generatorOutput))
 -&gt; IxStateT m layerNormGeneratorOutput generatorOutput output)
-&gt; (layerNormOutput
    -&gt; layerNormGeneratorOutput -&gt; m (output, generatorOutput))
-&gt; layerNormOutput
-&gt; IxStateT m layerNormGeneratorOutput generatorOutput output
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">Dropout dropoutP
-&gt; layerNormOutput
-&gt; layerNormGeneratorOutput
-&gt; m (output, generatorOutput)
forall model input generator output generatorOutput (m :: * -&gt; *).
(HasForward model input generator output generatorOutput,
 MonadThrow m) =&gt;
model -&gt; input -&gt; generator -&gt; m (output, generatorOutput)
</span><a href="Torch.GraduallyTyped.NN.Class.html#forward"><span class="hs-identifier hs-var">forward</span></a></span><span> </span><span class="annot"><span class="annottext">Dropout dropoutP
TEDropoutF 'ByT5 dropoutP
</span><a href="#local-6989586621679771074"><span class="hs-identifier hs-var">teDropout</span></a></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span><span>
</span><span id="line-612"></span><span>
</span><span id="line-613"></span><span class="hs-comment">-- | 'HasForward' instance for @TransformerEncoder numLayers 'BART@.</span><span>
</span><span id="line-614"></span><span class="hs-comment">--</span><span>
</span><span id="line-615"></span><span class="hs-comment">-- @</span><span>
</span><span id="line-616"></span><span class="hs-comment">-- &#9484;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9488;  &#9484;&#9472;&#9472;&#9472;&#9472;&#9472;&#9488;  &#9484;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9488;</span><span>
</span><span id="line-617"></span><span class="hs-comment">-- &#9474; input &#9474;  &#9474; pos &#9474;  &#9474; attentionMask &#9474;</span><span>
</span><span id="line-618"></span><span class="hs-comment">-- &#9492;&#9472;&#9472;&#9472;&#9516;&#9472;&#9472;&#9472;&#9496;  &#9492;&#9472;&#9472;&#9472;&#9472;&#9472;&#9496;  &#9492;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9516;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9496;</span><span>
</span><span id="line-619"></span><span class="hs-comment">--     &#9474;         &#9474;             &#9474;</span><span>
</span><span id="line-620"></span><span class="hs-comment">--     &#9474;         &#9660;             &#9474;</span><span>
</span><span id="line-621"></span><span class="hs-comment">--     &#9474;     tePosEnc          &#9474;</span><span>
</span><span id="line-622"></span><span class="hs-comment">--     &#9474;         &#9474;             &#9474;</span><span>
</span><span id="line-623"></span><span class="hs-comment">--     &#9492;&#9472;&#9472;&#9658;add&#9668;&#9472;&#9472;&#9496;             &#9474;</span><span>
</span><span id="line-624"></span><span class="hs-comment">--          &#9474;                  &#9474;</span><span>
</span><span id="line-625"></span><span class="hs-comment">--          &#9660;                  &#9474;</span><span>
</span><span id="line-626"></span><span class="hs-comment">--   teEmbedLayerNorm          &#9474;</span><span>
</span><span id="line-627"></span><span class="hs-comment">--          &#9660;                  &#9660;</span><span>
</span><span id="line-628"></span><span class="hs-comment">--      teDropout          unsqueeze</span><span>
</span><span id="line-629"></span><span class="hs-comment">--          &#9660;                  &#9474;</span><span>
</span><span id="line-630"></span><span class="hs-comment">--       teStack&#9668;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9496;</span><span>
</span><span id="line-631"></span><span class="hs-comment">--          &#9474;</span><span>
</span><span id="line-632"></span><span class="hs-comment">--          &#9660;</span><span>
</span><span id="line-633"></span><span class="hs-comment">--     &#9484;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9488;</span><span>
</span><span id="line-634"></span><span class="hs-comment">--     &#9474; output &#9474;</span><span>
</span><span id="line-635"></span><span class="hs-comment">--     &#9492;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9496;</span><span>
</span><span id="line-636"></span><span class="hs-comment">-- @</span><span>
</span><span id="line-637"></span><span id="local-6989586621679771034"><span id="local-6989586621679771035"><span id="local-6989586621679771036"><span id="local-6989586621679771037"><span id="local-6989586621679771038"><span id="local-6989586621679771039"><span id="local-6989586621679771040"><span id="local-6989586621679771041"><span id="local-6989586621679771042"><span id="local-6989586621679771043"><span id="local-6989586621679771044"><span id="local-6989586621679771045"><span id="local-6989586621679771046"><span id="local-6989586621679771047"><span id="local-6989586621679771048"><span id="local-6989586621679771049"><span id="local-6989586621679771050"><span id="local-6989586621679771051"><span id="local-6989586621679771052"><span id="local-6989586621679771053"><span id="local-6989586621679771054"><span id="local-6989586621679771055"><span id="local-6989586621679771056"><span id="local-6989586621679771057"><span id="local-6989586621679771058"><span id="local-6989586621679771059"><span id="local-6989586621679771060"><span id="local-6989586621679771061"><span id="local-6989586621679771062"><span id="local-6989586621679771063"><span id="local-6989586621679771064"><span id="local-6989586621679771065"><span class="hs-keyword">instance</span><span>
</span><span id="line-638"></span><span>  </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasForward"><span class="hs-identifier hs-type">HasForward</span></a></span><span>
</span><span id="line-639"></span><span>      </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Encoder.html#TEEmbedLayerNormF"><span class="hs-identifier hs-type">TEEmbedLayerNormF</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#BART"><span class="hs-identifier hs-type">BART</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771065"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771064"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771063"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771062"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-640"></span><span>      </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span>
</span><span id="line-641"></span><span>          </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679771061"><span class="hs-identifier hs-type">inputGradient</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%7C%3E"><span class="hs-operator hs-type">&lt;|&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771065"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%7C%3E"><span class="hs-operator hs-type">&lt;|&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771060"><span class="hs-identifier hs-type">posGradient</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-642"></span><span>          </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679771059"><span class="hs-identifier hs-type">inputLayout</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#Layout"><span class="hs-identifier hs-type">Layout</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#Dense"><span class="hs-identifier hs-type">Dense</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771058"><span class="hs-identifier hs-type">posLayout</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-643"></span><span>          </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679771057"><span class="hs-identifier hs-type">inputDevice</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771064"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771056"><span class="hs-identifier hs-type">posDevice</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-644"></span><span>          </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679771055"><span class="hs-identifier hs-type">inputDataType</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Prelude.html#Seq"><span class="hs-identifier hs-type">Seq</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679771054"><span class="hs-identifier hs-type">posDataType</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#DataType"><span class="hs-identifier hs-type">DataType</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#Int64"><span class="hs-identifier hs-type">Int64</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679771063"><span class="hs-identifier hs-type">dataType</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-645"></span><span>          </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Class.html#BroadcastShapesF"><span class="hs-identifier hs-type">BroadcastShapesF</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771053"><span class="hs-identifier hs-type">inputShape</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Functional.Sparse.html#EmbeddingF"><span class="hs-identifier hs-type">EmbeddingF</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Shape"><span class="hs-identifier hs-type">Shape</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="annot"><a href="#local-6989586621679771052"><span class="hs-identifier hs-type">posEncDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679771062"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span><span class="hs-special">]</span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679771051"><span class="hs-identifier hs-type">posShape</span></a></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-646"></span><span>      </span><span class="hs-special">)</span><span>
</span><span id="line-647"></span><span>      </span><span class="annot"><a href="#local-6989586621679771050"><span class="hs-identifier hs-type">generator</span></a></span><span>
</span><span id="line-648"></span><span>      </span><span class="annot"><a href="#local-6989586621679771049"><span class="hs-identifier hs-type">layerNormOutput</span></a></span><span>
</span><span id="line-649"></span><span>      </span><span class="annot"><a href="#local-6989586621679771050"><span class="hs-identifier hs-type">generator</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-650"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasForward"><span class="hs-identifier hs-type">HasForward</span></a></span><span>
</span><span id="line-651"></span><span>      </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Encoder.html#TEDropoutF"><span class="hs-identifier hs-type">TEDropoutF</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#BART"><span class="hs-identifier hs-type">BART</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771048"><span class="hs-identifier hs-type">dropoutP</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-652"></span><span>      </span><span class="annot"><a href="#local-6989586621679771049"><span class="hs-identifier hs-type">layerNormOutput</span></a></span><span>
</span><span id="line-653"></span><span>      </span><span class="annot"><a href="#local-6989586621679771050"><span class="hs-identifier hs-type">generator</span></a></span><span>
</span><span id="line-654"></span><span>      </span><span class="annot"><a href="#local-6989586621679771047"><span class="hs-identifier hs-type">dropoutOutput</span></a></span><span>
</span><span id="line-655"></span><span>      </span><span class="annot"><a href="#local-6989586621679771046"><span class="hs-identifier hs-type">dropoutGeneratorOutput</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-656"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasForward"><span class="hs-identifier hs-type">HasForward</span></a></span><span>
</span><span id="line-657"></span><span>      </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Encoder.html#TEStackF"><span class="hs-identifier hs-type">TEStackF</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#BART"><span class="hs-identifier hs-type">BART</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771045"><span class="hs-identifier hs-type">numLayers</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771065"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771064"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771063"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771044"><span class="hs-identifier hs-type">headDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771043"><span class="hs-identifier hs-type">headEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771042"><span class="hs-identifier hs-type">embedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771062"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771041"><span class="hs-identifier hs-type">ffnDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771048"><span class="hs-identifier hs-type">dropoutP</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-658"></span><span>      </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="#local-6989586621679771047"><span class="hs-identifier hs-type">dropoutOutput</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-659"></span><span>        </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span>
</span><span id="line-660"></span><span>          </span><span class="annot"><a href="#local-6989586621679771040"><span class="hs-identifier hs-type">attentionMaskGradient</span></a></span><span>
</span><span id="line-661"></span><span>          </span><span class="annot"><a href="#local-6989586621679771039"><span class="hs-identifier hs-type">attentionMaskLayout</span></a></span><span>
</span><span id="line-662"></span><span>          </span><span class="annot"><a href="#local-6989586621679771038"><span class="hs-identifier hs-type">attentionMaskDevice</span></a></span><span>
</span><span id="line-663"></span><span>          </span><span class="annot"><a href="#local-6989586621679771037"><span class="hs-identifier hs-type">attentionMaskDataType</span></a></span><span>
</span><span id="line-664"></span><span>          </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.IndexingSlicingJoining.html#UnsqueezeF"><span class="hs-identifier hs-type">UnsqueezeF</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SelectDim"><span class="hs-identifier hs-type">SelectDim</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#ByIndex"><span class="hs-identifier hs-type">ByIndex</span></a></span><span> </span><span class="annot"><span class="hs-number">1</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679771036"><span class="hs-identifier hs-type">attentionMaskShape</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-665"></span><span>      </span><span class="hs-special">)</span><span>
</span><span id="line-666"></span><span>      </span><span class="annot"><a href="#local-6989586621679771046"><span class="hs-identifier hs-type">dropoutGeneratorOutput</span></a></span><span>
</span><span id="line-667"></span><span>      </span><span class="annot"><a href="#local-6989586621679771035"><span class="hs-identifier hs-type">output</span></a></span><span>
</span><span id="line-668"></span><span>      </span><span class="annot"><a href="#local-6989586621679771034"><span class="hs-identifier hs-type">generatorOutput</span></a></span><span>
</span><span id="line-669"></span><span>  </span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-670"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasForward"><span class="hs-identifier hs-type">HasForward</span></a></span><span>
</span><span id="line-671"></span><span>    </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Encoder.html#TransformerEncoder"><span class="hs-identifier hs-type">TransformerEncoder</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#BART"><span class="hs-identifier hs-type">BART</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771045"><span class="hs-identifier hs-type">numLayers</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771065"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771064"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771063"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771044"><span class="hs-identifier hs-type">headDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771043"><span class="hs-identifier hs-type">headEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771042"><span class="hs-identifier hs-type">embedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771062"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771041"><span class="hs-identifier hs-type">ffnDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771052"><span class="hs-identifier hs-type">posEncDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771048"><span class="hs-identifier hs-type">dropoutP</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-672"></span><span>    </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771061"><span class="hs-identifier hs-type">inputGradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771059"><span class="hs-identifier hs-type">inputLayout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771057"><span class="hs-identifier hs-type">inputDevice</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771055"><span class="hs-identifier hs-type">inputDataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771053"><span class="hs-identifier hs-type">inputShape</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-673"></span><span>      </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771060"><span class="hs-identifier hs-type">posGradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771058"><span class="hs-identifier hs-type">posLayout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771056"><span class="hs-identifier hs-type">posDevice</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771054"><span class="hs-identifier hs-type">posDataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771051"><span class="hs-identifier hs-type">posShape</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-674"></span><span>      </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771040"><span class="hs-identifier hs-type">attentionMaskGradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771039"><span class="hs-identifier hs-type">attentionMaskLayout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771038"><span class="hs-identifier hs-type">attentionMaskDevice</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771037"><span class="hs-identifier hs-type">attentionMaskDataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771036"><span class="hs-identifier hs-type">attentionMaskShape</span></a></span><span>
</span><span id="line-675"></span><span>    </span><span class="hs-special">)</span><span>
</span><span id="line-676"></span><span>    </span><span class="annot"><a href="#local-6989586621679771050"><span class="hs-identifier hs-type">generator</span></a></span><span>
</span><span id="line-677"></span><span>    </span><span class="annot"><a href="#local-6989586621679771035"><span class="hs-identifier hs-type">output</span></a></span><span>
</span><span id="line-678"></span><span>    </span><span class="annot"><a href="#local-6989586621679771034"><span class="hs-identifier hs-type">generatorOutput</span></a></span><span>
</span><span id="line-679"></span><span>  </span><span class="hs-keyword">where</span><span>
</span><span id="line-680"></span><span>  </span><span id="local-6989586621679771032"><span class="annot"><span class="annottext">forward :: TransformerEncoder
  'BART
  numLayers
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  inputEmbedDim
  ffnDim
  posEncDim
  dropoutP
-&gt; (Tensor
      inputGradient inputLayout inputDevice inputDataType inputShape,
    Tensor posGradient posLayout posDevice posDataType posShape,
    Tensor
      attentionMaskGradient
      attentionMaskLayout
      attentionMaskDevice
      attentionMaskDataType
      attentionMaskShape)
-&gt; generator
-&gt; m (output, generatorOutput)
</span><a href="#local-6989586621679771032"><span class="hs-identifier hs-var hs-var hs-var hs-var">forward</span></a></span></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Encoder.html#TransformerEncoder"><span class="hs-identifier hs-type">TransformerEncoder</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Encoder.html#GTransformerEncoder"><span class="hs-identifier hs-type">GTransformerEncoder</span></a></span><span> </span><span class="hs-special">{</span><span id="local-6989586621679771027"><span id="local-6989586621679771028"><span id="local-6989586621679771029"><span id="local-6989586621679771030"><span id="local-6989586621679771031"><span class="annot"><span class="annottext">TEPosEncF
  'BART gradient device dataType headDim inputEmbedDim posEncDim
TEDropoutF 'BART dropoutP
TELayerNormF 'BART gradient device dataType inputEmbedDim
TEEmbedLayerNormF 'BART gradient device dataType inputEmbedDim
TEStackF
  'BART
  numLayers
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  inputEmbedDim
  ffnDim
  dropoutP
tePosEnc :: TEPosEncF
  'BART gradient device dataType headDim inputEmbedDim posEncDim
teDropout :: TEDropoutF 'BART dropoutP
teLayerNorm :: TELayerNormF 'BART gradient device dataType inputEmbedDim
teEmbedLayerNorm :: TEEmbedLayerNormF 'BART gradient device dataType inputEmbedDim
teStack :: TEStackF
  'BART
  numLayers
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  inputEmbedDim
  ffnDim
  dropoutP
tePosEnc :: forall stack embedLayerNorm layerNorm dropout posEnc.
GTransformerEncoder stack embedLayerNorm layerNorm dropout posEnc
-&gt; posEnc
teDropout :: forall stack embedLayerNorm layerNorm dropout posEnc.
GTransformerEncoder stack embedLayerNorm layerNorm dropout posEnc
-&gt; dropout
teLayerNorm :: forall stack embedLayerNorm layerNorm dropout posEnc.
GTransformerEncoder stack embedLayerNorm layerNorm dropout posEnc
-&gt; layerNorm
teEmbedLayerNorm :: forall stack embedLayerNorm layerNorm dropout posEnc.
GTransformerEncoder stack embedLayerNorm layerNorm dropout posEnc
-&gt; embedLayerNorm
teStack :: forall stack embedLayerNorm layerNorm dropout posEnc.
GTransformerEncoder stack embedLayerNorm layerNorm dropout posEnc
-&gt; stack
</span><a href="#local-6989586621679771027"><span class="hs-glyph hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var">..</span></a></span></span></span></span></span></span><span class="hs-special">}</span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span id="local-6989586621679771026"><span class="annot"><span class="annottext">Tensor
  inputGradient inputLayout inputDevice inputDataType inputShape
</span><a href="#local-6989586621679771026"><span class="hs-identifier hs-var">input</span></a></span></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679771025"><span class="annot"><span class="annottext">Tensor posGradient posLayout posDevice posDataType posShape
</span><a href="#local-6989586621679771025"><span class="hs-identifier hs-var">pos</span></a></span></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679771024"><span class="annot"><span class="annottext">Tensor
  attentionMaskGradient
  attentionMaskLayout
  attentionMaskDevice
  attentionMaskDataType
  attentionMaskShape
</span><a href="#local-6989586621679771024"><span class="hs-identifier hs-var">attentionMask</span></a></span></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-681"></span><span>    </span><span class="hs-keyword">let</span><span> </span><span id="local-6989586621679771023"><span class="annot"><span class="annottext">attentionBias :: Tensor
  attentionMaskGradient
  attentionMaskLayout
  attentionMaskDevice
  attentionMaskDataType
  (UnsqueezeF ('SelectDim ('ByIndex 1)) attentionMaskShape)
</span><a href="#local-6989586621679771023"><span class="hs-identifier hs-var hs-var">attentionBias</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Tensor
  attentionMaskGradient
  attentionMaskLayout
  attentionMaskDevice
  attentionMaskDataType
  attentionMaskShape
-&gt; Tensor
     attentionMaskGradient
     attentionMaskLayout
     attentionMaskDevice
     attentionMaskDataType
     (UnsqueezeF ('SelectDim ('ByIndex 1)) attentionMaskShape)
forall (selectDim :: SelectDim (By Symbol Nat))
       (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)])
       (shape' :: Shape [Dim (Name Symbol) (Size Nat)]).
(shape' ~ UnsqueezeF selectDim shape, SingI selectDim) =&gt;
Tensor gradient layout device dataType shape
-&gt; Tensor gradient layout device dataType shape'
</span><a href="Torch.GraduallyTyped.Tensor.IndexingSlicingJoining.html#unsqueeze"><span class="hs-identifier hs-var">unsqueeze</span></a></span><span> </span><span class="hs-glyph">@</span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SelectDim"><span class="hs-identifier hs-type">SelectDim</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#ByIndex"><span class="hs-identifier hs-type">ByIndex</span></a></span><span> </span><span class="annot"><span class="hs-number">1</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">Tensor
  attentionMaskGradient
  attentionMaskLayout
  attentionMaskDevice
  attentionMaskDataType
  attentionMaskShape
</span><a href="#local-6989586621679771024"><span class="hs-identifier hs-var">attentionMask</span></a></span><span>
</span><span id="line-682"></span><span>     </span><span class="hs-keyword">in</span><span> </span><span class="annot"><span class="annottext">IxStateT m generator generatorOutput output
-&gt; generator -&gt; m (output, generatorOutput)
forall (m :: * -&gt; *) i j a. IxStateT m i j a -&gt; i -&gt; m (a, j)
</span><a href="../file:///nix/store/8vjaffqxij7bih93d9mlzmc7ksanlw0i-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier hs-var hs-var">runIxStateT</span></a></span><span> </span><span class="annot"><span class="annottext">(IxStateT m generator generatorOutput output
 -&gt; generator -&gt; m (output, generatorOutput))
-&gt; IxStateT m generator generatorOutput output
-&gt; generator
-&gt; m (output, generatorOutput)
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span>
</span><span id="line-683"></span><span>          </span><span class="annot"><span class="annottext">Tensor posGradient posLayout posDevice posDataType posShape
-&gt; IxStateT
     m
     generator
     generator
     (Tensor posGradient posLayout posDevice posDataType posShape)
forall k (m :: k -&gt; k -&gt; * -&gt; *) a (i :: k).
IxPointed m =&gt;
a -&gt; m i i a
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-identifier hs-var">ireturn</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor posGradient posLayout posDevice posDataType posShape
</span><a href="#local-6989586621679771025"><span class="hs-identifier hs-var">pos</span></a></span><span>
</span><span id="line-684"></span><span>            </span><span class="annot"><span class="annottext">IxStateT
  m
  generator
  generator
  (Tensor posGradient posLayout posDevice posDataType posShape)
-&gt; (Tensor posGradient posLayout posDevice posDataType posShape
    -&gt; IxStateT
         m
         generator
         generator
         (Tensor
            (Or (Gradient RequiresGradient) gradient posGradient)
            (Unify (Layout LayoutType) ('Layout 'Dense) posLayout)
            (Unify (Device (DeviceType Nat)) device posDevice)
            (Seq
               (Unify (DataType DType) posDataType ('DataType 'Int64)) dataType)
            (EmbeddingF ('Shape '[posEncDim, inputEmbedDim]) posShape)))
-&gt; IxStateT
     m
     generator
     generator
     (Tensor
        (Or (Gradient RequiresGradient) gradient posGradient)
        (Unify (Layout LayoutType) ('Layout 'Dense) posLayout)
        (Unify (Device (DeviceType Nat)) device posDevice)
        (Seq
           (Unify (DataType DType) posDataType ('DataType 'Int64)) dataType)
        (EmbeddingF ('Shape '[posEncDim, inputEmbedDim]) posShape))
forall k1 (m :: k1 -&gt; k1 -&gt; * -&gt; *) (i :: k1) (j :: k1) a
       (k2 :: k1) b.
IxMonad m =&gt;
m i j a -&gt; (a -&gt; m j k2 b) -&gt; m i k2 b
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&gt;&gt;&gt;=</span></a></span><span> </span><span class="annot"><span class="annottext">(generator
 -&gt; m (Tensor
         (Or (Gradient RequiresGradient) gradient posGradient)
         (Unify (Layout LayoutType) ('Layout 'Dense) posLayout)
         (Unify (Device (DeviceType Nat)) device posDevice)
         (Seq
            (Unify (DataType DType) posDataType ('DataType 'Int64)) dataType)
         (EmbeddingF ('Shape '[posEncDim, inputEmbedDim]) posShape),
       generator))
-&gt; IxStateT
     m
     generator
     generator
     (Tensor
        (Or (Gradient RequiresGradient) gradient posGradient)
        (Unify (Layout LayoutType) ('Layout 'Dense) posLayout)
        (Unify (Device (DeviceType Nat)) device posDevice)
        (Seq
           (Unify (DataType DType) posDataType ('DataType 'Int64)) dataType)
        (EmbeddingF ('Shape '[posEncDim, inputEmbedDim]) posShape))
forall (m :: * -&gt; *) i j a. (i -&gt; m (a, j)) -&gt; IxStateT m i j a
</span><a href="../file:///nix/store/8vjaffqxij7bih93d9mlzmc7ksanlw0i-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier hs-var">IxStateT</span></a></span><span> </span><span class="annot"><span class="annottext">((generator
  -&gt; m (Tensor
          (Or (Gradient RequiresGradient) gradient posGradient)
          (Unify (Layout LayoutType) ('Layout 'Dense) posLayout)
          (Unify (Device (DeviceType Nat)) device posDevice)
          (Seq
             (Unify (DataType DType) posDataType ('DataType 'Int64)) dataType)
          (EmbeddingF ('Shape '[posEncDim, inputEmbedDim]) posShape),
        generator))
 -&gt; IxStateT
      m
      generator
      generator
      (Tensor
         (Or (Gradient RequiresGradient) gradient posGradient)
         (Unify (Layout LayoutType) ('Layout 'Dense) posLayout)
         (Unify (Device (DeviceType Nat)) device posDevice)
         (Seq
            (Unify (DataType DType) posDataType ('DataType 'Int64)) dataType)
         (EmbeddingF ('Shape '[posEncDim, inputEmbedDim]) posShape)))
-&gt; (Tensor posGradient posLayout posDevice posDataType posShape
    -&gt; generator
    -&gt; m (Tensor
            (Or (Gradient RequiresGradient) gradient posGradient)
            (Unify (Layout LayoutType) ('Layout 'Dense) posLayout)
            (Unify (Device (DeviceType Nat)) device posDevice)
            (Seq
               (Unify (DataType DType) posDataType ('DataType 'Int64)) dataType)
            (EmbeddingF ('Shape '[posEncDim, inputEmbedDim]) posShape),
          generator))
-&gt; Tensor posGradient posLayout posDevice posDataType posShape
-&gt; IxStateT
     m
     generator
     generator
     (Tensor
        (Or (Gradient RequiresGradient) gradient posGradient)
        (Unify (Layout LayoutType) ('Layout 'Dense) posLayout)
        (Unify (Device (DeviceType Nat)) device posDevice)
        (Seq
           (Unify (DataType DType) posDataType ('DataType 'Int64)) dataType)
        (EmbeddingF ('Shape '[posEncDim, inputEmbedDim]) posShape))
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">Embedding
  gradient
  ('Layout 'Dense)
  device
  dataType
  posEncDim
  inputEmbedDim
  'Nothing
-&gt; Tensor posGradient posLayout posDevice posDataType posShape
-&gt; generator
-&gt; m (Tensor
        (Or (Gradient RequiresGradient) gradient posGradient)
        (Unify (Layout LayoutType) ('Layout 'Dense) posLayout)
        (Unify (Device (DeviceType Nat)) device posDevice)
        (Seq
           (Unify (DataType DType) posDataType ('DataType 'Int64)) dataType)
        (EmbeddingF ('Shape '[posEncDim, inputEmbedDim]) posShape),
      generator)
forall model input generator output generatorOutput (m :: * -&gt; *).
(HasForward model input generator output generatorOutput,
 MonadThrow m) =&gt;
model -&gt; input -&gt; generator -&gt; m (output, generatorOutput)
</span><a href="Torch.GraduallyTyped.NN.Class.html#forward"><span class="hs-identifier hs-var">forward</span></a></span><span> </span><span class="annot"><span class="annottext">Embedding
  gradient
  ('Layout 'Dense)
  device
  dataType
  posEncDim
  inputEmbedDim
  'Nothing
TEPosEncF
  'BART gradient device dataType headDim inputEmbedDim posEncDim
</span><a href="#local-6989586621679771027"><span class="hs-identifier hs-var">tePosEnc</span></a></span><span>
</span><span id="line-685"></span><span>            </span><span class="annot"><span class="annottext">IxStateT
  m
  generator
  generator
  (Tensor
     (Or (Gradient RequiresGradient) gradient posGradient)
     (Unify (Layout LayoutType) ('Layout 'Dense) posLayout)
     (Unify (Device (DeviceType Nat)) device posDevice)
     (Seq
        (Unify (DataType DType) posDataType ('DataType 'Int64)) dataType)
     (EmbeddingF ('Shape '[posEncDim, inputEmbedDim]) posShape))
-&gt; (Tensor
      (Or (Gradient RequiresGradient) gradient posGradient)
      (Unify (Layout LayoutType) ('Layout 'Dense) posLayout)
      (Unify (Device (DeviceType Nat)) device posDevice)
      (Seq
         (Unify (DataType DType) posDataType ('DataType 'Int64)) dataType)
      (EmbeddingF ('Shape '[posEncDim, inputEmbedDim]) posShape)
    -&gt; IxStateT
         m
         generator
         generator
         (Tensor
            (Or
               (Gradient RequiresGradient)
               inputGradient
               (Or (Gradient RequiresGradient) gradient posGradient))
            (Unify
               (Layout LayoutType)
               inputLayout
               (Unify (Layout LayoutType) ('Layout 'Dense) posLayout))
            (Unify
               (Device (DeviceType Nat))
               inputDevice
               (Unify (Device (DeviceType Nat)) device posDevice))
            (Unify
               (DataType DType)
               inputDataType
               (Seq
                  (Unify (DataType DType) posDataType ('DataType 'Int64)) dataType))
            (BroadcastShapesF
               inputShape
               (EmbeddingF ('Shape '[posEncDim, inputEmbedDim]) posShape))))
-&gt; IxStateT
     m
     generator
     generator
     (Tensor
        (Or
           (Gradient RequiresGradient)
           inputGradient
           (Or (Gradient RequiresGradient) gradient posGradient))
        (Unify
           (Layout LayoutType)
           inputLayout
           (Unify (Layout LayoutType) ('Layout 'Dense) posLayout))
        (Unify
           (Device (DeviceType Nat))
           inputDevice
           (Unify (Device (DeviceType Nat)) device posDevice))
        (Unify
           (DataType DType)
           inputDataType
           (Seq
              (Unify (DataType DType) posDataType ('DataType 'Int64)) dataType))
        (BroadcastShapesF
           inputShape
           (EmbeddingF ('Shape '[posEncDim, inputEmbedDim]) posShape)))
forall k1 (m :: k1 -&gt; k1 -&gt; * -&gt; *) (i :: k1) (j :: k1) a
       (k2 :: k1) b.
IxMonad m =&gt;
m i j a -&gt; (a -&gt; m j k2 b) -&gt; m i k2 b
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&gt;&gt;&gt;=</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor
  (Or
     (Gradient RequiresGradient)
     inputGradient
     (Or (Gradient RequiresGradient) gradient posGradient))
  (Unify
     (Layout LayoutType)
     inputLayout
     (Unify (Layout LayoutType) ('Layout 'Dense) posLayout))
  (Unify
     (Device (DeviceType Nat))
     inputDevice
     (Unify (Device (DeviceType Nat)) device posDevice))
  (Unify
     (DataType DType)
     inputDataType
     (Seq
        (Unify (DataType DType) posDataType ('DataType 'Int64)) dataType))
  (BroadcastShapesF
     inputShape
     (EmbeddingF ('Shape '[posEncDim, inputEmbedDim]) posShape))
-&gt; IxStateT
     m
     generator
     generator
     (Tensor
        (Or
           (Gradient RequiresGradient)
           inputGradient
           (Or (Gradient RequiresGradient) gradient posGradient))
        (Unify
           (Layout LayoutType)
           inputLayout
           (Unify (Layout LayoutType) ('Layout 'Dense) posLayout))
        (Unify
           (Device (DeviceType Nat))
           inputDevice
           (Unify (Device (DeviceType Nat)) device posDevice))
        (Unify
           (DataType DType)
           inputDataType
           (Seq
              (Unify (DataType DType) posDataType ('DataType 'Int64)) dataType))
        (BroadcastShapesF
           inputShape
           (EmbeddingF ('Shape '[posEncDim, inputEmbedDim]) posShape)))
forall k (m :: k -&gt; k -&gt; * -&gt; *) a (i :: k).
IxPointed m =&gt;
a -&gt; m i i a
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-identifier hs-var">ireturn</span></a></span><span> </span><span class="annot"><span class="annottext">(Tensor
   (Or
      (Gradient RequiresGradient)
      inputGradient
      (Or (Gradient RequiresGradient) gradient posGradient))
   (Unify
      (Layout LayoutType)
      inputLayout
      (Unify (Layout LayoutType) ('Layout 'Dense) posLayout))
   (Unify
      (Device (DeviceType Nat))
      inputDevice
      (Unify (Device (DeviceType Nat)) device posDevice))
   (Unify
      (DataType DType)
      inputDataType
      (Seq
         (Unify (DataType DType) posDataType ('DataType 'Int64)) dataType))
   (BroadcastShapesF
      inputShape
      (EmbeddingF ('Shape '[posEncDim, inputEmbedDim]) posShape))
 -&gt; IxStateT
      m
      generator
      generator
      (Tensor
         (Or
            (Gradient RequiresGradient)
            inputGradient
            (Or (Gradient RequiresGradient) gradient posGradient))
         (Unify
            (Layout LayoutType)
            inputLayout
            (Unify (Layout LayoutType) ('Layout 'Dense) posLayout))
         (Unify
            (Device (DeviceType Nat))
            inputDevice
            (Unify (Device (DeviceType Nat)) device posDevice))
         (Unify
            (DataType DType)
            inputDataType
            (Seq
               (Unify (DataType DType) posDataType ('DataType 'Int64)) dataType))
         (BroadcastShapesF
            inputShape
            (EmbeddingF ('Shape '[posEncDim, inputEmbedDim]) posShape))))
-&gt; (Tensor
      (Or (Gradient RequiresGradient) gradient posGradient)
      (Unify (Layout LayoutType) ('Layout 'Dense) posLayout)
      (Unify (Device (DeviceType Nat)) device posDevice)
      (Seq
         (Unify (DataType DType) posDataType ('DataType 'Int64)) dataType)
      (EmbeddingF ('Shape '[posEncDim, inputEmbedDim]) posShape)
    -&gt; Tensor
         (Or
            (Gradient RequiresGradient)
            inputGradient
            (Or (Gradient RequiresGradient) gradient posGradient))
         (Unify
            (Layout LayoutType)
            inputLayout
            (Unify (Layout LayoutType) ('Layout 'Dense) posLayout))
         (Unify
            (Device (DeviceType Nat))
            inputDevice
            (Unify (Device (DeviceType Nat)) device posDevice))
         (Unify
            (DataType DType)
            inputDataType
            (Seq
               (Unify (DataType DType) posDataType ('DataType 'Int64)) dataType))
         (BroadcastShapesF
            inputShape
            (EmbeddingF ('Shape '[posEncDim, inputEmbedDim]) posShape)))
-&gt; Tensor
     (Or (Gradient RequiresGradient) gradient posGradient)
     (Unify (Layout LayoutType) ('Layout 'Dense) posLayout)
     (Unify (Device (DeviceType Nat)) device posDevice)
     (Seq
        (Unify (DataType DType) posDataType ('DataType 'Int64)) dataType)
     (EmbeddingF ('Shape '[posEncDim, inputEmbedDim]) posShape)
-&gt; IxStateT
     m
     generator
     generator
     (Tensor
        (Or
           (Gradient RequiresGradient)
           inputGradient
           (Or (Gradient RequiresGradient) gradient posGradient))
        (Unify
           (Layout LayoutType)
           inputLayout
           (Unify (Layout LayoutType) ('Layout 'Dense) posLayout))
        (Unify
           (Device (DeviceType Nat))
           inputDevice
           (Unify (Device (DeviceType Nat)) device posDevice))
        (Unify
           (DataType DType)
           inputDataType
           (Seq
              (Unify (DataType DType) posDataType ('DataType 'Int64)) dataType))
        (BroadcastShapesF
           inputShape
           (EmbeddingF ('Shape '[posEncDim, inputEmbedDim]) posShape)))
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">Tensor
  inputGradient inputLayout inputDevice inputDataType inputShape
</span><a href="#local-6989586621679771026"><span class="hs-identifier hs-var">input</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor
  inputGradient inputLayout inputDevice inputDataType inputShape
-&gt; Tensor
     (Or (Gradient RequiresGradient) gradient posGradient)
     (Unify (Layout LayoutType) ('Layout 'Dense) posLayout)
     (Unify (Device (DeviceType Nat)) device posDevice)
     (Seq
        (Unify (DataType DType) posDataType ('DataType 'Int64)) dataType)
     (EmbeddingF ('Shape '[posEncDim, inputEmbedDim]) posShape)
-&gt; Tensor
     (inputGradient
      &lt;|&gt; Or (Gradient RequiresGradient) gradient posGradient)
     (inputLayout
      &lt;+&gt; Unify (Layout LayoutType) ('Layout 'Dense) posLayout)
     (inputDevice &lt;+&gt; Unify (Device (DeviceType Nat)) device posDevice)
     (inputDataType
      &lt;+&gt; Seq
            (Unify (DataType DType) posDataType ('DataType 'Int64)) dataType)
     (BroadcastShapesF
        inputShape
        (EmbeddingF ('Shape '[posEncDim, inputEmbedDim]) posShape))
forall (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)])
       (gradient' :: Gradient RequiresGradient)
       (layout' :: Layout LayoutType) (device' :: Device (DeviceType Nat))
       (dataType' :: DataType DType)
       (shape' :: Shape [Dim (Name Symbol) (Size Nat)]).
Tensor gradient layout device dataType shape
-&gt; Tensor gradient' layout' device' dataType' shape'
-&gt; Tensor
     (gradient &lt;|&gt; gradient')
     (layout &lt;+&gt; layout')
     (device &lt;+&gt; device')
     (dataType &lt;+&gt; dataType')
     (BroadcastShapesF shape shape')
</span><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#add"><span class="hs-operator hs-var">`add`</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-686"></span><span>            </span><span class="annot"><span class="annottext">IxStateT
  m
  generator
  generator
  (Tensor
     (Or
        (Gradient RequiresGradient)
        inputGradient
        (Or (Gradient RequiresGradient) gradient posGradient))
     (Unify
        (Layout LayoutType)
        inputLayout
        (Unify (Layout LayoutType) ('Layout 'Dense) posLayout))
     (Unify
        (Device (DeviceType Nat))
        inputDevice
        (Unify (Device (DeviceType Nat)) device posDevice))
     (Unify
        (DataType DType)
        inputDataType
        (Seq
           (Unify (DataType DType) posDataType ('DataType 'Int64)) dataType))
     (BroadcastShapesF
        inputShape
        (EmbeddingF ('Shape '[posEncDim, inputEmbedDim]) posShape)))
-&gt; (Tensor
      (Or
         (Gradient RequiresGradient)
         inputGradient
         (Or (Gradient RequiresGradient) gradient posGradient))
      (Unify
         (Layout LayoutType)
         inputLayout
         (Unify (Layout LayoutType) ('Layout 'Dense) posLayout))
      (Unify
         (Device (DeviceType Nat))
         inputDevice
         (Unify (Device (DeviceType Nat)) device posDevice))
      (Unify
         (DataType DType)
         inputDataType
         (Seq
            (Unify (DataType DType) posDataType ('DataType 'Int64)) dataType))
      (BroadcastShapesF
         inputShape
         (EmbeddingF ('Shape '[posEncDim, inputEmbedDim]) posShape))
    -&gt; IxStateT m generator generator layerNormOutput)
-&gt; IxStateT m generator generator layerNormOutput
forall k1 (m :: k1 -&gt; k1 -&gt; * -&gt; *) (i :: k1) (j :: k1) a
       (k2 :: k1) b.
IxMonad m =&gt;
m i j a -&gt; (a -&gt; m j k2 b) -&gt; m i k2 b
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&gt;&gt;&gt;=</span></a></span><span> </span><span class="annot"><span class="annottext">(generator -&gt; m (layerNormOutput, generator))
-&gt; IxStateT m generator generator layerNormOutput
forall (m :: * -&gt; *) i j a. (i -&gt; m (a, j)) -&gt; IxStateT m i j a
</span><a href="../file:///nix/store/8vjaffqxij7bih93d9mlzmc7ksanlw0i-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier hs-var">IxStateT</span></a></span><span> </span><span class="annot"><span class="annottext">((generator -&gt; m (layerNormOutput, generator))
 -&gt; IxStateT m generator generator layerNormOutput)
-&gt; (Tensor
      (Or
         (Gradient RequiresGradient)
         inputGradient
         (Or (Gradient RequiresGradient) gradient posGradient))
      (Unify
         (Layout LayoutType)
         inputLayout
         (Unify (Layout LayoutType) ('Layout 'Dense) posLayout))
      (Unify
         (Device (DeviceType Nat))
         inputDevice
         (Unify (Device (DeviceType Nat)) device posDevice))
      (Unify
         (DataType DType)
         inputDataType
         (Seq
            (Unify (DataType DType) posDataType ('DataType 'Int64)) dataType))
      (BroadcastShapesF
         inputShape
         (EmbeddingF ('Shape '[posEncDim, inputEmbedDim]) posShape))
    -&gt; generator -&gt; m (layerNormOutput, generator))
-&gt; Tensor
     (Or
        (Gradient RequiresGradient)
        inputGradient
        (Or (Gradient RequiresGradient) gradient posGradient))
     (Unify
        (Layout LayoutType)
        inputLayout
        (Unify (Layout LayoutType) ('Layout 'Dense) posLayout))
     (Unify
        (Device (DeviceType Nat))
        inputDevice
        (Unify (Device (DeviceType Nat)) device posDevice))
     (Unify
        (DataType DType)
        inputDataType
        (Seq
           (Unify (DataType DType) posDataType ('DataType 'Int64)) dataType))
     (BroadcastShapesF
        inputShape
        (EmbeddingF ('Shape '[posEncDim, inputEmbedDim]) posShape))
-&gt; IxStateT m generator generator layerNormOutput
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">LayerNorm
  'WithBias gradient device dataType ('Shape '[inputEmbedDim])
-&gt; Tensor
     (Or
        (Gradient RequiresGradient)
        inputGradient
        (Or (Gradient RequiresGradient) gradient posGradient))
     (Unify
        (Layout LayoutType)
        inputLayout
        (Unify (Layout LayoutType) ('Layout 'Dense) posLayout))
     (Unify
        (Device (DeviceType Nat))
        inputDevice
        (Unify (Device (DeviceType Nat)) device posDevice))
     (Unify
        (DataType DType)
        inputDataType
        (Seq
           (Unify (DataType DType) posDataType ('DataType 'Int64)) dataType))
     (BroadcastShapesF
        inputShape
        (EmbeddingF ('Shape '[posEncDim, inputEmbedDim]) posShape))
-&gt; generator
-&gt; m (layerNormOutput, generator)
forall model input generator output generatorOutput (m :: * -&gt; *).
(HasForward model input generator output generatorOutput,
 MonadThrow m) =&gt;
model -&gt; input -&gt; generator -&gt; m (output, generatorOutput)
</span><a href="Torch.GraduallyTyped.NN.Class.html#forward"><span class="hs-identifier hs-var">forward</span></a></span><span> </span><span class="annot"><span class="annottext">LayerNorm
  'WithBias gradient device dataType ('Shape '[inputEmbedDim])
TEEmbedLayerNormF 'BART gradient device dataType inputEmbedDim
</span><a href="#local-6989586621679771030"><span class="hs-identifier hs-var">teEmbedLayerNorm</span></a></span><span>
</span><span id="line-687"></span><span>            </span><span class="annot"><span class="annottext">IxStateT m generator generator layerNormOutput
-&gt; (layerNormOutput
    -&gt; IxStateT m generator dropoutGeneratorOutput dropoutOutput)
-&gt; IxStateT m generator dropoutGeneratorOutput dropoutOutput
forall k1 (m :: k1 -&gt; k1 -&gt; * -&gt; *) (i :: k1) (j :: k1) a
       (k2 :: k1) b.
IxMonad m =&gt;
m i j a -&gt; (a -&gt; m j k2 b) -&gt; m i k2 b
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&gt;&gt;&gt;=</span></a></span><span> </span><span class="annot"><span class="annottext">(generator -&gt; m (dropoutOutput, dropoutGeneratorOutput))
-&gt; IxStateT m generator dropoutGeneratorOutput dropoutOutput
forall (m :: * -&gt; *) i j a. (i -&gt; m (a, j)) -&gt; IxStateT m i j a
</span><a href="../file:///nix/store/8vjaffqxij7bih93d9mlzmc7ksanlw0i-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier hs-var">IxStateT</span></a></span><span> </span><span class="annot"><span class="annottext">((generator -&gt; m (dropoutOutput, dropoutGeneratorOutput))
 -&gt; IxStateT m generator dropoutGeneratorOutput dropoutOutput)
-&gt; (layerNormOutput
    -&gt; generator -&gt; m (dropoutOutput, dropoutGeneratorOutput))
-&gt; layerNormOutput
-&gt; IxStateT m generator dropoutGeneratorOutput dropoutOutput
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">Dropout dropoutP
-&gt; layerNormOutput
-&gt; generator
-&gt; m (dropoutOutput, dropoutGeneratorOutput)
forall model input generator output generatorOutput (m :: * -&gt; *).
(HasForward model input generator output generatorOutput,
 MonadThrow m) =&gt;
model -&gt; input -&gt; generator -&gt; m (output, generatorOutput)
</span><a href="Torch.GraduallyTyped.NN.Class.html#forward"><span class="hs-identifier hs-var">forward</span></a></span><span> </span><span class="annot"><span class="annottext">Dropout dropoutP
TEDropoutF 'BART dropoutP
</span><a href="#local-6989586621679771028"><span class="hs-identifier hs-var">teDropout</span></a></span><span>
</span><span id="line-688"></span><span>            </span><span class="annot"><span class="annottext">IxStateT m generator dropoutGeneratorOutput dropoutOutput
-&gt; (dropoutOutput
    -&gt; IxStateT m dropoutGeneratorOutput generatorOutput output)
-&gt; IxStateT m generator generatorOutput output
forall k1 (m :: k1 -&gt; k1 -&gt; * -&gt; *) (i :: k1) (j :: k1) a
       (k2 :: k1) b.
IxMonad m =&gt;
m i j a -&gt; (a -&gt; m j k2 b) -&gt; m i k2 b
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&gt;&gt;&gt;=</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">\</span><span id="local-6989586621679771022"><span class="annot"><span class="annottext">dropoutOutput
</span><a href="#local-6989586621679771022"><span class="hs-identifier hs-var">input'</span></a></span></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><span class="annottext">(dropoutGeneratorOutput -&gt; m (output, generatorOutput))
-&gt; IxStateT m dropoutGeneratorOutput generatorOutput output
forall (m :: * -&gt; *) i j a. (i -&gt; m (a, j)) -&gt; IxStateT m i j a
</span><a href="../file:///nix/store/8vjaffqxij7bih93d9mlzmc7ksanlw0i-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier hs-var">IxStateT</span></a></span><span> </span><span class="annot"><span class="annottext">((dropoutGeneratorOutput -&gt; m (output, generatorOutput))
 -&gt; IxStateT m dropoutGeneratorOutput generatorOutput output)
-&gt; (dropoutGeneratorOutput -&gt; m (output, generatorOutput))
-&gt; IxStateT m dropoutGeneratorOutput generatorOutput output
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">TransformerStack
  'BART
  numLayers
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  inputEmbedDim
  ffnDim
  dropoutP
-&gt; (dropoutOutput,
    Tensor
      attentionMaskGradient
      attentionMaskLayout
      attentionMaskDevice
      attentionMaskDataType
      (UnsqueezeF ('SelectDim ('ByIndex 1)) attentionMaskShape))
-&gt; dropoutGeneratorOutput
-&gt; m (output, generatorOutput)
forall model input generator output generatorOutput (m :: * -&gt; *).
(HasForward model input generator output generatorOutput,
 MonadThrow m) =&gt;
model -&gt; input -&gt; generator -&gt; m (output, generatorOutput)
</span><a href="Torch.GraduallyTyped.NN.Class.html#forward"><span class="hs-identifier hs-var">forward</span></a></span><span> </span><span class="annot"><span class="annottext">TransformerStack
  'BART
  numLayers
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  inputEmbedDim
  ffnDim
  dropoutP
TEStackF
  'BART
  numLayers
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  inputEmbedDim
  ffnDim
  dropoutP
</span><a href="#local-6989586621679771031"><span class="hs-identifier hs-var">teStack</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">dropoutOutput
</span><a href="#local-6989586621679771022"><span class="hs-identifier hs-var">input'</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">Tensor
  attentionMaskGradient
  attentionMaskLayout
  attentionMaskDevice
  attentionMaskDataType
  (UnsqueezeF ('SelectDim ('ByIndex 1)) attentionMaskShape)
</span><a href="#local-6989586621679771023"><span class="hs-identifier hs-var">attentionBias</span></a></span><span class="hs-special">)</span><span class="hs-special">)</span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span><span>
</span><span id="line-689"></span><span>
</span><span id="line-690"></span><span class="hs-comment">-- | 'HasForward' instance for @TransformerEncoder numLayers 'MBART@.</span><span>
</span><span id="line-691"></span><span class="hs-comment">--</span><span>
</span><span id="line-692"></span><span class="hs-comment">-- @</span><span>
</span><span id="line-693"></span><span class="hs-comment">-- &#9484;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9488;  &#9484;&#9472;&#9472;&#9472;&#9472;&#9472;&#9488;  &#9484;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9488;</span><span>
</span><span id="line-694"></span><span class="hs-comment">-- &#9474; input &#9474;  &#9474; pos &#9474;  &#9474; attentionMask &#9474;</span><span>
</span><span id="line-695"></span><span class="hs-comment">-- &#9492;&#9472;&#9472;&#9472;&#9516;&#9472;&#9472;&#9472;&#9496;  &#9492;&#9472;&#9472;&#9472;&#9472;&#9472;&#9496;  &#9492;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9516;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9496;</span><span>
</span><span id="line-696"></span><span class="hs-comment">--     &#9474;         &#9474;             &#9474;</span><span>
</span><span id="line-697"></span><span class="hs-comment">--     &#9474;         &#9660;             &#9474;</span><span>
</span><span id="line-698"></span><span class="hs-comment">--     &#9474;     tePosEnc          &#9474;</span><span>
</span><span id="line-699"></span><span class="hs-comment">--     &#9474;         &#9474;             &#9474;</span><span>
</span><span id="line-700"></span><span class="hs-comment">--     &#9492;&#9472;&#9472;&#9658;add&#9668;&#9472;&#9472;&#9496;             &#9474;</span><span>
</span><span id="line-701"></span><span class="hs-comment">--          &#9474;                  &#9474;</span><span>
</span><span id="line-702"></span><span class="hs-comment">--          &#9660;                  &#9474;</span><span>
</span><span id="line-703"></span><span class="hs-comment">--   teEmbedLayerNorm          &#9474;</span><span>
</span><span id="line-704"></span><span class="hs-comment">--          &#9660;                  &#9660;</span><span>
</span><span id="line-705"></span><span class="hs-comment">--      teDropout          unsqueeze</span><span>
</span><span id="line-706"></span><span class="hs-comment">--          &#9660;                  &#9474;</span><span>
</span><span id="line-707"></span><span class="hs-comment">--       teStack&#9668;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9496;</span><span>
</span><span id="line-708"></span><span class="hs-comment">--          &#9660;</span><span>
</span><span id="line-709"></span><span class="hs-comment">--     teLayerNorm</span><span>
</span><span id="line-710"></span><span class="hs-comment">--          &#9474;</span><span>
</span><span id="line-711"></span><span class="hs-comment">--          &#9660;</span><span>
</span><span id="line-712"></span><span class="hs-comment">--     &#9484;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9488;</span><span>
</span><span id="line-713"></span><span class="hs-comment">--     &#9474; output &#9474;</span><span>
</span><span id="line-714"></span><span class="hs-comment">--     &#9492;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9496;</span><span>
</span><span id="line-715"></span><span class="hs-comment">-- @</span><span>
</span><span id="line-716"></span><span>
</span><span id="line-717"></span><span class="hs-comment">-- | 'HasForward' instance for @TransformerEncoder numLayers 'BERT@.</span><span>
</span><span id="line-718"></span><span class="hs-comment">--</span><span>
</span><span id="line-719"></span><span class="hs-comment">-- @</span><span>
</span><span id="line-720"></span><span class="hs-comment">-- &#9484;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9488;  &#9484;&#9472;&#9472;&#9472;&#9472;&#9472;&#9488;  &#9484;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9488;</span><span>
</span><span id="line-721"></span><span class="hs-comment">-- &#9474; input &#9474;  &#9474; pos &#9474;  &#9474; attentionMask &#9474;</span><span>
</span><span id="line-722"></span><span class="hs-comment">-- &#9492;&#9472;&#9472;&#9472;&#9516;&#9472;&#9472;&#9472;&#9496;  &#9492;&#9472;&#9472;&#9472;&#9472;&#9472;&#9496;  &#9492;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9516;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9496;</span><span>
</span><span id="line-723"></span><span class="hs-comment">--     &#9474;         &#9474;             &#9474;</span><span>
</span><span id="line-724"></span><span class="hs-comment">--     &#9474;         &#9660;             &#9474;</span><span>
</span><span id="line-725"></span><span class="hs-comment">--     &#9474;     tePosEnc          &#9474;</span><span>
</span><span id="line-726"></span><span class="hs-comment">--     &#9474;         &#9474;             &#9474;</span><span>
</span><span id="line-727"></span><span class="hs-comment">--     &#9492;&#9472;&#9472;&#9658;add&#9668;&#9472;&#9472;&#9496;             &#9474;</span><span>
</span><span id="line-728"></span><span class="hs-comment">--          &#9474;                  &#9474;</span><span>
</span><span id="line-729"></span><span class="hs-comment">--          &#9660;                  &#9474;</span><span>
</span><span id="line-730"></span><span class="hs-comment">--   teEmbedLayerNorm          &#9474;</span><span>
</span><span id="line-731"></span><span class="hs-comment">--          &#9660;                  &#9660;</span><span>
</span><span id="line-732"></span><span class="hs-comment">--      teDropout          unsqueeze</span><span>
</span><span id="line-733"></span><span class="hs-comment">--          &#9660;                  &#9474;</span><span>
</span><span id="line-734"></span><span class="hs-comment">--       teStack&#9668;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9496;</span><span>
</span><span id="line-735"></span><span class="hs-comment">--          &#9474;</span><span>
</span><span id="line-736"></span><span class="hs-comment">--          &#9660;</span><span>
</span><span id="line-737"></span><span class="hs-comment">--     &#9484;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9488;</span><span>
</span><span id="line-738"></span><span class="hs-comment">--     &#9474; output &#9474;</span><span>
</span><span id="line-739"></span><span class="hs-comment">--     &#9492;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9496;</span><span>
</span><span id="line-740"></span><span class="hs-comment">-- @</span><span>
</span><span id="line-741"></span><span id="local-6989586621679770990"><span id="local-6989586621679770991"><span id="local-6989586621679770992"><span id="local-6989586621679770993"><span id="local-6989586621679770994"><span id="local-6989586621679770995"><span id="local-6989586621679770996"><span id="local-6989586621679770997"><span id="local-6989586621679770998"><span id="local-6989586621679770999"><span id="local-6989586621679771000"><span id="local-6989586621679771001"><span id="local-6989586621679771002"><span id="local-6989586621679771003"><span id="local-6989586621679771004"><span id="local-6989586621679771005"><span id="local-6989586621679771006"><span id="local-6989586621679771007"><span id="local-6989586621679771008"><span id="local-6989586621679771009"><span id="local-6989586621679771010"><span id="local-6989586621679771011"><span id="local-6989586621679771012"><span id="local-6989586621679771013"><span id="local-6989586621679771014"><span id="local-6989586621679771015"><span id="local-6989586621679771016"><span id="local-6989586621679771017"><span id="local-6989586621679771018"><span id="local-6989586621679771019"><span id="local-6989586621679771020"><span id="local-6989586621679771021"><span class="hs-keyword">instance</span><span>
</span><span id="line-742"></span><span>  </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasForward"><span class="hs-identifier hs-type">HasForward</span></a></span><span>
</span><span id="line-743"></span><span>      </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Encoder.html#TEEmbedLayerNormF"><span class="hs-identifier hs-type">TEEmbedLayerNormF</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#BERT"><span class="hs-identifier hs-type">BERT</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771021"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771020"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771019"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771018"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-744"></span><span>      </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span>
</span><span id="line-745"></span><span>          </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679771017"><span class="hs-identifier hs-type">inputGradient</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%7C%3E"><span class="hs-operator hs-type">&lt;|&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771021"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%7C%3E"><span class="hs-operator hs-type">&lt;|&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771016"><span class="hs-identifier hs-type">posGradient</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-746"></span><span>          </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679771015"><span class="hs-identifier hs-type">inputLayout</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#Layout"><span class="hs-identifier hs-type">Layout</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#Dense"><span class="hs-identifier hs-type">Dense</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771014"><span class="hs-identifier hs-type">posLayout</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-747"></span><span>          </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679771013"><span class="hs-identifier hs-type">inputDevice</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771020"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771012"><span class="hs-identifier hs-type">posDevice</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-748"></span><span>          </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679771011"><span class="hs-identifier hs-type">inputDataType</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Prelude.html#Seq"><span class="hs-identifier hs-type">Seq</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679771010"><span class="hs-identifier hs-type">posDataType</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#DataType"><span class="hs-identifier hs-type">DataType</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#Int64"><span class="hs-identifier hs-type">Int64</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679771019"><span class="hs-identifier hs-type">dataType</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-749"></span><span>          </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Class.html#BroadcastShapesF"><span class="hs-identifier hs-type">BroadcastShapesF</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771009"><span class="hs-identifier hs-type">inputShape</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Functional.Sparse.html#EmbeddingF"><span class="hs-identifier hs-type">EmbeddingF</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Shape"><span class="hs-identifier hs-type">Shape</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="annot"><a href="#local-6989586621679771008"><span class="hs-identifier hs-type">posEncDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679771018"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span><span class="hs-special">]</span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679771007"><span class="hs-identifier hs-type">posShape</span></a></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-750"></span><span>      </span><span class="hs-special">)</span><span>
</span><span id="line-751"></span><span>      </span><span class="annot"><a href="#local-6989586621679771006"><span class="hs-identifier hs-type">generator</span></a></span><span>
</span><span id="line-752"></span><span>      </span><span class="annot"><a href="#local-6989586621679771005"><span class="hs-identifier hs-type">layerNormOutput</span></a></span><span>
</span><span id="line-753"></span><span>      </span><span class="annot"><a href="#local-6989586621679771006"><span class="hs-identifier hs-type">generator</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-754"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasForward"><span class="hs-identifier hs-type">HasForward</span></a></span><span>
</span><span id="line-755"></span><span>      </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Encoder.html#TEDropoutF"><span class="hs-identifier hs-type">TEDropoutF</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#BERT"><span class="hs-identifier hs-type">BERT</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771004"><span class="hs-identifier hs-type">dropoutP</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-756"></span><span>      </span><span class="annot"><a href="#local-6989586621679771005"><span class="hs-identifier hs-type">layerNormOutput</span></a></span><span>
</span><span id="line-757"></span><span>      </span><span class="annot"><a href="#local-6989586621679771006"><span class="hs-identifier hs-type">generator</span></a></span><span>
</span><span id="line-758"></span><span>      </span><span class="annot"><a href="#local-6989586621679771003"><span class="hs-identifier hs-type">dropoutOutput</span></a></span><span>
</span><span id="line-759"></span><span>      </span><span class="annot"><a href="#local-6989586621679771002"><span class="hs-identifier hs-type">dropoutGeneratorOutput</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-760"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasForward"><span class="hs-identifier hs-type">HasForward</span></a></span><span>
</span><span id="line-761"></span><span>      </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Encoder.html#TEStackF"><span class="hs-identifier hs-type">TEStackF</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#BERT"><span class="hs-identifier hs-type">BERT</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771001"><span class="hs-identifier hs-type">numLayers</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771021"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771020"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771019"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771000"><span class="hs-identifier hs-type">headDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679770999"><span class="hs-identifier hs-type">headEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679770998"><span class="hs-identifier hs-type">embedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771018"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679770997"><span class="hs-identifier hs-type">ffnDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771004"><span class="hs-identifier hs-type">dropoutP</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-762"></span><span>      </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="#local-6989586621679771003"><span class="hs-identifier hs-type">dropoutOutput</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-763"></span><span>        </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span>
</span><span id="line-764"></span><span>          </span><span class="annot"><a href="#local-6989586621679770996"><span class="hs-identifier hs-type">attentionMaskGradient</span></a></span><span>
</span><span id="line-765"></span><span>          </span><span class="annot"><a href="#local-6989586621679770995"><span class="hs-identifier hs-type">attentionMaskLayout</span></a></span><span>
</span><span id="line-766"></span><span>          </span><span class="annot"><a href="#local-6989586621679770994"><span class="hs-identifier hs-type">attentionMaskDevice</span></a></span><span>
</span><span id="line-767"></span><span>          </span><span class="annot"><a href="#local-6989586621679770993"><span class="hs-identifier hs-type">attentionMaskDataType</span></a></span><span>
</span><span id="line-768"></span><span>          </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.IndexingSlicingJoining.html#UnsqueezeF"><span class="hs-identifier hs-type">UnsqueezeF</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SelectDim"><span class="hs-identifier hs-type">SelectDim</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#ByIndex"><span class="hs-identifier hs-type">ByIndex</span></a></span><span> </span><span class="annot"><span class="hs-number">1</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679770992"><span class="hs-identifier hs-type">attentionMaskShape</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-769"></span><span>      </span><span class="hs-special">)</span><span>
</span><span id="line-770"></span><span>      </span><span class="annot"><a href="#local-6989586621679771002"><span class="hs-identifier hs-type">dropoutGeneratorOutput</span></a></span><span>
</span><span id="line-771"></span><span>      </span><span class="annot"><a href="#local-6989586621679770991"><span class="hs-identifier hs-type">output</span></a></span><span>
</span><span id="line-772"></span><span>      </span><span class="annot"><a href="#local-6989586621679770990"><span class="hs-identifier hs-type">generatorOutput</span></a></span><span>
</span><span id="line-773"></span><span>  </span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-774"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasForward"><span class="hs-identifier hs-type">HasForward</span></a></span><span>
</span><span id="line-775"></span><span>    </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Encoder.html#TransformerEncoder"><span class="hs-identifier hs-type">TransformerEncoder</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#BERT"><span class="hs-identifier hs-type">BERT</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771001"><span class="hs-identifier hs-type">numLayers</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771021"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771020"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771019"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771000"><span class="hs-identifier hs-type">headDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679770999"><span class="hs-identifier hs-type">headEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679770998"><span class="hs-identifier hs-type">embedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771018"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679770997"><span class="hs-identifier hs-type">ffnDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771008"><span class="hs-identifier hs-type">posEncDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771004"><span class="hs-identifier hs-type">dropoutP</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-776"></span><span>    </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771017"><span class="hs-identifier hs-type">inputGradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771015"><span class="hs-identifier hs-type">inputLayout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771013"><span class="hs-identifier hs-type">inputDevice</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771011"><span class="hs-identifier hs-type">inputDataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771009"><span class="hs-identifier hs-type">inputShape</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-777"></span><span>      </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771016"><span class="hs-identifier hs-type">posGradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771014"><span class="hs-identifier hs-type">posLayout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771012"><span class="hs-identifier hs-type">posDevice</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771010"><span class="hs-identifier hs-type">posDataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679771007"><span class="hs-identifier hs-type">posShape</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-778"></span><span>      </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679770996"><span class="hs-identifier hs-type">attentionMaskGradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679770995"><span class="hs-identifier hs-type">attentionMaskLayout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679770994"><span class="hs-identifier hs-type">attentionMaskDevice</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679770993"><span class="hs-identifier hs-type">attentionMaskDataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679770992"><span class="hs-identifier hs-type">attentionMaskShape</span></a></span><span>
</span><span id="line-779"></span><span>    </span><span class="hs-special">)</span><span>
</span><span id="line-780"></span><span>    </span><span class="annot"><a href="#local-6989586621679771006"><span class="hs-identifier hs-type">generator</span></a></span><span>
</span><span id="line-781"></span><span>    </span><span class="annot"><a href="#local-6989586621679770991"><span class="hs-identifier hs-type">output</span></a></span><span>
</span><span id="line-782"></span><span>    </span><span class="annot"><a href="#local-6989586621679770990"><span class="hs-identifier hs-type">generatorOutput</span></a></span><span>
</span><span id="line-783"></span><span>  </span><span class="hs-keyword">where</span><span>
</span><span id="line-784"></span><span>  </span><span id="local-6989586621679770988"><span class="annot"><span class="annottext">forward :: TransformerEncoder
  'BERT
  numLayers
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  inputEmbedDim
  ffnDim
  posEncDim
  dropoutP
-&gt; (Tensor
      inputGradient inputLayout inputDevice inputDataType inputShape,
    Tensor posGradient posLayout posDevice posDataType posShape,
    Tensor
      attentionMaskGradient
      attentionMaskLayout
      attentionMaskDevice
      attentionMaskDataType
      attentionMaskShape)
-&gt; generator
-&gt; m (output, generatorOutput)
</span><a href="#local-6989586621679770988"><span class="hs-identifier hs-var hs-var hs-var hs-var">forward</span></a></span></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Encoder.html#TransformerEncoder"><span class="hs-identifier hs-type">TransformerEncoder</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Encoder.html#GTransformerEncoder"><span class="hs-identifier hs-type">GTransformerEncoder</span></a></span><span> </span><span class="hs-special">{</span><span id="local-6989586621679770983"><span id="local-6989586621679770984"><span id="local-6989586621679770985"><span id="local-6989586621679770986"><span id="local-6989586621679770987"><span class="annot"><span class="annottext">TEPosEncF
  'BERT gradient device dataType headDim inputEmbedDim posEncDim
TEDropoutF 'BERT dropoutP
TELayerNormF 'BERT gradient device dataType inputEmbedDim
TEEmbedLayerNormF 'BERT gradient device dataType inputEmbedDim
TEStackF
  'BERT
  numLayers
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  inputEmbedDim
  ffnDim
  dropoutP
tePosEnc :: TEPosEncF
  'BERT gradient device dataType headDim inputEmbedDim posEncDim
teDropout :: TEDropoutF 'BERT dropoutP
teLayerNorm :: TELayerNormF 'BERT gradient device dataType inputEmbedDim
teEmbedLayerNorm :: TEEmbedLayerNormF 'BERT gradient device dataType inputEmbedDim
teStack :: TEStackF
  'BERT
  numLayers
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  inputEmbedDim
  ffnDim
  dropoutP
tePosEnc :: forall stack embedLayerNorm layerNorm dropout posEnc.
GTransformerEncoder stack embedLayerNorm layerNorm dropout posEnc
-&gt; posEnc
teDropout :: forall stack embedLayerNorm layerNorm dropout posEnc.
GTransformerEncoder stack embedLayerNorm layerNorm dropout posEnc
-&gt; dropout
teLayerNorm :: forall stack embedLayerNorm layerNorm dropout posEnc.
GTransformerEncoder stack embedLayerNorm layerNorm dropout posEnc
-&gt; layerNorm
teEmbedLayerNorm :: forall stack embedLayerNorm layerNorm dropout posEnc.
GTransformerEncoder stack embedLayerNorm layerNorm dropout posEnc
-&gt; embedLayerNorm
teStack :: forall stack embedLayerNorm layerNorm dropout posEnc.
GTransformerEncoder stack embedLayerNorm layerNorm dropout posEnc
-&gt; stack
</span><a href="#local-6989586621679770983"><span class="hs-glyph hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var">..</span></a></span></span></span></span></span></span><span class="hs-special">}</span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span id="local-6989586621679770982"><span class="annot"><span class="annottext">Tensor
  inputGradient inputLayout inputDevice inputDataType inputShape
</span><a href="#local-6989586621679770982"><span class="hs-identifier hs-var">input</span></a></span></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679770981"><span class="annot"><span class="annottext">Tensor posGradient posLayout posDevice posDataType posShape
</span><a href="#local-6989586621679770981"><span class="hs-identifier hs-var">pos</span></a></span></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679770980"><span class="annot"><span class="annottext">Tensor
  attentionMaskGradient
  attentionMaskLayout
  attentionMaskDevice
  attentionMaskDataType
  attentionMaskShape
</span><a href="#local-6989586621679770980"><span class="hs-identifier hs-var">attentionMask</span></a></span></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-785"></span><span>    </span><span class="hs-keyword">let</span><span> </span><span id="local-6989586621679770979"><span class="annot"><span class="annottext">attentionBias :: Tensor
  attentionMaskGradient
  attentionMaskLayout
  attentionMaskDevice
  attentionMaskDataType
  (UnsqueezeF ('SelectDim ('ByIndex 1)) attentionMaskShape)
</span><a href="#local-6989586621679770979"><span class="hs-identifier hs-var hs-var">attentionBias</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Tensor
  attentionMaskGradient
  attentionMaskLayout
  attentionMaskDevice
  attentionMaskDataType
  attentionMaskShape
-&gt; Tensor
     attentionMaskGradient
     attentionMaskLayout
     attentionMaskDevice
     attentionMaskDataType
     (UnsqueezeF ('SelectDim ('ByIndex 1)) attentionMaskShape)
forall (selectDim :: SelectDim (By Symbol Nat))
       (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)])
       (shape' :: Shape [Dim (Name Symbol) (Size Nat)]).
(shape' ~ UnsqueezeF selectDim shape, SingI selectDim) =&gt;
Tensor gradient layout device dataType shape
-&gt; Tensor gradient layout device dataType shape'
</span><a href="Torch.GraduallyTyped.Tensor.IndexingSlicingJoining.html#unsqueeze"><span class="hs-identifier hs-var">unsqueeze</span></a></span><span> </span><span class="hs-glyph">@</span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SelectDim"><span class="hs-identifier hs-type">SelectDim</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#ByIndex"><span class="hs-identifier hs-type">ByIndex</span></a></span><span> </span><span class="annot"><span class="hs-number">1</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">Tensor
  attentionMaskGradient
  attentionMaskLayout
  attentionMaskDevice
  attentionMaskDataType
  attentionMaskShape
</span><a href="#local-6989586621679770980"><span class="hs-identifier hs-var">attentionMask</span></a></span><span>
</span><span id="line-786"></span><span>     </span><span class="hs-keyword">in</span><span> </span><span class="annot"><span class="annottext">IxStateT m generator generatorOutput output
-&gt; generator -&gt; m (output, generatorOutput)
forall (m :: * -&gt; *) i j a. IxStateT m i j a -&gt; i -&gt; m (a, j)
</span><a href="../file:///nix/store/8vjaffqxij7bih93d9mlzmc7ksanlw0i-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier hs-var hs-var">runIxStateT</span></a></span><span> </span><span class="annot"><span class="annottext">(IxStateT m generator generatorOutput output
 -&gt; generator -&gt; m (output, generatorOutput))
-&gt; IxStateT m generator generatorOutput output
-&gt; generator
-&gt; m (output, generatorOutput)
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span>
</span><span id="line-787"></span><span>          </span><span class="annot"><span class="annottext">Tensor posGradient posLayout posDevice posDataType posShape
-&gt; IxStateT
     m
     generator
     generator
     (Tensor posGradient posLayout posDevice posDataType posShape)
forall k (m :: k -&gt; k -&gt; * -&gt; *) a (i :: k).
IxPointed m =&gt;
a -&gt; m i i a
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-identifier hs-var">ireturn</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor posGradient posLayout posDevice posDataType posShape
</span><a href="#local-6989586621679770981"><span class="hs-identifier hs-var">pos</span></a></span><span>
</span><span id="line-788"></span><span>            </span><span class="annot"><span class="annottext">IxStateT
  m
  generator
  generator
  (Tensor posGradient posLayout posDevice posDataType posShape)
-&gt; (Tensor posGradient posLayout posDevice posDataType posShape
    -&gt; IxStateT
         m
         generator
         generator
         (Tensor
            (Or (Gradient RequiresGradient) gradient posGradient)
            (Unify (Layout LayoutType) ('Layout 'Dense) posLayout)
            (Unify (Device (DeviceType Nat)) device posDevice)
            (Seq
               (Unify (DataType DType) posDataType ('DataType 'Int64)) dataType)
            (EmbeddingF ('Shape '[posEncDim, inputEmbedDim]) posShape)))
-&gt; IxStateT
     m
     generator
     generator
     (Tensor
        (Or (Gradient RequiresGradient) gradient posGradient)
        (Unify (Layout LayoutType) ('Layout 'Dense) posLayout)
        (Unify (Device (DeviceType Nat)) device posDevice)
        (Seq
           (Unify (DataType DType) posDataType ('DataType 'Int64)) dataType)
        (EmbeddingF ('Shape '[posEncDim, inputEmbedDim]) posShape))
forall k1 (m :: k1 -&gt; k1 -&gt; * -&gt; *) (i :: k1) (j :: k1) a
       (k2 :: k1) b.
IxMonad m =&gt;
m i j a -&gt; (a -&gt; m j k2 b) -&gt; m i k2 b
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&gt;&gt;&gt;=</span></a></span><span> </span><span class="annot"><span class="annottext">(generator
 -&gt; m (Tensor
         (Or (Gradient RequiresGradient) gradient posGradient)
         (Unify (Layout LayoutType) ('Layout 'Dense) posLayout)
         (Unify (Device (DeviceType Nat)) device posDevice)
         (Seq
            (Unify (DataType DType) posDataType ('DataType 'Int64)) dataType)
         (EmbeddingF ('Shape '[posEncDim, inputEmbedDim]) posShape),
       generator))
-&gt; IxStateT
     m
     generator
     generator
     (Tensor
        (Or (Gradient RequiresGradient) gradient posGradient)
        (Unify (Layout LayoutType) ('Layout 'Dense) posLayout)
        (Unify (Device (DeviceType Nat)) device posDevice)
        (Seq
           (Unify (DataType DType) posDataType ('DataType 'Int64)) dataType)
        (EmbeddingF ('Shape '[posEncDim, inputEmbedDim]) posShape))
forall (m :: * -&gt; *) i j a. (i -&gt; m (a, j)) -&gt; IxStateT m i j a
</span><a href="../file:///nix/store/8vjaffqxij7bih93d9mlzmc7ksanlw0i-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier hs-var">IxStateT</span></a></span><span> </span><span class="annot"><span class="annottext">((generator
  -&gt; m (Tensor
          (Or (Gradient RequiresGradient) gradient posGradient)
          (Unify (Layout LayoutType) ('Layout 'Dense) posLayout)
          (Unify (Device (DeviceType Nat)) device posDevice)
          (Seq
             (Unify (DataType DType) posDataType ('DataType 'Int64)) dataType)
          (EmbeddingF ('Shape '[posEncDim, inputEmbedDim]) posShape),
        generator))
 -&gt; IxStateT
      m
      generator
      generator
      (Tensor
         (Or (Gradient RequiresGradient) gradient posGradient)
         (Unify (Layout LayoutType) ('Layout 'Dense) posLayout)
         (Unify (Device (DeviceType Nat)) device posDevice)
         (Seq
            (Unify (DataType DType) posDataType ('DataType 'Int64)) dataType)
         (EmbeddingF ('Shape '[posEncDim, inputEmbedDim]) posShape)))
-&gt; (Tensor posGradient posLayout posDevice posDataType posShape
    -&gt; generator
    -&gt; m (Tensor
            (Or (Gradient RequiresGradient) gradient posGradient)
            (Unify (Layout LayoutType) ('Layout 'Dense) posLayout)
            (Unify (Device (DeviceType Nat)) device posDevice)
            (Seq
               (Unify (DataType DType) posDataType ('DataType 'Int64)) dataType)
            (EmbeddingF ('Shape '[posEncDim, inputEmbedDim]) posShape),
          generator))
-&gt; Tensor posGradient posLayout posDevice posDataType posShape
-&gt; IxStateT
     m
     generator
     generator
     (Tensor
        (Or (Gradient RequiresGradient) gradient posGradient)
        (Unify (Layout LayoutType) ('Layout 'Dense) posLayout)
        (Unify (Device (DeviceType Nat)) device posDevice)
        (Seq
           (Unify (DataType DType) posDataType ('DataType 'Int64)) dataType)
        (EmbeddingF ('Shape '[posEncDim, inputEmbedDim]) posShape))
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">Embedding
  gradient
  ('Layout 'Dense)
  device
  dataType
  posEncDim
  inputEmbedDim
  'Nothing
-&gt; Tensor posGradient posLayout posDevice posDataType posShape
-&gt; generator
-&gt; m (Tensor
        (Or (Gradient RequiresGradient) gradient posGradient)
        (Unify (Layout LayoutType) ('Layout 'Dense) posLayout)
        (Unify (Device (DeviceType Nat)) device posDevice)
        (Seq
           (Unify (DataType DType) posDataType ('DataType 'Int64)) dataType)
        (EmbeddingF ('Shape '[posEncDim, inputEmbedDim]) posShape),
      generator)
forall model input generator output generatorOutput (m :: * -&gt; *).
(HasForward model input generator output generatorOutput,
 MonadThrow m) =&gt;
model -&gt; input -&gt; generator -&gt; m (output, generatorOutput)
</span><a href="Torch.GraduallyTyped.NN.Class.html#forward"><span class="hs-identifier hs-var">forward</span></a></span><span> </span><span class="annot"><span class="annottext">Embedding
  gradient
  ('Layout 'Dense)
  device
  dataType
  posEncDim
  inputEmbedDim
  'Nothing
TEPosEncF
  'BERT gradient device dataType headDim inputEmbedDim posEncDim
</span><a href="#local-6989586621679770983"><span class="hs-identifier hs-var">tePosEnc</span></a></span><span>
</span><span id="line-789"></span><span>            </span><span class="annot"><span class="annottext">IxStateT
  m
  generator
  generator
  (Tensor
     (Or (Gradient RequiresGradient) gradient posGradient)
     (Unify (Layout LayoutType) ('Layout 'Dense) posLayout)
     (Unify (Device (DeviceType Nat)) device posDevice)
     (Seq
        (Unify (DataType DType) posDataType ('DataType 'Int64)) dataType)
     (EmbeddingF ('Shape '[posEncDim, inputEmbedDim]) posShape))
-&gt; (Tensor
      (Or (Gradient RequiresGradient) gradient posGradient)
      (Unify (Layout LayoutType) ('Layout 'Dense) posLayout)
      (Unify (Device (DeviceType Nat)) device posDevice)
      (Seq
         (Unify (DataType DType) posDataType ('DataType 'Int64)) dataType)
      (EmbeddingF ('Shape '[posEncDim, inputEmbedDim]) posShape)
    -&gt; IxStateT
         m
         generator
         generator
         (Tensor
            (Or
               (Gradient RequiresGradient)
               inputGradient
               (Or (Gradient RequiresGradient) gradient posGradient))
            (Unify
               (Layout LayoutType)
               inputLayout
               (Unify (Layout LayoutType) ('Layout 'Dense) posLayout))
            (Unify
               (Device (DeviceType Nat))
               inputDevice
               (Unify (Device (DeviceType Nat)) device posDevice))
            (Unify
               (DataType DType)
               inputDataType
               (Seq
                  (Unify (DataType DType) posDataType ('DataType 'Int64)) dataType))
            (BroadcastShapesF
               inputShape
               (EmbeddingF ('Shape '[posEncDim, inputEmbedDim]) posShape))))
-&gt; IxStateT
     m
     generator
     generator
     (Tensor
        (Or
           (Gradient RequiresGradient)
           inputGradient
           (Or (Gradient RequiresGradient) gradient posGradient))
        (Unify
           (Layout LayoutType)
           inputLayout
           (Unify (Layout LayoutType) ('Layout 'Dense) posLayout))
        (Unify
           (Device (DeviceType Nat))
           inputDevice
           (Unify (Device (DeviceType Nat)) device posDevice))
        (Unify
           (DataType DType)
           inputDataType
           (Seq
              (Unify (DataType DType) posDataType ('DataType 'Int64)) dataType))
        (BroadcastShapesF
           inputShape
           (EmbeddingF ('Shape '[posEncDim, inputEmbedDim]) posShape)))
forall k1 (m :: k1 -&gt; k1 -&gt; * -&gt; *) (i :: k1) (j :: k1) a
       (k2 :: k1) b.
IxMonad m =&gt;
m i j a -&gt; (a -&gt; m j k2 b) -&gt; m i k2 b
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&gt;&gt;&gt;=</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor
  (Or
     (Gradient RequiresGradient)
     inputGradient
     (Or (Gradient RequiresGradient) gradient posGradient))
  (Unify
     (Layout LayoutType)
     inputLayout
     (Unify (Layout LayoutType) ('Layout 'Dense) posLayout))
  (Unify
     (Device (DeviceType Nat))
     inputDevice
     (Unify (Device (DeviceType Nat)) device posDevice))
  (Unify
     (DataType DType)
     inputDataType
     (Seq
        (Unify (DataType DType) posDataType ('DataType 'Int64)) dataType))
  (BroadcastShapesF
     inputShape
     (EmbeddingF ('Shape '[posEncDim, inputEmbedDim]) posShape))
-&gt; IxStateT
     m
     generator
     generator
     (Tensor
        (Or
           (Gradient RequiresGradient)
           inputGradient
           (Or (Gradient RequiresGradient) gradient posGradient))
        (Unify
           (Layout LayoutType)
           inputLayout
           (Unify (Layout LayoutType) ('Layout 'Dense) posLayout))
        (Unify
           (Device (DeviceType Nat))
           inputDevice
           (Unify (Device (DeviceType Nat)) device posDevice))
        (Unify
           (DataType DType)
           inputDataType
           (Seq
              (Unify (DataType DType) posDataType ('DataType 'Int64)) dataType))
        (BroadcastShapesF
           inputShape
           (EmbeddingF ('Shape '[posEncDim, inputEmbedDim]) posShape)))
forall k (m :: k -&gt; k -&gt; * -&gt; *) a (i :: k).
IxPointed m =&gt;
a -&gt; m i i a
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-identifier hs-var">ireturn</span></a></span><span> </span><span class="annot"><span class="annottext">(Tensor
   (Or
      (Gradient RequiresGradient)
      inputGradient
      (Or (Gradient RequiresGradient) gradient posGradient))
   (Unify
      (Layout LayoutType)
      inputLayout
      (Unify (Layout LayoutType) ('Layout 'Dense) posLayout))
   (Unify
      (Device (DeviceType Nat))
      inputDevice
      (Unify (Device (DeviceType Nat)) device posDevice))
   (Unify
      (DataType DType)
      inputDataType
      (Seq
         (Unify (DataType DType) posDataType ('DataType 'Int64)) dataType))
   (BroadcastShapesF
      inputShape
      (EmbeddingF ('Shape '[posEncDim, inputEmbedDim]) posShape))
 -&gt; IxStateT
      m
      generator
      generator
      (Tensor
         (Or
            (Gradient RequiresGradient)
            inputGradient
            (Or (Gradient RequiresGradient) gradient posGradient))
         (Unify
            (Layout LayoutType)
            inputLayout
            (Unify (Layout LayoutType) ('Layout 'Dense) posLayout))
         (Unify
            (Device (DeviceType Nat))
            inputDevice
            (Unify (Device (DeviceType Nat)) device posDevice))
         (Unify
            (DataType DType)
            inputDataType
            (Seq
               (Unify (DataType DType) posDataType ('DataType 'Int64)) dataType))
         (BroadcastShapesF
            inputShape
            (EmbeddingF ('Shape '[posEncDim, inputEmbedDim]) posShape))))
-&gt; (Tensor
      (Or (Gradient RequiresGradient) gradient posGradient)
      (Unify (Layout LayoutType) ('Layout 'Dense) posLayout)
      (Unify (Device (DeviceType Nat)) device posDevice)
      (Seq
         (Unify (DataType DType) posDataType ('DataType 'Int64)) dataType)
      (EmbeddingF ('Shape '[posEncDim, inputEmbedDim]) posShape)
    -&gt; Tensor
         (Or
            (Gradient RequiresGradient)
            inputGradient
            (Or (Gradient RequiresGradient) gradient posGradient))
         (Unify
            (Layout LayoutType)
            inputLayout
            (Unify (Layout LayoutType) ('Layout 'Dense) posLayout))
         (Unify
            (Device (DeviceType Nat))
            inputDevice
            (Unify (Device (DeviceType Nat)) device posDevice))
         (Unify
            (DataType DType)
            inputDataType
            (Seq
               (Unify (DataType DType) posDataType ('DataType 'Int64)) dataType))
         (BroadcastShapesF
            inputShape
            (EmbeddingF ('Shape '[posEncDim, inputEmbedDim]) posShape)))
-&gt; Tensor
     (Or (Gradient RequiresGradient) gradient posGradient)
     (Unify (Layout LayoutType) ('Layout 'Dense) posLayout)
     (Unify (Device (DeviceType Nat)) device posDevice)
     (Seq
        (Unify (DataType DType) posDataType ('DataType 'Int64)) dataType)
     (EmbeddingF ('Shape '[posEncDim, inputEmbedDim]) posShape)
-&gt; IxStateT
     m
     generator
     generator
     (Tensor
        (Or
           (Gradient RequiresGradient)
           inputGradient
           (Or (Gradient RequiresGradient) gradient posGradient))
        (Unify
           (Layout LayoutType)
           inputLayout
           (Unify (Layout LayoutType) ('Layout 'Dense) posLayout))
        (Unify
           (Device (DeviceType Nat))
           inputDevice
           (Unify (Device (DeviceType Nat)) device posDevice))
        (Unify
           (DataType DType)
           inputDataType
           (Seq
              (Unify (DataType DType) posDataType ('DataType 'Int64)) dataType))
        (BroadcastShapesF
           inputShape
           (EmbeddingF ('Shape '[posEncDim, inputEmbedDim]) posShape)))
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">Tensor
  inputGradient inputLayout inputDevice inputDataType inputShape
</span><a href="#local-6989586621679770982"><span class="hs-identifier hs-var">input</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor
  inputGradient inputLayout inputDevice inputDataType inputShape
-&gt; Tensor
     (Or (Gradient RequiresGradient) gradient posGradient)
     (Unify (Layout LayoutType) ('Layout 'Dense) posLayout)
     (Unify (Device (DeviceType Nat)) device posDevice)
     (Seq
        (Unify (DataType DType) posDataType ('DataType 'Int64)) dataType)
     (EmbeddingF ('Shape '[posEncDim, inputEmbedDim]) posShape)
-&gt; Tensor
     (inputGradient
      &lt;|&gt; Or (Gradient RequiresGradient) gradient posGradient)
     (inputLayout
      &lt;+&gt; Unify (Layout LayoutType) ('Layout 'Dense) posLayout)
     (inputDevice &lt;+&gt; Unify (Device (DeviceType Nat)) device posDevice)
     (inputDataType
      &lt;+&gt; Seq
            (Unify (DataType DType) posDataType ('DataType 'Int64)) dataType)
     (BroadcastShapesF
        inputShape
        (EmbeddingF ('Shape '[posEncDim, inputEmbedDim]) posShape))
forall (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)])
       (gradient' :: Gradient RequiresGradient)
       (layout' :: Layout LayoutType) (device' :: Device (DeviceType Nat))
       (dataType' :: DataType DType)
       (shape' :: Shape [Dim (Name Symbol) (Size Nat)]).
Tensor gradient layout device dataType shape
-&gt; Tensor gradient' layout' device' dataType' shape'
-&gt; Tensor
     (gradient &lt;|&gt; gradient')
     (layout &lt;+&gt; layout')
     (device &lt;+&gt; device')
     (dataType &lt;+&gt; dataType')
     (BroadcastShapesF shape shape')
</span><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#add"><span class="hs-operator hs-var">`add`</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-790"></span><span>            </span><span class="annot"><span class="annottext">IxStateT
  m
  generator
  generator
  (Tensor
     (Or
        (Gradient RequiresGradient)
        inputGradient
        (Or (Gradient RequiresGradient) gradient posGradient))
     (Unify
        (Layout LayoutType)
        inputLayout
        (Unify (Layout LayoutType) ('Layout 'Dense) posLayout))
     (Unify
        (Device (DeviceType Nat))
        inputDevice
        (Unify (Device (DeviceType Nat)) device posDevice))
     (Unify
        (DataType DType)
        inputDataType
        (Seq
           (Unify (DataType DType) posDataType ('DataType 'Int64)) dataType))
     (BroadcastShapesF
        inputShape
        (EmbeddingF ('Shape '[posEncDim, inputEmbedDim]) posShape)))
-&gt; (Tensor
      (Or
         (Gradient RequiresGradient)
         inputGradient
         (Or (Gradient RequiresGradient) gradient posGradient))
      (Unify
         (Layout LayoutType)
         inputLayout
         (Unify (Layout LayoutType) ('Layout 'Dense) posLayout))
      (Unify
         (Device (DeviceType Nat))
         inputDevice
         (Unify (Device (DeviceType Nat)) device posDevice))
      (Unify
         (DataType DType)
         inputDataType
         (Seq
            (Unify (DataType DType) posDataType ('DataType 'Int64)) dataType))
      (BroadcastShapesF
         inputShape
         (EmbeddingF ('Shape '[posEncDim, inputEmbedDim]) posShape))
    -&gt; IxStateT m generator generator layerNormOutput)
-&gt; IxStateT m generator generator layerNormOutput
forall k1 (m :: k1 -&gt; k1 -&gt; * -&gt; *) (i :: k1) (j :: k1) a
       (k2 :: k1) b.
IxMonad m =&gt;
m i j a -&gt; (a -&gt; m j k2 b) -&gt; m i k2 b
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&gt;&gt;&gt;=</span></a></span><span> </span><span class="annot"><span class="annottext">(generator -&gt; m (layerNormOutput, generator))
-&gt; IxStateT m generator generator layerNormOutput
forall (m :: * -&gt; *) i j a. (i -&gt; m (a, j)) -&gt; IxStateT m i j a
</span><a href="../file:///nix/store/8vjaffqxij7bih93d9mlzmc7ksanlw0i-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier hs-var">IxStateT</span></a></span><span> </span><span class="annot"><span class="annottext">((generator -&gt; m (layerNormOutput, generator))
 -&gt; IxStateT m generator generator layerNormOutput)
-&gt; (Tensor
      (Or
         (Gradient RequiresGradient)
         inputGradient
         (Or (Gradient RequiresGradient) gradient posGradient))
      (Unify
         (Layout LayoutType)
         inputLayout
         (Unify (Layout LayoutType) ('Layout 'Dense) posLayout))
      (Unify
         (Device (DeviceType Nat))
         inputDevice
         (Unify (Device (DeviceType Nat)) device posDevice))
      (Unify
         (DataType DType)
         inputDataType
         (Seq
            (Unify (DataType DType) posDataType ('DataType 'Int64)) dataType))
      (BroadcastShapesF
         inputShape
         (EmbeddingF ('Shape '[posEncDim, inputEmbedDim]) posShape))
    -&gt; generator -&gt; m (layerNormOutput, generator))
-&gt; Tensor
     (Or
        (Gradient RequiresGradient)
        inputGradient
        (Or (Gradient RequiresGradient) gradient posGradient))
     (Unify
        (Layout LayoutType)
        inputLayout
        (Unify (Layout LayoutType) ('Layout 'Dense) posLayout))
     (Unify
        (Device (DeviceType Nat))
        inputDevice
        (Unify (Device (DeviceType Nat)) device posDevice))
     (Unify
        (DataType DType)
        inputDataType
        (Seq
           (Unify (DataType DType) posDataType ('DataType 'Int64)) dataType))
     (BroadcastShapesF
        inputShape
        (EmbeddingF ('Shape '[posEncDim, inputEmbedDim]) posShape))
-&gt; IxStateT m generator generator layerNormOutput
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">LayerNorm
  'WithBias gradient device dataType ('Shape '[inputEmbedDim])
-&gt; Tensor
     (Or
        (Gradient RequiresGradient)
        inputGradient
        (Or (Gradient RequiresGradient) gradient posGradient))
     (Unify
        (Layout LayoutType)
        inputLayout
        (Unify (Layout LayoutType) ('Layout 'Dense) posLayout))
     (Unify
        (Device (DeviceType Nat))
        inputDevice
        (Unify (Device (DeviceType Nat)) device posDevice))
     (Unify
        (DataType DType)
        inputDataType
        (Seq
           (Unify (DataType DType) posDataType ('DataType 'Int64)) dataType))
     (BroadcastShapesF
        inputShape
        (EmbeddingF ('Shape '[posEncDim, inputEmbedDim]) posShape))
-&gt; generator
-&gt; m (layerNormOutput, generator)
forall model input generator output generatorOutput (m :: * -&gt; *).
(HasForward model input generator output generatorOutput,
 MonadThrow m) =&gt;
model -&gt; input -&gt; generator -&gt; m (output, generatorOutput)
</span><a href="Torch.GraduallyTyped.NN.Class.html#forward"><span class="hs-identifier hs-var">forward</span></a></span><span> </span><span class="annot"><span class="annottext">LayerNorm
  'WithBias gradient device dataType ('Shape '[inputEmbedDim])
TEEmbedLayerNormF 'BERT gradient device dataType inputEmbedDim
</span><a href="#local-6989586621679770986"><span class="hs-identifier hs-var">teEmbedLayerNorm</span></a></span><span>
</span><span id="line-791"></span><span>            </span><span class="annot"><span class="annottext">IxStateT m generator generator layerNormOutput
-&gt; (layerNormOutput
    -&gt; IxStateT m generator dropoutGeneratorOutput dropoutOutput)
-&gt; IxStateT m generator dropoutGeneratorOutput dropoutOutput
forall k1 (m :: k1 -&gt; k1 -&gt; * -&gt; *) (i :: k1) (j :: k1) a
       (k2 :: k1) b.
IxMonad m =&gt;
m i j a -&gt; (a -&gt; m j k2 b) -&gt; m i k2 b
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&gt;&gt;&gt;=</span></a></span><span> </span><span class="annot"><span class="annottext">(generator -&gt; m (dropoutOutput, dropoutGeneratorOutput))
-&gt; IxStateT m generator dropoutGeneratorOutput dropoutOutput
forall (m :: * -&gt; *) i j a. (i -&gt; m (a, j)) -&gt; IxStateT m i j a
</span><a href="../file:///nix/store/8vjaffqxij7bih93d9mlzmc7ksanlw0i-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier hs-var">IxStateT</span></a></span><span> </span><span class="annot"><span class="annottext">((generator -&gt; m (dropoutOutput, dropoutGeneratorOutput))
 -&gt; IxStateT m generator dropoutGeneratorOutput dropoutOutput)
-&gt; (layerNormOutput
    -&gt; generator -&gt; m (dropoutOutput, dropoutGeneratorOutput))
-&gt; layerNormOutput
-&gt; IxStateT m generator dropoutGeneratorOutput dropoutOutput
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">Dropout dropoutP
-&gt; layerNormOutput
-&gt; generator
-&gt; m (dropoutOutput, dropoutGeneratorOutput)
forall model input generator output generatorOutput (m :: * -&gt; *).
(HasForward model input generator output generatorOutput,
 MonadThrow m) =&gt;
model -&gt; input -&gt; generator -&gt; m (output, generatorOutput)
</span><a href="Torch.GraduallyTyped.NN.Class.html#forward"><span class="hs-identifier hs-var">forward</span></a></span><span> </span><span class="annot"><span class="annottext">Dropout dropoutP
TEDropoutF 'BERT dropoutP
</span><a href="#local-6989586621679770984"><span class="hs-identifier hs-var">teDropout</span></a></span><span>
</span><span id="line-792"></span><span>            </span><span class="annot"><span class="annottext">IxStateT m generator dropoutGeneratorOutput dropoutOutput
-&gt; (dropoutOutput
    -&gt; IxStateT m dropoutGeneratorOutput generatorOutput output)
-&gt; IxStateT m generator generatorOutput output
forall k1 (m :: k1 -&gt; k1 -&gt; * -&gt; *) (i :: k1) (j :: k1) a
       (k2 :: k1) b.
IxMonad m =&gt;
m i j a -&gt; (a -&gt; m j k2 b) -&gt; m i k2 b
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&gt;&gt;&gt;=</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">\</span><span id="local-6989586621679770978"><span class="annot"><span class="annottext">dropoutOutput
</span><a href="#local-6989586621679770978"><span class="hs-identifier hs-var">input'</span></a></span></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><span class="annottext">(dropoutGeneratorOutput -&gt; m (output, generatorOutput))
-&gt; IxStateT m dropoutGeneratorOutput generatorOutput output
forall (m :: * -&gt; *) i j a. (i -&gt; m (a, j)) -&gt; IxStateT m i j a
</span><a href="../file:///nix/store/8vjaffqxij7bih93d9mlzmc7ksanlw0i-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier hs-var">IxStateT</span></a></span><span> </span><span class="annot"><span class="annottext">((dropoutGeneratorOutput -&gt; m (output, generatorOutput))
 -&gt; IxStateT m dropoutGeneratorOutput generatorOutput output)
-&gt; (dropoutGeneratorOutput -&gt; m (output, generatorOutput))
-&gt; IxStateT m dropoutGeneratorOutput generatorOutput output
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">TransformerStack
  'BERT
  numLayers
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  inputEmbedDim
  ffnDim
  dropoutP
-&gt; (dropoutOutput,
    Tensor
      attentionMaskGradient
      attentionMaskLayout
      attentionMaskDevice
      attentionMaskDataType
      (UnsqueezeF ('SelectDim ('ByIndex 1)) attentionMaskShape))
-&gt; dropoutGeneratorOutput
-&gt; m (output, generatorOutput)
forall model input generator output generatorOutput (m :: * -&gt; *).
(HasForward model input generator output generatorOutput,
 MonadThrow m) =&gt;
model -&gt; input -&gt; generator -&gt; m (output, generatorOutput)
</span><a href="Torch.GraduallyTyped.NN.Class.html#forward"><span class="hs-identifier hs-var">forward</span></a></span><span> </span><span class="annot"><span class="annottext">TransformerStack
  'BERT
  numLayers
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  inputEmbedDim
  ffnDim
  dropoutP
TEStackF
  'BERT
  numLayers
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  inputEmbedDim
  ffnDim
  dropoutP
</span><a href="#local-6989586621679770987"><span class="hs-identifier hs-var">teStack</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">dropoutOutput
</span><a href="#local-6989586621679770978"><span class="hs-identifier hs-var">input'</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">Tensor
  attentionMaskGradient
  attentionMaskLayout
  attentionMaskDevice
  attentionMaskDataType
  (UnsqueezeF ('SelectDim ('ByIndex 1)) attentionMaskShape)
</span><a href="#local-6989586621679770979"><span class="hs-identifier hs-var">attentionBias</span></a></span><span class="hs-special">)</span><span class="hs-special">)</span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span><span>
</span><span id="line-793"></span><span>
</span><span id="line-794"></span><span class="hs-comment">-- | 'HasForward' instance for @TransformerEncoder numLayers 'RoBERTa@.</span><span>
</span><span id="line-795"></span><span class="hs-comment">--</span><span>
</span><span id="line-796"></span><span class="hs-comment">-- @</span><span>
</span><span id="line-797"></span><span class="hs-comment">-- &#9484;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9488;  &#9484;&#9472;&#9472;&#9472;&#9472;&#9472;&#9488;  &#9484;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9488;</span><span>
</span><span id="line-798"></span><span class="hs-comment">-- &#9474; input &#9474;  &#9474; pos &#9474;  &#9474; attentionMask &#9474;</span><span>
</span><span id="line-799"></span><span class="hs-comment">-- &#9492;&#9472;&#9472;&#9472;&#9516;&#9472;&#9472;&#9472;&#9496;  &#9492;&#9472;&#9472;&#9472;&#9472;&#9472;&#9496;  &#9492;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9516;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9496;</span><span>
</span><span id="line-800"></span><span class="hs-comment">--     &#9474;         &#9474;             &#9474;</span><span>
</span><span id="line-801"></span><span class="hs-comment">--     &#9474;         &#9660;             &#9474;</span><span>
</span><span id="line-802"></span><span class="hs-comment">--     &#9474;     tePosEnc          &#9474;</span><span>
</span><span id="line-803"></span><span class="hs-comment">--     &#9474;         &#9474;             &#9474;</span><span>
</span><span id="line-804"></span><span class="hs-comment">--     &#9492;&#9472;&#9472;&#9658;add&#9668;&#9472;&#9472;&#9496;             &#9474;</span><span>
</span><span id="line-805"></span><span class="hs-comment">--          &#9474;                  &#9474;</span><span>
</span><span id="line-806"></span><span class="hs-comment">--          &#9660;                  &#9474;</span><span>
</span><span id="line-807"></span><span class="hs-comment">--   teEmbedLayerNorm          &#9474;</span><span>
</span><span id="line-808"></span><span class="hs-comment">--          &#9660;                  &#9660;</span><span>
</span><span id="line-809"></span><span class="hs-comment">--      teDropout          unsqueeze</span><span>
</span><span id="line-810"></span><span class="hs-comment">--          &#9660;                  &#9474;</span><span>
</span><span id="line-811"></span><span class="hs-comment">--       teStack&#9668;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9496;</span><span>
</span><span id="line-812"></span><span class="hs-comment">--          &#9474;</span><span>
</span><span id="line-813"></span><span class="hs-comment">--          &#9660;</span><span>
</span><span id="line-814"></span><span class="hs-comment">--     &#9484;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9488;</span><span>
</span><span id="line-815"></span><span class="hs-comment">--     &#9474; output &#9474;</span><span>
</span><span id="line-816"></span><span class="hs-comment">--     &#9492;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9496;</span><span>
</span><span id="line-817"></span><span class="hs-comment">-- @</span><span>
</span><span id="line-818"></span><span id="local-6989586621679770946"><span id="local-6989586621679770947"><span id="local-6989586621679770948"><span id="local-6989586621679770949"><span id="local-6989586621679770950"><span id="local-6989586621679770951"><span id="local-6989586621679770952"><span id="local-6989586621679770953"><span id="local-6989586621679770954"><span id="local-6989586621679770955"><span id="local-6989586621679770956"><span id="local-6989586621679770957"><span id="local-6989586621679770958"><span id="local-6989586621679770959"><span id="local-6989586621679770960"><span id="local-6989586621679770961"><span id="local-6989586621679770962"><span id="local-6989586621679770963"><span id="local-6989586621679770964"><span id="local-6989586621679770965"><span id="local-6989586621679770966"><span id="local-6989586621679770967"><span id="local-6989586621679770968"><span id="local-6989586621679770969"><span id="local-6989586621679770970"><span id="local-6989586621679770971"><span id="local-6989586621679770972"><span id="local-6989586621679770973"><span id="local-6989586621679770974"><span id="local-6989586621679770975"><span id="local-6989586621679770976"><span id="local-6989586621679770977"><span class="hs-keyword">instance</span><span>
</span><span id="line-819"></span><span>  </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasForward"><span class="hs-identifier hs-type">HasForward</span></a></span><span>
</span><span id="line-820"></span><span>      </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Encoder.html#TEEmbedLayerNormF"><span class="hs-identifier hs-type">TEEmbedLayerNormF</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#RoBERTa"><span class="hs-identifier hs-type">RoBERTa</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679770977"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679770976"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679770975"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679770974"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-821"></span><span>      </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span>
</span><span id="line-822"></span><span>          </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679770973"><span class="hs-identifier hs-type">inputGradient</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%7C%3E"><span class="hs-operator hs-type">&lt;|&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679770977"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%7C%3E"><span class="hs-operator hs-type">&lt;|&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679770972"><span class="hs-identifier hs-type">posGradient</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-823"></span><span>          </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679770971"><span class="hs-identifier hs-type">inputLayout</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#Layout"><span class="hs-identifier hs-type">Layout</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#Dense"><span class="hs-identifier hs-type">Dense</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679770970"><span class="hs-identifier hs-type">posLayout</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-824"></span><span>          </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679770969"><span class="hs-identifier hs-type">inputDevice</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679770976"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679770968"><span class="hs-identifier hs-type">posDevice</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-825"></span><span>          </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679770967"><span class="hs-identifier hs-type">inputDataType</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Prelude.html#Seq"><span class="hs-identifier hs-type">Seq</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679770966"><span class="hs-identifier hs-type">posDataType</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#DataType"><span class="hs-identifier hs-type">DataType</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#Int64"><span class="hs-identifier hs-type">Int64</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679770975"><span class="hs-identifier hs-type">dataType</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-826"></span><span>          </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Class.html#BroadcastShapesF"><span class="hs-identifier hs-type">BroadcastShapesF</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679770965"><span class="hs-identifier hs-type">inputShape</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Functional.Sparse.html#EmbeddingF"><span class="hs-identifier hs-type">EmbeddingF</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Shape"><span class="hs-identifier hs-type">Shape</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="annot"><a href="#local-6989586621679770964"><span class="hs-identifier hs-type">posEncDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679770974"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span><span class="hs-special">]</span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679770963"><span class="hs-identifier hs-type">posShape</span></a></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-827"></span><span>      </span><span class="hs-special">)</span><span>
</span><span id="line-828"></span><span>      </span><span class="annot"><a href="#local-6989586621679770962"><span class="hs-identifier hs-type">generator</span></a></span><span>
</span><span id="line-829"></span><span>      </span><span class="annot"><a href="#local-6989586621679770961"><span class="hs-identifier hs-type">layerNormOutput</span></a></span><span>
</span><span id="line-830"></span><span>      </span><span class="annot"><a href="#local-6989586621679770962"><span class="hs-identifier hs-type">generator</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-831"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasForward"><span class="hs-identifier hs-type">HasForward</span></a></span><span>
</span><span id="line-832"></span><span>      </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Encoder.html#TEDropoutF"><span class="hs-identifier hs-type">TEDropoutF</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#RoBERTa"><span class="hs-identifier hs-type">RoBERTa</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679770960"><span class="hs-identifier hs-type">dropoutP</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-833"></span><span>      </span><span class="annot"><a href="#local-6989586621679770961"><span class="hs-identifier hs-type">layerNormOutput</span></a></span><span>
</span><span id="line-834"></span><span>      </span><span class="annot"><a href="#local-6989586621679770962"><span class="hs-identifier hs-type">generator</span></a></span><span>
</span><span id="line-835"></span><span>      </span><span class="annot"><a href="#local-6989586621679770959"><span class="hs-identifier hs-type">dropoutOutput</span></a></span><span>
</span><span id="line-836"></span><span>      </span><span class="annot"><a href="#local-6989586621679770958"><span class="hs-identifier hs-type">dropoutGeneratorOutput</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-837"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasForward"><span class="hs-identifier hs-type">HasForward</span></a></span><span>
</span><span id="line-838"></span><span>      </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Encoder.html#TEStackF"><span class="hs-identifier hs-type">TEStackF</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#RoBERTa"><span class="hs-identifier hs-type">RoBERTa</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679770957"><span class="hs-identifier hs-type">numLayers</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679770977"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679770976"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679770975"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679770956"><span class="hs-identifier hs-type">headDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679770955"><span class="hs-identifier hs-type">headEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679770954"><span class="hs-identifier hs-type">embedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679770974"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679770953"><span class="hs-identifier hs-type">ffnDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679770960"><span class="hs-identifier hs-type">dropoutP</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-839"></span><span>      </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="#local-6989586621679770959"><span class="hs-identifier hs-type">dropoutOutput</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-840"></span><span>        </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span>
</span><span id="line-841"></span><span>          </span><span class="annot"><a href="#local-6989586621679770952"><span class="hs-identifier hs-type">attentionMaskGradient</span></a></span><span>
</span><span id="line-842"></span><span>          </span><span class="annot"><a href="#local-6989586621679770951"><span class="hs-identifier hs-type">attentionMaskLayout</span></a></span><span>
</span><span id="line-843"></span><span>          </span><span class="annot"><a href="#local-6989586621679770950"><span class="hs-identifier hs-type">attentionMaskDevice</span></a></span><span>
</span><span id="line-844"></span><span>          </span><span class="annot"><a href="#local-6989586621679770949"><span class="hs-identifier hs-type">attentionMaskDataType</span></a></span><span>
</span><span id="line-845"></span><span>          </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.IndexingSlicingJoining.html#UnsqueezeF"><span class="hs-identifier hs-type">UnsqueezeF</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SelectDim"><span class="hs-identifier hs-type">SelectDim</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#ByIndex"><span class="hs-identifier hs-type">ByIndex</span></a></span><span> </span><span class="annot"><span class="hs-number">1</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679770948"><span class="hs-identifier hs-type">attentionMaskShape</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-846"></span><span>      </span><span class="hs-special">)</span><span>
</span><span id="line-847"></span><span>      </span><span class="annot"><a href="#local-6989586621679770958"><span class="hs-identifier hs-type">dropoutGeneratorOutput</span></a></span><span>
</span><span id="line-848"></span><span>      </span><span class="annot"><a href="#local-6989586621679770947"><span class="hs-identifier hs-type">output</span></a></span><span>
</span><span id="line-849"></span><span>      </span><span class="annot"><a href="#local-6989586621679770946"><span class="hs-identifier hs-type">generatorOutput</span></a></span><span>
</span><span id="line-850"></span><span>  </span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-851"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasForward"><span class="hs-identifier hs-type">HasForward</span></a></span><span>
</span><span id="line-852"></span><span>    </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Encoder.html#TransformerEncoder"><span class="hs-identifier hs-type">TransformerEncoder</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#RoBERTa"><span class="hs-identifier hs-type">RoBERTa</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679770957"><span class="hs-identifier hs-type">numLayers</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679770977"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679770976"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679770975"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679770956"><span class="hs-identifier hs-type">headDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679770955"><span class="hs-identifier hs-type">headEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679770954"><span class="hs-identifier hs-type">embedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679770974"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679770953"><span class="hs-identifier hs-type">ffnDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679770964"><span class="hs-identifier hs-type">posEncDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679770960"><span class="hs-identifier hs-type">dropoutP</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-853"></span><span>    </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679770973"><span class="hs-identifier hs-type">inputGradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679770971"><span class="hs-identifier hs-type">inputLayout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679770969"><span class="hs-identifier hs-type">inputDevice</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679770967"><span class="hs-identifier hs-type">inputDataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679770965"><span class="hs-identifier hs-type">inputShape</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-854"></span><span>      </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679770972"><span class="hs-identifier hs-type">posGradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679770970"><span class="hs-identifier hs-type">posLayout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679770968"><span class="hs-identifier hs-type">posDevice</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679770966"><span class="hs-identifier hs-type">posDataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679770963"><span class="hs-identifier hs-type">posShape</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-855"></span><span>      </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679770952"><span class="hs-identifier hs-type">attentionMaskGradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679770951"><span class="hs-identifier hs-type">attentionMaskLayout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679770950"><span class="hs-identifier hs-type">attentionMaskDevice</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679770949"><span class="hs-identifier hs-type">attentionMaskDataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679770948"><span class="hs-identifier hs-type">attentionMaskShape</span></a></span><span>
</span><span id="line-856"></span><span>    </span><span class="hs-special">)</span><span>
</span><span id="line-857"></span><span>    </span><span class="annot"><a href="#local-6989586621679770962"><span class="hs-identifier hs-type">generator</span></a></span><span>
</span><span id="line-858"></span><span>    </span><span class="annot"><a href="#local-6989586621679770947"><span class="hs-identifier hs-type">output</span></a></span><span>
</span><span id="line-859"></span><span>    </span><span class="annot"><a href="#local-6989586621679770946"><span class="hs-identifier hs-type">generatorOutput</span></a></span><span>
</span><span id="line-860"></span><span>  </span><span class="hs-keyword">where</span><span>
</span><span id="line-861"></span><span>  </span><span id="local-6989586621679770944"><span class="annot"><span class="annottext">forward :: TransformerEncoder
  'RoBERTa
  numLayers
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  inputEmbedDim
  ffnDim
  posEncDim
  dropoutP
-&gt; (Tensor
      inputGradient inputLayout inputDevice inputDataType inputShape,
    Tensor posGradient posLayout posDevice posDataType posShape,
    Tensor
      attentionMaskGradient
      attentionMaskLayout
      attentionMaskDevice
      attentionMaskDataType
      attentionMaskShape)
-&gt; generator
-&gt; m (output, generatorOutput)
</span><a href="#local-6989586621679770944"><span class="hs-identifier hs-var hs-var hs-var hs-var">forward</span></a></span></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Encoder.html#TransformerEncoder"><span class="hs-identifier hs-type">TransformerEncoder</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Encoder.html#GTransformerEncoder"><span class="hs-identifier hs-type">GTransformerEncoder</span></a></span><span> </span><span class="hs-special">{</span><span id="local-6989586621679770939"><span id="local-6989586621679770940"><span id="local-6989586621679770941"><span id="local-6989586621679770942"><span id="local-6989586621679770943"><span class="annot"><span class="annottext">TEPosEncF
  'RoBERTa gradient device dataType headDim inputEmbedDim posEncDim
TEDropoutF 'RoBERTa dropoutP
TELayerNormF 'RoBERTa gradient device dataType inputEmbedDim
TEEmbedLayerNormF 'RoBERTa gradient device dataType inputEmbedDim
TEStackF
  'RoBERTa
  numLayers
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  inputEmbedDim
  ffnDim
  dropoutP
tePosEnc :: TEPosEncF
  'RoBERTa gradient device dataType headDim inputEmbedDim posEncDim
teDropout :: TEDropoutF 'RoBERTa dropoutP
teLayerNorm :: TELayerNormF 'RoBERTa gradient device dataType inputEmbedDim
teEmbedLayerNorm :: TEEmbedLayerNormF 'RoBERTa gradient device dataType inputEmbedDim
teStack :: TEStackF
  'RoBERTa
  numLayers
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  inputEmbedDim
  ffnDim
  dropoutP
tePosEnc :: forall stack embedLayerNorm layerNorm dropout posEnc.
GTransformerEncoder stack embedLayerNorm layerNorm dropout posEnc
-&gt; posEnc
teDropout :: forall stack embedLayerNorm layerNorm dropout posEnc.
GTransformerEncoder stack embedLayerNorm layerNorm dropout posEnc
-&gt; dropout
teLayerNorm :: forall stack embedLayerNorm layerNorm dropout posEnc.
GTransformerEncoder stack embedLayerNorm layerNorm dropout posEnc
-&gt; layerNorm
teEmbedLayerNorm :: forall stack embedLayerNorm layerNorm dropout posEnc.
GTransformerEncoder stack embedLayerNorm layerNorm dropout posEnc
-&gt; embedLayerNorm
teStack :: forall stack embedLayerNorm layerNorm dropout posEnc.
GTransformerEncoder stack embedLayerNorm layerNorm dropout posEnc
-&gt; stack
</span><a href="#local-6989586621679770939"><span class="hs-glyph hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var">..</span></a></span></span></span></span></span></span><span class="hs-special">}</span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span id="local-6989586621679770938"><span class="annot"><span class="annottext">Tensor
  inputGradient inputLayout inputDevice inputDataType inputShape
</span><a href="#local-6989586621679770938"><span class="hs-identifier hs-var">input</span></a></span></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679770937"><span class="annot"><span class="annottext">Tensor posGradient posLayout posDevice posDataType posShape
</span><a href="#local-6989586621679770937"><span class="hs-identifier hs-var">pos</span></a></span></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679770936"><span class="annot"><span class="annottext">Tensor
  attentionMaskGradient
  attentionMaskLayout
  attentionMaskDevice
  attentionMaskDataType
  attentionMaskShape
</span><a href="#local-6989586621679770936"><span class="hs-identifier hs-var">attentionMask</span></a></span></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-862"></span><span>    </span><span class="hs-keyword">let</span><span> </span><span id="local-6989586621679770935"><span class="annot"><span class="annottext">attentionBias :: Tensor
  attentionMaskGradient
  attentionMaskLayout
  attentionMaskDevice
  attentionMaskDataType
  (UnsqueezeF ('SelectDim ('ByIndex 1)) attentionMaskShape)
</span><a href="#local-6989586621679770935"><span class="hs-identifier hs-var hs-var">attentionBias</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Tensor
  attentionMaskGradient
  attentionMaskLayout
  attentionMaskDevice
  attentionMaskDataType
  attentionMaskShape
-&gt; Tensor
     attentionMaskGradient
     attentionMaskLayout
     attentionMaskDevice
     attentionMaskDataType
     (UnsqueezeF ('SelectDim ('ByIndex 1)) attentionMaskShape)
forall (selectDim :: SelectDim (By Symbol Nat))
       (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)])
       (shape' :: Shape [Dim (Name Symbol) (Size Nat)]).
(shape' ~ UnsqueezeF selectDim shape, SingI selectDim) =&gt;
Tensor gradient layout device dataType shape
-&gt; Tensor gradient layout device dataType shape'
</span><a href="Torch.GraduallyTyped.Tensor.IndexingSlicingJoining.html#unsqueeze"><span class="hs-identifier hs-var">unsqueeze</span></a></span><span> </span><span class="hs-glyph">@</span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SelectDim"><span class="hs-identifier hs-type">SelectDim</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#ByIndex"><span class="hs-identifier hs-type">ByIndex</span></a></span><span> </span><span class="annot"><span class="hs-number">1</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">Tensor
  attentionMaskGradient
  attentionMaskLayout
  attentionMaskDevice
  attentionMaskDataType
  attentionMaskShape
</span><a href="#local-6989586621679770936"><span class="hs-identifier hs-var">attentionMask</span></a></span><span>
</span><span id="line-863"></span><span>     </span><span class="hs-keyword">in</span><span> </span><span class="annot"><span class="annottext">IxStateT m generator generatorOutput output
-&gt; generator -&gt; m (output, generatorOutput)
forall (m :: * -&gt; *) i j a. IxStateT m i j a -&gt; i -&gt; m (a, j)
</span><a href="../file:///nix/store/8vjaffqxij7bih93d9mlzmc7ksanlw0i-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier hs-var hs-var">runIxStateT</span></a></span><span> </span><span class="annot"><span class="annottext">(IxStateT m generator generatorOutput output
 -&gt; generator -&gt; m (output, generatorOutput))
-&gt; IxStateT m generator generatorOutput output
-&gt; generator
-&gt; m (output, generatorOutput)
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span>
</span><span id="line-864"></span><span>          </span><span class="annot"><span class="annottext">Tensor posGradient posLayout posDevice posDataType posShape
-&gt; IxStateT
     m
     generator
     generator
     (Tensor posGradient posLayout posDevice posDataType posShape)
forall k (m :: k -&gt; k -&gt; * -&gt; *) a (i :: k).
IxPointed m =&gt;
a -&gt; m i i a
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-identifier hs-var">ireturn</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor posGradient posLayout posDevice posDataType posShape
</span><a href="#local-6989586621679770937"><span class="hs-identifier hs-var">pos</span></a></span><span>
</span><span id="line-865"></span><span>            </span><span class="annot"><span class="annottext">IxStateT
  m
  generator
  generator
  (Tensor posGradient posLayout posDevice posDataType posShape)
-&gt; (Tensor posGradient posLayout posDevice posDataType posShape
    -&gt; IxStateT
         m
         generator
         generator
         (Tensor
            (Or (Gradient RequiresGradient) gradient posGradient)
            (Unify (Layout LayoutType) ('Layout 'Dense) posLayout)
            (Unify (Device (DeviceType Nat)) device posDevice)
            (Seq
               (Unify (DataType DType) posDataType ('DataType 'Int64)) dataType)
            (EmbeddingF ('Shape '[posEncDim, inputEmbedDim]) posShape)))
-&gt; IxStateT
     m
     generator
     generator
     (Tensor
        (Or (Gradient RequiresGradient) gradient posGradient)
        (Unify (Layout LayoutType) ('Layout 'Dense) posLayout)
        (Unify (Device (DeviceType Nat)) device posDevice)
        (Seq
           (Unify (DataType DType) posDataType ('DataType 'Int64)) dataType)
        (EmbeddingF ('Shape '[posEncDim, inputEmbedDim]) posShape))
forall k1 (m :: k1 -&gt; k1 -&gt; * -&gt; *) (i :: k1) (j :: k1) a
       (k2 :: k1) b.
IxMonad m =&gt;
m i j a -&gt; (a -&gt; m j k2 b) -&gt; m i k2 b
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&gt;&gt;&gt;=</span></a></span><span> </span><span class="annot"><span class="annottext">(generator
 -&gt; m (Tensor
         (Or (Gradient RequiresGradient) gradient posGradient)
         (Unify (Layout LayoutType) ('Layout 'Dense) posLayout)
         (Unify (Device (DeviceType Nat)) device posDevice)
         (Seq
            (Unify (DataType DType) posDataType ('DataType 'Int64)) dataType)
         (EmbeddingF ('Shape '[posEncDim, inputEmbedDim]) posShape),
       generator))
-&gt; IxStateT
     m
     generator
     generator
     (Tensor
        (Or (Gradient RequiresGradient) gradient posGradient)
        (Unify (Layout LayoutType) ('Layout 'Dense) posLayout)
        (Unify (Device (DeviceType Nat)) device posDevice)
        (Seq
           (Unify (DataType DType) posDataType ('DataType 'Int64)) dataType)
        (EmbeddingF ('Shape '[posEncDim, inputEmbedDim]) posShape))
forall (m :: * -&gt; *) i j a. (i -&gt; m (a, j)) -&gt; IxStateT m i j a
</span><a href="../file:///nix/store/8vjaffqxij7bih93d9mlzmc7ksanlw0i-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier hs-var">IxStateT</span></a></span><span> </span><span class="annot"><span class="annottext">((generator
  -&gt; m (Tensor
          (Or (Gradient RequiresGradient) gradient posGradient)
          (Unify (Layout LayoutType) ('Layout 'Dense) posLayout)
          (Unify (Device (DeviceType Nat)) device posDevice)
          (Seq
             (Unify (DataType DType) posDataType ('DataType 'Int64)) dataType)
          (EmbeddingF ('Shape '[posEncDim, inputEmbedDim]) posShape),
        generator))
 -&gt; IxStateT
      m
      generator
      generator
      (Tensor
         (Or (Gradient RequiresGradient) gradient posGradient)
         (Unify (Layout LayoutType) ('Layout 'Dense) posLayout)
         (Unify (Device (DeviceType Nat)) device posDevice)
         (Seq
            (Unify (DataType DType) posDataType ('DataType 'Int64)) dataType)
         (EmbeddingF ('Shape '[posEncDim, inputEmbedDim]) posShape)))
-&gt; (Tensor posGradient posLayout posDevice posDataType posShape
    -&gt; generator
    -&gt; m (Tensor
            (Or (Gradient RequiresGradient) gradient posGradient)
            (Unify (Layout LayoutType) ('Layout 'Dense) posLayout)
            (Unify (Device (DeviceType Nat)) device posDevice)
            (Seq
               (Unify (DataType DType) posDataType ('DataType 'Int64)) dataType)
            (EmbeddingF ('Shape '[posEncDim, inputEmbedDim]) posShape),
          generator))
-&gt; Tensor posGradient posLayout posDevice posDataType posShape
-&gt; IxStateT
     m
     generator
     generator
     (Tensor
        (Or (Gradient RequiresGradient) gradient posGradient)
        (Unify (Layout LayoutType) ('Layout 'Dense) posLayout)
        (Unify (Device (DeviceType Nat)) device posDevice)
        (Seq
           (Unify (DataType DType) posDataType ('DataType 'Int64)) dataType)
        (EmbeddingF ('Shape '[posEncDim, inputEmbedDim]) posShape))
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">Embedding
  gradient
  ('Layout 'Dense)
  device
  dataType
  posEncDim
  inputEmbedDim
  'Nothing
-&gt; Tensor posGradient posLayout posDevice posDataType posShape
-&gt; generator
-&gt; m (Tensor
        (Or (Gradient RequiresGradient) gradient posGradient)
        (Unify (Layout LayoutType) ('Layout 'Dense) posLayout)
        (Unify (Device (DeviceType Nat)) device posDevice)
        (Seq
           (Unify (DataType DType) posDataType ('DataType 'Int64)) dataType)
        (EmbeddingF ('Shape '[posEncDim, inputEmbedDim]) posShape),
      generator)
forall model input generator output generatorOutput (m :: * -&gt; *).
(HasForward model input generator output generatorOutput,
 MonadThrow m) =&gt;
model -&gt; input -&gt; generator -&gt; m (output, generatorOutput)
</span><a href="Torch.GraduallyTyped.NN.Class.html#forward"><span class="hs-identifier hs-var">forward</span></a></span><span> </span><span class="annot"><span class="annottext">Embedding
  gradient
  ('Layout 'Dense)
  device
  dataType
  posEncDim
  inputEmbedDim
  'Nothing
TEPosEncF
  'RoBERTa gradient device dataType headDim inputEmbedDim posEncDim
</span><a href="#local-6989586621679770939"><span class="hs-identifier hs-var">tePosEnc</span></a></span><span>
</span><span id="line-866"></span><span>            </span><span class="annot"><span class="annottext">IxStateT
  m
  generator
  generator
  (Tensor
     (Or (Gradient RequiresGradient) gradient posGradient)
     (Unify (Layout LayoutType) ('Layout 'Dense) posLayout)
     (Unify (Device (DeviceType Nat)) device posDevice)
     (Seq
        (Unify (DataType DType) posDataType ('DataType 'Int64)) dataType)
     (EmbeddingF ('Shape '[posEncDim, inputEmbedDim]) posShape))
-&gt; (Tensor
      (Or (Gradient RequiresGradient) gradient posGradient)
      (Unify (Layout LayoutType) ('Layout 'Dense) posLayout)
      (Unify (Device (DeviceType Nat)) device posDevice)
      (Seq
         (Unify (DataType DType) posDataType ('DataType 'Int64)) dataType)
      (EmbeddingF ('Shape '[posEncDim, inputEmbedDim]) posShape)
    -&gt; IxStateT
         m
         generator
         generator
         (Tensor
            (Or
               (Gradient RequiresGradient)
               inputGradient
               (Or (Gradient RequiresGradient) gradient posGradient))
            (Unify
               (Layout LayoutType)
               inputLayout
               (Unify (Layout LayoutType) ('Layout 'Dense) posLayout))
            (Unify
               (Device (DeviceType Nat))
               inputDevice
               (Unify (Device (DeviceType Nat)) device posDevice))
            (Unify
               (DataType DType)
               inputDataType
               (Seq
                  (Unify (DataType DType) posDataType ('DataType 'Int64)) dataType))
            (BroadcastShapesF
               inputShape
               (EmbeddingF ('Shape '[posEncDim, inputEmbedDim]) posShape))))
-&gt; IxStateT
     m
     generator
     generator
     (Tensor
        (Or
           (Gradient RequiresGradient)
           inputGradient
           (Or (Gradient RequiresGradient) gradient posGradient))
        (Unify
           (Layout LayoutType)
           inputLayout
           (Unify (Layout LayoutType) ('Layout 'Dense) posLayout))
        (Unify
           (Device (DeviceType Nat))
           inputDevice
           (Unify (Device (DeviceType Nat)) device posDevice))
        (Unify
           (DataType DType)
           inputDataType
           (Seq
              (Unify (DataType DType) posDataType ('DataType 'Int64)) dataType))
        (BroadcastShapesF
           inputShape
           (EmbeddingF ('Shape '[posEncDim, inputEmbedDim]) posShape)))
forall k1 (m :: k1 -&gt; k1 -&gt; * -&gt; *) (i :: k1) (j :: k1) a
       (k2 :: k1) b.
IxMonad m =&gt;
m i j a -&gt; (a -&gt; m j k2 b) -&gt; m i k2 b
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&gt;&gt;&gt;=</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor
  (Or
     (Gradient RequiresGradient)
     inputGradient
     (Or (Gradient RequiresGradient) gradient posGradient))
  (Unify
     (Layout LayoutType)
     inputLayout
     (Unify (Layout LayoutType) ('Layout 'Dense) posLayout))
  (Unify
     (Device (DeviceType Nat))
     inputDevice
     (Unify (Device (DeviceType Nat)) device posDevice))
  (Unify
     (DataType DType)
     inputDataType
     (Seq
        (Unify (DataType DType) posDataType ('DataType 'Int64)) dataType))
  (BroadcastShapesF
     inputShape
     (EmbeddingF ('Shape '[posEncDim, inputEmbedDim]) posShape))
-&gt; IxStateT
     m
     generator
     generator
     (Tensor
        (Or
           (Gradient RequiresGradient)
           inputGradient
           (Or (Gradient RequiresGradient) gradient posGradient))
        (Unify
           (Layout LayoutType)
           inputLayout
           (Unify (Layout LayoutType) ('Layout 'Dense) posLayout))
        (Unify
           (Device (DeviceType Nat))
           inputDevice
           (Unify (Device (DeviceType Nat)) device posDevice))
        (Unify
           (DataType DType)
           inputDataType
           (Seq
              (Unify (DataType DType) posDataType ('DataType 'Int64)) dataType))
        (BroadcastShapesF
           inputShape
           (EmbeddingF ('Shape '[posEncDim, inputEmbedDim]) posShape)))
forall k (m :: k -&gt; k -&gt; * -&gt; *) a (i :: k).
IxPointed m =&gt;
a -&gt; m i i a
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-identifier hs-var">ireturn</span></a></span><span> </span><span class="annot"><span class="annottext">(Tensor
   (Or
      (Gradient RequiresGradient)
      inputGradient
      (Or (Gradient RequiresGradient) gradient posGradient))
   (Unify
      (Layout LayoutType)
      inputLayout
      (Unify (Layout LayoutType) ('Layout 'Dense) posLayout))
   (Unify
      (Device (DeviceType Nat))
      inputDevice
      (Unify (Device (DeviceType Nat)) device posDevice))
   (Unify
      (DataType DType)
      inputDataType
      (Seq
         (Unify (DataType DType) posDataType ('DataType 'Int64)) dataType))
   (BroadcastShapesF
      inputShape
      (EmbeddingF ('Shape '[posEncDim, inputEmbedDim]) posShape))
 -&gt; IxStateT
      m
      generator
      generator
      (Tensor
         (Or
            (Gradient RequiresGradient)
            inputGradient
            (Or (Gradient RequiresGradient) gradient posGradient))
         (Unify
            (Layout LayoutType)
            inputLayout
            (Unify (Layout LayoutType) ('Layout 'Dense) posLayout))
         (Unify
            (Device (DeviceType Nat))
            inputDevice
            (Unify (Device (DeviceType Nat)) device posDevice))
         (Unify
            (DataType DType)
            inputDataType
            (Seq
               (Unify (DataType DType) posDataType ('DataType 'Int64)) dataType))
         (BroadcastShapesF
            inputShape
            (EmbeddingF ('Shape '[posEncDim, inputEmbedDim]) posShape))))
-&gt; (Tensor
      (Or (Gradient RequiresGradient) gradient posGradient)
      (Unify (Layout LayoutType) ('Layout 'Dense) posLayout)
      (Unify (Device (DeviceType Nat)) device posDevice)
      (Seq
         (Unify (DataType DType) posDataType ('DataType 'Int64)) dataType)
      (EmbeddingF ('Shape '[posEncDim, inputEmbedDim]) posShape)
    -&gt; Tensor
         (Or
            (Gradient RequiresGradient)
            inputGradient
            (Or (Gradient RequiresGradient) gradient posGradient))
         (Unify
            (Layout LayoutType)
            inputLayout
            (Unify (Layout LayoutType) ('Layout 'Dense) posLayout))
         (Unify
            (Device (DeviceType Nat))
            inputDevice
            (Unify (Device (DeviceType Nat)) device posDevice))
         (Unify
            (DataType DType)
            inputDataType
            (Seq
               (Unify (DataType DType) posDataType ('DataType 'Int64)) dataType))
         (BroadcastShapesF
            inputShape
            (EmbeddingF ('Shape '[posEncDim, inputEmbedDim]) posShape)))
-&gt; Tensor
     (Or (Gradient RequiresGradient) gradient posGradient)
     (Unify (Layout LayoutType) ('Layout 'Dense) posLayout)
     (Unify (Device (DeviceType Nat)) device posDevice)
     (Seq
        (Unify (DataType DType) posDataType ('DataType 'Int64)) dataType)
     (EmbeddingF ('Shape '[posEncDim, inputEmbedDim]) posShape)
-&gt; IxStateT
     m
     generator
     generator
     (Tensor
        (Or
           (Gradient RequiresGradient)
           inputGradient
           (Or (Gradient RequiresGradient) gradient posGradient))
        (Unify
           (Layout LayoutType)
           inputLayout
           (Unify (Layout LayoutType) ('Layout 'Dense) posLayout))
        (Unify
           (Device (DeviceType Nat))
           inputDevice
           (Unify (Device (DeviceType Nat)) device posDevice))
        (Unify
           (DataType DType)
           inputDataType
           (Seq
              (Unify (DataType DType) posDataType ('DataType 'Int64)) dataType))
        (BroadcastShapesF
           inputShape
           (EmbeddingF ('Shape '[posEncDim, inputEmbedDim]) posShape)))
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">Tensor
  inputGradient inputLayout inputDevice inputDataType inputShape
</span><a href="#local-6989586621679770938"><span class="hs-identifier hs-var">input</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor
  inputGradient inputLayout inputDevice inputDataType inputShape
-&gt; Tensor
     (Or (Gradient RequiresGradient) gradient posGradient)
     (Unify (Layout LayoutType) ('Layout 'Dense) posLayout)
     (Unify (Device (DeviceType Nat)) device posDevice)
     (Seq
        (Unify (DataType DType) posDataType ('DataType 'Int64)) dataType)
     (EmbeddingF ('Shape '[posEncDim, inputEmbedDim]) posShape)
-&gt; Tensor
     (inputGradient
      &lt;|&gt; Or (Gradient RequiresGradient) gradient posGradient)
     (inputLayout
      &lt;+&gt; Unify (Layout LayoutType) ('Layout 'Dense) posLayout)
     (inputDevice &lt;+&gt; Unify (Device (DeviceType Nat)) device posDevice)
     (inputDataType
      &lt;+&gt; Seq
            (Unify (DataType DType) posDataType ('DataType 'Int64)) dataType)
     (BroadcastShapesF
        inputShape
        (EmbeddingF ('Shape '[posEncDim, inputEmbedDim]) posShape))
forall (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)])
       (gradient' :: Gradient RequiresGradient)
       (layout' :: Layout LayoutType) (device' :: Device (DeviceType Nat))
       (dataType' :: DataType DType)
       (shape' :: Shape [Dim (Name Symbol) (Size Nat)]).
Tensor gradient layout device dataType shape
-&gt; Tensor gradient' layout' device' dataType' shape'
-&gt; Tensor
     (gradient &lt;|&gt; gradient')
     (layout &lt;+&gt; layout')
     (device &lt;+&gt; device')
     (dataType &lt;+&gt; dataType')
     (BroadcastShapesF shape shape')
</span><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#add"><span class="hs-operator hs-var">`add`</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-867"></span><span>            </span><span class="annot"><span class="annottext">IxStateT
  m
  generator
  generator
  (Tensor
     (Or
        (Gradient RequiresGradient)
        inputGradient
        (Or (Gradient RequiresGradient) gradient posGradient))
     (Unify
        (Layout LayoutType)
        inputLayout
        (Unify (Layout LayoutType) ('Layout 'Dense) posLayout))
     (Unify
        (Device (DeviceType Nat))
        inputDevice
        (Unify (Device (DeviceType Nat)) device posDevice))
     (Unify
        (DataType DType)
        inputDataType
        (Seq
           (Unify (DataType DType) posDataType ('DataType 'Int64)) dataType))
     (BroadcastShapesF
        inputShape
        (EmbeddingF ('Shape '[posEncDim, inputEmbedDim]) posShape)))
-&gt; (Tensor
      (Or
         (Gradient RequiresGradient)
         inputGradient
         (Or (Gradient RequiresGradient) gradient posGradient))
      (Unify
         (Layout LayoutType)
         inputLayout
         (Unify (Layout LayoutType) ('Layout 'Dense) posLayout))
      (Unify
         (Device (DeviceType Nat))
         inputDevice
         (Unify (Device (DeviceType Nat)) device posDevice))
      (Unify
         (DataType DType)
         inputDataType
         (Seq
            (Unify (DataType DType) posDataType ('DataType 'Int64)) dataType))
      (BroadcastShapesF
         inputShape
         (EmbeddingF ('Shape '[posEncDim, inputEmbedDim]) posShape))
    -&gt; IxStateT m generator generator layerNormOutput)
-&gt; IxStateT m generator generator layerNormOutput
forall k1 (m :: k1 -&gt; k1 -&gt; * -&gt; *) (i :: k1) (j :: k1) a
       (k2 :: k1) b.
IxMonad m =&gt;
m i j a -&gt; (a -&gt; m j k2 b) -&gt; m i k2 b
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&gt;&gt;&gt;=</span></a></span><span> </span><span class="annot"><span class="annottext">(generator -&gt; m (layerNormOutput, generator))
-&gt; IxStateT m generator generator layerNormOutput
forall (m :: * -&gt; *) i j a. (i -&gt; m (a, j)) -&gt; IxStateT m i j a
</span><a href="../file:///nix/store/8vjaffqxij7bih93d9mlzmc7ksanlw0i-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier hs-var">IxStateT</span></a></span><span> </span><span class="annot"><span class="annottext">((generator -&gt; m (layerNormOutput, generator))
 -&gt; IxStateT m generator generator layerNormOutput)
-&gt; (Tensor
      (Or
         (Gradient RequiresGradient)
         inputGradient
         (Or (Gradient RequiresGradient) gradient posGradient))
      (Unify
         (Layout LayoutType)
         inputLayout
         (Unify (Layout LayoutType) ('Layout 'Dense) posLayout))
      (Unify
         (Device (DeviceType Nat))
         inputDevice
         (Unify (Device (DeviceType Nat)) device posDevice))
      (Unify
         (DataType DType)
         inputDataType
         (Seq
            (Unify (DataType DType) posDataType ('DataType 'Int64)) dataType))
      (BroadcastShapesF
         inputShape
         (EmbeddingF ('Shape '[posEncDim, inputEmbedDim]) posShape))
    -&gt; generator -&gt; m (layerNormOutput, generator))
-&gt; Tensor
     (Or
        (Gradient RequiresGradient)
        inputGradient
        (Or (Gradient RequiresGradient) gradient posGradient))
     (Unify
        (Layout LayoutType)
        inputLayout
        (Unify (Layout LayoutType) ('Layout 'Dense) posLayout))
     (Unify
        (Device (DeviceType Nat))
        inputDevice
        (Unify (Device (DeviceType Nat)) device posDevice))
     (Unify
        (DataType DType)
        inputDataType
        (Seq
           (Unify (DataType DType) posDataType ('DataType 'Int64)) dataType))
     (BroadcastShapesF
        inputShape
        (EmbeddingF ('Shape '[posEncDim, inputEmbedDim]) posShape))
-&gt; IxStateT m generator generator layerNormOutput
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">LayerNorm
  'WithBias gradient device dataType ('Shape '[inputEmbedDim])
-&gt; Tensor
     (Or
        (Gradient RequiresGradient)
        inputGradient
        (Or (Gradient RequiresGradient) gradient posGradient))
     (Unify
        (Layout LayoutType)
        inputLayout
        (Unify (Layout LayoutType) ('Layout 'Dense) posLayout))
     (Unify
        (Device (DeviceType Nat))
        inputDevice
        (Unify (Device (DeviceType Nat)) device posDevice))
     (Unify
        (DataType DType)
        inputDataType
        (Seq
           (Unify (DataType DType) posDataType ('DataType 'Int64)) dataType))
     (BroadcastShapesF
        inputShape
        (EmbeddingF ('Shape '[posEncDim, inputEmbedDim]) posShape))
-&gt; generator
-&gt; m (layerNormOutput, generator)
forall model input generator output generatorOutput (m :: * -&gt; *).
(HasForward model input generator output generatorOutput,
 MonadThrow m) =&gt;
model -&gt; input -&gt; generator -&gt; m (output, generatorOutput)
</span><a href="Torch.GraduallyTyped.NN.Class.html#forward"><span class="hs-identifier hs-var">forward</span></a></span><span> </span><span class="annot"><span class="annottext">LayerNorm
  'WithBias gradient device dataType ('Shape '[inputEmbedDim])
TEEmbedLayerNormF 'RoBERTa gradient device dataType inputEmbedDim
</span><a href="#local-6989586621679770942"><span class="hs-identifier hs-var">teEmbedLayerNorm</span></a></span><span>
</span><span id="line-868"></span><span>            </span><span class="annot"><span class="annottext">IxStateT m generator generator layerNormOutput
-&gt; (layerNormOutput
    -&gt; IxStateT m generator dropoutGeneratorOutput dropoutOutput)
-&gt; IxStateT m generator dropoutGeneratorOutput dropoutOutput
forall k1 (m :: k1 -&gt; k1 -&gt; * -&gt; *) (i :: k1) (j :: k1) a
       (k2 :: k1) b.
IxMonad m =&gt;
m i j a -&gt; (a -&gt; m j k2 b) -&gt; m i k2 b
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&gt;&gt;&gt;=</span></a></span><span> </span><span class="annot"><span class="annottext">(generator -&gt; m (dropoutOutput, dropoutGeneratorOutput))
-&gt; IxStateT m generator dropoutGeneratorOutput dropoutOutput
forall (m :: * -&gt; *) i j a. (i -&gt; m (a, j)) -&gt; IxStateT m i j a
</span><a href="../file:///nix/store/8vjaffqxij7bih93d9mlzmc7ksanlw0i-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier hs-var">IxStateT</span></a></span><span> </span><span class="annot"><span class="annottext">((generator -&gt; m (dropoutOutput, dropoutGeneratorOutput))
 -&gt; IxStateT m generator dropoutGeneratorOutput dropoutOutput)
-&gt; (layerNormOutput
    -&gt; generator -&gt; m (dropoutOutput, dropoutGeneratorOutput))
-&gt; layerNormOutput
-&gt; IxStateT m generator dropoutGeneratorOutput dropoutOutput
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">Dropout dropoutP
-&gt; layerNormOutput
-&gt; generator
-&gt; m (dropoutOutput, dropoutGeneratorOutput)
forall model input generator output generatorOutput (m :: * -&gt; *).
(HasForward model input generator output generatorOutput,
 MonadThrow m) =&gt;
model -&gt; input -&gt; generator -&gt; m (output, generatorOutput)
</span><a href="Torch.GraduallyTyped.NN.Class.html#forward"><span class="hs-identifier hs-var">forward</span></a></span><span> </span><span class="annot"><span class="annottext">Dropout dropoutP
TEDropoutF 'RoBERTa dropoutP
</span><a href="#local-6989586621679770940"><span class="hs-identifier hs-var">teDropout</span></a></span><span>
</span><span id="line-869"></span><span>            </span><span class="annot"><span class="annottext">IxStateT m generator dropoutGeneratorOutput dropoutOutput
-&gt; (dropoutOutput
    -&gt; IxStateT m dropoutGeneratorOutput generatorOutput output)
-&gt; IxStateT m generator generatorOutput output
forall k1 (m :: k1 -&gt; k1 -&gt; * -&gt; *) (i :: k1) (j :: k1) a
       (k2 :: k1) b.
IxMonad m =&gt;
m i j a -&gt; (a -&gt; m j k2 b) -&gt; m i k2 b
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&gt;&gt;&gt;=</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">\</span><span id="local-6989586621679770934"><span class="annot"><span class="annottext">dropoutOutput
</span><a href="#local-6989586621679770934"><span class="hs-identifier hs-var">input'</span></a></span></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><span class="annottext">(dropoutGeneratorOutput -&gt; m (output, generatorOutput))
-&gt; IxStateT m dropoutGeneratorOutput generatorOutput output
forall (m :: * -&gt; *) i j a. (i -&gt; m (a, j)) -&gt; IxStateT m i j a
</span><a href="../file:///nix/store/8vjaffqxij7bih93d9mlzmc7ksanlw0i-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier hs-var">IxStateT</span></a></span><span> </span><span class="annot"><span class="annottext">((dropoutGeneratorOutput -&gt; m (output, generatorOutput))
 -&gt; IxStateT m dropoutGeneratorOutput generatorOutput output)
-&gt; (dropoutGeneratorOutput -&gt; m (output, generatorOutput))
-&gt; IxStateT m dropoutGeneratorOutput generatorOutput output
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">TransformerStack
  'RoBERTa
  numLayers
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  inputEmbedDim
  ffnDim
  dropoutP
-&gt; (dropoutOutput,
    Tensor
      attentionMaskGradient
      attentionMaskLayout
      attentionMaskDevice
      attentionMaskDataType
      (UnsqueezeF ('SelectDim ('ByIndex 1)) attentionMaskShape))
-&gt; dropoutGeneratorOutput
-&gt; m (output, generatorOutput)
forall model input generator output generatorOutput (m :: * -&gt; *).
(HasForward model input generator output generatorOutput,
 MonadThrow m) =&gt;
model -&gt; input -&gt; generator -&gt; m (output, generatorOutput)
</span><a href="Torch.GraduallyTyped.NN.Class.html#forward"><span class="hs-identifier hs-var">forward</span></a></span><span> </span><span class="annot"><span class="annottext">TransformerStack
  'RoBERTa
  numLayers
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  inputEmbedDim
  ffnDim
  dropoutP
TEStackF
  'RoBERTa
  numLayers
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  inputEmbedDim
  ffnDim
  dropoutP
</span><a href="#local-6989586621679770943"><span class="hs-identifier hs-var">teStack</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">dropoutOutput
</span><a href="#local-6989586621679770934"><span class="hs-identifier hs-var">input'</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">Tensor
  attentionMaskGradient
  attentionMaskLayout
  attentionMaskDevice
  attentionMaskDataType
  (UnsqueezeF ('SelectDim ('ByIndex 1)) attentionMaskShape)
</span><a href="#local-6989586621679770935"><span class="hs-identifier hs-var">attentionBias</span></a></span><span class="hs-special">)</span><span class="hs-special">)</span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span><span>
</span><span id="line-870"></span><span>
</span><span id="line-871"></span><span class="hs-comment">-- | 'HasForward' instance for @TransformerEncoder numLayers 'Pegasus@.</span><span>
</span><span id="line-872"></span><span class="hs-comment">--</span><span>
</span><span id="line-873"></span><span class="hs-comment">-- @</span><span>
</span><span id="line-874"></span><span class="hs-comment">-- &#9484;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9488;  &#9484;&#9472;&#9472;&#9472;&#9472;&#9472;&#9488;  &#9484;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9488;</span><span>
</span><span id="line-875"></span><span class="hs-comment">-- &#9474; input &#9474;  &#9474; pos &#9474;  &#9474; attentionMask &#9474;</span><span>
</span><span id="line-876"></span><span class="hs-comment">-- &#9492;&#9472;&#9472;&#9472;&#9516;&#9472;&#9472;&#9472;&#9496;  &#9492;&#9472;&#9472;&#9472;&#9472;&#9472;&#9496;  &#9492;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9516;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9496;</span><span>
</span><span id="line-877"></span><span class="hs-comment">--     &#9474;         &#9474;             &#9474;</span><span>
</span><span id="line-878"></span><span class="hs-comment">--     &#9474;         &#9660;             &#9474;</span><span>
</span><span id="line-879"></span><span class="hs-comment">--     &#9474;     tePosEnc          &#9474;</span><span>
</span><span id="line-880"></span><span class="hs-comment">--     &#9474;         &#9474;             &#9474;</span><span>
</span><span id="line-881"></span><span class="hs-comment">--     &#9492;&#9472;&#9472;&#9658;add&#9668;&#9472;&#9472;&#9496;             &#9474;</span><span>
</span><span id="line-882"></span><span class="hs-comment">--          &#9474;                  &#9474;</span><span>
</span><span id="line-883"></span><span class="hs-comment">--          &#9660;                  &#9660;</span><span>
</span><span id="line-884"></span><span class="hs-comment">--      teDropout          unsqueeze</span><span>
</span><span id="line-885"></span><span class="hs-comment">--          &#9660;                  &#9474;</span><span>
</span><span id="line-886"></span><span class="hs-comment">--       teStack&#9668;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9496;</span><span>
</span><span id="line-887"></span><span class="hs-comment">--          &#9660;</span><span>
</span><span id="line-888"></span><span class="hs-comment">--     teLayerNorm</span><span>
</span><span id="line-889"></span><span class="hs-comment">--          &#9474;</span><span>
</span><span id="line-890"></span><span class="hs-comment">--          &#9660;</span><span>
</span><span id="line-891"></span><span class="hs-comment">--     &#9484;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9488;</span><span>
</span><span id="line-892"></span><span class="hs-comment">--     &#9474; output &#9474;</span><span>
</span><span id="line-893"></span><span class="hs-comment">--     &#9492;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9496;</span><span>
</span><span id="line-894"></span><span class="hs-comment">-- @</span><span>
</span><span id="line-895"></span><span id="local-6989586621679770902"><span id="local-6989586621679770903"><span id="local-6989586621679770904"><span id="local-6989586621679770905"><span id="local-6989586621679770906"><span id="local-6989586621679770907"><span id="local-6989586621679770908"><span id="local-6989586621679770909"><span id="local-6989586621679770910"><span id="local-6989586621679770911"><span id="local-6989586621679770912"><span id="local-6989586621679770913"><span id="local-6989586621679770914"><span id="local-6989586621679770915"><span id="local-6989586621679770916"><span id="local-6989586621679770917"><span id="local-6989586621679770918"><span id="local-6989586621679770919"><span id="local-6989586621679770920"><span id="local-6989586621679770921"><span id="local-6989586621679770922"><span id="local-6989586621679770923"><span id="local-6989586621679770924"><span id="local-6989586621679770925"><span id="local-6989586621679770926"><span id="local-6989586621679770927"><span id="local-6989586621679770928"><span id="local-6989586621679770929"><span id="local-6989586621679770930"><span id="local-6989586621679770931"><span id="local-6989586621679770932"><span id="local-6989586621679770933"><span class="hs-keyword">instance</span><span>
</span><span id="line-896"></span><span>  </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasForward"><span class="hs-identifier hs-type">HasForward</span></a></span><span>
</span><span id="line-897"></span><span>      </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Encoder.html#TEDropoutF"><span class="hs-identifier hs-type">TEDropoutF</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#Pegasus"><span class="hs-identifier hs-type">Pegasus</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679770933"><span class="hs-identifier hs-type">dropoutP</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-898"></span><span>      </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span>
</span><span id="line-899"></span><span>          </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679770932"><span class="hs-identifier hs-type">inputGradient</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%7C%3E"><span class="hs-operator hs-type">&lt;|&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679770931"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%7C%3E"><span class="hs-operator hs-type">&lt;|&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679770930"><span class="hs-identifier hs-type">posGradient</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-900"></span><span>          </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679770929"><span class="hs-identifier hs-type">inputLayout</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#Layout"><span class="hs-identifier hs-type">Layout</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#Dense"><span class="hs-identifier hs-type">Dense</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679770928"><span class="hs-identifier hs-type">posLayout</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-901"></span><span>          </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679770927"><span class="hs-identifier hs-type">inputDevice</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679770926"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679770925"><span class="hs-identifier hs-type">posDevice</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-902"></span><span>          </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679770924"><span class="hs-identifier hs-type">inputDataType</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Prelude.html#Seq"><span class="hs-identifier hs-type">Seq</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679770923"><span class="hs-identifier hs-type">posDataType</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#DataType"><span class="hs-identifier hs-type">DataType</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#Int64"><span class="hs-identifier hs-type">Int64</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679770922"><span class="hs-identifier hs-type">dataType</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-903"></span><span>          </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Class.html#BroadcastShapesF"><span class="hs-identifier hs-type">BroadcastShapesF</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679770921"><span class="hs-identifier hs-type">inputShape</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Functional.Sparse.html#EmbeddingF"><span class="hs-identifier hs-type">EmbeddingF</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Shape"><span class="hs-identifier hs-type">Shape</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="annot"><a href="#local-6989586621679770920"><span class="hs-identifier hs-type">posEncDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679770919"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span><span class="hs-special">]</span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679770918"><span class="hs-identifier hs-type">posShape</span></a></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-904"></span><span>      </span><span class="hs-special">)</span><span>
</span><span id="line-905"></span><span>      </span><span class="annot"><a href="#local-6989586621679770917"><span class="hs-identifier hs-type">generator</span></a></span><span>
</span><span id="line-906"></span><span>      </span><span class="annot"><a href="#local-6989586621679770916"><span class="hs-identifier hs-type">dropoutOutput</span></a></span><span>
</span><span id="line-907"></span><span>      </span><span class="annot"><a href="#local-6989586621679770915"><span class="hs-identifier hs-type">dropoutGeneratorOutput</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-908"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasForward"><span class="hs-identifier hs-type">HasForward</span></a></span><span>
</span><span id="line-909"></span><span>      </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Encoder.html#TEStackF"><span class="hs-identifier hs-type">TEStackF</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#Pegasus"><span class="hs-identifier hs-type">Pegasus</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679770914"><span class="hs-identifier hs-type">numLayers</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679770931"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679770926"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679770922"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679770913"><span class="hs-identifier hs-type">headDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679770912"><span class="hs-identifier hs-type">headEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679770911"><span class="hs-identifier hs-type">embedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679770919"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679770910"><span class="hs-identifier hs-type">ffnDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679770933"><span class="hs-identifier hs-type">dropoutP</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-910"></span><span>      </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="#local-6989586621679770916"><span class="hs-identifier hs-type">dropoutOutput</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-911"></span><span>        </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span>
</span><span id="line-912"></span><span>          </span><span class="annot"><a href="#local-6989586621679770909"><span class="hs-identifier hs-type">attentionMaskGradient</span></a></span><span>
</span><span id="line-913"></span><span>          </span><span class="annot"><a href="#local-6989586621679770908"><span class="hs-identifier hs-type">attentionMaskLayout</span></a></span><span>
</span><span id="line-914"></span><span>          </span><span class="annot"><a href="#local-6989586621679770907"><span class="hs-identifier hs-type">attentionMaskDevice</span></a></span><span>
</span><span id="line-915"></span><span>          </span><span class="annot"><a href="#local-6989586621679770906"><span class="hs-identifier hs-type">attentionMaskDataType</span></a></span><span>
</span><span id="line-916"></span><span>          </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.IndexingSlicingJoining.html#UnsqueezeF"><span class="hs-identifier hs-type">UnsqueezeF</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SelectDim"><span class="hs-identifier hs-type">SelectDim</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#ByIndex"><span class="hs-identifier hs-type">ByIndex</span></a></span><span> </span><span class="annot"><span class="hs-number">1</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679770905"><span class="hs-identifier hs-type">attentionMaskShape</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-917"></span><span>      </span><span class="hs-special">)</span><span>
</span><span id="line-918"></span><span>      </span><span class="annot"><a href="#local-6989586621679770915"><span class="hs-identifier hs-type">dropoutGeneratorOutput</span></a></span><span>
</span><span id="line-919"></span><span>      </span><span class="annot"><a href="#local-6989586621679770904"><span class="hs-identifier hs-type">stackOutput</span></a></span><span>
</span><span id="line-920"></span><span>      </span><span class="annot"><a href="#local-6989586621679770903"><span class="hs-identifier hs-type">generatorOutput</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-921"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasForward"><span class="hs-identifier hs-type">HasForward</span></a></span><span>
</span><span id="line-922"></span><span>      </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Encoder.html#TELayerNormF"><span class="hs-identifier hs-type">TELayerNormF</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#Pegasus"><span class="hs-identifier hs-type">Pegasus</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679770931"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679770926"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679770922"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679770919"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-923"></span><span>      </span><span class="annot"><a href="#local-6989586621679770904"><span class="hs-identifier hs-type">stackOutput</span></a></span><span>
</span><span id="line-924"></span><span>      </span><span class="annot"><a href="#local-6989586621679770903"><span class="hs-identifier hs-type">generatorOutput</span></a></span><span>
</span><span id="line-925"></span><span>      </span><span class="annot"><a href="#local-6989586621679770902"><span class="hs-identifier hs-type">output</span></a></span><span>
</span><span id="line-926"></span><span>      </span><span class="annot"><a href="#local-6989586621679770903"><span class="hs-identifier hs-type">generatorOutput</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-927"></span><span>    </span><span class="annot"><span class="hs-identifier hs-type">Show</span></span><span> </span><span class="annot"><a href="#local-6989586621679770902"><span class="hs-identifier hs-type">output</span></a></span><span>
</span><span id="line-928"></span><span>  </span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-929"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasForward"><span class="hs-identifier hs-type">HasForward</span></a></span><span>
</span><span id="line-930"></span><span>    </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Encoder.html#TransformerEncoder"><span class="hs-identifier hs-type">TransformerEncoder</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#Pegasus"><span class="hs-identifier hs-type">Pegasus</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679770914"><span class="hs-identifier hs-type">numLayers</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679770931"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679770926"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679770922"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679770913"><span class="hs-identifier hs-type">headDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679770912"><span class="hs-identifier hs-type">headEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679770911"><span class="hs-identifier hs-type">embedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679770919"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679770910"><span class="hs-identifier hs-type">ffnDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679770920"><span class="hs-identifier hs-type">posEncDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679770933"><span class="hs-identifier hs-type">dropoutP</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-931"></span><span>    </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679770932"><span class="hs-identifier hs-type">inputGradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679770929"><span class="hs-identifier hs-type">inputLayout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679770927"><span class="hs-identifier hs-type">inputDevice</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679770924"><span class="hs-identifier hs-type">inputDataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679770921"><span class="hs-identifier hs-type">inputShape</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-932"></span><span>      </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679770930"><span class="hs-identifier hs-type">posGradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679770928"><span class="hs-identifier hs-type">posLayout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679770925"><span class="hs-identifier hs-type">posDevice</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679770923"><span class="hs-identifier hs-type">posDataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679770918"><span class="hs-identifier hs-type">posShape</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-933"></span><span>      </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679770909"><span class="hs-identifier hs-type">attentionMaskGradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679770908"><span class="hs-identifier hs-type">attentionMaskLayout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679770907"><span class="hs-identifier hs-type">attentionMaskDevice</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679770906"><span class="hs-identifier hs-type">attentionMaskDataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679770905"><span class="hs-identifier hs-type">attentionMaskShape</span></a></span><span>
</span><span id="line-934"></span><span>    </span><span class="hs-special">)</span><span>
</span><span id="line-935"></span><span>    </span><span class="annot"><a href="#local-6989586621679770917"><span class="hs-identifier hs-type">generator</span></a></span><span>
</span><span id="line-936"></span><span>    </span><span class="annot"><a href="#local-6989586621679770902"><span class="hs-identifier hs-type">output</span></a></span><span>
</span><span id="line-937"></span><span>    </span><span class="annot"><a href="#local-6989586621679770903"><span class="hs-identifier hs-type">generatorOutput</span></a></span><span>
</span><span id="line-938"></span><span>  </span><span class="hs-keyword">where</span><span>
</span><span id="line-939"></span><span>  </span><span id="local-6989586621679770900"><span class="annot"><span class="annottext">forward :: TransformerEncoder
  'Pegasus
  numLayers
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  inputEmbedDim
  ffnDim
  posEncDim
  dropoutP
-&gt; (Tensor
      inputGradient inputLayout inputDevice inputDataType inputShape,
    Tensor posGradient posLayout posDevice posDataType posShape,
    Tensor
      attentionMaskGradient
      attentionMaskLayout
      attentionMaskDevice
      attentionMaskDataType
      attentionMaskShape)
-&gt; generator
-&gt; m (output, generatorOutput)
</span><a href="#local-6989586621679770900"><span class="hs-identifier hs-var hs-var hs-var hs-var">forward</span></a></span></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Encoder.html#TransformerEncoder"><span class="hs-identifier hs-type">TransformerEncoder</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Encoder.html#GTransformerEncoder"><span class="hs-identifier hs-type">GTransformerEncoder</span></a></span><span> </span><span class="hs-special">{</span><span id="local-6989586621679770895"><span id="local-6989586621679770896"><span id="local-6989586621679770897"><span id="local-6989586621679770898"><span id="local-6989586621679770899"><span class="annot"><span class="annottext">TEPosEncF
  'Pegasus gradient device dataType headDim inputEmbedDim posEncDim
TEDropoutF 'Pegasus dropoutP
TELayerNormF 'Pegasus gradient device dataType inputEmbedDim
TEEmbedLayerNormF 'Pegasus gradient device dataType inputEmbedDim
TEStackF
  'Pegasus
  numLayers
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  inputEmbedDim
  ffnDim
  dropoutP
tePosEnc :: TEPosEncF
  'Pegasus gradient device dataType headDim inputEmbedDim posEncDim
teDropout :: TEDropoutF 'Pegasus dropoutP
teLayerNorm :: TELayerNormF 'Pegasus gradient device dataType inputEmbedDim
teEmbedLayerNorm :: TEEmbedLayerNormF 'Pegasus gradient device dataType inputEmbedDim
teStack :: TEStackF
  'Pegasus
  numLayers
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  inputEmbedDim
  ffnDim
  dropoutP
tePosEnc :: forall stack embedLayerNorm layerNorm dropout posEnc.
GTransformerEncoder stack embedLayerNorm layerNorm dropout posEnc
-&gt; posEnc
teDropout :: forall stack embedLayerNorm layerNorm dropout posEnc.
GTransformerEncoder stack embedLayerNorm layerNorm dropout posEnc
-&gt; dropout
teLayerNorm :: forall stack embedLayerNorm layerNorm dropout posEnc.
GTransformerEncoder stack embedLayerNorm layerNorm dropout posEnc
-&gt; layerNorm
teEmbedLayerNorm :: forall stack embedLayerNorm layerNorm dropout posEnc.
GTransformerEncoder stack embedLayerNorm layerNorm dropout posEnc
-&gt; embedLayerNorm
teStack :: forall stack embedLayerNorm layerNorm dropout posEnc.
GTransformerEncoder stack embedLayerNorm layerNorm dropout posEnc
-&gt; stack
</span><a href="#local-6989586621679770895"><span class="hs-glyph hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var">..</span></a></span></span></span></span></span></span><span class="hs-special">}</span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span id="local-6989586621679770894"><span class="annot"><span class="annottext">Tensor
  inputGradient inputLayout inputDevice inputDataType inputShape
</span><a href="#local-6989586621679770894"><span class="hs-identifier hs-var">input</span></a></span></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679770893"><span class="annot"><span class="annottext">Tensor posGradient posLayout posDevice posDataType posShape
</span><a href="#local-6989586621679770893"><span class="hs-identifier hs-var">pos</span></a></span></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679770892"><span class="annot"><span class="annottext">Tensor
  attentionMaskGradient
  attentionMaskLayout
  attentionMaskDevice
  attentionMaskDataType
  attentionMaskShape
</span><a href="#local-6989586621679770892"><span class="hs-identifier hs-var">attentionMask</span></a></span></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-940"></span><span>    </span><span class="hs-keyword">let</span><span> </span><span id="local-6989586621679770891"><span class="annot"><span class="annottext">attentionBias :: Tensor
  attentionMaskGradient
  attentionMaskLayout
  attentionMaskDevice
  attentionMaskDataType
  (UnsqueezeF ('SelectDim ('ByIndex 1)) attentionMaskShape)
</span><a href="#local-6989586621679770891"><span class="hs-identifier hs-var hs-var">attentionBias</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Tensor
  attentionMaskGradient
  attentionMaskLayout
  attentionMaskDevice
  attentionMaskDataType
  attentionMaskShape
-&gt; Tensor
     attentionMaskGradient
     attentionMaskLayout
     attentionMaskDevice
     attentionMaskDataType
     (UnsqueezeF ('SelectDim ('ByIndex 1)) attentionMaskShape)
forall (selectDim :: SelectDim (By Symbol Nat))
       (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)])
       (shape' :: Shape [Dim (Name Symbol) (Size Nat)]).
(shape' ~ UnsqueezeF selectDim shape, SingI selectDim) =&gt;
Tensor gradient layout device dataType shape
-&gt; Tensor gradient layout device dataType shape'
</span><a href="Torch.GraduallyTyped.Tensor.IndexingSlicingJoining.html#unsqueeze"><span class="hs-identifier hs-var">unsqueeze</span></a></span><span> </span><span class="hs-glyph">@</span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SelectDim"><span class="hs-identifier hs-type">SelectDim</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#ByIndex"><span class="hs-identifier hs-type">ByIndex</span></a></span><span> </span><span class="annot"><span class="hs-number">1</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">Tensor
  attentionMaskGradient
  attentionMaskLayout
  attentionMaskDevice
  attentionMaskDataType
  attentionMaskShape
</span><a href="#local-6989586621679770892"><span class="hs-identifier hs-var">attentionMask</span></a></span><span>
</span><span id="line-941"></span><span>     </span><span class="hs-keyword">in</span><span> </span><span class="annot"><span class="annottext">IxStateT m generator generatorOutput output
-&gt; generator -&gt; m (output, generatorOutput)
forall (m :: * -&gt; *) i j a. IxStateT m i j a -&gt; i -&gt; m (a, j)
</span><a href="../file:///nix/store/8vjaffqxij7bih93d9mlzmc7ksanlw0i-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier hs-var hs-var">runIxStateT</span></a></span><span> </span><span class="annot"><span class="annottext">(IxStateT m generator generatorOutput output
 -&gt; generator -&gt; m (output, generatorOutput))
-&gt; IxStateT m generator generatorOutput output
-&gt; generator
-&gt; m (output, generatorOutput)
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span>
</span><span id="line-942"></span><span>          </span><span class="annot"><span class="annottext">Tensor posGradient posLayout posDevice posDataType posShape
-&gt; IxStateT
     m
     generator
     generator
     (Tensor posGradient posLayout posDevice posDataType posShape)
forall k (m :: k -&gt; k -&gt; * -&gt; *) a (i :: k).
IxPointed m =&gt;
a -&gt; m i i a
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-identifier hs-var">ireturn</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor posGradient posLayout posDevice posDataType posShape
</span><a href="#local-6989586621679770893"><span class="hs-identifier hs-var">pos</span></a></span><span>
</span><span id="line-943"></span><span>            </span><span class="annot"><span class="annottext">IxStateT
  m
  generator
  generator
  (Tensor posGradient posLayout posDevice posDataType posShape)
-&gt; (Tensor posGradient posLayout posDevice posDataType posShape
    -&gt; IxStateT
         m
         generator
         generator
         (Tensor
            (Or (Gradient RequiresGradient) gradient posGradient)
            (Unify (Layout LayoutType) ('Layout 'Dense) posLayout)
            (Unify (Device (DeviceType Nat)) device posDevice)
            (Seq
               (Unify (DataType DType) posDataType ('DataType 'Int64)) dataType)
            (EmbeddingF ('Shape '[posEncDim, inputEmbedDim]) posShape)))
-&gt; IxStateT
     m
     generator
     generator
     (Tensor
        (Or (Gradient RequiresGradient) gradient posGradient)
        (Unify (Layout LayoutType) ('Layout 'Dense) posLayout)
        (Unify (Device (DeviceType Nat)) device posDevice)
        (Seq
           (Unify (DataType DType) posDataType ('DataType 'Int64)) dataType)
        (EmbeddingF ('Shape '[posEncDim, inputEmbedDim]) posShape))
forall k1 (m :: k1 -&gt; k1 -&gt; * -&gt; *) (i :: k1) (j :: k1) a
       (k2 :: k1) b.
IxMonad m =&gt;
m i j a -&gt; (a -&gt; m j k2 b) -&gt; m i k2 b
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&gt;&gt;&gt;=</span></a></span><span> </span><span class="annot"><span class="annottext">(generator
 -&gt; m (Tensor
         (Or (Gradient RequiresGradient) gradient posGradient)
         (Unify (Layout LayoutType) ('Layout 'Dense) posLayout)
         (Unify (Device (DeviceType Nat)) device posDevice)
         (Seq
            (Unify (DataType DType) posDataType ('DataType 'Int64)) dataType)
         (EmbeddingF ('Shape '[posEncDim, inputEmbedDim]) posShape),
       generator))
-&gt; IxStateT
     m
     generator
     generator
     (Tensor
        (Or (Gradient RequiresGradient) gradient posGradient)
        (Unify (Layout LayoutType) ('Layout 'Dense) posLayout)
        (Unify (Device (DeviceType Nat)) device posDevice)
        (Seq
           (Unify (DataType DType) posDataType ('DataType 'Int64)) dataType)
        (EmbeddingF ('Shape '[posEncDim, inputEmbedDim]) posShape))
forall (m :: * -&gt; *) i j a. (i -&gt; m (a, j)) -&gt; IxStateT m i j a
</span><a href="../file:///nix/store/8vjaffqxij7bih93d9mlzmc7ksanlw0i-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier hs-var">IxStateT</span></a></span><span> </span><span class="annot"><span class="annottext">((generator
  -&gt; m (Tensor
          (Or (Gradient RequiresGradient) gradient posGradient)
          (Unify (Layout LayoutType) ('Layout 'Dense) posLayout)
          (Unify (Device (DeviceType Nat)) device posDevice)
          (Seq
             (Unify (DataType DType) posDataType ('DataType 'Int64)) dataType)
          (EmbeddingF ('Shape '[posEncDim, inputEmbedDim]) posShape),
        generator))
 -&gt; IxStateT
      m
      generator
      generator
      (Tensor
         (Or (Gradient RequiresGradient) gradient posGradient)
         (Unify (Layout LayoutType) ('Layout 'Dense) posLayout)
         (Unify (Device (DeviceType Nat)) device posDevice)
         (Seq
            (Unify (DataType DType) posDataType ('DataType 'Int64)) dataType)
         (EmbeddingF ('Shape '[posEncDim, inputEmbedDim]) posShape)))
-&gt; (Tensor posGradient posLayout posDevice posDataType posShape
    -&gt; generator
    -&gt; m (Tensor
            (Or (Gradient RequiresGradient) gradient posGradient)
            (Unify (Layout LayoutType) ('Layout 'Dense) posLayout)
            (Unify (Device (DeviceType Nat)) device posDevice)
            (Seq
               (Unify (DataType DType) posDataType ('DataType 'Int64)) dataType)
            (EmbeddingF ('Shape '[posEncDim, inputEmbedDim]) posShape),
          generator))
-&gt; Tensor posGradient posLayout posDevice posDataType posShape
-&gt; IxStateT
     m
     generator
     generator
     (Tensor
        (Or (Gradient RequiresGradient) gradient posGradient)
        (Unify (Layout LayoutType) ('Layout 'Dense) posLayout)
        (Unify (Device (DeviceType Nat)) device posDevice)
        (Seq
           (Unify (DataType DType) posDataType ('DataType 'Int64)) dataType)
        (EmbeddingF ('Shape '[posEncDim, inputEmbedDim]) posShape))
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">Embedding
  gradient
  ('Layout 'Dense)
  device
  dataType
  posEncDim
  inputEmbedDim
  'Nothing
-&gt; Tensor posGradient posLayout posDevice posDataType posShape
-&gt; generator
-&gt; m (Tensor
        (Or (Gradient RequiresGradient) gradient posGradient)
        (Unify (Layout LayoutType) ('Layout 'Dense) posLayout)
        (Unify (Device (DeviceType Nat)) device posDevice)
        (Seq
           (Unify (DataType DType) posDataType ('DataType 'Int64)) dataType)
        (EmbeddingF ('Shape '[posEncDim, inputEmbedDim]) posShape),
      generator)
forall model input generator output generatorOutput (m :: * -&gt; *).
(HasForward model input generator output generatorOutput,
 MonadThrow m) =&gt;
model -&gt; input -&gt; generator -&gt; m (output, generatorOutput)
</span><a href="Torch.GraduallyTyped.NN.Class.html#forward"><span class="hs-identifier hs-var">forward</span></a></span><span> </span><span class="annot"><span class="annottext">Embedding
  gradient
  ('Layout 'Dense)
  device
  dataType
  posEncDim
  inputEmbedDim
  'Nothing
TEPosEncF
  'Pegasus gradient device dataType headDim inputEmbedDim posEncDim
</span><a href="#local-6989586621679770895"><span class="hs-identifier hs-var">tePosEnc</span></a></span><span>
</span><span id="line-944"></span><span>            </span><span class="annot"><span class="annottext">IxStateT
  m
  generator
  generator
  (Tensor
     (Or (Gradient RequiresGradient) gradient posGradient)
     (Unify (Layout LayoutType) ('Layout 'Dense) posLayout)
     (Unify (Device (DeviceType Nat)) device posDevice)
     (Seq
        (Unify (DataType DType) posDataType ('DataType 'Int64)) dataType)
     (EmbeddingF ('Shape '[posEncDim, inputEmbedDim]) posShape))
-&gt; (Tensor
      (Or (Gradient RequiresGradient) gradient posGradient)
      (Unify (Layout LayoutType) ('Layout 'Dense) posLayout)
      (Unify (Device (DeviceType Nat)) device posDevice)
      (Seq
         (Unify (DataType DType) posDataType ('DataType 'Int64)) dataType)
      (EmbeddingF ('Shape '[posEncDim, inputEmbedDim]) posShape)
    -&gt; IxStateT
         m
         generator
         generator
         (Tensor
            (Or
               (Gradient RequiresGradient)
               inputGradient
               (Or (Gradient RequiresGradient) gradient posGradient))
            (Unify
               (Layout LayoutType)
               inputLayout
               (Unify (Layout LayoutType) ('Layout 'Dense) posLayout))
            (Unify
               (Device (DeviceType Nat))
               inputDevice
               (Unify (Device (DeviceType Nat)) device posDevice))
            (Unify
               (DataType DType)
               inputDataType
               (Seq
                  (Unify (DataType DType) posDataType ('DataType 'Int64)) dataType))
            (BroadcastShapesF
               inputShape
               (EmbeddingF ('Shape '[posEncDim, inputEmbedDim]) posShape))))
-&gt; IxStateT
     m
     generator
     generator
     (Tensor
        (Or
           (Gradient RequiresGradient)
           inputGradient
           (Or (Gradient RequiresGradient) gradient posGradient))
        (Unify
           (Layout LayoutType)
           inputLayout
           (Unify (Layout LayoutType) ('Layout 'Dense) posLayout))
        (Unify
           (Device (DeviceType Nat))
           inputDevice
           (Unify (Device (DeviceType Nat)) device posDevice))
        (Unify
           (DataType DType)
           inputDataType
           (Seq
              (Unify (DataType DType) posDataType ('DataType 'Int64)) dataType))
        (BroadcastShapesF
           inputShape
           (EmbeddingF ('Shape '[posEncDim, inputEmbedDim]) posShape)))
forall k1 (m :: k1 -&gt; k1 -&gt; * -&gt; *) (i :: k1) (j :: k1) a
       (k2 :: k1) b.
IxMonad m =&gt;
m i j a -&gt; (a -&gt; m j k2 b) -&gt; m i k2 b
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&gt;&gt;&gt;=</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor
  (Or
     (Gradient RequiresGradient)
     inputGradient
     (Or (Gradient RequiresGradient) gradient posGradient))
  (Unify
     (Layout LayoutType)
     inputLayout
     (Unify (Layout LayoutType) ('Layout 'Dense) posLayout))
  (Unify
     (Device (DeviceType Nat))
     inputDevice
     (Unify (Device (DeviceType Nat)) device posDevice))
  (Unify
     (DataType DType)
     inputDataType
     (Seq
        (Unify (DataType DType) posDataType ('DataType 'Int64)) dataType))
  (BroadcastShapesF
     inputShape
     (EmbeddingF ('Shape '[posEncDim, inputEmbedDim]) posShape))
-&gt; IxStateT
     m
     generator
     generator
     (Tensor
        (Or
           (Gradient RequiresGradient)
           inputGradient
           (Or (Gradient RequiresGradient) gradient posGradient))
        (Unify
           (Layout LayoutType)
           inputLayout
           (Unify (Layout LayoutType) ('Layout 'Dense) posLayout))
        (Unify
           (Device (DeviceType Nat))
           inputDevice
           (Unify (Device (DeviceType Nat)) device posDevice))
        (Unify
           (DataType DType)
           inputDataType
           (Seq
              (Unify (DataType DType) posDataType ('DataType 'Int64)) dataType))
        (BroadcastShapesF
           inputShape
           (EmbeddingF ('Shape '[posEncDim, inputEmbedDim]) posShape)))
forall k (m :: k -&gt; k -&gt; * -&gt; *) a (i :: k).
IxPointed m =&gt;
a -&gt; m i i a
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-identifier hs-var">ireturn</span></a></span><span> </span><span class="annot"><span class="annottext">(Tensor
   (Or
      (Gradient RequiresGradient)
      inputGradient
      (Or (Gradient RequiresGradient) gradient posGradient))
   (Unify
      (Layout LayoutType)
      inputLayout
      (Unify (Layout LayoutType) ('Layout 'Dense) posLayout))
   (Unify
      (Device (DeviceType Nat))
      inputDevice
      (Unify (Device (DeviceType Nat)) device posDevice))
   (Unify
      (DataType DType)
      inputDataType
      (Seq
         (Unify (DataType DType) posDataType ('DataType 'Int64)) dataType))
   (BroadcastShapesF
      inputShape
      (EmbeddingF ('Shape '[posEncDim, inputEmbedDim]) posShape))
 -&gt; IxStateT
      m
      generator
      generator
      (Tensor
         (Or
            (Gradient RequiresGradient)
            inputGradient
            (Or (Gradient RequiresGradient) gradient posGradient))
         (Unify
            (Layout LayoutType)
            inputLayout
            (Unify (Layout LayoutType) ('Layout 'Dense) posLayout))
         (Unify
            (Device (DeviceType Nat))
            inputDevice
            (Unify (Device (DeviceType Nat)) device posDevice))
         (Unify
            (DataType DType)
            inputDataType
            (Seq
               (Unify (DataType DType) posDataType ('DataType 'Int64)) dataType))
         (BroadcastShapesF
            inputShape
            (EmbeddingF ('Shape '[posEncDim, inputEmbedDim]) posShape))))
-&gt; (Tensor
      (Or (Gradient RequiresGradient) gradient posGradient)
      (Unify (Layout LayoutType) ('Layout 'Dense) posLayout)
      (Unify (Device (DeviceType Nat)) device posDevice)
      (Seq
         (Unify (DataType DType) posDataType ('DataType 'Int64)) dataType)
      (EmbeddingF ('Shape '[posEncDim, inputEmbedDim]) posShape)
    -&gt; Tensor
         (Or
            (Gradient RequiresGradient)
            inputGradient
            (Or (Gradient RequiresGradient) gradient posGradient))
         (Unify
            (Layout LayoutType)
            inputLayout
            (Unify (Layout LayoutType) ('Layout 'Dense) posLayout))
         (Unify
            (Device (DeviceType Nat))
            inputDevice
            (Unify (Device (DeviceType Nat)) device posDevice))
         (Unify
            (DataType DType)
            inputDataType
            (Seq
               (Unify (DataType DType) posDataType ('DataType 'Int64)) dataType))
         (BroadcastShapesF
            inputShape
            (EmbeddingF ('Shape '[posEncDim, inputEmbedDim]) posShape)))
-&gt; Tensor
     (Or (Gradient RequiresGradient) gradient posGradient)
     (Unify (Layout LayoutType) ('Layout 'Dense) posLayout)
     (Unify (Device (DeviceType Nat)) device posDevice)
     (Seq
        (Unify (DataType DType) posDataType ('DataType 'Int64)) dataType)
     (EmbeddingF ('Shape '[posEncDim, inputEmbedDim]) posShape)
-&gt; IxStateT
     m
     generator
     generator
     (Tensor
        (Or
           (Gradient RequiresGradient)
           inputGradient
           (Or (Gradient RequiresGradient) gradient posGradient))
        (Unify
           (Layout LayoutType)
           inputLayout
           (Unify (Layout LayoutType) ('Layout 'Dense) posLayout))
        (Unify
           (Device (DeviceType Nat))
           inputDevice
           (Unify (Device (DeviceType Nat)) device posDevice))
        (Unify
           (DataType DType)
           inputDataType
           (Seq
              (Unify (DataType DType) posDataType ('DataType 'Int64)) dataType))
        (BroadcastShapesF
           inputShape
           (EmbeddingF ('Shape '[posEncDim, inputEmbedDim]) posShape)))
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">Tensor
  inputGradient inputLayout inputDevice inputDataType inputShape
</span><a href="#local-6989586621679770894"><span class="hs-identifier hs-var">input</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor
  inputGradient inputLayout inputDevice inputDataType inputShape
-&gt; Tensor
     (Or (Gradient RequiresGradient) gradient posGradient)
     (Unify (Layout LayoutType) ('Layout 'Dense) posLayout)
     (Unify (Device (DeviceType Nat)) device posDevice)
     (Seq
        (Unify (DataType DType) posDataType ('DataType 'Int64)) dataType)
     (EmbeddingF ('Shape '[posEncDim, inputEmbedDim]) posShape)
-&gt; Tensor
     (inputGradient
      &lt;|&gt; Or (Gradient RequiresGradient) gradient posGradient)
     (inputLayout
      &lt;+&gt; Unify (Layout LayoutType) ('Layout 'Dense) posLayout)
     (inputDevice &lt;+&gt; Unify (Device (DeviceType Nat)) device posDevice)
     (inputDataType
      &lt;+&gt; Seq
            (Unify (DataType DType) posDataType ('DataType 'Int64)) dataType)
     (BroadcastShapesF
        inputShape
        (EmbeddingF ('Shape '[posEncDim, inputEmbedDim]) posShape))
forall (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)])
       (gradient' :: Gradient RequiresGradient)
       (layout' :: Layout LayoutType) (device' :: Device (DeviceType Nat))
       (dataType' :: DataType DType)
       (shape' :: Shape [Dim (Name Symbol) (Size Nat)]).
Tensor gradient layout device dataType shape
-&gt; Tensor gradient' layout' device' dataType' shape'
-&gt; Tensor
     (gradient &lt;|&gt; gradient')
     (layout &lt;+&gt; layout')
     (device &lt;+&gt; device')
     (dataType &lt;+&gt; dataType')
     (BroadcastShapesF shape shape')
</span><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#add"><span class="hs-operator hs-var">`add`</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-945"></span><span>            </span><span class="annot"><span class="annottext">IxStateT
  m
  generator
  generator
  (Tensor
     (Or
        (Gradient RequiresGradient)
        inputGradient
        (Or (Gradient RequiresGradient) gradient posGradient))
     (Unify
        (Layout LayoutType)
        inputLayout
        (Unify (Layout LayoutType) ('Layout 'Dense) posLayout))
     (Unify
        (Device (DeviceType Nat))
        inputDevice
        (Unify (Device (DeviceType Nat)) device posDevice))
     (Unify
        (DataType DType)
        inputDataType
        (Seq
           (Unify (DataType DType) posDataType ('DataType 'Int64)) dataType))
     (BroadcastShapesF
        inputShape
        (EmbeddingF ('Shape '[posEncDim, inputEmbedDim]) posShape)))
-&gt; (Tensor
      (Or
         (Gradient RequiresGradient)
         inputGradient
         (Or (Gradient RequiresGradient) gradient posGradient))
      (Unify
         (Layout LayoutType)
         inputLayout
         (Unify (Layout LayoutType) ('Layout 'Dense) posLayout))
      (Unify
         (Device (DeviceType Nat))
         inputDevice
         (Unify (Device (DeviceType Nat)) device posDevice))
      (Unify
         (DataType DType)
         inputDataType
         (Seq
            (Unify (DataType DType) posDataType ('DataType 'Int64)) dataType))
      (BroadcastShapesF
         inputShape
         (EmbeddingF ('Shape '[posEncDim, inputEmbedDim]) posShape))
    -&gt; IxStateT m generator dropoutGeneratorOutput dropoutOutput)
-&gt; IxStateT m generator dropoutGeneratorOutput dropoutOutput
forall k1 (m :: k1 -&gt; k1 -&gt; * -&gt; *) (i :: k1) (j :: k1) a
       (k2 :: k1) b.
IxMonad m =&gt;
m i j a -&gt; (a -&gt; m j k2 b) -&gt; m i k2 b
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&gt;&gt;&gt;=</span></a></span><span> </span><span class="annot"><span class="annottext">(generator -&gt; m (dropoutOutput, dropoutGeneratorOutput))
-&gt; IxStateT m generator dropoutGeneratorOutput dropoutOutput
forall (m :: * -&gt; *) i j a. (i -&gt; m (a, j)) -&gt; IxStateT m i j a
</span><a href="../file:///nix/store/8vjaffqxij7bih93d9mlzmc7ksanlw0i-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier hs-var">IxStateT</span></a></span><span> </span><span class="annot"><span class="annottext">((generator -&gt; m (dropoutOutput, dropoutGeneratorOutput))
 -&gt; IxStateT m generator dropoutGeneratorOutput dropoutOutput)
-&gt; (Tensor
      (Or
         (Gradient RequiresGradient)
         inputGradient
         (Or (Gradient RequiresGradient) gradient posGradient))
      (Unify
         (Layout LayoutType)
         inputLayout
         (Unify (Layout LayoutType) ('Layout 'Dense) posLayout))
      (Unify
         (Device (DeviceType Nat))
         inputDevice
         (Unify (Device (DeviceType Nat)) device posDevice))
      (Unify
         (DataType DType)
         inputDataType
         (Seq
            (Unify (DataType DType) posDataType ('DataType 'Int64)) dataType))
      (BroadcastShapesF
         inputShape
         (EmbeddingF ('Shape '[posEncDim, inputEmbedDim]) posShape))
    -&gt; generator -&gt; m (dropoutOutput, dropoutGeneratorOutput))
-&gt; Tensor
     (Or
        (Gradient RequiresGradient)
        inputGradient
        (Or (Gradient RequiresGradient) gradient posGradient))
     (Unify
        (Layout LayoutType)
        inputLayout
        (Unify (Layout LayoutType) ('Layout 'Dense) posLayout))
     (Unify
        (Device (DeviceType Nat))
        inputDevice
        (Unify (Device (DeviceType Nat)) device posDevice))
     (Unify
        (DataType DType)
        inputDataType
        (Seq
           (Unify (DataType DType) posDataType ('DataType 'Int64)) dataType))
     (BroadcastShapesF
        inputShape
        (EmbeddingF ('Shape '[posEncDim, inputEmbedDim]) posShape))
-&gt; IxStateT m generator dropoutGeneratorOutput dropoutOutput
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">Dropout dropoutP
-&gt; Tensor
     (Or
        (Gradient RequiresGradient)
        inputGradient
        (Or (Gradient RequiresGradient) gradient posGradient))
     (Unify
        (Layout LayoutType)
        inputLayout
        (Unify (Layout LayoutType) ('Layout 'Dense) posLayout))
     (Unify
        (Device (DeviceType Nat))
        inputDevice
        (Unify (Device (DeviceType Nat)) device posDevice))
     (Unify
        (DataType DType)
        inputDataType
        (Seq
           (Unify (DataType DType) posDataType ('DataType 'Int64)) dataType))
     (BroadcastShapesF
        inputShape
        (EmbeddingF ('Shape '[posEncDim, inputEmbedDim]) posShape))
-&gt; generator
-&gt; m (dropoutOutput, dropoutGeneratorOutput)
forall model input generator output generatorOutput (m :: * -&gt; *).
(HasForward model input generator output generatorOutput,
 MonadThrow m) =&gt;
model -&gt; input -&gt; generator -&gt; m (output, generatorOutput)
</span><a href="Torch.GraduallyTyped.NN.Class.html#forward"><span class="hs-identifier hs-var">forward</span></a></span><span> </span><span class="annot"><span class="annottext">Dropout dropoutP
TEDropoutF 'Pegasus dropoutP
</span><a href="#local-6989586621679770896"><span class="hs-identifier hs-var">teDropout</span></a></span><span>
</span><span id="line-946"></span><span>            </span><span class="annot"><span class="annottext">IxStateT m generator dropoutGeneratorOutput dropoutOutput
-&gt; (dropoutOutput
    -&gt; IxStateT m dropoutGeneratorOutput generatorOutput stackOutput)
-&gt; IxStateT m generator generatorOutput stackOutput
forall k1 (m :: k1 -&gt; k1 -&gt; * -&gt; *) (i :: k1) (j :: k1) a
       (k2 :: k1) b.
IxMonad m =&gt;
m i j a -&gt; (a -&gt; m j k2 b) -&gt; m i k2 b
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&gt;&gt;&gt;=</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">\</span><span id="local-6989586621679770890"><span class="annot"><span class="annottext">dropoutOutput
</span><a href="#local-6989586621679770890"><span class="hs-identifier hs-var">input'</span></a></span></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><span class="annottext">(dropoutGeneratorOutput -&gt; m (stackOutput, generatorOutput))
-&gt; IxStateT m dropoutGeneratorOutput generatorOutput stackOutput
forall (m :: * -&gt; *) i j a. (i -&gt; m (a, j)) -&gt; IxStateT m i j a
</span><a href="../file:///nix/store/8vjaffqxij7bih93d9mlzmc7ksanlw0i-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier hs-var">IxStateT</span></a></span><span> </span><span class="annot"><span class="annottext">((dropoutGeneratorOutput -&gt; m (stackOutput, generatorOutput))
 -&gt; IxStateT m dropoutGeneratorOutput generatorOutput stackOutput)
-&gt; (dropoutGeneratorOutput -&gt; m (stackOutput, generatorOutput))
-&gt; IxStateT m dropoutGeneratorOutput generatorOutput stackOutput
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">TransformerStack
  'Pegasus
  numLayers
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  inputEmbedDim
  ffnDim
  dropoutP
-&gt; (dropoutOutput,
    Tensor
      attentionMaskGradient
      attentionMaskLayout
      attentionMaskDevice
      attentionMaskDataType
      (UnsqueezeF ('SelectDim ('ByIndex 1)) attentionMaskShape))
-&gt; dropoutGeneratorOutput
-&gt; m (stackOutput, generatorOutput)
forall model input generator output generatorOutput (m :: * -&gt; *).
(HasForward model input generator output generatorOutput,
 MonadThrow m) =&gt;
model -&gt; input -&gt; generator -&gt; m (output, generatorOutput)
</span><a href="Torch.GraduallyTyped.NN.Class.html#forward"><span class="hs-identifier hs-var">forward</span></a></span><span> </span><span class="annot"><span class="annottext">TransformerStack
  'Pegasus
  numLayers
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  inputEmbedDim
  ffnDim
  dropoutP
TEStackF
  'Pegasus
  numLayers
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  inputEmbedDim
  ffnDim
  dropoutP
</span><a href="#local-6989586621679770899"><span class="hs-identifier hs-var">teStack</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">dropoutOutput
</span><a href="#local-6989586621679770890"><span class="hs-identifier hs-var">input'</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">Tensor
  attentionMaskGradient
  attentionMaskLayout
  attentionMaskDevice
  attentionMaskDataType
  (UnsqueezeF ('SelectDim ('ByIndex 1)) attentionMaskShape)
</span><a href="#local-6989586621679770891"><span class="hs-identifier hs-var">attentionBias</span></a></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-947"></span><span>            </span><span class="annot"><span class="annottext">IxStateT m generator generatorOutput stackOutput
-&gt; (stackOutput
    -&gt; IxStateT m generatorOutput generatorOutput output)
-&gt; IxStateT m generator generatorOutput output
forall k1 (m :: k1 -&gt; k1 -&gt; * -&gt; *) (i :: k1) (j :: k1) a
       (k2 :: k1) b.
IxMonad m =&gt;
m i j a -&gt; (a -&gt; m j k2 b) -&gt; m i k2 b
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&gt;&gt;&gt;=</span></a></span><span> </span><span class="annot"><span class="annottext">(generatorOutput -&gt; m (output, generatorOutput))
-&gt; IxStateT m generatorOutput generatorOutput output
forall (m :: * -&gt; *) i j a. (i -&gt; m (a, j)) -&gt; IxStateT m i j a
</span><a href="../file:///nix/store/8vjaffqxij7bih93d9mlzmc7ksanlw0i-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier hs-var">IxStateT</span></a></span><span> </span><span class="annot"><span class="annottext">((generatorOutput -&gt; m (output, generatorOutput))
 -&gt; IxStateT m generatorOutput generatorOutput output)
-&gt; (stackOutput -&gt; generatorOutput -&gt; m (output, generatorOutput))
-&gt; stackOutput
-&gt; IxStateT m generatorOutput generatorOutput output
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">LayerNorm
  'WithBias gradient device dataType ('Shape '[inputEmbedDim])
-&gt; stackOutput -&gt; generatorOutput -&gt; m (output, generatorOutput)
forall model input generator output generatorOutput (m :: * -&gt; *).
(HasForward model input generator output generatorOutput,
 MonadThrow m) =&gt;
model -&gt; input -&gt; generator -&gt; m (output, generatorOutput)
</span><a href="Torch.GraduallyTyped.NN.Class.html#forward"><span class="hs-identifier hs-var">forward</span></a></span><span> </span><span class="annot"><span class="annottext">LayerNorm
  'WithBias gradient device dataType ('Shape '[inputEmbedDim])
TELayerNormF 'Pegasus gradient device dataType inputEmbedDim
</span><a href="#local-6989586621679770897"><span class="hs-identifier hs-var">teLayerNorm</span></a></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span><span>
</span><span id="line-948"></span></pre></body></html>