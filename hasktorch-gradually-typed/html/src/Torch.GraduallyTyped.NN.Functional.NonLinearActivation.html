<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd"><html xmlns="http://www.w3.org/1999/xhtml"><head><link rel="stylesheet" type="text/css" href="style.css" /><script type="text/javascript" src="highlight.js"></script></head><body><pre><span class="hs-pragma">{-# LANGUAGE DataKinds #-}</span><span>
</span><span id="line-2"></span><span class="hs-pragma">{-# LANGUAGE RankNTypes #-}</span><span>
</span><span id="line-3"></span><span class="hs-pragma">{-# LANGUAGE TypeFamilies #-}</span><span>
</span><span id="line-4"></span><span class="hs-pragma">{-# LANGUAGE TypeOperators #-}</span><span>
</span><span id="line-5"></span><span class="hs-pragma">{-# LANGUAGE UndecidableInstances #-}</span><span>
</span><span id="line-6"></span><span>
</span><span id="line-7"></span><span class="hs-keyword">module</span><span> </span><span class="hs-identifier">Torch.GraduallyTyped.NN.Functional.NonLinearActivation</span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-8"></span><span>
</span><span id="line-9"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><span class="hs-identifier">Control.Monad.Catch</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="hs-identifier">MonadThrow</span></span><span class="hs-special">)</span><span>
</span><span id="line-10"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="../file:///nix/store/44d7539k7gqlplsaxjj66fck1zc772zc-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier">Data.Singletons</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="../file:///nix/store/44d7539k7gqlplsaxjj66fck1zc772zc-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier">SingKind</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-11"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><span class="hs-identifier">GHC.TypeLits</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="hs-identifier">Nat</span></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="hs-identifier">Symbol</span></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="hs-identifier">TypeError</span></span><span class="hs-special">)</span><span>
</span><span id="line-12"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Prelude.html"><span class="hs-identifier">Torch.GraduallyTyped.Prelude</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Prelude.html#Catch"><span class="hs-identifier">Catch</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Prelude.html#forgetIsChecked"><span class="hs-identifier">forgetIsChecked</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-13"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.html"><span class="hs-identifier">Torch.GraduallyTyped.Shape</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#By"><span class="hs-identifier">By</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Class.html#GetDimImplF"><span class="hs-identifier">GetDimImplF</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier">Name</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SSelectDim"><span class="hs-identifier">SSelectDim</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SelectDim"><span class="hs-identifier">SelectDim</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Shape"><span class="hs-identifier">Shape</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier">Size</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-14"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html"><span class="hs-identifier">Torch.GraduallyTyped.Tensor.Type</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier">Tensor</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-15"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier">Torch.Internal.Cast</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier">cast2</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-16"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier">Torch.Internal.GC</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier">unsafeThrowableIO</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-17"></span><span class="hs-keyword">import</span><span> </span><span class="hs-keyword">qualified</span><span> </span><span class="annot"><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier">Torch.Internal.Managed.Native</span></a></span><span> </span><span class="hs-keyword">as</span><span> </span><span class="annot"><span class="hs-identifier">ATen</span></span><span>
</span><span id="line-18"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="../file:///nix/store/r6jdzwafy5276v4j29nczdzrg130l9ff-type-errors-pretty-lib-type-errors-pretty-0.0.1.2-haddock-doc/share/doc/type-errors-pretty/html/src"><span class="hs-identifier">Type.Errors.Pretty</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-keyword">type</span><span> </span><span class="annot"><a href="../file:///nix/store/r6jdzwafy5276v4j29nczdzrg130l9ff-type-errors-pretty-lib-type-errors-pretty-0.0.1.2-haddock-doc/share/doc/type-errors-pretty/html/src"><span class="hs-operator">(%)</span></a></span><span class="hs-special">,</span><span> </span><span class="hs-keyword">type</span><span> </span><span class="annot"><a href="../file:///nix/store/r6jdzwafy5276v4j29nczdzrg130l9ff-type-errors-pretty-lib-type-errors-pretty-0.0.1.2-haddock-doc/share/doc/type-errors-pretty/html/src"><span class="hs-operator">(&lt;&gt;)</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-19"></span><span>
</span><span id="line-20"></span><span class="hs-comment">-- $setup</span><span>
</span><span id="line-21"></span><span class="hs-comment">-- &gt;&gt;&gt; import Torch.GraduallyTyped.Prelude.List (SList (..))</span><span>
</span><span id="line-22"></span><span class="hs-comment">-- &gt;&gt;&gt; import Torch.GraduallyTyped</span><span>
</span><span id="line-23"></span><span>
</span><span id="line-24"></span><span class="hs-keyword">type</span><span> </span><span id="SoftMaxErrorMessage"><span class="annot"><a href="Torch.GraduallyTyped.NN.Functional.NonLinearActivation.html#SoftMaxErrorMessage"><span class="hs-identifier hs-var">SoftMaxErrorMessage</span></a></span></span><span> </span><span class="hs-special">(</span><span id="local-6989586621679689290"><span class="annot"><a href="#local-6989586621679689290"><span class="hs-identifier hs-type">by</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#By"><span class="hs-identifier hs-type">By</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Symbol</span></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span id="local-6989586621679689289"><span class="annot"><a href="#local-6989586621679689289"><span class="hs-identifier hs-type">dims</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="hs-special">[</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Symbol</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">]</span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-25"></span><span>  </span><span class="annot"><span class="hs-string">&quot;Cannot apply softmax on the dimension matching&quot;</span></span><span>
</span><span id="line-26"></span><span>    </span><span class="annot"><a href="../file:///nix/store/r6jdzwafy5276v4j29nczdzrg130l9ff-type-errors-pretty-lib-type-errors-pretty-0.0.1.2-haddock-doc/share/doc/type-errors-pretty/html/src"><span class="hs-operator hs-type">%</span></a></span><span> </span><span class="annot"><span class="hs-string">&quot;&quot;</span></span><span>
</span><span id="line-27"></span><span>    </span><span class="annot"><a href="../file:///nix/store/r6jdzwafy5276v4j29nczdzrg130l9ff-type-errors-pretty-lib-type-errors-pretty-0.0.1.2-haddock-doc/share/doc/type-errors-pretty/html/src"><span class="hs-operator hs-type">%</span></a></span><span> </span><span class="annot"><span class="hs-string">&quot;    '&quot;</span></span><span> </span><span class="annot"><a href="../file:///nix/store/r6jdzwafy5276v4j29nczdzrg130l9ff-type-errors-pretty-lib-type-errors-pretty-0.0.1.2-haddock-doc/share/doc/type-errors-pretty/html/src"><span class="hs-operator hs-type">&lt;&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679689290"><span class="hs-identifier hs-type">by</span></a></span><span> </span><span class="annot"><a href="../file:///nix/store/r6jdzwafy5276v4j29nczdzrg130l9ff-type-errors-pretty-lib-type-errors-pretty-0.0.1.2-haddock-doc/share/doc/type-errors-pretty/html/src"><span class="hs-operator hs-type">&lt;&gt;</span></a></span><span> </span><span class="annot"><span class="hs-string">&quot;'&quot;</span></span><span>
</span><span id="line-28"></span><span>    </span><span class="annot"><a href="../file:///nix/store/r6jdzwafy5276v4j29nczdzrg130l9ff-type-errors-pretty-lib-type-errors-pretty-0.0.1.2-haddock-doc/share/doc/type-errors-pretty/html/src"><span class="hs-operator hs-type">%</span></a></span><span> </span><span class="annot"><span class="hs-string">&quot;&quot;</span></span><span>
</span><span id="line-29"></span><span>    </span><span class="annot"><a href="../file:///nix/store/r6jdzwafy5276v4j29nczdzrg130l9ff-type-errors-pretty-lib-type-errors-pretty-0.0.1.2-haddock-doc/share/doc/type-errors-pretty/html/src"><span class="hs-operator hs-type">%</span></a></span><span> </span><span class="annot"><span class="hs-string">&quot;in the shape&quot;</span></span><span>
</span><span id="line-30"></span><span>    </span><span class="annot"><a href="../file:///nix/store/r6jdzwafy5276v4j29nczdzrg130l9ff-type-errors-pretty-lib-type-errors-pretty-0.0.1.2-haddock-doc/share/doc/type-errors-pretty/html/src"><span class="hs-operator hs-type">%</span></a></span><span> </span><span class="annot"><span class="hs-string">&quot;&quot;</span></span><span>
</span><span id="line-31"></span><span>    </span><span class="annot"><a href="../file:///nix/store/r6jdzwafy5276v4j29nczdzrg130l9ff-type-errors-pretty-lib-type-errors-pretty-0.0.1.2-haddock-doc/share/doc/type-errors-pretty/html/src"><span class="hs-operator hs-type">%</span></a></span><span> </span><span class="annot"><span class="hs-string">&quot;    '&quot;</span></span><span> </span><span class="annot"><a href="../file:///nix/store/r6jdzwafy5276v4j29nczdzrg130l9ff-type-errors-pretty-lib-type-errors-pretty-0.0.1.2-haddock-doc/share/doc/type-errors-pretty/html/src"><span class="hs-operator hs-type">&lt;&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679689289"><span class="hs-identifier hs-type">dims</span></a></span><span> </span><span class="annot"><a href="../file:///nix/store/r6jdzwafy5276v4j29nczdzrg130l9ff-type-errors-pretty-lib-type-errors-pretty-0.0.1.2-haddock-doc/share/doc/type-errors-pretty/html/src"><span class="hs-operator hs-type">&lt;&gt;</span></a></span><span> </span><span class="annot"><span class="hs-string">&quot;'.&quot;</span></span><span>
</span><span id="line-32"></span><span>    </span><span class="annot"><a href="../file:///nix/store/r6jdzwafy5276v4j29nczdzrg130l9ff-type-errors-pretty-lib-type-errors-pretty-0.0.1.2-haddock-doc/share/doc/type-errors-pretty/html/src"><span class="hs-operator hs-type">%</span></a></span><span> </span><span class="annot"><span class="hs-string">&quot;&quot;</span></span><span>
</span><span id="line-33"></span><span>
</span><span id="line-34"></span><span class="hs-keyword">type</span><span> </span><span class="hs-keyword">family</span><span> </span><span id="SoftmaxCheckF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Functional.NonLinearActivation.html#SoftmaxCheckF"><span class="hs-identifier hs-var">SoftmaxCheckF</span></a></span></span><span> </span><span class="hs-special">(</span><span id="local-6989586621679689287"><span class="annot"><a href="#local-6989586621679689287"><span class="hs-identifier hs-type">by</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#By"><span class="hs-identifier hs-type">By</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Symbol</span></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span id="local-6989586621679689286"><span class="annot"><a href="#local-6989586621679689286"><span class="hs-identifier hs-type">dims</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="hs-special">[</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Symbol</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">]</span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span id="local-6989586621679689285"><span class="annot"><a href="#local-6989586621679689285"><span class="hs-identifier hs-type">result</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Maybe</span></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Symbol</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span class="hs-special">)</span><span> </span><span class="hs-glyph">::</span><span> </span><span class="hs-special">[</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Symbol</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">]</span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-35"></span><span>  </span><span id="SoftmaxCheckF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Functional.NonLinearActivation.html#SoftmaxCheckF"><span class="hs-identifier hs-var">SoftmaxCheckF</span></a></span></span><span> </span><span id="local-6989586621679689284"><span class="annot"><a href="#local-6989586621679689284"><span class="hs-identifier hs-type hs-type">by</span></a></span></span><span> </span><span id="local-6989586621679689283"><span class="annot"><a href="#local-6989586621679689283"><span class="hs-identifier hs-type hs-type">dims</span></a></span></span><span> </span><span class="hs-special">'</span><span class="annot"><span class="hs-identifier hs-type">Nothing</span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="hs-identifier hs-type">TypeError</span></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Functional.NonLinearActivation.html#SoftMaxErrorMessage"><span class="hs-identifier hs-type">SoftMaxErrorMessage</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679689284"><span class="hs-identifier hs-type">by</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679689283"><span class="hs-identifier hs-type">dims</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-36"></span><span>  </span><span id="SoftmaxCheckF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Functional.NonLinearActivation.html#SoftmaxCheckF"><span class="hs-identifier hs-var">SoftmaxCheckF</span></a></span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span id="local-6989586621679689282"><span class="annot"><a href="#local-6989586621679689282"><span class="hs-identifier hs-type hs-type">dims</span></a></span></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><span class="hs-identifier hs-type">Just</span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><a href="#local-6989586621679689282"><span class="hs-identifier hs-type">dims</span></a></span><span>
</span><span id="line-37"></span><span>
</span><span id="line-38"></span><span class="hs-keyword">type</span><span> </span><span class="hs-keyword">family</span><span> </span><span id="SoftmaxF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Functional.NonLinearActivation.html#SoftmaxF"><span class="hs-identifier hs-var">SoftmaxF</span></a></span></span><span> </span><span class="hs-special">(</span><span id="local-6989586621679689280"><span class="annot"><a href="#local-6989586621679689280"><span class="hs-identifier hs-type">selectDim</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SelectDim"><span class="hs-identifier hs-type">SelectDim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#By"><span class="hs-identifier hs-type">By</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Symbol</span></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span id="local-6989586621679689279"><span class="annot"><a href="#local-6989586621679689279"><span class="hs-identifier hs-type">shape</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Shape"><span class="hs-identifier hs-type">Shape</span></a></span><span> </span><span class="hs-special">[</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Symbol</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">]</span><span class="hs-special">)</span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Shape"><span class="hs-identifier hs-type">Shape</span></a></span><span> </span><span class="hs-special">[</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Symbol</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">]</span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-39"></span><span>  </span><span id="SoftmaxF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Functional.NonLinearActivation.html#SoftmaxF"><span class="hs-identifier hs-var">SoftmaxF</span></a></span></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#UncheckedSelectDim"><span class="hs-identifier hs-type">UncheckedSelectDim</span></a></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#UncheckedShape"><span class="hs-identifier hs-type">UncheckedShape</span></a></span><span>
</span><span id="line-40"></span><span>  </span><span id="SoftmaxF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Functional.NonLinearActivation.html#SoftmaxF"><span class="hs-identifier hs-var">SoftmaxF</span></a></span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#UncheckedShape"><span class="hs-identifier hs-type">UncheckedShape</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#UncheckedShape"><span class="hs-identifier hs-type">UncheckedShape</span></a></span><span>
</span><span id="line-41"></span><span>  </span><span id="SoftmaxF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Functional.NonLinearActivation.html#SoftmaxF"><span class="hs-identifier hs-var">SoftmaxF</span></a></span></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SelectDim"><span class="hs-identifier hs-type">SelectDim</span></a></span><span> </span><span id="local-6989586621679689275"><span class="annot"><a href="#local-6989586621679689275"><span class="hs-identifier hs-type hs-type">by</span></a></span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Shape"><span class="hs-identifier hs-type">Shape</span></a></span><span> </span><span id="local-6989586621679689273"><span class="annot"><a href="#local-6989586621679689273"><span class="hs-identifier hs-type hs-type">dims</span></a></span></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=</span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Shape"><span class="hs-identifier hs-type">Shape</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Functional.NonLinearActivation.html#SoftmaxCheckF"><span class="hs-identifier hs-type">SoftmaxCheckF</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679689275"><span class="hs-identifier hs-type">by</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679689273"><span class="hs-identifier hs-type">dims</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Class.html#GetDimImplF"><span class="hs-identifier hs-type">GetDimImplF</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679689275"><span class="hs-identifier hs-type">by</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679689273"><span class="hs-identifier hs-type">dims</span></a></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-42"></span><span>
</span><span id="line-43"></span><span class="hs-comment">-- | Applies the softmax function that is defined as:</span><span>
</span><span id="line-44"></span><span class="hs-comment">--</span><span>
</span><span id="line-45"></span><span class="hs-comment">-- \[</span><span>
</span><span id="line-46"></span><span class="hs-comment">-- \mathrm{Softmax}(\mathrm{input}_{i}) = \frac{\exp\left(\mathrm{input}_{i}\right)}{\sum_j \exp\left(\mathrm{input}_{j}\right)}</span><span>
</span><span id="line-47"></span><span class="hs-comment">-- \]</span><span>
</span><span id="line-48"></span><span class="hs-comment">--</span><span>
</span><span id="line-49"></span><span class="hs-comment">-- Softmax is applied to all slices along 'selectDim',</span><span>
</span><span id="line-50"></span><span class="hs-comment">-- and will re-scale them so that the elements lie in the range \([0, 1]\) and sum to \(1\):</span><span>
</span><span id="line-51"></span><span class="hs-comment">--</span><span>
</span><span id="line-52"></span><span class="hs-comment">-- &gt;&gt;&gt; g &lt;- sMkGenerator (SDevice SCPU) 0</span><span>
</span><span id="line-53"></span><span class="hs-comment">-- &gt;&gt;&gt; (input, _) &lt;- sRandn (TensorSpec (SGradient SWithGradient) (SLayout SDense) (SDevice SCPU) (SDataType SFloat) (SShape $ SName @&quot;batch&quot; :&amp;: SSize @32 :|: SName @&quot;feature&quot; :&amp;: SSize @8 :|: SNil)) g</span><span>
</span><span id="line-54"></span><span class="hs-comment">-- &gt;&gt;&gt; result &lt;- softmax (SSelectDim (SByName @&quot;feature&quot;)) input</span><span>
</span><span id="line-55"></span><span class="hs-comment">-- &gt;&gt;&gt; :type result</span><span>
</span><span id="line-56"></span><span class="hs-comment">-- result</span><span>
</span><span id="line-57"></span><span class="hs-comment">--   :: Tensor</span><span>
</span><span id="line-58"></span><span class="hs-comment">--        ('Gradient 'WithGradient)</span><span>
</span><span id="line-59"></span><span class="hs-comment">--        ('Layout 'Dense)</span><span>
</span><span id="line-60"></span><span class="hs-comment">--        ('Device 'CPU)</span><span>
</span><span id="line-61"></span><span class="hs-comment">--        ('DataType 'Float)</span><span>
</span><span id="line-62"></span><span class="hs-comment">--        ('Shape</span><span>
</span><span id="line-63"></span><span class="hs-comment">--           '[ 'Dim ('Name &quot;batch&quot;) ('Size 32),</span><span>
</span><span id="line-64"></span><span class="hs-comment">--              'Dim ('Name &quot;feature&quot;) ('Size 8)])</span><span>
</span><span id="line-65"></span><span class="annot"><a href="Torch.GraduallyTyped.NN.Functional.NonLinearActivation.html#softmax"><span class="hs-identifier hs-type">softmax</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-66"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Functional.NonLinearActivation.html#logSoftmax"><span class="hs-identifier hs-type">logSoftmax</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-67"></span><span>    </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679689270"><span class="annot"><a href="#local-6989586621679689270"><span class="hs-identifier hs-type">selectDim</span></a></span></span><span> </span><span id="local-6989586621679689269"><span class="annot"><a href="#local-6989586621679689269"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679689268"><span class="annot"><a href="#local-6989586621679689268"><span class="hs-identifier hs-type">layout</span></a></span></span><span> </span><span id="local-6989586621679689267"><span class="annot"><a href="#local-6989586621679689267"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679689266"><span class="annot"><a href="#local-6989586621679689266"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679689265"><span class="annot"><a href="#local-6989586621679689265"><span class="hs-identifier hs-type">shape</span></a></span></span><span> </span><span id="local-6989586621679689264"><span class="annot"><a href="#local-6989586621679689264"><span class="hs-identifier hs-type">shape'</span></a></span></span><span> </span><span id="local-6989586621679689263"><span class="annot"><a href="#local-6989586621679689263"><span class="hs-identifier hs-type">m</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-68"></span><span>    </span><span class="hs-special">(</span><span class="annot"><span class="hs-identifier hs-type">MonadThrow</span></span><span> </span><span class="annot"><a href="#local-6989586621679689263"><span class="hs-identifier hs-type">m</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679689264"><span class="hs-identifier hs-type">shape'</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Functional.NonLinearActivation.html#SoftmaxF"><span class="hs-identifier hs-type">SoftmaxF</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679689270"><span class="hs-identifier hs-type">selectDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679689265"><span class="hs-identifier hs-type">shape</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Prelude.html#Catch"><span class="hs-identifier hs-type">Catch</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679689264"><span class="hs-identifier hs-type">shape'</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-69"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SSelectDim"><span class="hs-identifier hs-type">SSelectDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679689270"><span class="hs-identifier hs-type">selectDim</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-70"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679689269"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679689268"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679689267"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679689266"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679689265"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-71"></span><span>    </span><span class="annot"><a href="#local-6989586621679689263"><span class="hs-identifier hs-type">m</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679689269"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679689268"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679689267"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679689266"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679689264"><span class="hs-identifier hs-type">shape'</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-72"></span><span id="softmax"><span class="annot"><span class="annottext">softmax :: SSelectDim selectDim
-&gt; Tensor gradient layout device dataType shape
-&gt; m (Tensor gradient layout device dataType shape')
</span><a href="Torch.GraduallyTyped.NN.Functional.NonLinearActivation.html#softmax"><span class="hs-identifier hs-var hs-var">softmax</span></a></span></span><span> </span><span id="local-6989586621679689262"><span class="annot"><span class="annottext">SSelectDim selectDim
</span><a href="#local-6989586621679689262"><span class="hs-identifier hs-var">selectDim</span></a></span></span><span> </span><span id="local-6989586621679689261"><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679689261"><span class="hs-identifier hs-var">tensor</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-73"></span><span>  </span><span class="hs-keyword">case</span><span> </span><span class="annot"><span class="annottext">IsChecked (By String Integer) -&gt; By String Integer
forall a. IsChecked a -&gt; a
</span><a href="Torch.GraduallyTyped.Prelude.html#forgetIsChecked"><span class="hs-identifier hs-var">forgetIsChecked</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">Sing selectDim -&gt; Demote (SelectDim (By Symbol Nat))
forall k (a :: k). SingKind k =&gt; Sing a -&gt; Demote k
</span><a href="../file:///nix/store/44d7539k7gqlplsaxjj66fck1zc772zc-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-var">fromSing</span></a></span><span> </span><span class="annot"><span class="annottext">Sing selectDim
SSelectDim selectDim
</span><a href="#local-6989586621679689262"><span class="hs-identifier hs-var">selectDim</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-keyword">of</span><span>
</span><span id="line-74"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#ByName"><span class="hs-identifier hs-type">ByName</span></a></span><span> </span><span id="local-6989586621679689258"><span class="annot"><span class="annottext">String
</span><a href="#local-6989586621679689258"><span class="hs-identifier hs-var">name</span></a></span></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><span class="annottext">IO (Tensor gradient layout device dataType shape')
-&gt; m (Tensor gradient layout device dataType shape')
forall a (m :: * -&gt; *). MonadThrow m =&gt; IO a -&gt; m a
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">unsafeThrowableIO</span></a></span><span> </span><span class="annot"><span class="annottext">(IO (Tensor gradient layout device dataType shape')
 -&gt; m (Tensor gradient layout device dataType shape'))
-&gt; IO (Tensor gradient layout device dataType shape')
-&gt; m (Tensor gradient layout device dataType shape')
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; ForeignPtr Dimname -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor gradient layout device dataType shape
-&gt; String
-&gt; IO (Tensor gradient layout device dataType shape')
forall a ca x1 cx1 y cy.
(Castable a ca, Castable x1 cx1, Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; IO cy) -&gt; a -&gt; x1 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast2</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; ForeignPtr Dimname -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.softmax_tn</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679689261"><span class="hs-identifier hs-var">tensor</span></a></span><span> </span><span class="annot"><span class="annottext">String
</span><a href="#local-6989586621679689258"><span class="hs-identifier hs-var">name</span></a></span><span>
</span><span id="line-75"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#ByIndex"><span class="hs-identifier hs-type">ByIndex</span></a></span><span> </span><span id="local-6989586621679689255"><span class="annot"><span class="annottext">Integer
</span><a href="#local-6989586621679689255"><span class="hs-identifier hs-var">index</span></a></span></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><span class="annottext">IO (Tensor gradient layout device dataType shape')
-&gt; m (Tensor gradient layout device dataType shape')
forall a (m :: * -&gt; *). MonadThrow m =&gt; IO a -&gt; m a
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">unsafeThrowableIO</span></a></span><span> </span><span class="annot"><span class="annottext">(IO (Tensor gradient layout device dataType shape')
 -&gt; m (Tensor gradient layout device dataType shape'))
-&gt; IO (Tensor gradient layout device dataType shape')
-&gt; m (Tensor gradient layout device dataType shape')
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; Int64 -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor gradient layout device dataType shape
-&gt; Int
-&gt; IO (Tensor gradient layout device dataType shape')
forall a ca x1 cx1 y cy.
(Castable a ca, Castable x1 cx1, Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; IO cy) -&gt; a -&gt; x1 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast2</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; Int64 -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.softmax_tl</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679689261"><span class="hs-identifier hs-var">tensor</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">Integer -&gt; Int
forall a. Num a =&gt; Integer -&gt; a
</span><span class="hs-identifier hs-var">fromInteger</span></span><span> </span><span class="annot"><span class="annottext">Integer
</span><a href="#local-6989586621679689255"><span class="hs-identifier hs-var">index</span></a></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Int</span></span><span class="hs-special">)</span><span>
</span><span id="line-76"></span><span id="logSoftmax"><span class="annot"><span class="annottext">logSoftmax :: SSelectDim selectDim
-&gt; Tensor gradient layout device dataType shape
-&gt; m (Tensor gradient layout device dataType shape')
</span><a href="Torch.GraduallyTyped.NN.Functional.NonLinearActivation.html#logSoftmax"><span class="hs-identifier hs-var hs-var">logSoftmax</span></a></span></span><span> </span><span id="local-6989586621679689253"><span class="annot"><span class="annottext">SSelectDim selectDim
</span><a href="#local-6989586621679689253"><span class="hs-identifier hs-var">selectDim</span></a></span></span><span> </span><span id="local-6989586621679689252"><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679689252"><span class="hs-identifier hs-var">tensor</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-77"></span><span>  </span><span class="hs-keyword">case</span><span> </span><span class="annot"><span class="annottext">IsChecked (By String Integer) -&gt; By String Integer
forall a. IsChecked a -&gt; a
</span><a href="Torch.GraduallyTyped.Prelude.html#forgetIsChecked"><span class="hs-identifier hs-var">forgetIsChecked</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">Sing selectDim -&gt; Demote (SelectDim (By Symbol Nat))
forall k (a :: k). SingKind k =&gt; Sing a -&gt; Demote k
</span><a href="../file:///nix/store/44d7539k7gqlplsaxjj66fck1zc772zc-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-var">fromSing</span></a></span><span> </span><span class="annot"><span class="annottext">Sing selectDim
SSelectDim selectDim
</span><a href="#local-6989586621679689253"><span class="hs-identifier hs-var">selectDim</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-keyword">of</span><span>
</span><span id="line-78"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#ByName"><span class="hs-identifier hs-type">ByName</span></a></span><span> </span><span id="local-6989586621679689251"><span class="annot"><span class="annottext">String
</span><a href="#local-6989586621679689251"><span class="hs-identifier hs-var">name</span></a></span></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><span class="annottext">IO (Tensor gradient layout device dataType shape')
-&gt; m (Tensor gradient layout device dataType shape')
forall a (m :: * -&gt; *). MonadThrow m =&gt; IO a -&gt; m a
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">unsafeThrowableIO</span></a></span><span> </span><span class="annot"><span class="annottext">(IO (Tensor gradient layout device dataType shape')
 -&gt; m (Tensor gradient layout device dataType shape'))
-&gt; IO (Tensor gradient layout device dataType shape')
-&gt; m (Tensor gradient layout device dataType shape')
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; ForeignPtr Dimname -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor gradient layout device dataType shape
-&gt; String
-&gt; IO (Tensor gradient layout device dataType shape')
forall a ca x1 cx1 y cy.
(Castable a ca, Castable x1 cx1, Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; IO cy) -&gt; a -&gt; x1 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast2</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; ForeignPtr Dimname -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.log_softmax_tn</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679689252"><span class="hs-identifier hs-var">tensor</span></a></span><span> </span><span class="annot"><span class="annottext">String
</span><a href="#local-6989586621679689251"><span class="hs-identifier hs-var">name</span></a></span><span>
</span><span id="line-79"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#ByIndex"><span class="hs-identifier hs-type">ByIndex</span></a></span><span> </span><span id="local-6989586621679689249"><span class="annot"><span class="annottext">Integer
</span><a href="#local-6989586621679689249"><span class="hs-identifier hs-var">index</span></a></span></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><span class="annottext">IO (Tensor gradient layout device dataType shape')
-&gt; m (Tensor gradient layout device dataType shape')
forall a (m :: * -&gt; *). MonadThrow m =&gt; IO a -&gt; m a
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">unsafeThrowableIO</span></a></span><span> </span><span class="annot"><span class="annottext">(IO (Tensor gradient layout device dataType shape')
 -&gt; m (Tensor gradient layout device dataType shape'))
-&gt; IO (Tensor gradient layout device dataType shape')
-&gt; m (Tensor gradient layout device dataType shape')
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; Int64 -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor gradient layout device dataType shape
-&gt; Int
-&gt; IO (Tensor gradient layout device dataType shape')
forall a ca x1 cx1 y cy.
(Castable a ca, Castable x1 cx1, Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; IO cy) -&gt; a -&gt; x1 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast2</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; Int64 -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.log_softmax_tl</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679689252"><span class="hs-identifier hs-var">tensor</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">Integer -&gt; Int
forall a. Num a =&gt; Integer -&gt; a
</span><span class="hs-identifier hs-var">fromInteger</span></span><span> </span><span class="annot"><span class="annottext">Integer
</span><a href="#local-6989586621679689249"><span class="hs-identifier hs-var">index</span></a></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Int</span></span><span class="hs-special">)</span><span>
</span><span id="line-80"></span></pre></body></html>