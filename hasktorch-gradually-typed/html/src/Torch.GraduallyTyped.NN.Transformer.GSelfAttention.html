<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd"><html xmlns="http://www.w3.org/1999/xhtml"><head><link rel="stylesheet" type="text/css" href="style.css" /><script type="text/javascript" src="highlight.js"></script></head><body><pre><span class="hs-pragma">{-# LANGUAGE DataKinds #-}</span><span>
</span><span id="line-2"></span><span class="hs-pragma">{-# LANGUAGE DeriveGeneric #-}</span><span>
</span><span id="line-3"></span><span class="hs-pragma">{-# LANGUAGE DerivingStrategies #-}</span><span>
</span><span id="line-4"></span><span class="hs-pragma">{-# LANGUAGE FlexibleContexts #-}</span><span>
</span><span id="line-5"></span><span class="hs-pragma">{-# LANGUAGE FlexibleInstances #-}</span><span>
</span><span id="line-6"></span><span class="hs-pragma">{-# LANGUAGE GADTs #-}</span><span>
</span><span id="line-7"></span><span class="hs-pragma">{-# LANGUAGE MultiParamTypeClasses #-}</span><span>
</span><span id="line-8"></span><span class="hs-pragma">{-# LANGUAGE OverloadedStrings #-}</span><span>
</span><span id="line-9"></span><span class="hs-pragma">{-# LANGUAGE PatternSynonyms #-}</span><span>
</span><span id="line-10"></span><span class="hs-pragma">{-# LANGUAGE RecordWildCards #-}</span><span>
</span><span id="line-11"></span><span class="hs-pragma">{-# LANGUAGE ScopedTypeVariables #-}</span><span>
</span><span id="line-12"></span><span class="hs-pragma">{-# LANGUAGE TypeFamilies #-}</span><span>
</span><span id="line-13"></span><span class="hs-pragma">{-# LANGUAGE TypeOperators #-}</span><span>
</span><span id="line-14"></span><span class="hs-pragma">{-# LANGUAGE UndecidableInstances #-}</span><span>
</span><span id="line-15"></span><span>
</span><span id="line-16"></span><span class="hs-keyword">module</span><span> </span><span class="hs-identifier">Torch.GraduallyTyped.NN.Transformer.GSelfAttention</span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-17"></span><span>
</span><span id="line-18"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="../file:///nix/store/63793hdp0xr2k87xmzbhjz0cpd7vssdh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-identifier">Control.Monad.Indexed</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="../file:///nix/store/63793hdp0xr2k87xmzbhjz0cpd7vssdh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-identifier">ireturn</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="../file:///nix/store/63793hdp0xr2k87xmzbhjz0cpd7vssdh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator">(&gt;&gt;&gt;=)</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-19"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="../file:///nix/store/hlan16hghcygrr1n0fqljpsq2978pxwg-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier">Control.Monad.Indexed.State</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="../file:///nix/store/hlan16hghcygrr1n0fqljpsq2978pxwg-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier">IxStateT</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-20"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="../file:///nix/store/63793hdp0xr2k87xmzbhjz0cpd7vssdh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-identifier">Control.Monad.Indexed.Trans</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="../file:///nix/store/63793hdp0xr2k87xmzbhjz0cpd7vssdh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-identifier">IxMonadTrans</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="../file:///nix/store/63793hdp0xr2k87xmzbhjz0cpd7vssdh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-identifier">ilift</span></a></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-21"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="../file:///nix/store/9z106fx3296sgdwa5s05xi381ayi6qfk-ghc-9.2.4-doc/share/doc/ghc/html/libraries/base-4.16.3.0/src"><span class="hs-identifier">Data.Kind</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="../file:///nix/store/9z106fx3296sgdwa5s05xi381ayi6qfk-ghc-9.2.4-doc/share/doc/ghc/html/libraries/ghc-prim-0.8.0/src"><span class="hs-identifier">Type</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-22"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="../file:///nix/store/9z106fx3296sgdwa5s05xi381ayi6qfk-ghc-9.2.4-doc/share/doc/ghc/html/libraries/base-4.16.3.0/src"><span class="hs-identifier">GHC.Generics</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="../file:///nix/store/9z106fx3296sgdwa5s05xi381ayi6qfk-ghc-9.2.4-doc/share/doc/ghc/html/libraries/base-4.16.3.0/src"><span class="hs-identifier">Generic</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-23"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="../file:///nix/store/9z106fx3296sgdwa5s05xi381ayi6qfk-ghc-9.2.4-doc/share/doc/ghc/html/libraries/base-4.16.3.0/src"><span class="hs-identifier">GHC.TypeLits</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="../file:///nix/store/9z106fx3296sgdwa5s05xi381ayi6qfk-ghc-9.2.4-doc/share/doc/ghc/html/libraries/base-4.16.3.0/src"><span class="hs-identifier">Nat</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="../file:///nix/store/9z106fx3296sgdwa5s05xi381ayi6qfk-ghc-9.2.4-doc/share/doc/ghc/html/libraries/ghc-prim-0.8.0/src"><span class="hs-identifier">Symbol</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-24"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html"><span class="hs-identifier">Torch.GraduallyTyped.DType</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#DType"><span class="hs-identifier">DType</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#DataType"><span class="hs-identifier">DataType</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#SDataType"><span class="hs-identifier">SDataType</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-25"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Device.html"><span class="hs-identifier">Torch.GraduallyTyped.Device</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#Device"><span class="hs-identifier">Device</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#DeviceType"><span class="hs-identifier">DeviceType</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#SDevice"><span class="hs-identifier">SDevice</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-26"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html"><span class="hs-identifier">Torch.GraduallyTyped.NN.Class</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasForward"><span class="hs-identifier">HasForward</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasInitialize"><span class="hs-identifier">HasInitialize</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasStateDict"><span class="hs-identifier">HasStateDict</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#ModelSpec"><span class="hs-identifier">ModelSpec</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#NamedModel"><span class="hs-identifier">NamedModel</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-27"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Dropout.html"><span class="hs-identifier">Torch.GraduallyTyped.NN.Dropout</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Dropout.html#Dropout"><span class="hs-identifier">Dropout</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-28"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Normalization.html"><span class="hs-identifier">Torch.GraduallyTyped.NN.Normalization</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Normalization.html#LayerNorm"><span class="hs-identifier">LayerNorm</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Normalization.html#LayerNormSpec"><span class="hs-identifier">LayerNormSpec</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-29"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GMultiHeadAttention.html"><span class="hs-identifier">Torch.GraduallyTyped.NN.Transformer.GMultiHeadAttention</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GMultiHeadAttention.html#GMultiHeadAttentionF"><span class="hs-identifier">GMultiHeadAttentionF</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GMultiHeadAttention.html#multiHeadAttentionSpec"><span class="hs-identifier">multiHeadAttentionSpec</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-30"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html"><span class="hs-identifier">Torch.GraduallyTyped.NN.Transformer.Type</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#STransformerStyle"><span class="hs-identifier">STransformerStyle</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#TransformerStyle"><span class="hs-identifier">TransformerStyle</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-31"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Type.html"><span class="hs-identifier">Torch.GraduallyTyped.NN.Type</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Type.html#HasBias"><span class="hs-identifier">HasBias</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Type.html#HasDropout"><span class="hs-identifier">HasDropout</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Type.html#SHasBias"><span class="hs-identifier">SHasBias</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Type.html#SHasDropout"><span class="hs-identifier">SHasDropout</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-32"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Prelude.html"><span class="hs-identifier">Torch.GraduallyTyped.Prelude</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Prelude.html#Catch"><span class="hs-identifier">Catch</span></a></span><span class="hs-special">,</span><span> </span><span class="hs-keyword">pattern</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Prelude.html#%3A%7C%3A"><span class="hs-operator">(:|:)</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-33"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Prelude.List.html"><span class="hs-identifier">Torch.GraduallyTyped.Prelude.List</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="../file:///nix/store/cmxygbwkg9vwm5iizgff5i2x5awqcjjn-singletons-base-lib-singletons-base-3.1-haddock-doc/share/doc/singletons-base/html/src"><span class="hs-identifier">SList</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="../file:///nix/store/cmxygbwkg9vwm5iizgff5i2x5awqcjjn-singletons-base-lib-singletons-base-3.1-haddock-doc/share/doc/singletons-base/html/src"><span class="hs-identifier">SNil</span></a></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-34"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html"><span class="hs-identifier">Torch.GraduallyTyped.RequiresGradient</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#Gradient"><span class="hs-identifier">Gradient</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#RequiresGradient"><span class="hs-identifier">RequiresGradient</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#SGradient"><span class="hs-identifier">SGradient</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-35"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Class.html"><span class="hs-identifier">Torch.GraduallyTyped.Shape.Class</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Class.html#BroadcastShapesF"><span class="hs-identifier">BroadcastShapesF</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-36"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html"><span class="hs-identifier">Torch.GraduallyTyped.Shape.Type</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier">Name</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SDim"><span class="hs-identifier">SDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SShape"><span class="hs-identifier">SShape</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Shape"><span class="hs-identifier">Shape</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier">Size</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-37"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html"><span class="hs-identifier">Torch.GraduallyTyped.Tensor.MathOperations.Pointwise</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#add"><span class="hs-identifier">add</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-38"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html"><span class="hs-identifier">Torch.GraduallyTyped.Tensor.Type</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier">Tensor</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-39"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html"><span class="hs-identifier">Torch.GraduallyTyped.Unify</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-keyword">type</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator">(&lt;+&gt;)</span></a></span><span class="hs-special">,</span><span> </span><span class="hs-keyword">type</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%7C%3E"><span class="hs-operator">(&lt;|&gt;)</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-40"></span><span>
</span><span id="line-41"></span><span class="hs-comment">-- | Generic self-attention layer data type.</span><span>
</span><span id="line-42"></span><span class="hs-comment">--</span><span>
</span><span id="line-43"></span><span class="hs-comment">-- - @initialLayerNorm@: the initial layer normalization</span><span>
</span><span id="line-44"></span><span class="hs-comment">-- - @mha@: the multi-headed attention layer</span><span>
</span><span id="line-45"></span><span class="hs-comment">-- - @dropout@: the dropout layer</span><span>
</span><span id="line-46"></span><span class="hs-comment">-- - @finalLayerNorm@: the final layer normalization</span><span>
</span><span id="line-47"></span><span id="local-6989586621679709787"><span id="local-6989586621679709788"></span></span><span class="hs-keyword">data</span><span>
</span><span id="line-48"></span><span>  </span><span id="GSelfAttention"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GSelfAttention.html#GSelfAttention"><span class="hs-identifier hs-var">GSelfAttention</span></a></span></span><span>
</span><span id="line-49"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679710172"><span class="annot"><a href="#local-6989586621679710172"><span class="hs-identifier hs-type">initialLayerNorm</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="../file:///nix/store/9z106fx3296sgdwa5s05xi381ayi6qfk-ghc-9.2.4-doc/share/doc/ghc/html/libraries/ghc-prim-0.8.0/src"><span class="hs-identifier hs-type">Type</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-50"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679710171"><span class="annot"><a href="#local-6989586621679710171"><span class="hs-identifier hs-type">mha</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="../file:///nix/store/9z106fx3296sgdwa5s05xi381ayi6qfk-ghc-9.2.4-doc/share/doc/ghc/html/libraries/ghc-prim-0.8.0/src"><span class="hs-identifier hs-type">Type</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-51"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679710170"><span class="annot"><a href="#local-6989586621679710170"><span class="hs-identifier hs-type">dropout</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="../file:///nix/store/9z106fx3296sgdwa5s05xi381ayi6qfk-ghc-9.2.4-doc/share/doc/ghc/html/libraries/ghc-prim-0.8.0/src"><span class="hs-identifier hs-type">Type</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-52"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679710169"><span class="annot"><a href="#local-6989586621679710169"><span class="hs-identifier hs-type">finalLayerNorm</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="../file:///nix/store/9z106fx3296sgdwa5s05xi381ayi6qfk-ghc-9.2.4-doc/share/doc/ghc/html/libraries/ghc-prim-0.8.0/src"><span class="hs-identifier hs-type">Type</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-53"></span><span>  </span><span class="hs-keyword">where</span><span>
</span><span id="line-54"></span><span>  </span><span id="GSelfAttention"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GSelfAttention.html#GSelfAttention"><span class="hs-identifier hs-var">GSelfAttention</span></a></span></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-55"></span><span>    </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679710193"><span class="annot"><a href="#local-6989586621679710193"><span class="hs-identifier hs-type">initialLayerNorm</span></a></span></span><span> </span><span id="local-6989586621679710192"><span class="annot"><a href="#local-6989586621679710192"><span class="hs-identifier hs-type">mha</span></a></span></span><span> </span><span id="local-6989586621679710191"><span class="annot"><a href="#local-6989586621679710191"><span class="hs-identifier hs-type">dropout</span></a></span></span><span> </span><span id="local-6989586621679710190"><span class="annot"><a href="#local-6989586621679710190"><span class="hs-identifier hs-type">finalLayerNorm</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-56"></span><span>    </span><span class="hs-special">{</span><span> </span><span class="hs-comment">-- | initial layer normalization of the self-attention layer.</span><span>
</span><span id="line-57"></span><span>      </span><span id="saInitialLayerNorm"><span class="annot"><span class="annottext">forall initialLayerNorm mha dropout finalLayerNorm.
GSelfAttention initialLayerNorm mha dropout finalLayerNorm
-&gt; initialLayerNorm
</span><a href="Torch.GraduallyTyped.NN.Transformer.GSelfAttention.html#saInitialLayerNorm"><span class="hs-identifier hs-var hs-var">saInitialLayerNorm</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="#local-6989586621679710193"><span class="hs-identifier hs-type">initialLayerNorm</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-58"></span><span>      </span><span class="hs-comment">-- | multi-headed attention layer specialized for self-attention.</span><span>
</span><span id="line-59"></span><span>      </span><span id="saMultiHeadAttention"><span class="annot"><span class="annottext">forall initialLayerNorm mha dropout finalLayerNorm.
GSelfAttention initialLayerNorm mha dropout finalLayerNorm -&gt; mha
</span><a href="Torch.GraduallyTyped.NN.Transformer.GSelfAttention.html#saMultiHeadAttention"><span class="hs-identifier hs-var hs-var">saMultiHeadAttention</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="#local-6989586621679710192"><span class="hs-identifier hs-type">mha</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-60"></span><span>      </span><span class="hs-comment">-- | dropout</span><span>
</span><span id="line-61"></span><span>      </span><span id="saDropout"><span class="annot"><span class="annottext">forall initialLayerNorm mha dropout finalLayerNorm.
GSelfAttention initialLayerNorm mha dropout finalLayerNorm
-&gt; dropout
</span><a href="Torch.GraduallyTyped.NN.Transformer.GSelfAttention.html#saDropout"><span class="hs-identifier hs-var hs-var">saDropout</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="#local-6989586621679710191"><span class="hs-identifier hs-type">dropout</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-62"></span><span>      </span><span class="hs-comment">-- | final layer normalization of the self-attention layer.</span><span>
</span><span id="line-63"></span><span>      </span><span id="saFinalLayerNorm"><span class="annot"><span class="annottext">forall initialLayerNorm mha dropout finalLayerNorm.
GSelfAttention initialLayerNorm mha dropout finalLayerNorm
-&gt; finalLayerNorm
</span><a href="Torch.GraduallyTyped.NN.Transformer.GSelfAttention.html#saFinalLayerNorm"><span class="hs-identifier hs-var hs-var">saFinalLayerNorm</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="#local-6989586621679710190"><span class="hs-identifier hs-type">finalLayerNorm</span></a></span><span>
</span><span id="line-64"></span><span>    </span><span class="hs-special">}</span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-65"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GSelfAttention.html#GSelfAttention"><span class="hs-identifier hs-type">GSelfAttention</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710193"><span class="hs-identifier hs-type">initialLayerNorm</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710192"><span class="hs-identifier hs-type">mha</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710191"><span class="hs-identifier hs-type">dropout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710190"><span class="hs-identifier hs-type">finalLayerNorm</span></a></span><span>
</span><span id="line-66"></span><span>  </span><span class="hs-keyword">deriving</span><span> </span><span class="annot"><span class="hs-keyword">stock</span></span><span> </span><span class="hs-special">(</span><span id="local-6989586621679709774"><span id="local-6989586621679709780"><span class="annot"><span class="annottext">GSelfAttention initialLayerNorm mha dropout finalLayerNorm
-&gt; GSelfAttention initialLayerNorm mha dropout finalLayerNorm
-&gt; Bool
forall a. (a -&gt; a -&gt; Bool) -&gt; (a -&gt; a -&gt; Bool) -&gt; Eq a
forall initialLayerNorm mha dropout finalLayerNorm.
(Eq initialLayerNorm, Eq mha, Eq dropout, Eq finalLayerNorm) =&gt;
GSelfAttention initialLayerNorm mha dropout finalLayerNorm
-&gt; GSelfAttention initialLayerNorm mha dropout finalLayerNorm
-&gt; Bool
/= :: GSelfAttention initialLayerNorm mha dropout finalLayerNorm
-&gt; GSelfAttention initialLayerNorm mha dropout finalLayerNorm
-&gt; Bool
$c/= :: forall initialLayerNorm mha dropout finalLayerNorm.
(Eq initialLayerNorm, Eq mha, Eq dropout, Eq finalLayerNorm) =&gt;
GSelfAttention initialLayerNorm mha dropout finalLayerNorm
-&gt; GSelfAttention initialLayerNorm mha dropout finalLayerNorm
-&gt; Bool
== :: GSelfAttention initialLayerNorm mha dropout finalLayerNorm
-&gt; GSelfAttention initialLayerNorm mha dropout finalLayerNorm
-&gt; Bool
$c== :: forall initialLayerNorm mha dropout finalLayerNorm.
(Eq initialLayerNorm, Eq mha, Eq dropout, Eq finalLayerNorm) =&gt;
GSelfAttention initialLayerNorm mha dropout finalLayerNorm
-&gt; GSelfAttention initialLayerNorm mha dropout finalLayerNorm
-&gt; Bool
</span><a href="../file:///nix/store/9z106fx3296sgdwa5s05xi381ayi6qfk-ghc-9.2.4-doc/share/doc/ghc/html/libraries/ghc-prim-0.8.0/src"><span class="hs-identifier hs-var hs-var hs-var hs-var hs-var hs-var">Eq</span></a></span></span></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679709746"><span id="local-6989586621679709748"><span id="local-6989586621679709751"><span id="local-6989586621679709754"><span id="local-6989586621679709757"><span id="local-6989586621679709763"><span id="local-6989586621679709769"><span class="annot"><span class="annottext">GSelfAttention initialLayerNorm mha dropout finalLayerNorm
-&gt; GSelfAttention initialLayerNorm mha dropout finalLayerNorm
-&gt; Bool
GSelfAttention initialLayerNorm mha dropout finalLayerNorm
-&gt; GSelfAttention initialLayerNorm mha dropout finalLayerNorm
-&gt; Ordering
forall a.
Eq a
-&gt; (a -&gt; a -&gt; Ordering)
-&gt; (a -&gt; a -&gt; Bool)
-&gt; (a -&gt; a -&gt; Bool)
-&gt; (a -&gt; a -&gt; Bool)
-&gt; (a -&gt; a -&gt; Bool)
-&gt; (a -&gt; a -&gt; a)
-&gt; (a -&gt; a -&gt; a)
-&gt; Ord a
forall {initialLayerNorm} {mha} {dropout} {finalLayerNorm}.
(Ord initialLayerNorm, Ord mha, Ord dropout, Ord finalLayerNorm) =&gt;
Eq (GSelfAttention initialLayerNorm mha dropout finalLayerNorm)
forall initialLayerNorm mha dropout finalLayerNorm.
(Ord initialLayerNorm, Ord mha, Ord dropout, Ord finalLayerNorm) =&gt;
GSelfAttention initialLayerNorm mha dropout finalLayerNorm
-&gt; GSelfAttention initialLayerNorm mha dropout finalLayerNorm
-&gt; Bool
forall initialLayerNorm mha dropout finalLayerNorm.
(Ord initialLayerNorm, Ord mha, Ord dropout, Ord finalLayerNorm) =&gt;
GSelfAttention initialLayerNorm mha dropout finalLayerNorm
-&gt; GSelfAttention initialLayerNorm mha dropout finalLayerNorm
-&gt; Ordering
forall initialLayerNorm mha dropout finalLayerNorm.
(Ord initialLayerNorm, Ord mha, Ord dropout, Ord finalLayerNorm) =&gt;
GSelfAttention initialLayerNorm mha dropout finalLayerNorm
-&gt; GSelfAttention initialLayerNorm mha dropout finalLayerNorm
-&gt; GSelfAttention initialLayerNorm mha dropout finalLayerNorm
min :: GSelfAttention initialLayerNorm mha dropout finalLayerNorm
-&gt; GSelfAttention initialLayerNorm mha dropout finalLayerNorm
-&gt; GSelfAttention initialLayerNorm mha dropout finalLayerNorm
$cmin :: forall initialLayerNorm mha dropout finalLayerNorm.
(Ord initialLayerNorm, Ord mha, Ord dropout, Ord finalLayerNorm) =&gt;
GSelfAttention initialLayerNorm mha dropout finalLayerNorm
-&gt; GSelfAttention initialLayerNorm mha dropout finalLayerNorm
-&gt; GSelfAttention initialLayerNorm mha dropout finalLayerNorm
max :: GSelfAttention initialLayerNorm mha dropout finalLayerNorm
-&gt; GSelfAttention initialLayerNorm mha dropout finalLayerNorm
-&gt; GSelfAttention initialLayerNorm mha dropout finalLayerNorm
$cmax :: forall initialLayerNorm mha dropout finalLayerNorm.
(Ord initialLayerNorm, Ord mha, Ord dropout, Ord finalLayerNorm) =&gt;
GSelfAttention initialLayerNorm mha dropout finalLayerNorm
-&gt; GSelfAttention initialLayerNorm mha dropout finalLayerNorm
-&gt; GSelfAttention initialLayerNorm mha dropout finalLayerNorm
&gt;= :: GSelfAttention initialLayerNorm mha dropout finalLayerNorm
-&gt; GSelfAttention initialLayerNorm mha dropout finalLayerNorm
-&gt; Bool
$c&gt;= :: forall initialLayerNorm mha dropout finalLayerNorm.
(Ord initialLayerNorm, Ord mha, Ord dropout, Ord finalLayerNorm) =&gt;
GSelfAttention initialLayerNorm mha dropout finalLayerNorm
-&gt; GSelfAttention initialLayerNorm mha dropout finalLayerNorm
-&gt; Bool
&gt; :: GSelfAttention initialLayerNorm mha dropout finalLayerNorm
-&gt; GSelfAttention initialLayerNorm mha dropout finalLayerNorm
-&gt; Bool
$c&gt; :: forall initialLayerNorm mha dropout finalLayerNorm.
(Ord initialLayerNorm, Ord mha, Ord dropout, Ord finalLayerNorm) =&gt;
GSelfAttention initialLayerNorm mha dropout finalLayerNorm
-&gt; GSelfAttention initialLayerNorm mha dropout finalLayerNorm
-&gt; Bool
&lt;= :: GSelfAttention initialLayerNorm mha dropout finalLayerNorm
-&gt; GSelfAttention initialLayerNorm mha dropout finalLayerNorm
-&gt; Bool
$c&lt;= :: forall initialLayerNorm mha dropout finalLayerNorm.
(Ord initialLayerNorm, Ord mha, Ord dropout, Ord finalLayerNorm) =&gt;
GSelfAttention initialLayerNorm mha dropout finalLayerNorm
-&gt; GSelfAttention initialLayerNorm mha dropout finalLayerNorm
-&gt; Bool
&lt; :: GSelfAttention initialLayerNorm mha dropout finalLayerNorm
-&gt; GSelfAttention initialLayerNorm mha dropout finalLayerNorm
-&gt; Bool
$c&lt; :: forall initialLayerNorm mha dropout finalLayerNorm.
(Ord initialLayerNorm, Ord mha, Ord dropout, Ord finalLayerNorm) =&gt;
GSelfAttention initialLayerNorm mha dropout finalLayerNorm
-&gt; GSelfAttention initialLayerNorm mha dropout finalLayerNorm
-&gt; Bool
compare :: GSelfAttention initialLayerNorm mha dropout finalLayerNorm
-&gt; GSelfAttention initialLayerNorm mha dropout finalLayerNorm
-&gt; Ordering
$ccompare :: forall initialLayerNorm mha dropout finalLayerNorm.
(Ord initialLayerNorm, Ord mha, Ord dropout, Ord finalLayerNorm) =&gt;
GSelfAttention initialLayerNorm mha dropout finalLayerNorm
-&gt; GSelfAttention initialLayerNorm mha dropout finalLayerNorm
-&gt; Ordering
</span><a href="../file:///nix/store/9z106fx3296sgdwa5s05xi381ayi6qfk-ghc-9.2.4-doc/share/doc/ghc/html/libraries/ghc-prim-0.8.0/src"><span class="hs-identifier hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var">Ord</span></a></span></span></span></span></span></span></span></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679709733"><span id="local-6989586621679709735"><span id="local-6989586621679709743"><span class="annot"><span class="annottext">Int
-&gt; GSelfAttention initialLayerNorm mha dropout finalLayerNorm
-&gt; ShowS
forall a.
(Int -&gt; a -&gt; ShowS) -&gt; (a -&gt; String) -&gt; ([a] -&gt; ShowS) -&gt; Show a
forall initialLayerNorm mha dropout finalLayerNorm.
(Show initialLayerNorm, Show mha, Show dropout,
 Show finalLayerNorm) =&gt;
Int
-&gt; GSelfAttention initialLayerNorm mha dropout finalLayerNorm
-&gt; ShowS
forall initialLayerNorm mha dropout finalLayerNorm.
(Show initialLayerNorm, Show mha, Show dropout,
 Show finalLayerNorm) =&gt;
[GSelfAttention initialLayerNorm mha dropout finalLayerNorm]
-&gt; ShowS
forall initialLayerNorm mha dropout finalLayerNorm.
(Show initialLayerNorm, Show mha, Show dropout,
 Show finalLayerNorm) =&gt;
GSelfAttention initialLayerNorm mha dropout finalLayerNorm
-&gt; String
showList :: [GSelfAttention initialLayerNorm mha dropout finalLayerNorm]
-&gt; ShowS
$cshowList :: forall initialLayerNorm mha dropout finalLayerNorm.
(Show initialLayerNorm, Show mha, Show dropout,
 Show finalLayerNorm) =&gt;
[GSelfAttention initialLayerNorm mha dropout finalLayerNorm]
-&gt; ShowS
show :: GSelfAttention initialLayerNorm mha dropout finalLayerNorm
-&gt; String
$cshow :: forall initialLayerNorm mha dropout finalLayerNorm.
(Show initialLayerNorm, Show mha, Show dropout,
 Show finalLayerNorm) =&gt;
GSelfAttention initialLayerNorm mha dropout finalLayerNorm
-&gt; String
showsPrec :: Int
-&gt; GSelfAttention initialLayerNorm mha dropout finalLayerNorm
-&gt; ShowS
$cshowsPrec :: forall initialLayerNorm mha dropout finalLayerNorm.
(Show initialLayerNorm, Show mha, Show dropout,
 Show finalLayerNorm) =&gt;
Int
-&gt; GSelfAttention initialLayerNorm mha dropout finalLayerNorm
-&gt; ShowS
</span><a href="../file:///nix/store/9z106fx3296sgdwa5s05xi381ayi6qfk-ghc-9.2.4-doc/share/doc/ghc/html/libraries/base-4.16.3.0/src"><span class="hs-identifier hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var">Show</span></a></span></span></span></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">forall a.
(forall x. a -&gt; Rep a x) -&gt; (forall x. Rep a x -&gt; a) -&gt; Generic a
forall initialLayerNorm mha dropout finalLayerNorm x.
Rep (GSelfAttention initialLayerNorm mha dropout finalLayerNorm) x
-&gt; GSelfAttention initialLayerNorm mha dropout finalLayerNorm
forall initialLayerNorm mha dropout finalLayerNorm x.
GSelfAttention initialLayerNorm mha dropout finalLayerNorm
-&gt; Rep
     (GSelfAttention initialLayerNorm mha dropout finalLayerNorm) x
$cto :: forall initialLayerNorm mha dropout finalLayerNorm x.
Rep (GSelfAttention initialLayerNorm mha dropout finalLayerNorm) x
-&gt; GSelfAttention initialLayerNorm mha dropout finalLayerNorm
$cfrom :: forall initialLayerNorm mha dropout finalLayerNorm x.
GSelfAttention initialLayerNorm mha dropout finalLayerNorm
-&gt; Rep
     (GSelfAttention initialLayerNorm mha dropout finalLayerNorm) x
</span><a href="../file:///nix/store/9z106fx3296sgdwa5s05xi381ayi6qfk-ghc-9.2.4-doc/share/doc/ghc/html/libraries/base-4.16.3.0/src"><span class="hs-identifier hs-var hs-var hs-var hs-var">Generic</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-67"></span><span>
</span><span id="line-68"></span><span class="hs-keyword">type</span><span> </span><span class="hs-keyword">instance</span><span>
</span><span id="line-69"></span><span>  </span><span id="ModelSpec"><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#ModelSpec"><span class="hs-identifier hs-var">ModelSpec</span></a></span></span><span> </span><span id="local-6989586621679709725"><span id="local-6989586621679709726"><span id="local-6989586621679709727"><span id="local-6989586621679709728"><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GSelfAttention.html#GSelfAttention"><span class="hs-identifier hs-type">GSelfAttention</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709728"><span class="hs-identifier hs-type">initialLayerNorm</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709727"><span class="hs-identifier hs-type">mha</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709726"><span class="hs-identifier hs-type">dropout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709725"><span class="hs-identifier hs-type">finalLayerNorm</span></a></span><span class="hs-special">)</span></span></span></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-70"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GSelfAttention.html#GSelfAttention"><span class="hs-identifier hs-type">GSelfAttention</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#ModelSpec"><span class="hs-identifier hs-type">ModelSpec</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709728"><span class="hs-identifier hs-type">initialLayerNorm</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#ModelSpec"><span class="hs-identifier hs-type">ModelSpec</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709727"><span class="hs-identifier hs-type">mha</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#ModelSpec"><span class="hs-identifier hs-type">ModelSpec</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709726"><span class="hs-identifier hs-type">dropout</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#ModelSpec"><span class="hs-identifier hs-type">ModelSpec</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709725"><span class="hs-identifier hs-type">finalLayerNorm</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-71"></span><span>
</span><span id="line-72"></span><span class="hs-keyword">type</span><span> </span><span class="hs-keyword">family</span><span>
</span><span id="line-73"></span><span>  </span><span id="GSelfAttentionF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GSelfAttention.html#GSelfAttentionF"><span class="hs-identifier hs-var">GSelfAttentionF</span></a></span></span><span>
</span><span id="line-74"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679709724"><span class="annot"><a href="#local-6989586621679709724"><span class="hs-identifier hs-type">style</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#TransformerStyle"><span class="hs-identifier hs-type">TransformerStyle</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-75"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679709723"><span class="annot"><a href="#local-6989586621679709723"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#Gradient"><span class="hs-identifier hs-type">Gradient</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#RequiresGradient"><span class="hs-identifier hs-type">RequiresGradient</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-76"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679709722"><span class="annot"><a href="#local-6989586621679709722"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#Device"><span class="hs-identifier hs-type">Device</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#DeviceType"><span class="hs-identifier hs-type">DeviceType</span></a></span><span> </span><span class="annot"><a href="../file:///nix/store/9z106fx3296sgdwa5s05xi381ayi6qfk-ghc-9.2.4-doc/share/doc/ghc/html/libraries/base-4.16.3.0/src"><span class="hs-identifier hs-type">Nat</span></a></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-77"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679709721"><span class="annot"><a href="#local-6989586621679709721"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#DataType"><span class="hs-identifier hs-type">DataType</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#DType"><span class="hs-identifier hs-type">DType</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-78"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679709720"><span class="annot"><a href="#local-6989586621679709720"><span class="hs-identifier hs-type">headDim</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><a href="../file:///nix/store/9z106fx3296sgdwa5s05xi381ayi6qfk-ghc-9.2.4-doc/share/doc/ghc/html/libraries/ghc-prim-0.8.0/src"><span class="hs-identifier hs-type">Symbol</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><a href="../file:///nix/store/9z106fx3296sgdwa5s05xi381ayi6qfk-ghc-9.2.4-doc/share/doc/ghc/html/libraries/base-4.16.3.0/src"><span class="hs-identifier hs-type">Nat</span></a></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-79"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679709719"><span class="annot"><a href="#local-6989586621679709719"><span class="hs-identifier hs-type">headEmbedDim</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><a href="../file:///nix/store/9z106fx3296sgdwa5s05xi381ayi6qfk-ghc-9.2.4-doc/share/doc/ghc/html/libraries/ghc-prim-0.8.0/src"><span class="hs-identifier hs-type">Symbol</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><a href="../file:///nix/store/9z106fx3296sgdwa5s05xi381ayi6qfk-ghc-9.2.4-doc/share/doc/ghc/html/libraries/base-4.16.3.0/src"><span class="hs-identifier hs-type">Nat</span></a></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-80"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679709718"><span class="annot"><a href="#local-6989586621679709718"><span class="hs-identifier hs-type">embedDim</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><a href="../file:///nix/store/9z106fx3296sgdwa5s05xi381ayi6qfk-ghc-9.2.4-doc/share/doc/ghc/html/libraries/ghc-prim-0.8.0/src"><span class="hs-identifier hs-type">Symbol</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><a href="../file:///nix/store/9z106fx3296sgdwa5s05xi381ayi6qfk-ghc-9.2.4-doc/share/doc/ghc/html/libraries/base-4.16.3.0/src"><span class="hs-identifier hs-type">Nat</span></a></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-81"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679709717"><span class="annot"><a href="#local-6989586621679709717"><span class="hs-identifier hs-type">queryEmbedDim</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><a href="../file:///nix/store/9z106fx3296sgdwa5s05xi381ayi6qfk-ghc-9.2.4-doc/share/doc/ghc/html/libraries/ghc-prim-0.8.0/src"><span class="hs-identifier hs-type">Symbol</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><a href="../file:///nix/store/9z106fx3296sgdwa5s05xi381ayi6qfk-ghc-9.2.4-doc/share/doc/ghc/html/libraries/base-4.16.3.0/src"><span class="hs-identifier hs-type">Nat</span></a></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-82"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679709716"><span class="annot"><a href="#local-6989586621679709716"><span class="hs-identifier hs-type">hasDropout</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Type.html#HasDropout"><span class="hs-identifier hs-type">HasDropout</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-83"></span><span>    </span><span class="annot"><a href="../file:///nix/store/9z106fx3296sgdwa5s05xi381ayi6qfk-ghc-9.2.4-doc/share/doc/ghc/html/libraries/ghc-prim-0.8.0/src"><span class="hs-identifier hs-type">Type</span></a></span><span>
</span><span id="line-84"></span><span>  </span><span class="hs-keyword">where</span><span>
</span><span id="line-85"></span><span>  </span><span id="GSelfAttentionF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GSelfAttention.html#GSelfAttentionF"><span class="hs-identifier hs-var">GSelfAttentionF</span></a></span></span><span> </span><span id="local-6989586621679709707"><span id="local-6989586621679709708"><span id="local-6989586621679709709"><span id="local-6989586621679709710"><span id="local-6989586621679709711"><span id="local-6989586621679709712"><span id="local-6989586621679709713"><span id="local-6989586621679709714"><span id="local-6989586621679709715"><span class="annot"><a href="#local-6989586621679709715"><span class="hs-identifier hs-type">style</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709714"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709713"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709712"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709711"><span class="hs-identifier hs-type">headDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709710"><span class="hs-identifier hs-type">headEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709709"><span class="hs-identifier hs-type">embedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709708"><span class="hs-identifier hs-type">queryEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709707"><span class="hs-identifier hs-type">hasDropout</span></a></span></span></span></span></span></span></span></span></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-86"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GSelfAttention.html#GSelfAttention"><span class="hs-identifier hs-type">GSelfAttention</span></a></span><span>
</span><span id="line-87"></span><span>      </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GSelfAttention.html#SAInitialLayerNormF"><span class="hs-identifier hs-type">SAInitialLayerNormF</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709715"><span class="hs-identifier hs-type">style</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709714"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709713"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709712"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709708"><span class="hs-identifier hs-type">queryEmbedDim</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-88"></span><span>      </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GSelfAttention.html#SAMultiheadAttentionF"><span class="hs-identifier hs-type">SAMultiheadAttentionF</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709715"><span class="hs-identifier hs-type">style</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709714"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709713"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709712"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709711"><span class="hs-identifier hs-type">headDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709710"><span class="hs-identifier hs-type">headEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709709"><span class="hs-identifier hs-type">embedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709708"><span class="hs-identifier hs-type">queryEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709707"><span class="hs-identifier hs-type">hasDropout</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-89"></span><span>      </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GSelfAttention.html#SADropoutF"><span class="hs-identifier hs-type">SADropoutF</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709715"><span class="hs-identifier hs-type">style</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709707"><span class="hs-identifier hs-type">hasDropout</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-90"></span><span>      </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GSelfAttention.html#SAFinalLayerNormF"><span class="hs-identifier hs-type">SAFinalLayerNormF</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709715"><span class="hs-identifier hs-type">style</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709714"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709713"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709712"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709708"><span class="hs-identifier hs-type">queryEmbedDim</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-91"></span><span>
</span><span id="line-92"></span><span class="hs-comment">-- | Specifies the initial layer normalization of the self-attention layer.</span><span>
</span><span id="line-93"></span><span class="hs-keyword">type</span><span> </span><span class="hs-keyword">family</span><span>
</span><span id="line-94"></span><span>  </span><span id="SAInitialLayerNormF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GSelfAttention.html#SAInitialLayerNormF"><span class="hs-identifier hs-var">SAInitialLayerNormF</span></a></span></span><span>
</span><span id="line-95"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679709705"><span class="annot"><a href="#local-6989586621679709705"><span class="hs-identifier hs-type">style</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#TransformerStyle"><span class="hs-identifier hs-type">TransformerStyle</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-96"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679709704"><span class="annot"><a href="#local-6989586621679709704"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#Gradient"><span class="hs-identifier hs-type">Gradient</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#RequiresGradient"><span class="hs-identifier hs-type">RequiresGradient</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-97"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679709703"><span class="annot"><a href="#local-6989586621679709703"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#Device"><span class="hs-identifier hs-type">Device</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#DeviceType"><span class="hs-identifier hs-type">DeviceType</span></a></span><span> </span><span class="annot"><a href="../file:///nix/store/9z106fx3296sgdwa5s05xi381ayi6qfk-ghc-9.2.4-doc/share/doc/ghc/html/libraries/base-4.16.3.0/src"><span class="hs-identifier hs-type">Nat</span></a></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-98"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679709702"><span class="annot"><a href="#local-6989586621679709702"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#DataType"><span class="hs-identifier hs-type">DataType</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#DType"><span class="hs-identifier hs-type">DType</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-99"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679709701"><span class="annot"><a href="#local-6989586621679709701"><span class="hs-identifier hs-type">queryEmbedDim</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><a href="../file:///nix/store/9z106fx3296sgdwa5s05xi381ayi6qfk-ghc-9.2.4-doc/share/doc/ghc/html/libraries/ghc-prim-0.8.0/src"><span class="hs-identifier hs-type">Symbol</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><a href="../file:///nix/store/9z106fx3296sgdwa5s05xi381ayi6qfk-ghc-9.2.4-doc/share/doc/ghc/html/libraries/base-4.16.3.0/src"><span class="hs-identifier hs-type">Nat</span></a></span><span class="hs-special">)</span><span class="hs-special">)</span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-100"></span><span>    </span><span class="annot"><a href="../file:///nix/store/9z106fx3296sgdwa5s05xi381ayi6qfk-ghc-9.2.4-doc/share/doc/ghc/html/libraries/ghc-prim-0.8.0/src"><span class="hs-identifier hs-type">Type</span></a></span><span>
</span><span id="line-101"></span><span>  </span><span class="hs-keyword">where</span><span>
</span><span id="line-102"></span><span>  </span><span id="SAInitialLayerNormF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GSelfAttention.html#SAInitialLayerNormF"><span class="hs-identifier hs-var">SAInitialLayerNormF</span></a></span></span><span> </span><span id="local-6989586621679709697"><span id="local-6989586621679709698"><span id="local-6989586621679709699"><span id="local-6989586621679709700"><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#T5"><span class="hs-identifier hs-type">T5</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709700"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709699"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709698"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709697"><span class="hs-identifier hs-type">queryEmbedDim</span></a></span></span></span></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-103"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#NamedModel"><span class="hs-identifier hs-type">NamedModel</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Normalization.html#LayerNorm"><span class="hs-identifier hs-type">LayerNorm</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Type.html#WithoutBias"><span class="hs-identifier hs-type">WithoutBias</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709700"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709699"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709698"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Shape"><span class="hs-identifier hs-type">Shape</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="annot"><a href="#local-6989586621679709697"><span class="hs-identifier hs-type">queryEmbedDim</span></a></span><span class="hs-special">]</span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-104"></span><span>  </span><span id="SAInitialLayerNormF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GSelfAttention.html#SAInitialLayerNormF"><span class="hs-identifier hs-var">SAInitialLayerNormF</span></a></span></span><span> </span><span id="local-6989586621679709693"><span id="local-6989586621679709694"><span id="local-6989586621679709695"><span id="local-6989586621679709696"><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#ByT5"><span class="hs-identifier hs-type">ByT5</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709696"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709695"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709694"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709693"><span class="hs-identifier hs-type">queryEmbedDim</span></a></span></span></span></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-105"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GSelfAttention.html#SAInitialLayerNormF"><span class="hs-identifier hs-type">SAInitialLayerNormF</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#T5"><span class="hs-identifier hs-type">T5</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709696"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709695"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709694"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709693"><span class="hs-identifier hs-type">queryEmbedDim</span></a></span><span>
</span><span id="line-106"></span><span>  </span><span id="SAInitialLayerNormF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GSelfAttention.html#SAInitialLayerNormF"><span class="hs-identifier hs-var">SAInitialLayerNormF</span></a></span></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#BART"><span class="hs-identifier hs-type">BART</span></a></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-107"></span><span>    </span><span class="hs-special">(</span><span class="hs-special">)</span><span>
</span><span id="line-108"></span><span>  </span><span id="SAInitialLayerNormF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GSelfAttention.html#SAInitialLayerNormF"><span class="hs-identifier hs-var">SAInitialLayerNormF</span></a></span></span><span> </span><span id="local-6989586621679709689"><span id="local-6989586621679709690"><span id="local-6989586621679709691"><span id="local-6989586621679709692"><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#MBART"><span class="hs-identifier hs-type">MBART</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709692"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709691"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709690"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709689"><span class="hs-identifier hs-type">queryEmbedDim</span></a></span></span></span></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-109"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GSelfAttention.html#SAInitialLayerNormF"><span class="hs-identifier hs-type">SAInitialLayerNormF</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#BART"><span class="hs-identifier hs-type">BART</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709692"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709691"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709690"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709689"><span class="hs-identifier hs-type">queryEmbedDim</span></a></span><span>
</span><span id="line-110"></span><span>  </span><span id="SAInitialLayerNormF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GSelfAttention.html#SAInitialLayerNormF"><span class="hs-identifier hs-var">SAInitialLayerNormF</span></a></span></span><span> </span><span id="local-6989586621679709685"><span id="local-6989586621679709686"><span id="local-6989586621679709687"><span id="local-6989586621679709688"><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#Pegasus"><span class="hs-identifier hs-type">Pegasus</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709688"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709687"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709686"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709685"><span class="hs-identifier hs-type">queryEmbedDim</span></a></span></span></span></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-111"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#NamedModel"><span class="hs-identifier hs-type">NamedModel</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Normalization.html#LayerNorm"><span class="hs-identifier hs-type">LayerNorm</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Type.html#WithBias"><span class="hs-identifier hs-type">WithBias</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709688"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709687"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709686"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Shape"><span class="hs-identifier hs-type">Shape</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="annot"><a href="#local-6989586621679709685"><span class="hs-identifier hs-type">queryEmbedDim</span></a></span><span class="hs-special">]</span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-112"></span><span>  </span><span id="SAInitialLayerNormF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GSelfAttention.html#SAInitialLayerNormF"><span class="hs-identifier hs-var">SAInitialLayerNormF</span></a></span></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#BERT"><span class="hs-identifier hs-type">BERT</span></a></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-113"></span><span>    </span><span class="hs-special">(</span><span class="hs-special">)</span><span>
</span><span id="line-114"></span><span>  </span><span id="SAInitialLayerNormF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GSelfAttention.html#SAInitialLayerNormF"><span class="hs-identifier hs-var">SAInitialLayerNormF</span></a></span></span><span> </span><span id="local-6989586621679709681"><span id="local-6989586621679709682"><span id="local-6989586621679709683"><span id="local-6989586621679709684"><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#RoBERTa"><span class="hs-identifier hs-type">RoBERTa</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709684"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709683"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709682"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709681"><span class="hs-identifier hs-type">queryEmbedDim</span></a></span></span></span></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-115"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GSelfAttention.html#SAInitialLayerNormF"><span class="hs-identifier hs-type">SAInitialLayerNormF</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#BERT"><span class="hs-identifier hs-type">BERT</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709684"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709683"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709682"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709681"><span class="hs-identifier hs-type">queryEmbedDim</span></a></span><span>
</span><span id="line-116"></span><span>
</span><span id="line-117"></span><span class="hs-comment">-- | Specifies the multi-headed attention layer of the self-attention layer.</span><span>
</span><span id="line-118"></span><span class="hs-keyword">type</span><span> </span><span class="hs-keyword">family</span><span>
</span><span id="line-119"></span><span>  </span><span id="SAMultiheadAttentionF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GSelfAttention.html#SAMultiheadAttentionF"><span class="hs-identifier hs-var">SAMultiheadAttentionF</span></a></span></span><span>
</span><span id="line-120"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679709680"><span class="annot"><a href="#local-6989586621679709680"><span class="hs-identifier hs-type">style</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#TransformerStyle"><span class="hs-identifier hs-type">TransformerStyle</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-121"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679709679"><span class="annot"><a href="#local-6989586621679709679"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#Gradient"><span class="hs-identifier hs-type">Gradient</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#RequiresGradient"><span class="hs-identifier hs-type">RequiresGradient</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-122"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679709678"><span class="annot"><a href="#local-6989586621679709678"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#Device"><span class="hs-identifier hs-type">Device</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#DeviceType"><span class="hs-identifier hs-type">DeviceType</span></a></span><span> </span><span class="annot"><a href="../file:///nix/store/9z106fx3296sgdwa5s05xi381ayi6qfk-ghc-9.2.4-doc/share/doc/ghc/html/libraries/base-4.16.3.0/src"><span class="hs-identifier hs-type">Nat</span></a></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-123"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679709677"><span class="annot"><a href="#local-6989586621679709677"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#DataType"><span class="hs-identifier hs-type">DataType</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#DType"><span class="hs-identifier hs-type">DType</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-124"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679709676"><span class="annot"><a href="#local-6989586621679709676"><span class="hs-identifier hs-type">headDim</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><a href="../file:///nix/store/9z106fx3296sgdwa5s05xi381ayi6qfk-ghc-9.2.4-doc/share/doc/ghc/html/libraries/ghc-prim-0.8.0/src"><span class="hs-identifier hs-type">Symbol</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><a href="../file:///nix/store/9z106fx3296sgdwa5s05xi381ayi6qfk-ghc-9.2.4-doc/share/doc/ghc/html/libraries/base-4.16.3.0/src"><span class="hs-identifier hs-type">Nat</span></a></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-125"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679709675"><span class="annot"><a href="#local-6989586621679709675"><span class="hs-identifier hs-type">headEmbedDim</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><a href="../file:///nix/store/9z106fx3296sgdwa5s05xi381ayi6qfk-ghc-9.2.4-doc/share/doc/ghc/html/libraries/ghc-prim-0.8.0/src"><span class="hs-identifier hs-type">Symbol</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><a href="../file:///nix/store/9z106fx3296sgdwa5s05xi381ayi6qfk-ghc-9.2.4-doc/share/doc/ghc/html/libraries/base-4.16.3.0/src"><span class="hs-identifier hs-type">Nat</span></a></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-126"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679709674"><span class="annot"><a href="#local-6989586621679709674"><span class="hs-identifier hs-type">embedDim</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><a href="../file:///nix/store/9z106fx3296sgdwa5s05xi381ayi6qfk-ghc-9.2.4-doc/share/doc/ghc/html/libraries/ghc-prim-0.8.0/src"><span class="hs-identifier hs-type">Symbol</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><a href="../file:///nix/store/9z106fx3296sgdwa5s05xi381ayi6qfk-ghc-9.2.4-doc/share/doc/ghc/html/libraries/base-4.16.3.0/src"><span class="hs-identifier hs-type">Nat</span></a></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-127"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679709673"><span class="annot"><a href="#local-6989586621679709673"><span class="hs-identifier hs-type">queryEmbedDim</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><a href="../file:///nix/store/9z106fx3296sgdwa5s05xi381ayi6qfk-ghc-9.2.4-doc/share/doc/ghc/html/libraries/ghc-prim-0.8.0/src"><span class="hs-identifier hs-type">Symbol</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><a href="../file:///nix/store/9z106fx3296sgdwa5s05xi381ayi6qfk-ghc-9.2.4-doc/share/doc/ghc/html/libraries/base-4.16.3.0/src"><span class="hs-identifier hs-type">Nat</span></a></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-128"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679709672"><span class="annot"><a href="#local-6989586621679709672"><span class="hs-identifier hs-type">hasDropout</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Type.html#HasDropout"><span class="hs-identifier hs-type">HasDropout</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-129"></span><span>    </span><span class="annot"><a href="../file:///nix/store/9z106fx3296sgdwa5s05xi381ayi6qfk-ghc-9.2.4-doc/share/doc/ghc/html/libraries/ghc-prim-0.8.0/src"><span class="hs-identifier hs-type">Type</span></a></span><span>
</span><span id="line-130"></span><span>  </span><span class="hs-keyword">where</span><span>
</span><span id="line-131"></span><span>  </span><span id="SAMultiheadAttentionF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GSelfAttention.html#SAMultiheadAttentionF"><span class="hs-identifier hs-var">SAMultiheadAttentionF</span></a></span></span><span> </span><span id="local-6989586621679709663"><span id="local-6989586621679709664"><span id="local-6989586621679709665"><span id="local-6989586621679709666"><span id="local-6989586621679709667"><span id="local-6989586621679709668"><span id="local-6989586621679709669"><span id="local-6989586621679709670"><span id="local-6989586621679709671"><span class="annot"><a href="#local-6989586621679709671"><span class="hs-identifier hs-type">style</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709670"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709669"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709668"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709667"><span class="hs-identifier hs-type">headDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709666"><span class="hs-identifier hs-type">headEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709665"><span class="hs-identifier hs-type">embedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709664"><span class="hs-identifier hs-type">queryEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709663"><span class="hs-identifier hs-type">hasDropout</span></a></span></span></span></span></span></span></span></span></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-132"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#NamedModel"><span class="hs-identifier hs-type">NamedModel</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GMultiHeadAttention.html#GMultiHeadAttentionF"><span class="hs-identifier hs-type">GMultiHeadAttentionF</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709671"><span class="hs-identifier hs-type">style</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709670"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709669"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709668"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709667"><span class="hs-identifier hs-type">headDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709666"><span class="hs-identifier hs-type">headEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709665"><span class="hs-identifier hs-type">embedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709664"><span class="hs-identifier hs-type">queryEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709664"><span class="hs-identifier hs-type">queryEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709664"><span class="hs-identifier hs-type">queryEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709663"><span class="hs-identifier hs-type">hasDropout</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-133"></span><span>
</span><span id="line-134"></span><span class="hs-comment">-- | Specifies the dropout layer of the self-attention layer.</span><span>
</span><span id="line-135"></span><span class="hs-keyword">type</span><span> </span><span class="hs-keyword">family</span><span>
</span><span id="line-136"></span><span>  </span><span id="SADropoutF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GSelfAttention.html#SADropoutF"><span class="hs-identifier hs-var">SADropoutF</span></a></span></span><span>
</span><span id="line-137"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679709662"><span class="annot"><a href="#local-6989586621679709662"><span class="hs-identifier hs-type">style</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#TransformerStyle"><span class="hs-identifier hs-type">TransformerStyle</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-138"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679709661"><span class="annot"><a href="#local-6989586621679709661"><span class="hs-identifier hs-type">hasDropout</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Type.html#HasDropout"><span class="hs-identifier hs-type">HasDropout</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-139"></span><span>    </span><span class="annot"><a href="../file:///nix/store/9z106fx3296sgdwa5s05xi381ayi6qfk-ghc-9.2.4-doc/share/doc/ghc/html/libraries/ghc-prim-0.8.0/src"><span class="hs-identifier hs-type">Type</span></a></span><span>
</span><span id="line-140"></span><span>  </span><span class="hs-keyword">where</span><span>
</span><span id="line-141"></span><span>  </span><span id="SADropoutF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GSelfAttention.html#SADropoutF"><span class="hs-identifier hs-var">SADropoutF</span></a></span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Type.html#WithDropout"><span class="hs-identifier hs-type">WithDropout</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Dropout.html#Dropout"><span class="hs-identifier hs-type">Dropout</span></a></span><span>
</span><span id="line-142"></span><span>  </span><span id="SADropoutF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GSelfAttention.html#SADropoutF"><span class="hs-identifier hs-var">SADropoutF</span></a></span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Type.html#WithoutDropout"><span class="hs-identifier hs-type">WithoutDropout</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="hs-special">(</span><span class="hs-special">)</span><span>
</span><span id="line-143"></span><span>
</span><span id="line-144"></span><span class="hs-comment">-- | Specifies the final layer normalization of the self-attention layer.</span><span>
</span><span id="line-145"></span><span class="hs-keyword">type</span><span> </span><span class="hs-keyword">family</span><span>
</span><span id="line-146"></span><span>  </span><span id="SAFinalLayerNormF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GSelfAttention.html#SAFinalLayerNormF"><span class="hs-identifier hs-var">SAFinalLayerNormF</span></a></span></span><span>
</span><span id="line-147"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679709660"><span class="annot"><a href="#local-6989586621679709660"><span class="hs-identifier hs-type">style</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#TransformerStyle"><span class="hs-identifier hs-type">TransformerStyle</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-148"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679709659"><span class="annot"><a href="#local-6989586621679709659"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#Gradient"><span class="hs-identifier hs-type">Gradient</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#RequiresGradient"><span class="hs-identifier hs-type">RequiresGradient</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-149"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679709658"><span class="annot"><a href="#local-6989586621679709658"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#Device"><span class="hs-identifier hs-type">Device</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#DeviceType"><span class="hs-identifier hs-type">DeviceType</span></a></span><span> </span><span class="annot"><a href="../file:///nix/store/9z106fx3296sgdwa5s05xi381ayi6qfk-ghc-9.2.4-doc/share/doc/ghc/html/libraries/base-4.16.3.0/src"><span class="hs-identifier hs-type">Nat</span></a></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-150"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679709657"><span class="annot"><a href="#local-6989586621679709657"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#DataType"><span class="hs-identifier hs-type">DataType</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#DType"><span class="hs-identifier hs-type">DType</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-151"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679709656"><span class="annot"><a href="#local-6989586621679709656"><span class="hs-identifier hs-type">queryEmbedDim</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><a href="../file:///nix/store/9z106fx3296sgdwa5s05xi381ayi6qfk-ghc-9.2.4-doc/share/doc/ghc/html/libraries/ghc-prim-0.8.0/src"><span class="hs-identifier hs-type">Symbol</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><a href="../file:///nix/store/9z106fx3296sgdwa5s05xi381ayi6qfk-ghc-9.2.4-doc/share/doc/ghc/html/libraries/base-4.16.3.0/src"><span class="hs-identifier hs-type">Nat</span></a></span><span class="hs-special">)</span><span class="hs-special">)</span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-152"></span><span>    </span><span class="annot"><a href="../file:///nix/store/9z106fx3296sgdwa5s05xi381ayi6qfk-ghc-9.2.4-doc/share/doc/ghc/html/libraries/ghc-prim-0.8.0/src"><span class="hs-identifier hs-type">Type</span></a></span><span>
</span><span id="line-153"></span><span>  </span><span class="hs-keyword">where</span><span>
</span><span id="line-154"></span><span>  </span><span id="SAFinalLayerNormF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GSelfAttention.html#SAFinalLayerNormF"><span class="hs-identifier hs-var">SAFinalLayerNormF</span></a></span></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#T5"><span class="hs-identifier hs-type">T5</span></a></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-155"></span><span>    </span><span class="hs-special">(</span><span class="hs-special">)</span><span>
</span><span id="line-156"></span><span>  </span><span id="SAFinalLayerNormF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GSelfAttention.html#SAFinalLayerNormF"><span class="hs-identifier hs-var">SAFinalLayerNormF</span></a></span></span><span> </span><span id="local-6989586621679709652"><span id="local-6989586621679709653"><span id="local-6989586621679709654"><span id="local-6989586621679709655"><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#ByT5"><span class="hs-identifier hs-type">ByT5</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709655"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709654"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709653"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709652"><span class="hs-identifier hs-type">queryEmbedDim</span></a></span></span></span></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-157"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GSelfAttention.html#SAFinalLayerNormF"><span class="hs-identifier hs-type">SAFinalLayerNormF</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#T5"><span class="hs-identifier hs-type">T5</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709655"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709654"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709653"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709652"><span class="hs-identifier hs-type">queryEmbedDim</span></a></span><span>
</span><span id="line-158"></span><span>  </span><span id="SAFinalLayerNormF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GSelfAttention.html#SAFinalLayerNormF"><span class="hs-identifier hs-var">SAFinalLayerNormF</span></a></span></span><span> </span><span id="local-6989586621679709648"><span id="local-6989586621679709649"><span id="local-6989586621679709650"><span id="local-6989586621679709651"><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#BART"><span class="hs-identifier hs-type">BART</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709651"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709650"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709649"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709648"><span class="hs-identifier hs-type">queryEmbedDim</span></a></span></span></span></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-159"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#NamedModel"><span class="hs-identifier hs-type">NamedModel</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Normalization.html#LayerNorm"><span class="hs-identifier hs-type">LayerNorm</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Type.html#WithBias"><span class="hs-identifier hs-type">WithBias</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709651"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709650"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709649"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Shape"><span class="hs-identifier hs-type">Shape</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="annot"><a href="#local-6989586621679709648"><span class="hs-identifier hs-type">queryEmbedDim</span></a></span><span class="hs-special">]</span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-160"></span><span>  </span><span id="SAFinalLayerNormF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GSelfAttention.html#SAFinalLayerNormF"><span class="hs-identifier hs-var">SAFinalLayerNormF</span></a></span></span><span> </span><span id="local-6989586621679709644"><span id="local-6989586621679709645"><span id="local-6989586621679709646"><span id="local-6989586621679709647"><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#MBART"><span class="hs-identifier hs-type">MBART</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709647"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709646"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709645"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709644"><span class="hs-identifier hs-type">queryEmbedDim</span></a></span></span></span></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-161"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GSelfAttention.html#SAFinalLayerNormF"><span class="hs-identifier hs-type">SAFinalLayerNormF</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#BART"><span class="hs-identifier hs-type">BART</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709647"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709646"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709645"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709644"><span class="hs-identifier hs-type">queryEmbedDim</span></a></span><span>
</span><span id="line-162"></span><span>  </span><span id="SAFinalLayerNormF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GSelfAttention.html#SAFinalLayerNormF"><span class="hs-identifier hs-var">SAFinalLayerNormF</span></a></span></span><span> </span><span id="local-6989586621679709640"><span id="local-6989586621679709641"><span id="local-6989586621679709642"><span id="local-6989586621679709643"><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#Pegasus"><span class="hs-identifier hs-type">Pegasus</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709643"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709642"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709641"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709640"><span class="hs-identifier hs-type">queryEmbedDim</span></a></span></span></span></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-163"></span><span>    </span><span class="hs-special">(</span><span class="hs-special">)</span><span>
</span><span id="line-164"></span><span>  </span><span id="SAFinalLayerNormF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GSelfAttention.html#SAFinalLayerNormF"><span class="hs-identifier hs-var">SAFinalLayerNormF</span></a></span></span><span> </span><span id="local-6989586621679709636"><span id="local-6989586621679709637"><span id="local-6989586621679709638"><span id="local-6989586621679709639"><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#BERT"><span class="hs-identifier hs-type">BERT</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709639"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709638"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709637"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709636"><span class="hs-identifier hs-type">queryEmbedDim</span></a></span></span></span></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-165"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#NamedModel"><span class="hs-identifier hs-type">NamedModel</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Normalization.html#LayerNorm"><span class="hs-identifier hs-type">LayerNorm</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Type.html#WithBias"><span class="hs-identifier hs-type">WithBias</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709639"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709638"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709637"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Shape"><span class="hs-identifier hs-type">Shape</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="annot"><a href="#local-6989586621679709636"><span class="hs-identifier hs-type">queryEmbedDim</span></a></span><span class="hs-special">]</span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-166"></span><span>  </span><span id="SAFinalLayerNormF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GSelfAttention.html#SAFinalLayerNormF"><span class="hs-identifier hs-var">SAFinalLayerNormF</span></a></span></span><span> </span><span id="local-6989586621679709632"><span id="local-6989586621679709633"><span id="local-6989586621679709634"><span id="local-6989586621679709635"><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#RoBERTa"><span class="hs-identifier hs-type">RoBERTa</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709635"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709634"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709633"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709632"><span class="hs-identifier hs-type">queryEmbedDim</span></a></span></span></span></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-167"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GSelfAttention.html#SAFinalLayerNormF"><span class="hs-identifier hs-type">SAFinalLayerNormF</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#BERT"><span class="hs-identifier hs-type">BERT</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709635"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709634"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709633"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709632"><span class="hs-identifier hs-type">queryEmbedDim</span></a></span><span>
</span><span id="line-168"></span><span>
</span><span id="line-169"></span><span class="hs-comment">-- | Specifies the parameters of a self-attention layer.</span><span>
</span><span id="line-170"></span><span class="hs-comment">--</span><span>
</span><span id="line-171"></span><span class="hs-comment">-- - @style@: the style of the transformer stack, e.g. 'ST5', 'SByT5', etc.</span><span>
</span><span id="line-172"></span><span class="hs-comment">-- - @gradient@: whether to compute the gradient of the stack's parameters.</span><span>
</span><span id="line-173"></span><span class="hs-comment">-- - @device@: the computational device on which the stack is allocated.</span><span>
</span><span id="line-174"></span><span class="hs-comment">-- - @dataType@: the data type of the stack's parameters.</span><span>
</span><span id="line-175"></span><span class="hs-comment">-- - @headDim@: the dimension of all transformer heads in the stack.</span><span>
</span><span id="line-176"></span><span class="hs-comment">-- - @headEmbedDim@: the dimension of the transformer head embeddings.</span><span>
</span><span id="line-177"></span><span class="hs-comment">-- - @embedDim@: the dimension of the transformer embeddings.</span><span>
</span><span id="line-178"></span><span class="hs-comment">-- - @queryEmbedDim@: the dimension of the transformer query embeddings.</span><span>
</span><span id="line-179"></span><span class="hs-comment">-- - @dropoutP@: the dropout rate.</span><span>
</span><span id="line-180"></span><span class="hs-comment">-- - @eps@: the epsilon value for numerical stability of the layer normalization.</span><span>
</span><span id="line-181"></span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GSelfAttention.html#selfAttentionSpec"><span class="hs-identifier hs-type">selfAttentionSpec</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-182"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679710152"><span class="annot"><a href="#local-6989586621679710152"><span class="hs-identifier hs-type">style</span></a></span></span><span> </span><span id="local-6989586621679710150"><span class="annot"><a href="#local-6989586621679710150"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679710148"><span class="annot"><a href="#local-6989586621679710148"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679710146"><span class="annot"><a href="#local-6989586621679710146"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679710144"><span class="annot"><a href="#local-6989586621679710144"><span class="hs-identifier hs-type">headDim</span></a></span></span><span> </span><span id="local-6989586621679710142"><span class="annot"><a href="#local-6989586621679710142"><span class="hs-identifier hs-type">headEmbedDim</span></a></span></span><span> </span><span id="local-6989586621679710141"><span class="annot"><a href="#local-6989586621679710141"><span class="hs-identifier hs-type">embedDim</span></a></span></span><span> </span><span id="local-6989586621679710140"><span class="annot"><a href="#local-6989586621679710140"><span class="hs-identifier hs-type">queryEmbedDim</span></a></span></span><span> </span><span id="local-6989586621679710139"><span class="annot"><a href="#local-6989586621679710139"><span class="hs-identifier hs-type">hasDropout</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-183"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#STransformerStyle"><span class="hs-identifier hs-type">STransformerStyle</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710152"><span class="hs-identifier hs-type">style</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-184"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#SGradient"><span class="hs-identifier hs-type">SGradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710150"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-185"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#SDevice"><span class="hs-identifier hs-type">SDevice</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710148"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-186"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#SDataType"><span class="hs-identifier hs-type">SDataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710146"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-187"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SDim"><span class="hs-identifier hs-type">SDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710144"><span class="hs-identifier hs-type">headDim</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-188"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SDim"><span class="hs-identifier hs-type">SDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710142"><span class="hs-identifier hs-type">headEmbedDim</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-189"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SDim"><span class="hs-identifier hs-type">SDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710141"><span class="hs-identifier hs-type">embedDim</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-190"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SDim"><span class="hs-identifier hs-type">SDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710140"><span class="hs-identifier hs-type">queryEmbedDim</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-191"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Type.html#SHasDropout"><span class="hs-identifier hs-type">SHasDropout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710139"><span class="hs-identifier hs-type">hasDropout</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-192"></span><span>  </span><span class="annot"><a href="../file:///nix/store/9z106fx3296sgdwa5s05xi381ayi6qfk-ghc-9.2.4-doc/share/doc/ghc/html/libraries/ghc-prim-0.8.0/src"><span class="hs-identifier hs-type">Double</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-193"></span><span>  </span><span class="annot"><a href="../file:///nix/store/9z106fx3296sgdwa5s05xi381ayi6qfk-ghc-9.2.4-doc/share/doc/ghc/html/libraries/ghc-prim-0.8.0/src"><span class="hs-identifier hs-type">Double</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-194"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#ModelSpec"><span class="hs-identifier hs-type">ModelSpec</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GSelfAttention.html#GSelfAttentionF"><span class="hs-identifier hs-type">GSelfAttentionF</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710152"><span class="hs-identifier hs-type">style</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710150"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710148"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710146"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710144"><span class="hs-identifier hs-type">headDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710142"><span class="hs-identifier hs-type">headEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710141"><span class="hs-identifier hs-type">embedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710140"><span class="hs-identifier hs-type">queryEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710139"><span class="hs-identifier hs-type">hasDropout</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-195"></span><span id="selfAttentionSpec"><span class="annot"><span class="annottext">selfAttentionSpec :: forall (style :: TransformerStyle)
       (gradient :: Gradient RequiresGradient)
       (device :: Device (DeviceType Nat)) (dataType :: DataType DType)
       (headDim :: Dim (Name Symbol) (Size Nat))
       (headEmbedDim :: Dim (Name Symbol) (Size Nat))
       (embedDim :: Dim (Name Symbol) (Size Nat))
       (queryEmbedDim :: Dim (Name Symbol) (Size Nat))
       (hasDropout :: HasDropout).
STransformerStyle style
-&gt; SGradient gradient
-&gt; SDevice device
-&gt; SDataType dataType
-&gt; SDim headDim
-&gt; SDim headEmbedDim
-&gt; SDim embedDim
-&gt; SDim queryEmbedDim
-&gt; SHasDropout hasDropout
-&gt; Double
-&gt; Double
-&gt; ModelSpec
     (GSelfAttentionF
        style
        gradient
        device
        dataType
        headDim
        headEmbedDim
        embedDim
        queryEmbedDim
        hasDropout)
</span><a href="Torch.GraduallyTyped.NN.Transformer.GSelfAttention.html#selfAttentionSpec"><span class="hs-identifier hs-var hs-var">selfAttentionSpec</span></a></span></span><span> </span><span id="local-6989586621679709630"><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="#local-6989586621679709630"><span class="hs-identifier hs-var">style</span></a></span></span><span> </span><span id="local-6989586621679709629"><span class="annot"><span class="annottext">SGradient gradient
</span><a href="#local-6989586621679709629"><span class="hs-identifier hs-var">gradient</span></a></span></span><span> </span><span id="local-6989586621679709628"><span class="annot"><span class="annottext">SDevice device
</span><a href="#local-6989586621679709628"><span class="hs-identifier hs-var">device</span></a></span></span><span> </span><span id="local-6989586621679709627"><span class="annot"><span class="annottext">SDataType dataType
</span><a href="#local-6989586621679709627"><span class="hs-identifier hs-var">dataType</span></a></span></span><span> </span><span id="local-6989586621679709626"><span class="annot"><span class="annottext">SDim headDim
</span><a href="#local-6989586621679709626"><span class="hs-identifier hs-var">headDim</span></a></span></span><span> </span><span id="local-6989586621679709625"><span class="annot"><span class="annottext">SDim headEmbedDim
</span><a href="#local-6989586621679709625"><span class="hs-identifier hs-var">headEmbedDim</span></a></span></span><span> </span><span id="local-6989586621679709624"><span class="annot"><span class="annottext">SDim embedDim
</span><a href="#local-6989586621679709624"><span class="hs-identifier hs-var">embedDim</span></a></span></span><span> </span><span id="local-6989586621679709623"><span class="annot"><span class="annottext">SDim queryEmbedDim
</span><a href="#local-6989586621679709623"><span class="hs-identifier hs-var">queryEmbedDim</span></a></span></span><span> </span><span id="local-6989586621679709622"><span class="annot"><span class="annottext">SHasDropout hasDropout
</span><a href="#local-6989586621679709622"><span class="hs-identifier hs-var">hasDropout</span></a></span></span><span> </span><span id="local-6989586621679709621"><span class="annot"><span class="annottext">Double
</span><a href="#local-6989586621679709621"><span class="hs-identifier hs-var">dropoutP</span></a></span></span><span> </span><span id="local-6989586621679709620"><span class="annot"><span class="annottext">Double
</span><a href="#local-6989586621679709620"><span class="hs-identifier hs-var">eps</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-196"></span><span>  </span><span class="hs-keyword">let</span><span> </span><span id="local-6989586621679709619"><span class="annot"><span class="annottext">initialLayerNormSpec :: STransformerStyle style
-&gt; ModelSpec
     (SAInitialLayerNormF style gradient device dataType queryEmbedDim)
</span><a href="#local-6989586621679709619"><span class="hs-identifier hs-var hs-var">initialLayerNormSpec</span></a></span></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#ST5"><span class="hs-identifier hs-var">ST5</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">forall model. Text -&gt; model -&gt; NamedModel model
</span><a href="Torch.GraduallyTyped.NN.Class.html#NamedModel"><span class="hs-identifier hs-var">NamedModel</span></a></span><span> </span><span class="annot"><span class="annottext">Text
</span><span class="hs-string">&quot;layer_norm.&quot;</span></span><span> </span><span class="annot"><span class="annottext">LayerNormSpec
  'WithoutBias gradient device dataType ('Shape '[queryEmbedDim])
</span><a href="#local-6989586621679709613"><span class="hs-identifier hs-var">layerNormWithoutBiasSpec</span></a></span><span>
</span><span id="line-197"></span><span>      </span><span class="annot"><a href="#local-6989586621679709619"><span class="hs-identifier hs-var">initialLayerNormSpec</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SByT5"><span class="hs-identifier hs-var">SByT5</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">forall model. Text -&gt; model -&gt; NamedModel model
</span><a href="Torch.GraduallyTyped.NN.Class.html#NamedModel"><span class="hs-identifier hs-var">NamedModel</span></a></span><span> </span><span class="annot"><span class="annottext">Text
</span><span class="hs-string">&quot;layer_norm.&quot;</span></span><span> </span><span class="annot"><span class="annottext">LayerNormSpec
  'WithoutBias gradient device dataType ('Shape '[queryEmbedDim])
</span><a href="#local-6989586621679709613"><span class="hs-identifier hs-var">layerNormWithoutBiasSpec</span></a></span><span>
</span><span id="line-198"></span><span>      </span><span class="annot"><a href="#local-6989586621679709619"><span class="hs-identifier hs-var">initialLayerNormSpec</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SBART"><span class="hs-identifier hs-var">SBART</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="hs-special">(</span><span class="hs-special">)</span><span>
</span><span id="line-199"></span><span>      </span><span class="annot"><a href="#local-6989586621679709619"><span class="hs-identifier hs-var">initialLayerNormSpec</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SMBART"><span class="hs-identifier hs-var">SMBART</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="hs-special">(</span><span class="hs-special">)</span><span>
</span><span id="line-200"></span><span>      </span><span class="annot"><a href="#local-6989586621679709619"><span class="hs-identifier hs-var">initialLayerNormSpec</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SPegasus"><span class="hs-identifier hs-var">SPegasus</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">forall model. Text -&gt; model -&gt; NamedModel model
</span><a href="Torch.GraduallyTyped.NN.Class.html#NamedModel"><span class="hs-identifier hs-var">NamedModel</span></a></span><span> </span><span class="annot"><span class="annottext">Text
</span><span class="hs-string">&quot;self_attn_layer_norm.&quot;</span></span><span> </span><span class="annot"><span class="annottext">LayerNormSpec
  'WithBias gradient device dataType ('Shape '[queryEmbedDim])
</span><a href="#local-6989586621679709602"><span class="hs-identifier hs-var">layerNormWithBiasSpec</span></a></span><span>
</span><span id="line-201"></span><span>      </span><span class="annot"><a href="#local-6989586621679709619"><span class="hs-identifier hs-var">initialLayerNormSpec</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SBERT"><span class="hs-identifier hs-var">SBERT</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="hs-special">(</span><span class="hs-special">)</span><span>
</span><span id="line-202"></span><span>      </span><span class="annot"><a href="#local-6989586621679709619"><span class="hs-identifier hs-var">initialLayerNormSpec</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SRoBERTa"><span class="hs-identifier hs-var">SRoBERTa</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="hs-special">(</span><span class="hs-special">)</span><span>
</span><span id="line-203"></span><span>      </span><span class="annot"><a href="#local-6989586621679709619"><span class="hs-identifier hs-var">initialLayerNormSpec</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SGPT2"><span class="hs-identifier hs-var">SGPT2</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">forall a. HasCallStack =&gt; a
</span><a href="../file:///nix/store/9z106fx3296sgdwa5s05xi381ayi6qfk-ghc-9.2.4-doc/share/doc/ghc/html/libraries/base-4.16.3.0/src"><span class="hs-identifier hs-var">undefined</span></a></span><span>
</span><span id="line-204"></span><span>      </span><span id="local-6989586621679709592"><span class="annot"><span class="annottext">mhaSpec :: STransformerStyle style
-&gt; NamedModel
     (GMultiHeadAttention
        headDim
        headEmbedDim
        embedDim
        (ModelSpec
           (QInProjF style gradient device dataType queryEmbedDim embedDim))
        (ModelSpec
           (KInProjF style gradient device dataType queryEmbedDim embedDim))
        (ModelSpec
           (VInProjF style gradient device dataType queryEmbedDim embedDim))
        (ModelSpec
           (OutProjF style gradient device dataType embedDim queryEmbedDim))
        (ModelSpec (DropoutF style hasDropout)))
</span><a href="#local-6989586621679709592"><span class="hs-identifier hs-var hs-var">mhaSpec</span></a></span></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#ST5"><span class="hs-identifier hs-var">ST5</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">forall model. Text -&gt; model -&gt; NamedModel model
</span><a href="Torch.GraduallyTyped.NN.Class.html#NamedModel"><span class="hs-identifier hs-var">NamedModel</span></a></span><span> </span><span class="annot"><span class="annottext">Text
</span><span class="hs-string">&quot;SelfAttention.&quot;</span></span><span> </span><span class="annot"><span class="annottext">forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><a href="../file:///nix/store/9z106fx3296sgdwa5s05xi381ayi6qfk-ghc-9.2.4-doc/share/doc/ghc/html/libraries/base-4.16.3.0/src"><span class="hs-operator hs-var">$</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
-&gt; ModelSpec
     (GMultiHeadAttentionF
        style
        gradient
        device
        dataType
        headDim
        headEmbedDim
        embedDim
        queryEmbedDim
        queryEmbedDim
        queryEmbedDim
        hasDropout)
</span><a href="#local-6989586621679709589"><span class="hs-identifier hs-var">mhaSpec'</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle 'T5
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#ST5"><span class="hs-identifier hs-var">ST5</span></a></span><span>
</span><span id="line-205"></span><span>      </span><span class="annot"><a href="#local-6989586621679709592"><span class="hs-identifier hs-var">mhaSpec</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SByT5"><span class="hs-identifier hs-var">SByT5</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">forall model. Text -&gt; model -&gt; NamedModel model
</span><a href="Torch.GraduallyTyped.NN.Class.html#NamedModel"><span class="hs-identifier hs-var">NamedModel</span></a></span><span> </span><span class="annot"><span class="annottext">Text
</span><span class="hs-string">&quot;SelfAttention.&quot;</span></span><span> </span><span class="annot"><span class="annottext">forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><a href="../file:///nix/store/9z106fx3296sgdwa5s05xi381ayi6qfk-ghc-9.2.4-doc/share/doc/ghc/html/libraries/base-4.16.3.0/src"><span class="hs-operator hs-var">$</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
-&gt; ModelSpec
     (GMultiHeadAttentionF
        style
        gradient
        device
        dataType
        headDim
        headEmbedDim
        embedDim
        queryEmbedDim
        queryEmbedDim
        queryEmbedDim
        hasDropout)
</span><a href="#local-6989586621679709589"><span class="hs-identifier hs-var">mhaSpec'</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle 'ByT5
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SByT5"><span class="hs-identifier hs-var">SByT5</span></a></span><span>
</span><span id="line-206"></span><span>      </span><span class="annot"><a href="#local-6989586621679709592"><span class="hs-identifier hs-var">mhaSpec</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SBART"><span class="hs-identifier hs-var">SBART</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">forall model. Text -&gt; model -&gt; NamedModel model
</span><a href="Torch.GraduallyTyped.NN.Class.html#NamedModel"><span class="hs-identifier hs-var">NamedModel</span></a></span><span> </span><span class="annot"><span class="annottext">Text
</span><span class="hs-string">&quot;self_attn.&quot;</span></span><span> </span><span class="annot"><span class="annottext">forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><a href="../file:///nix/store/9z106fx3296sgdwa5s05xi381ayi6qfk-ghc-9.2.4-doc/share/doc/ghc/html/libraries/base-4.16.3.0/src"><span class="hs-operator hs-var">$</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
-&gt; ModelSpec
     (GMultiHeadAttentionF
        style
        gradient
        device
        dataType
        headDim
        headEmbedDim
        embedDim
        queryEmbedDim
        queryEmbedDim
        queryEmbedDim
        hasDropout)
</span><a href="#local-6989586621679709589"><span class="hs-identifier hs-var">mhaSpec'</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle 'BART
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SBART"><span class="hs-identifier hs-var">SBART</span></a></span><span>
</span><span id="line-207"></span><span>      </span><span class="annot"><a href="#local-6989586621679709592"><span class="hs-identifier hs-var">mhaSpec</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SMBART"><span class="hs-identifier hs-var">SMBART</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">forall model. Text -&gt; model -&gt; NamedModel model
</span><a href="Torch.GraduallyTyped.NN.Class.html#NamedModel"><span class="hs-identifier hs-var">NamedModel</span></a></span><span> </span><span class="annot"><span class="annottext">Text
</span><span class="hs-string">&quot;self_attn.&quot;</span></span><span> </span><span class="annot"><span class="annottext">forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><a href="../file:///nix/store/9z106fx3296sgdwa5s05xi381ayi6qfk-ghc-9.2.4-doc/share/doc/ghc/html/libraries/base-4.16.3.0/src"><span class="hs-operator hs-var">$</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
-&gt; ModelSpec
     (GMultiHeadAttentionF
        style
        gradient
        device
        dataType
        headDim
        headEmbedDim
        embedDim
        queryEmbedDim
        queryEmbedDim
        queryEmbedDim
        hasDropout)
</span><a href="#local-6989586621679709589"><span class="hs-identifier hs-var">mhaSpec'</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle 'MBART
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SMBART"><span class="hs-identifier hs-var">SMBART</span></a></span><span>
</span><span id="line-208"></span><span>      </span><span class="annot"><a href="#local-6989586621679709592"><span class="hs-identifier hs-var">mhaSpec</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SPegasus"><span class="hs-identifier hs-var">SPegasus</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">forall model. Text -&gt; model -&gt; NamedModel model
</span><a href="Torch.GraduallyTyped.NN.Class.html#NamedModel"><span class="hs-identifier hs-var">NamedModel</span></a></span><span> </span><span class="annot"><span class="annottext">Text
</span><span class="hs-string">&quot;self_attn.&quot;</span></span><span> </span><span class="annot"><span class="annottext">forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><a href="../file:///nix/store/9z106fx3296sgdwa5s05xi381ayi6qfk-ghc-9.2.4-doc/share/doc/ghc/html/libraries/base-4.16.3.0/src"><span class="hs-operator hs-var">$</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
-&gt; ModelSpec
     (GMultiHeadAttentionF
        style
        gradient
        device
        dataType
        headDim
        headEmbedDim
        embedDim
        queryEmbedDim
        queryEmbedDim
        queryEmbedDim
        hasDropout)
</span><a href="#local-6989586621679709589"><span class="hs-identifier hs-var">mhaSpec'</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle 'Pegasus
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SPegasus"><span class="hs-identifier hs-var">SPegasus</span></a></span><span>
</span><span id="line-209"></span><span>      </span><span class="annot"><a href="#local-6989586621679709592"><span class="hs-identifier hs-var">mhaSpec</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SBERT"><span class="hs-identifier hs-var">SBERT</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">forall model. Text -&gt; model -&gt; NamedModel model
</span><a href="Torch.GraduallyTyped.NN.Class.html#NamedModel"><span class="hs-identifier hs-var">NamedModel</span></a></span><span> </span><span class="annot"><span class="annottext">forall a. Monoid a =&gt; a
</span><a href="../file:///nix/store/9z106fx3296sgdwa5s05xi381ayi6qfk-ghc-9.2.4-doc/share/doc/ghc/html/libraries/base-4.16.3.0/src"><span class="hs-identifier hs-var">mempty</span></a></span><span> </span><span class="annot"><span class="annottext">forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><a href="../file:///nix/store/9z106fx3296sgdwa5s05xi381ayi6qfk-ghc-9.2.4-doc/share/doc/ghc/html/libraries/base-4.16.3.0/src"><span class="hs-operator hs-var">$</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
-&gt; ModelSpec
     (GMultiHeadAttentionF
        style
        gradient
        device
        dataType
        headDim
        headEmbedDim
        embedDim
        queryEmbedDim
        queryEmbedDim
        queryEmbedDim
        hasDropout)
</span><a href="#local-6989586621679709589"><span class="hs-identifier hs-var">mhaSpec'</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle 'BERT
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SBERT"><span class="hs-identifier hs-var">SBERT</span></a></span><span>
</span><span id="line-210"></span><span>      </span><span class="annot"><a href="#local-6989586621679709592"><span class="hs-identifier hs-var">mhaSpec</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SRoBERTa"><span class="hs-identifier hs-var">SRoBERTa</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">forall model. Text -&gt; model -&gt; NamedModel model
</span><a href="Torch.GraduallyTyped.NN.Class.html#NamedModel"><span class="hs-identifier hs-var">NamedModel</span></a></span><span> </span><span class="annot"><span class="annottext">forall a. Monoid a =&gt; a
</span><a href="../file:///nix/store/9z106fx3296sgdwa5s05xi381ayi6qfk-ghc-9.2.4-doc/share/doc/ghc/html/libraries/base-4.16.3.0/src"><span class="hs-identifier hs-var">mempty</span></a></span><span> </span><span class="annot"><span class="annottext">forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><a href="../file:///nix/store/9z106fx3296sgdwa5s05xi381ayi6qfk-ghc-9.2.4-doc/share/doc/ghc/html/libraries/base-4.16.3.0/src"><span class="hs-operator hs-var">$</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
-&gt; ModelSpec
     (GMultiHeadAttentionF
        style
        gradient
        device
        dataType
        headDim
        headEmbedDim
        embedDim
        queryEmbedDim
        queryEmbedDim
        queryEmbedDim
        hasDropout)
</span><a href="#local-6989586621679709589"><span class="hs-identifier hs-var">mhaSpec'</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle 'RoBERTa
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SRoBERTa"><span class="hs-identifier hs-var">SRoBERTa</span></a></span><span>
</span><span id="line-211"></span><span>      </span><span class="annot"><a href="#local-6989586621679709592"><span class="hs-identifier hs-var">mhaSpec</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SGPT2"><span class="hs-identifier hs-var">SGPT2</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">forall a. HasCallStack =&gt; a
</span><a href="../file:///nix/store/9z106fx3296sgdwa5s05xi381ayi6qfk-ghc-9.2.4-doc/share/doc/ghc/html/libraries/base-4.16.3.0/src"><span class="hs-identifier hs-var">undefined</span></a></span><span>
</span><span id="line-212"></span><span>      </span><span id="local-6989586621679709572"><span class="annot"><span class="annottext">dropoutSpec :: STransformerStyle style
-&gt; SHasDropout hasDropout
-&gt; ModelSpec (SADropoutF style hasDropout)
</span><a href="#local-6989586621679709572"><span class="hs-identifier hs-var hs-var">dropoutSpec</span></a></span></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><span class="hs-identifier">_</span></span><span> </span><span class="annot"><span class="annottext">SHasDropout hasDropout
</span><a href="Torch.GraduallyTyped.NN.Type.html#SWithDropout"><span class="hs-identifier hs-var">SWithDropout</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Double -&gt; Dropout
</span><a href="Torch.GraduallyTyped.NN.Dropout.html#Dropout"><span class="hs-identifier hs-var">Dropout</span></a></span><span> </span><span class="annot"><span class="annottext">Double
</span><a href="#local-6989586621679709621"><span class="hs-identifier hs-var">dropoutP</span></a></span><span>
</span><span id="line-213"></span><span>      </span><span class="annot"><a href="#local-6989586621679709572"><span class="hs-identifier hs-var">dropoutSpec</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><span class="hs-identifier">_</span></span><span> </span><span class="annot"><span class="annottext">SHasDropout hasDropout
</span><a href="Torch.GraduallyTyped.NN.Type.html#SWithoutDropout"><span class="hs-identifier hs-var">SWithoutDropout</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="hs-special">(</span><span class="hs-special">)</span><span>
</span><span id="line-214"></span><span>      </span><span id="local-6989586621679709566"><span class="annot"><span class="annottext">finalLayerNormSpec :: STransformerStyle style
-&gt; ModelSpec
     (SAFinalLayerNormF style gradient device dataType queryEmbedDim)
</span><a href="#local-6989586621679709566"><span class="hs-identifier hs-var hs-var">finalLayerNormSpec</span></a></span></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#ST5"><span class="hs-identifier hs-var">ST5</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="hs-special">(</span><span class="hs-special">)</span><span>
</span><span id="line-215"></span><span>      </span><span class="annot"><a href="#local-6989586621679709566"><span class="hs-identifier hs-var">finalLayerNormSpec</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SByT5"><span class="hs-identifier hs-var">SByT5</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="hs-special">(</span><span class="hs-special">)</span><span>
</span><span id="line-216"></span><span>      </span><span class="annot"><a href="#local-6989586621679709566"><span class="hs-identifier hs-var">finalLayerNormSpec</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SBART"><span class="hs-identifier hs-var">SBART</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">forall model. Text -&gt; model -&gt; NamedModel model
</span><a href="Torch.GraduallyTyped.NN.Class.html#NamedModel"><span class="hs-identifier hs-var">NamedModel</span></a></span><span> </span><span class="annot"><span class="annottext">Text
</span><span class="hs-string">&quot;self_attn_layer_norm.&quot;</span></span><span> </span><span class="annot"><span class="annottext">LayerNormSpec
  'WithBias gradient device dataType ('Shape '[queryEmbedDim])
</span><a href="#local-6989586621679709602"><span class="hs-identifier hs-var">layerNormWithBiasSpec</span></a></span><span>
</span><span id="line-217"></span><span>      </span><span class="annot"><a href="#local-6989586621679709566"><span class="hs-identifier hs-var">finalLayerNormSpec</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SMBART"><span class="hs-identifier hs-var">SMBART</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">forall model. Text -&gt; model -&gt; NamedModel model
</span><a href="Torch.GraduallyTyped.NN.Class.html#NamedModel"><span class="hs-identifier hs-var">NamedModel</span></a></span><span> </span><span class="annot"><span class="annottext">Text
</span><span class="hs-string">&quot;self_attn_layer_norm.&quot;</span></span><span> </span><span class="annot"><span class="annottext">LayerNormSpec
  'WithBias gradient device dataType ('Shape '[queryEmbedDim])
</span><a href="#local-6989586621679709602"><span class="hs-identifier hs-var">layerNormWithBiasSpec</span></a></span><span>
</span><span id="line-218"></span><span>      </span><span class="annot"><a href="#local-6989586621679709566"><span class="hs-identifier hs-var">finalLayerNormSpec</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SPegasus"><span class="hs-identifier hs-var">SPegasus</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="hs-special">(</span><span class="hs-special">)</span><span>
</span><span id="line-219"></span><span>      </span><span class="annot"><a href="#local-6989586621679709566"><span class="hs-identifier hs-var">finalLayerNormSpec</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SBERT"><span class="hs-identifier hs-var">SBERT</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">forall model. Text -&gt; model -&gt; NamedModel model
</span><a href="Torch.GraduallyTyped.NN.Class.html#NamedModel"><span class="hs-identifier hs-var">NamedModel</span></a></span><span> </span><span class="annot"><span class="annottext">Text
</span><span class="hs-string">&quot;output.LayerNorm.&quot;</span></span><span> </span><span class="annot"><span class="annottext">LayerNormSpec
  'WithBias gradient device dataType ('Shape '[queryEmbedDim])
</span><a href="#local-6989586621679709602"><span class="hs-identifier hs-var">layerNormWithBiasSpec</span></a></span><span>
</span><span id="line-220"></span><span>      </span><span class="annot"><a href="#local-6989586621679709566"><span class="hs-identifier hs-var">finalLayerNormSpec</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SRoBERTa"><span class="hs-identifier hs-var">SRoBERTa</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">forall model. Text -&gt; model -&gt; NamedModel model
</span><a href="Torch.GraduallyTyped.NN.Class.html#NamedModel"><span class="hs-identifier hs-var">NamedModel</span></a></span><span> </span><span class="annot"><span class="annottext">Text
</span><span class="hs-string">&quot;output.LayerNorm.&quot;</span></span><span> </span><span class="annot"><span class="annottext">LayerNormSpec
  'WithBias gradient device dataType ('Shape '[queryEmbedDim])
</span><a href="#local-6989586621679709602"><span class="hs-identifier hs-var">layerNormWithBiasSpec</span></a></span><span>
</span><span id="line-221"></span><span>      </span><span class="annot"><a href="#local-6989586621679709566"><span class="hs-identifier hs-var">finalLayerNormSpec</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SGPT2"><span class="hs-identifier hs-var">SGPT2</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">forall a. HasCallStack =&gt; a
</span><a href="../file:///nix/store/9z106fx3296sgdwa5s05xi381ayi6qfk-ghc-9.2.4-doc/share/doc/ghc/html/libraries/base-4.16.3.0/src"><span class="hs-identifier hs-var">undefined</span></a></span><span>
</span><span id="line-222"></span><span>   </span><span class="hs-keyword">in</span><span> </span><span class="annot"><span class="annottext">forall initialLayerNorm mha dropout finalLayerNorm.
initialLayerNorm
-&gt; mha
-&gt; dropout
-&gt; finalLayerNorm
-&gt; GSelfAttention initialLayerNorm mha dropout finalLayerNorm
</span><a href="Torch.GraduallyTyped.NN.Transformer.GSelfAttention.html#GSelfAttention"><span class="hs-identifier hs-var">GSelfAttention</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">STransformerStyle style
-&gt; ModelSpec
     (SAInitialLayerNormF style gradient device dataType queryEmbedDim)
</span><a href="#local-6989586621679709619"><span class="hs-identifier hs-var">initialLayerNormSpec</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="#local-6989586621679709630"><span class="hs-identifier hs-var">style</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">STransformerStyle style
-&gt; NamedModel
     (GMultiHeadAttention
        headDim
        headEmbedDim
        embedDim
        (ModelSpec
           (QInProjF style gradient device dataType queryEmbedDim embedDim))
        (ModelSpec
           (KInProjF style gradient device dataType queryEmbedDim embedDim))
        (ModelSpec
           (VInProjF style gradient device dataType queryEmbedDim embedDim))
        (ModelSpec
           (OutProjF style gradient device dataType embedDim queryEmbedDim))
        (ModelSpec (DropoutF style hasDropout)))
</span><a href="#local-6989586621679709592"><span class="hs-identifier hs-var">mhaSpec</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="#local-6989586621679709630"><span class="hs-identifier hs-var">style</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">STransformerStyle style
-&gt; SHasDropout hasDropout
-&gt; ModelSpec (SADropoutF style hasDropout)
</span><a href="#local-6989586621679709572"><span class="hs-identifier hs-var">dropoutSpec</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="#local-6989586621679709630"><span class="hs-identifier hs-var">style</span></a></span><span> </span><span class="annot"><span class="annottext">SHasDropout hasDropout
</span><a href="#local-6989586621679709622"><span class="hs-identifier hs-var">hasDropout</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">STransformerStyle style
-&gt; ModelSpec
     (SAFinalLayerNormF style gradient device dataType queryEmbedDim)
</span><a href="#local-6989586621679709566"><span class="hs-identifier hs-var">finalLayerNormSpec</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="#local-6989586621679709630"><span class="hs-identifier hs-var">style</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-223"></span><span>  </span><span class="hs-keyword">where</span><span>
</span><span id="line-224"></span><span>    </span><span class="annot"><a href="#local-6989586621679709589"><span class="hs-identifier hs-type">mhaSpec'</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-225"></span><span>      </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#STransformerStyle"><span class="hs-identifier hs-type">STransformerStyle</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710152"><span class="hs-identifier hs-type">style</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-226"></span><span>      </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#ModelSpec"><span class="hs-identifier hs-type">ModelSpec</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GMultiHeadAttention.html#GMultiHeadAttentionF"><span class="hs-identifier hs-type">GMultiHeadAttentionF</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710152"><span class="hs-identifier hs-type">style</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710150"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710148"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710146"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710144"><span class="hs-identifier hs-type">headDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710142"><span class="hs-identifier hs-type">headEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710141"><span class="hs-identifier hs-type">embedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710140"><span class="hs-identifier hs-type">queryEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710140"><span class="hs-identifier hs-type">queryEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710140"><span class="hs-identifier hs-type">queryEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710139"><span class="hs-identifier hs-type">hasDropout</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-227"></span><span>    </span><span id="local-6989586621679709589"><span class="annot"><span class="annottext">mhaSpec' :: STransformerStyle style
-&gt; ModelSpec
     (GMultiHeadAttentionF
        style
        gradient
        device
        dataType
        headDim
        headEmbedDim
        embedDim
        queryEmbedDim
        queryEmbedDim
        queryEmbedDim
        hasDropout)
</span><a href="#local-6989586621679709589"><span class="hs-identifier hs-var hs-var">mhaSpec'</span></a></span></span><span> </span><span id="local-6989586621679709551"><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="#local-6989586621679709551"><span class="hs-identifier hs-var">style'</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">forall (style :: TransformerStyle)
       (gradient :: Gradient RequiresGradient)
       (device :: Device (DeviceType Nat)) (dataType :: DataType DType)
       (headDim :: Dim (Name Symbol) (Size Nat))
       (headEmbedDim :: Dim (Name Symbol) (Size Nat))
       (embedDim :: Dim (Name Symbol) (Size Nat))
       (queryEmbedDim :: Dim (Name Symbol) (Size Nat))
       (keyEmbedDim :: Dim (Name Symbol) (Size Nat))
       (valueEmbedDim :: Dim (Name Symbol) (Size Nat))
       (hasDropout :: HasDropout).
STransformerStyle style
-&gt; SGradient gradient
-&gt; SDevice device
-&gt; SDataType dataType
-&gt; SDim headDim
-&gt; SDim headEmbedDim
-&gt; SDim embedDim
-&gt; SDim queryEmbedDim
-&gt; SDim keyEmbedDim
-&gt; SDim valueEmbedDim
-&gt; SHasDropout hasDropout
-&gt; Double
-&gt; ModelSpec
     (GMultiHeadAttentionF
        style
        gradient
        device
        dataType
        headDim
        headEmbedDim
        embedDim
        queryEmbedDim
        keyEmbedDim
        valueEmbedDim
        hasDropout)
</span><a href="Torch.GraduallyTyped.NN.Transformer.GMultiHeadAttention.html#multiHeadAttentionSpec"><span class="hs-identifier hs-var">multiHeadAttentionSpec</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="#local-6989586621679709551"><span class="hs-identifier hs-var">style'</span></a></span><span> </span><span class="annot"><span class="annottext">SGradient gradient
</span><a href="#local-6989586621679709629"><span class="hs-identifier hs-var">gradient</span></a></span><span> </span><span class="annot"><span class="annottext">SDevice device
</span><a href="#local-6989586621679709628"><span class="hs-identifier hs-var">device</span></a></span><span> </span><span class="annot"><span class="annottext">SDataType dataType
</span><a href="#local-6989586621679709627"><span class="hs-identifier hs-var">dataType</span></a></span><span> </span><span class="annot"><span class="annottext">SDim headDim
</span><a href="#local-6989586621679709626"><span class="hs-identifier hs-var">headDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim headEmbedDim
</span><a href="#local-6989586621679709625"><span class="hs-identifier hs-var">headEmbedDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim embedDim
</span><a href="#local-6989586621679709624"><span class="hs-identifier hs-var">embedDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim queryEmbedDim
</span><a href="#local-6989586621679709623"><span class="hs-identifier hs-var">queryEmbedDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim queryEmbedDim
</span><a href="#local-6989586621679709623"><span class="hs-identifier hs-var">queryEmbedDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim queryEmbedDim
</span><a href="#local-6989586621679709623"><span class="hs-identifier hs-var">queryEmbedDim</span></a></span><span> </span><span class="annot"><span class="annottext">SHasDropout hasDropout
</span><a href="#local-6989586621679709622"><span class="hs-identifier hs-var">hasDropout</span></a></span><span> </span><span class="annot"><span class="annottext">Double
</span><a href="#local-6989586621679709621"><span class="hs-identifier hs-var">dropoutP</span></a></span><span>
</span><span id="line-228"></span><span>    </span><span id="local-6989586621679709613"><span class="annot"><span class="annottext">layerNormWithoutBiasSpec :: LayerNormSpec
  'WithoutBias gradient device dataType ('Shape '[queryEmbedDim])
</span><a href="#local-6989586621679709613"><span class="hs-identifier hs-var hs-var">layerNormWithoutBiasSpec</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">forall (hasBias :: HasBias) (gradient :: Gradient RequiresGradient)
       (device :: Device (DeviceType Nat)) (dataType :: DataType DType)
       (normalizedShape :: Shape [Dim (Name Symbol) (Size Nat)]).
SHasBias hasBias
-&gt; SGradient gradient
-&gt; SDevice device
-&gt; SDataType dataType
-&gt; SShape normalizedShape
-&gt; Double
-&gt; LayerNormSpec hasBias gradient device dataType normalizedShape
</span><a href="Torch.GraduallyTyped.NN.Normalization.html#LayerNormSpec"><span class="hs-identifier hs-var">LayerNormSpec</span></a></span><span> </span><span class="annot"><span class="annottext">SHasBias 'WithoutBias
</span><a href="Torch.GraduallyTyped.NN.Type.html#SWithoutBias"><span class="hs-identifier hs-var">SWithoutBias</span></a></span><span> </span><span class="annot"><span class="annottext">SGradient gradient
</span><a href="#local-6989586621679709629"><span class="hs-identifier hs-var">gradient</span></a></span><span> </span><span class="annot"><span class="annottext">SDevice device
</span><a href="#local-6989586621679709628"><span class="hs-identifier hs-var">device</span></a></span><span> </span><span class="annot"><span class="annottext">SDataType dataType
</span><a href="#local-6989586621679709627"><span class="hs-identifier hs-var">dataType</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">forall (dims :: [Dim (Name Symbol) (Size Nat)]).
SList dims -&gt; SShape ('Shape dims)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SShape"><span class="hs-identifier hs-var">SShape</span></a></span><span> </span><span class="annot"><span class="annottext">forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><a href="../file:///nix/store/9z106fx3296sgdwa5s05xi381ayi6qfk-ghc-9.2.4-doc/share/doc/ghc/html/libraries/base-4.16.3.0/src"><span class="hs-operator hs-var">$</span></a></span><span> </span><span class="annot"><span class="annottext">SDim queryEmbedDim
</span><a href="#local-6989586621679709623"><span class="hs-identifier hs-var">queryEmbedDim</span></a></span><span> </span><span class="annot"><span class="annottext">forall {k} (a :: k) (as :: [k]).
Sing a -&gt; SList as -&gt; SList (a : as)
</span><a href="Torch.GraduallyTyped.Prelude.html#%3A%7C%3A"><span class="hs-operator hs-var">:|:</span></a></span><span> </span><span class="annot"><span class="annottext">forall a. SList '[]
</span><a href="../file:///nix/store/cmxygbwkg9vwm5iizgff5i2x5awqcjjn-singletons-base-lib-singletons-base-3.1-haddock-doc/share/doc/singletons-base/html/src"><span class="hs-identifier hs-var">SNil</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">Double
</span><a href="#local-6989586621679709620"><span class="hs-identifier hs-var">eps</span></a></span><span>
</span><span id="line-229"></span><span>    </span><span id="local-6989586621679709602"><span class="annot"><span class="annottext">layerNormWithBiasSpec :: LayerNormSpec
  'WithBias gradient device dataType ('Shape '[queryEmbedDim])
</span><a href="#local-6989586621679709602"><span class="hs-identifier hs-var hs-var">layerNormWithBiasSpec</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">forall (hasBias :: HasBias) (gradient :: Gradient RequiresGradient)
       (device :: Device (DeviceType Nat)) (dataType :: DataType DType)
       (normalizedShape :: Shape [Dim (Name Symbol) (Size Nat)]).
SHasBias hasBias
-&gt; SGradient gradient
-&gt; SDevice device
-&gt; SDataType dataType
-&gt; SShape normalizedShape
-&gt; Double
-&gt; LayerNormSpec hasBias gradient device dataType normalizedShape
</span><a href="Torch.GraduallyTyped.NN.Normalization.html#LayerNormSpec"><span class="hs-identifier hs-var">LayerNormSpec</span></a></span><span> </span><span class="annot"><span class="annottext">SHasBias 'WithBias
</span><a href="Torch.GraduallyTyped.NN.Type.html#SWithBias"><span class="hs-identifier hs-var">SWithBias</span></a></span><span> </span><span class="annot"><span class="annottext">SGradient gradient
</span><a href="#local-6989586621679709629"><span class="hs-identifier hs-var">gradient</span></a></span><span> </span><span class="annot"><span class="annottext">SDevice device
</span><a href="#local-6989586621679709628"><span class="hs-identifier hs-var">device</span></a></span><span> </span><span class="annot"><span class="annottext">SDataType dataType
</span><a href="#local-6989586621679709627"><span class="hs-identifier hs-var">dataType</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">forall (dims :: [Dim (Name Symbol) (Size Nat)]).
SList dims -&gt; SShape ('Shape dims)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SShape"><span class="hs-identifier hs-var">SShape</span></a></span><span> </span><span class="annot"><span class="annottext">forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><a href="../file:///nix/store/9z106fx3296sgdwa5s05xi381ayi6qfk-ghc-9.2.4-doc/share/doc/ghc/html/libraries/base-4.16.3.0/src"><span class="hs-operator hs-var">$</span></a></span><span> </span><span class="annot"><span class="annottext">SDim queryEmbedDim
</span><a href="#local-6989586621679709623"><span class="hs-identifier hs-var">queryEmbedDim</span></a></span><span> </span><span class="annot"><span class="annottext">forall {k} (a :: k) (as :: [k]).
Sing a -&gt; SList as -&gt; SList (a : as)
</span><a href="Torch.GraduallyTyped.Prelude.html#%3A%7C%3A"><span class="hs-operator hs-var">:|:</span></a></span><span> </span><span class="annot"><span class="annottext">forall a. SList '[]
</span><a href="../file:///nix/store/cmxygbwkg9vwm5iizgff5i2x5awqcjjn-singletons-base-lib-singletons-base-3.1-haddock-doc/share/doc/singletons-base/html/src"><span class="hs-identifier hs-var">SNil</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">Double
</span><a href="#local-6989586621679709620"><span class="hs-identifier hs-var">eps</span></a></span><span>
</span><span id="line-230"></span><span>
</span><span id="line-231"></span><span class="hs-keyword">instance</span><span>
</span><span id="line-232"></span><span>  </span><span id="local-6989586621679709545"><span id="local-6989586621679710047"><span id="local-6989586621679710048"><span id="local-6989586621679710049"><span id="local-6989586621679710050"><span id="local-6989586621679710051"><span id="local-6989586621679710052"><span id="local-6989586621679710053"><span id="local-6989586621679710054"><span id="local-6989586621679710055"><span id="local-6989586621679710056"><span id="local-6989586621679710057"><span id="local-6989586621679710058"><span id="local-6989586621679710059"><span class="hs-special">(</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasInitialize"><span class="hs-identifier hs-type">HasInitialize</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710059"><span class="hs-identifier hs-type">initialLayerNorm</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710058"><span class="hs-identifier hs-type">generatorDevice</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710057"><span class="hs-identifier hs-type">initialLayerNorm'</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710056"><span class="hs-identifier hs-type">generatorDevice0</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-233"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasInitialize"><span class="hs-identifier hs-type">HasInitialize</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710055"><span class="hs-identifier hs-type">multiHeadAttention</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710056"><span class="hs-identifier hs-type">generatorDevice0</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710054"><span class="hs-identifier hs-type">multiHeadAttention'</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710053"><span class="hs-identifier hs-type">generatorDevice1</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-234"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasInitialize"><span class="hs-identifier hs-type">HasInitialize</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710052"><span class="hs-identifier hs-type">dropout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710053"><span class="hs-identifier hs-type">generatorDevice1</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710051"><span class="hs-identifier hs-type">dropout'</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710050"><span class="hs-identifier hs-type">generatorDevice2</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-235"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasInitialize"><span class="hs-identifier hs-type">HasInitialize</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710049"><span class="hs-identifier hs-type">finalLayerNorm</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710050"><span class="hs-identifier hs-type">generatorDevice2</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710048"><span class="hs-identifier hs-type">finalLayerNorm'</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710047"><span class="hs-identifier hs-type">generatorOutputDevice</span></a></span><span>
</span><span id="line-236"></span><span>  </span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-237"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasInitialize"><span class="hs-identifier hs-type">HasInitialize</span></a></span><span>
</span><span id="line-238"></span><span>    </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GSelfAttention.html#GSelfAttention"><span class="hs-identifier hs-type">GSelfAttention</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710059"><span class="hs-identifier hs-type">initialLayerNorm</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710055"><span class="hs-identifier hs-type">multiHeadAttention</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710052"><span class="hs-identifier hs-type">dropout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710049"><span class="hs-identifier hs-type">finalLayerNorm</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-239"></span><span>    </span><span class="annot"><a href="#local-6989586621679710058"><span class="hs-identifier hs-type">generatorDevice</span></a></span><span>
</span><span id="line-240"></span><span>    </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GSelfAttention.html#GSelfAttention"><span class="hs-identifier hs-type">GSelfAttention</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710057"><span class="hs-identifier hs-type">initialLayerNorm'</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710054"><span class="hs-identifier hs-type">multiHeadAttention'</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710051"><span class="hs-identifier hs-type">dropout'</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710048"><span class="hs-identifier hs-type">finalLayerNorm'</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-241"></span><span>    </span><span class="annot"><a href="#local-6989586621679710047"><span class="hs-identifier hs-type">generatorOutputDevice</span></a></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span><span>
</span><span id="line-242"></span><span>
</span><span id="line-243"></span><span class="hs-keyword">instance</span><span>
</span><span id="line-244"></span><span>  </span><span id="local-6989586621679709540"><span id="local-6989586621679709542"><span id="local-6989586621679710040"><span id="local-6989586621679710041"><span id="local-6989586621679710042"><span id="local-6989586621679710043"><span class="hs-special">(</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasStateDict"><span class="hs-identifier hs-type">HasStateDict</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710043"><span class="hs-identifier hs-type">initialLayerNorm</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-245"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasStateDict"><span class="hs-identifier hs-type">HasStateDict</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710042"><span class="hs-identifier hs-type">multiHeadAttention</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-246"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasStateDict"><span class="hs-identifier hs-type">HasStateDict</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710041"><span class="hs-identifier hs-type">dropout</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-247"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasStateDict"><span class="hs-identifier hs-type">HasStateDict</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710040"><span class="hs-identifier hs-type">finalLayerNorm</span></a></span><span>
</span><span id="line-248"></span><span>  </span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-249"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasStateDict"><span class="hs-identifier hs-type">HasStateDict</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GSelfAttention.html#GSelfAttention"><span class="hs-identifier hs-type">GSelfAttention</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710043"><span class="hs-identifier hs-type">initialLayerNorm</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710042"><span class="hs-identifier hs-type">multiHeadAttention</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710041"><span class="hs-identifier hs-type">dropout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710040"><span class="hs-identifier hs-type">finalLayerNorm</span></a></span><span class="hs-special">)</span></span></span></span></span></span></span><span>
</span><span id="line-250"></span><span>
</span><span id="line-251"></span><span class="hs-comment">-- | 'HasForward' instance for 'GSelfAttention'.</span><span>
</span><span id="line-252"></span><span class="hs-comment">--</span><span>
</span><span id="line-253"></span><span class="hs-comment">-- @</span><span>
</span><span id="line-254"></span><span class="hs-comment">-- &#9484;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9488;     &#9484;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9488;</span><span>
</span><span id="line-255"></span><span class="hs-comment">-- &#9474; attentionBias &#9474;     &#9474; query &#9474;</span><span>
</span><span id="line-256"></span><span class="hs-comment">-- &#9492;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9516;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9496;     &#9492;&#9472;&#9472;&#9472;&#9516;&#9472;&#9472;&#9472;&#9496;</span><span>
</span><span id="line-257"></span><span class="hs-comment">--         &#9474;                 &#9474;</span><span>
</span><span id="line-258"></span><span class="hs-comment">--         &#9474;           &#9484;&#9472;&#9472;&#9472;&#9472;&#9472;&#9524;&#9472;&#9472;&#9472;&#9472;&#9472;&#9488;</span><span>
</span><span id="line-259"></span><span class="hs-comment">--         &#9474;           &#9474;           &#9474;</span><span>
</span><span id="line-260"></span><span class="hs-comment">--         &#9474;           &#9660;           &#9474;</span><span>
</span><span id="line-261"></span><span class="hs-comment">--         &#9474;  (saInitialLayerNorm) &#9474;</span><span>
</span><span id="line-262"></span><span class="hs-comment">--         &#9474;           &#9474;           &#9474;</span><span>
</span><span id="line-263"></span><span class="hs-comment">--         &#9474;      &#9484;&#9472;&#9472;&#9472;&#9472;&#9532;&#9472;&#9472;&#9472;&#9472;&#9488;      &#9474;</span><span>
</span><span id="line-264"></span><span class="hs-comment">--         &#9474;      &#9474;    &#9474;    &#9474;      &#9474;</span><span>
</span><span id="line-265"></span><span class="hs-comment">--         &#9474;      &#9660;    &#9660;    &#9660;      &#9474;</span><span>
</span><span id="line-266"></span><span class="hs-comment">--         &#9492;&#9472;&#9658;saMultiHeadAttention &#9474;</span><span>
</span><span id="line-267"></span><span class="hs-comment">--                     &#9474;           &#9474;</span><span>
</span><span id="line-268"></span><span class="hs-comment">--                     &#9660;           &#9474;</span><span>
</span><span id="line-269"></span><span class="hs-comment">--                 saDropout       &#9474;</span><span>
</span><span id="line-270"></span><span class="hs-comment">--                     &#9474;           &#9474;</span><span>
</span><span id="line-271"></span><span class="hs-comment">--                     &#9492;&#9472;&#9472;&#9472;&#9658;add&#9668;&#9472;&#9472;&#9472;&#9496;</span><span>
</span><span id="line-272"></span><span class="hs-comment">--                           &#9474;</span><span>
</span><span id="line-273"></span><span class="hs-comment">--                           &#9660;</span><span>
</span><span id="line-274"></span><span class="hs-comment">--                   (saFinalLayerNorm)</span><span>
</span><span id="line-275"></span><span class="hs-comment">--                           &#9474;</span><span>
</span><span id="line-276"></span><span class="hs-comment">--                           &#9660;</span><span>
</span><span id="line-277"></span><span class="hs-comment">--                       &#9484;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9488;</span><span>
</span><span id="line-278"></span><span class="hs-comment">--                       &#9474; query &#9474;</span><span>
</span><span id="line-279"></span><span class="hs-comment">--                       &#9492;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9496;</span><span>
</span><span id="line-280"></span><span class="hs-comment">-- @</span><span>
</span><span id="line-281"></span><span class="hs-keyword">instance</span><span>
</span><span id="line-282"></span><span>  </span><span id="local-6989586621679709972"><span id="local-6989586621679709973"><span id="local-6989586621679709974"><span id="local-6989586621679709975"><span id="local-6989586621679709976"><span id="local-6989586621679709977"><span id="local-6989586621679709978"><span id="local-6989586621679709979"><span id="local-6989586621679709980"><span id="local-6989586621679709981"><span id="local-6989586621679709982"><span id="local-6989586621679709983"><span id="local-6989586621679709984"><span id="local-6989586621679709985"><span id="local-6989586621679709986"><span id="local-6989586621679709987"><span id="local-6989586621679709988"><span id="local-6989586621679709989"><span id="local-6989586621679709990"><span id="local-6989586621679709991"><span id="local-6989586621679709992"><span id="local-6989586621679709993"><span id="local-6989586621679709994"><span id="local-6989586621679709995"><span id="local-6989586621679709996"><span id="local-6989586621679709997"><span id="local-6989586621679709998"><span class="hs-special">(</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasForward"><span class="hs-identifier hs-type">HasForward</span></a></span><span>
</span><span id="line-283"></span><span>      </span><span class="annot"><a href="#local-6989586621679709998"><span class="hs-identifier hs-type">initialLayerNorm</span></a></span><span>
</span><span id="line-284"></span><span>      </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709997"><span class="hs-identifier hs-type">queryGradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709996"><span class="hs-identifier hs-type">queryLayout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709995"><span class="hs-identifier hs-type">queryDevice</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709994"><span class="hs-identifier hs-type">queryDataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709993"><span class="hs-identifier hs-type">queryShape</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-285"></span><span>      </span><span class="annot"><a href="#local-6989586621679709992"><span class="hs-identifier hs-type">generatorDevice</span></a></span><span>
</span><span id="line-286"></span><span>      </span><span class="annot"><a href="#local-6989586621679709991"><span class="hs-identifier hs-type">tensor0</span></a></span><span>
</span><span id="line-287"></span><span>      </span><span class="annot"><a href="#local-6989586621679709990"><span class="hs-identifier hs-type">generatorDevice0</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-288"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasForward"><span class="hs-identifier hs-type">HasForward</span></a></span><span>
</span><span id="line-289"></span><span>      </span><span class="annot"><a href="#local-6989586621679709989"><span class="hs-identifier hs-type">multiHeadAttention</span></a></span><span>
</span><span id="line-290"></span><span>      </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="#local-6989586621679709991"><span class="hs-identifier hs-type">tensor0</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-291"></span><span>        </span><span class="annot"><a href="#local-6989586621679709991"><span class="hs-identifier hs-type">tensor0</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-292"></span><span>        </span><span class="annot"><a href="#local-6989586621679709991"><span class="hs-identifier hs-type">tensor0</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-293"></span><span>        </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709988"><span class="hs-identifier hs-type">attentionBiasGradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709987"><span class="hs-identifier hs-type">attentionBiasLayout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709986"><span class="hs-identifier hs-type">attentionBiasDevice</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709985"><span class="hs-identifier hs-type">attentionBiasDataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709984"><span class="hs-identifier hs-type">attentionBiasShape</span></a></span><span>
</span><span id="line-294"></span><span>      </span><span class="hs-special">)</span><span>
</span><span id="line-295"></span><span>      </span><span class="annot"><a href="#local-6989586621679709990"><span class="hs-identifier hs-type">generatorDevice0</span></a></span><span>
</span><span id="line-296"></span><span>      </span><span class="annot"><a href="#local-6989586621679709983"><span class="hs-identifier hs-type">tensor1</span></a></span><span>
</span><span id="line-297"></span><span>      </span><span class="annot"><a href="#local-6989586621679709982"><span class="hs-identifier hs-type">generatorDevice1</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-298"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasForward"><span class="hs-identifier hs-type">HasForward</span></a></span><span>
</span><span id="line-299"></span><span>      </span><span class="annot"><a href="#local-6989586621679709981"><span class="hs-identifier hs-type">dropout</span></a></span><span>
</span><span id="line-300"></span><span>      </span><span class="annot"><a href="#local-6989586621679709983"><span class="hs-identifier hs-type">tensor1</span></a></span><span>
</span><span id="line-301"></span><span>      </span><span class="annot"><a href="#local-6989586621679709982"><span class="hs-identifier hs-type">generatorDevice1</span></a></span><span>
</span><span id="line-302"></span><span>      </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709980"><span class="hs-identifier hs-type">gradient2</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709979"><span class="hs-identifier hs-type">layout2</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709978"><span class="hs-identifier hs-type">device2</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709977"><span class="hs-identifier hs-type">dataType2</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709976"><span class="hs-identifier hs-type">shape2</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-303"></span><span>      </span><span class="annot"><a href="#local-6989586621679709975"><span class="hs-identifier hs-type">generatorDevice2</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-304"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasForward"><span class="hs-identifier hs-type">HasForward</span></a></span><span>
</span><span id="line-305"></span><span>      </span><span class="annot"><a href="#local-6989586621679709974"><span class="hs-identifier hs-type">finalLayerNorm</span></a></span><span>
</span><span id="line-306"></span><span>      </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679709997"><span class="hs-identifier hs-type">queryGradient</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%7C%3E"><span class="hs-operator hs-type">&lt;|&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709980"><span class="hs-identifier hs-type">gradient2</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679709996"><span class="hs-identifier hs-type">queryLayout</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709979"><span class="hs-identifier hs-type">layout2</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679709995"><span class="hs-identifier hs-type">queryDevice</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709978"><span class="hs-identifier hs-type">device2</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679709994"><span class="hs-identifier hs-type">queryDataType</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709977"><span class="hs-identifier hs-type">dataType2</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Class.html#BroadcastShapesF"><span class="hs-identifier hs-type">BroadcastShapesF</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709993"><span class="hs-identifier hs-type">queryShape</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709976"><span class="hs-identifier hs-type">shape2</span></a></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-307"></span><span>      </span><span class="annot"><a href="#local-6989586621679709975"><span class="hs-identifier hs-type">generatorDevice2</span></a></span><span>
</span><span id="line-308"></span><span>      </span><span class="annot"><a href="#local-6989586621679709973"><span class="hs-identifier hs-type">output</span></a></span><span>
</span><span id="line-309"></span><span>      </span><span class="annot"><a href="#local-6989586621679709972"><span class="hs-identifier hs-type">generatorOutputDevice</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-310"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.Prelude.html#Catch"><span class="hs-identifier hs-type">Catch</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Class.html#BroadcastShapesF"><span class="hs-identifier hs-type">BroadcastShapesF</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709993"><span class="hs-identifier hs-type">queryShape</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709976"><span class="hs-identifier hs-type">shape2</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-311"></span><span>  </span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-312"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasForward"><span class="hs-identifier hs-type">HasForward</span></a></span><span>
</span><span id="line-313"></span><span>    </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GSelfAttention.html#GSelfAttention"><span class="hs-identifier hs-type">GSelfAttention</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709998"><span class="hs-identifier hs-type">initialLayerNorm</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709989"><span class="hs-identifier hs-type">multiHeadAttention</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709981"><span class="hs-identifier hs-type">dropout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709974"><span class="hs-identifier hs-type">finalLayerNorm</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-314"></span><span>    </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709997"><span class="hs-identifier hs-type">queryGradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709996"><span class="hs-identifier hs-type">queryLayout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709995"><span class="hs-identifier hs-type">queryDevice</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709994"><span class="hs-identifier hs-type">queryDataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709993"><span class="hs-identifier hs-type">queryShape</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-315"></span><span>      </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709988"><span class="hs-identifier hs-type">attentionBiasGradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709987"><span class="hs-identifier hs-type">attentionBiasLayout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709986"><span class="hs-identifier hs-type">attentionBiasDevice</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709985"><span class="hs-identifier hs-type">attentionBiasDataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709984"><span class="hs-identifier hs-type">attentionBiasShape</span></a></span><span>
</span><span id="line-316"></span><span>    </span><span class="hs-special">)</span><span>
</span><span id="line-317"></span><span>    </span><span class="annot"><a href="#local-6989586621679709992"><span class="hs-identifier hs-type">generatorDevice</span></a></span><span>
</span><span id="line-318"></span><span>    </span><span class="annot"><a href="#local-6989586621679709973"><span class="hs-identifier hs-type">output</span></a></span><span>
</span><span id="line-319"></span><span>    </span><span class="annot"><a href="#local-6989586621679709972"><span class="hs-identifier hs-type">generatorOutputDevice</span></a></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span><span>
</span><span id="line-320"></span><span>  </span><span class="hs-keyword">where</span><span>
</span><span id="line-321"></span><span>  </span><span id="local-6989586621679709504"><span class="annot"><span class="annottext">forward :: forall (m :: * -&gt; *).
MonadThrow m =&gt;
GSelfAttention
  initialLayerNorm multiHeadAttention dropout finalLayerNorm
-&gt; (Tensor
      queryGradient queryLayout queryDevice queryDataType queryShape,
    Tensor
      attentionBiasGradient
      attentionBiasLayout
      attentionBiasDevice
      attentionBiasDataType
      attentionBiasShape)
-&gt; Generator generatorDevice
-&gt; m (output, Generator generatorOutputDevice)
</span><a href="Torch.GraduallyTyped.NN.Class.html#forward"><span class="hs-identifier hs-var hs-var hs-var hs-var">forward</span></a></span></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GSelfAttention.html#GSelfAttention"><span class="hs-identifier hs-type">GSelfAttention</span></a></span><span> </span><span class="hs-special">{</span><span id="local-6989586621679709499"><span id="local-6989586621679709500"><span id="local-6989586621679709501"><span id="local-6989586621679709502"><span class="annot"><span class="annottext">initialLayerNorm
multiHeadAttention
dropout
finalLayerNorm
saFinalLayerNorm :: finalLayerNorm
saDropout :: dropout
saMultiHeadAttention :: multiHeadAttention
saInitialLayerNorm :: initialLayerNorm
saFinalLayerNorm :: forall initialLayerNorm mha dropout finalLayerNorm.
GSelfAttention initialLayerNorm mha dropout finalLayerNorm
-&gt; finalLayerNorm
saDropout :: forall initialLayerNorm mha dropout finalLayerNorm.
GSelfAttention initialLayerNorm mha dropout finalLayerNorm
-&gt; dropout
saMultiHeadAttention :: forall initialLayerNorm mha dropout finalLayerNorm.
GSelfAttention initialLayerNorm mha dropout finalLayerNorm -&gt; mha
saInitialLayerNorm :: forall initialLayerNorm mha dropout finalLayerNorm.
GSelfAttention initialLayerNorm mha dropout finalLayerNorm
-&gt; initialLayerNorm
</span><a href="#local-6989586621679709499"><span class="hs-glyph hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var">..</span></a></span></span></span></span></span><span class="hs-special">}</span><span> </span><span class="hs-special">(</span><span id="local-6989586621679709498"><span class="annot"><span class="annottext">Tensor
  queryGradient queryLayout queryDevice queryDataType queryShape
</span><a href="#local-6989586621679709498"><span class="hs-identifier hs-var">query</span></a></span></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679709497"><span class="annot"><span class="annottext">Tensor
  attentionBiasGradient
  attentionBiasLayout
  attentionBiasDevice
  attentionBiasDataType
  attentionBiasShape
</span><a href="#local-6989586621679709497"><span class="hs-identifier hs-var">attentionBias</span></a></span></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-322"></span><span>    </span><span class="annot"><span class="annottext">forall (m :: * -&gt; *) i j a. IxStateT m i j a -&gt; i -&gt; m (a, j)
</span><a href="../file:///nix/store/hlan16hghcygrr1n0fqljpsq2978pxwg-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier hs-var">runIxStateT</span></a></span><span> </span><span class="annot"><span class="annottext">forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><a href="../file:///nix/store/9z106fx3296sgdwa5s05xi381ayi6qfk-ghc-9.2.4-doc/share/doc/ghc/html/libraries/base-4.16.3.0/src"><span class="hs-operator hs-var">$</span></a></span><span>
</span><span id="line-323"></span><span>      </span><span class="annot"><span class="annottext">forall {k} (m :: k -&gt; k -&gt; * -&gt; *) a (i :: k).
IxPointed m =&gt;
a -&gt; m i i a
</span><a href="../file:///nix/store/63793hdp0xr2k87xmzbhjz0cpd7vssdh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-identifier hs-var">ireturn</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor
  queryGradient queryLayout queryDevice queryDataType queryShape
</span><a href="#local-6989586621679709498"><span class="hs-identifier hs-var">query</span></a></span><span>
</span><span id="line-324"></span><span>        </span><span class="annot"><span class="annottext">forall {k1} (m :: k1 -&gt; k1 -&gt; * -&gt; *) (i :: k1) (j :: k1) a
       (k2 :: k1) b.
IxMonad m =&gt;
m i j a -&gt; (a -&gt; m j k2 b) -&gt; m i k2 b
</span><a href="../file:///nix/store/63793hdp0xr2k87xmzbhjz0cpd7vssdh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&gt;&gt;&gt;=</span></a></span><span> </span><span class="annot"><span class="annottext">forall (m :: * -&gt; *) i j a. (i -&gt; m (a, j)) -&gt; IxStateT m i j a
</span><a href="../file:///nix/store/hlan16hghcygrr1n0fqljpsq2978pxwg-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier hs-var">IxStateT</span></a></span><span> </span><span class="annot"><span class="annottext">forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><a href="../file:///nix/store/9z106fx3296sgdwa5s05xi381ayi6qfk-ghc-9.2.4-doc/share/doc/ghc/html/libraries/base-4.16.3.0/src"><span class="hs-operator hs-var">.</span></a></span><span> </span><span class="annot"><span class="annottext">forall model input (generatorDevice :: Device (DeviceType Nat))
       output (generatorOutputDevice :: Device (DeviceType Nat))
       (m :: * -&gt; *).
(HasForward
   model input generatorDevice output generatorOutputDevice,
 MonadThrow m) =&gt;
model
-&gt; input
-&gt; Generator generatorDevice
-&gt; m (output, Generator generatorOutputDevice)
</span><a href="Torch.GraduallyTyped.NN.Class.html#forward"><span class="hs-identifier hs-var">forward</span></a></span><span> </span><span class="annot"><span class="annottext">initialLayerNorm
</span><a href="#local-6989586621679709502"><span class="hs-identifier hs-var">saInitialLayerNorm</span></a></span><span>
</span><span id="line-325"></span><span>        </span><span class="annot"><span class="annottext">forall {k1} (m :: k1 -&gt; k1 -&gt; * -&gt; *) (i :: k1) (j :: k1) a
       (k2 :: k1) b.
IxMonad m =&gt;
m i j a -&gt; (a -&gt; m j k2 b) -&gt; m i k2 b
</span><a href="../file:///nix/store/63793hdp0xr2k87xmzbhjz0cpd7vssdh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&gt;&gt;&gt;=</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">\</span><span id="local-6989586621679709493"><span class="annot"><span class="annottext">tensor0
</span><a href="#local-6989586621679709493"><span class="hs-identifier hs-var">query'</span></a></span></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><span class="annottext">forall (m :: * -&gt; *) i j a. (i -&gt; m (a, j)) -&gt; IxStateT m i j a
</span><a href="../file:///nix/store/hlan16hghcygrr1n0fqljpsq2978pxwg-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier hs-var">IxStateT</span></a></span><span> </span><span class="annot"><span class="annottext">forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><a href="../file:///nix/store/9z106fx3296sgdwa5s05xi381ayi6qfk-ghc-9.2.4-doc/share/doc/ghc/html/libraries/base-4.16.3.0/src"><span class="hs-operator hs-var">$</span></a></span><span> </span><span class="annot"><span class="annottext">forall model input (generatorDevice :: Device (DeviceType Nat))
       output (generatorOutputDevice :: Device (DeviceType Nat))
       (m :: * -&gt; *).
(HasForward
   model input generatorDevice output generatorOutputDevice,
 MonadThrow m) =&gt;
model
-&gt; input
-&gt; Generator generatorDevice
-&gt; m (output, Generator generatorOutputDevice)
</span><a href="Torch.GraduallyTyped.NN.Class.html#forward"><span class="hs-identifier hs-var">forward</span></a></span><span> </span><span class="annot"><span class="annottext">multiHeadAttention
</span><a href="#local-6989586621679709501"><span class="hs-identifier hs-var">saMultiHeadAttention</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">tensor0
</span><a href="#local-6989586621679709493"><span class="hs-identifier hs-var">query'</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">tensor0
</span><a href="#local-6989586621679709493"><span class="hs-identifier hs-var">query'</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">tensor0
</span><a href="#local-6989586621679709493"><span class="hs-identifier hs-var">query'</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">Tensor
  attentionBiasGradient
  attentionBiasLayout
  attentionBiasDevice
  attentionBiasDataType
  attentionBiasShape
</span><a href="#local-6989586621679709497"><span class="hs-identifier hs-var">attentionBias</span></a></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-326"></span><span>        </span><span class="annot"><span class="annottext">forall {k1} (m :: k1 -&gt; k1 -&gt; * -&gt; *) (i :: k1) (j :: k1) a
       (k2 :: k1) b.
IxMonad m =&gt;
m i j a -&gt; (a -&gt; m j k2 b) -&gt; m i k2 b
</span><a href="../file:///nix/store/63793hdp0xr2k87xmzbhjz0cpd7vssdh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&gt;&gt;&gt;=</span></a></span><span> </span><span class="annot"><span class="annottext">forall (m :: * -&gt; *) i j a. (i -&gt; m (a, j)) -&gt; IxStateT m i j a
</span><a href="../file:///nix/store/hlan16hghcygrr1n0fqljpsq2978pxwg-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier hs-var">IxStateT</span></a></span><span> </span><span class="annot"><span class="annottext">forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><a href="../file:///nix/store/9z106fx3296sgdwa5s05xi381ayi6qfk-ghc-9.2.4-doc/share/doc/ghc/html/libraries/base-4.16.3.0/src"><span class="hs-operator hs-var">.</span></a></span><span> </span><span class="annot"><span class="annottext">forall model input (generatorDevice :: Device (DeviceType Nat))
       output (generatorOutputDevice :: Device (DeviceType Nat))
       (m :: * -&gt; *).
(HasForward
   model input generatorDevice output generatorOutputDevice,
 MonadThrow m) =&gt;
model
-&gt; input
-&gt; Generator generatorDevice
-&gt; m (output, Generator generatorOutputDevice)
</span><a href="Torch.GraduallyTyped.NN.Class.html#forward"><span class="hs-identifier hs-var">forward</span></a></span><span> </span><span class="annot"><span class="annottext">dropout
</span><a href="#local-6989586621679709500"><span class="hs-identifier hs-var">saDropout</span></a></span><span>
</span><span id="line-327"></span><span>        </span><span class="annot"><span class="annottext">forall {k1} (m :: k1 -&gt; k1 -&gt; * -&gt; *) (i :: k1) (j :: k1) a
       (k2 :: k1) b.
IxMonad m =&gt;
m i j a -&gt; (a -&gt; m j k2 b) -&gt; m i k2 b
</span><a href="../file:///nix/store/63793hdp0xr2k87xmzbhjz0cpd7vssdh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&gt;&gt;&gt;=</span></a></span><span> </span><span class="annot"><span class="annottext">forall {k} (t :: (* -&gt; *) -&gt; k -&gt; k -&gt; * -&gt; *) (m :: * -&gt; *) a
       (i :: k).
(IxMonadTrans t, Monad m) =&gt;
m a -&gt; t m i i a
</span><a href="../file:///nix/store/63793hdp0xr2k87xmzbhjz0cpd7vssdh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-identifier hs-var">ilift</span></a></span><span> </span><span class="annot"><span class="annottext">forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><a href="../file:///nix/store/9z106fx3296sgdwa5s05xi381ayi6qfk-ghc-9.2.4-doc/share/doc/ghc/html/libraries/base-4.16.3.0/src"><span class="hs-operator hs-var">.</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">Tensor
  queryGradient queryLayout queryDevice queryDataType queryShape
</span><a href="#local-6989586621679709498"><span class="hs-identifier hs-var">query</span></a></span><span> </span><span class="annot"><span class="annottext">forall (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)])
       (gradient' :: Gradient RequiresGradient)
       (layout' :: Layout LayoutType) (device' :: Device (DeviceType Nat))
       (dataType' :: DataType DType)
       (shape' :: Shape [Dim (Name Symbol) (Size Nat)])
       (shape'' :: Shape [Dim (Name Symbol) (Size Nat)]) (m :: * -&gt; *).
(MonadThrow m, shape'' ~ BroadcastShapesF shape shape',
 Catch shape'') =&gt;
Tensor gradient layout device dataType shape
-&gt; Tensor gradient' layout' device' dataType' shape'
-&gt; m (Tensor
        (gradient &lt;|&gt; gradient')
        (layout &lt;+&gt; layout')
        (device &lt;+&gt; device')
        (dataType &lt;+&gt; dataType')
        shape'')
</span><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#add"><span class="hs-operator hs-var">`add`</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-328"></span><span>        </span><span class="annot"><span class="annottext">forall {k1} (m :: k1 -&gt; k1 -&gt; * -&gt; *) (i :: k1) (j :: k1) a
       (k2 :: k1) b.
IxMonad m =&gt;
m i j a -&gt; (a -&gt; m j k2 b) -&gt; m i k2 b
</span><a href="../file:///nix/store/63793hdp0xr2k87xmzbhjz0cpd7vssdh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&gt;&gt;&gt;=</span></a></span><span> </span><span class="annot"><span class="annottext">forall (m :: * -&gt; *) i j a. (i -&gt; m (a, j)) -&gt; IxStateT m i j a
</span><a href="../file:///nix/store/hlan16hghcygrr1n0fqljpsq2978pxwg-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier hs-var">IxStateT</span></a></span><span> </span><span class="annot"><span class="annottext">forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><a href="../file:///nix/store/9z106fx3296sgdwa5s05xi381ayi6qfk-ghc-9.2.4-doc/share/doc/ghc/html/libraries/base-4.16.3.0/src"><span class="hs-operator hs-var">.</span></a></span><span> </span><span class="annot"><span class="annottext">forall model input (generatorDevice :: Device (DeviceType Nat))
       output (generatorOutputDevice :: Device (DeviceType Nat))
       (m :: * -&gt; *).
(HasForward
   model input generatorDevice output generatorOutputDevice,
 MonadThrow m) =&gt;
model
-&gt; input
-&gt; Generator generatorDevice
-&gt; m (output, Generator generatorOutputDevice)
</span><a href="Torch.GraduallyTyped.NN.Class.html#forward"><span class="hs-identifier hs-var">forward</span></a></span><span> </span><span class="annot"><span class="annottext">finalLayerNorm
</span><a href="#local-6989586621679709499"><span class="hs-identifier hs-var">saFinalLayerNorm</span></a></span><span>
</span><span id="line-329"></span></pre></body></html>