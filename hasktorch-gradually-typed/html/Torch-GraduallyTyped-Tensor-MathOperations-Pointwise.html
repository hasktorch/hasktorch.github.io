<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd"><html xmlns="http://www.w3.org/1999/xhtml"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8" /><meta name="viewport" content="width=device-width, initial-scale=1" /><title>Torch.GraduallyTyped.Tensor.MathOperations.Pointwise</title><link href="linuwial.css" rel="stylesheet" type="text/css" title="Linuwial" /><link rel="stylesheet" type="text/css" href="quick-jump.css" /><link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=PT+Sans:400,400i,700" /><script src="haddock-bundle.min.js" async="async" type="text/javascript"></script><script type="text/x-mathjax-config">MathJax.Hub.Config({ tex2jax: { processClass: "mathjax", ignoreClass: ".*" } });</script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script></head><body><div id="package-header"><span class="caption">hasktorch-gradually-typed-0.2.0.0: experimental project for hasktorch</span><ul class="links" id="page-menu"><li><a href="src/Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html">Source</a></li><li><a href="../../share/doc/index.html">Contents</a></li><li><a href="../../share/doc/doc-index.html">Index</a></li></ul></div><div id="content"><div id="module-header"><table class="info"><tr><th>Safe Haskell</th><td>None</td></tr><tr><th>Language</th><td>Haskell2010</td></tr></table><p class="caption">Torch.GraduallyTyped.Tensor.MathOperations.Pointwise</p></div><div id="synopsis"><details id="syn"><summary>Synopsis</summary><ul class="details-toggle" data-details-id="syn"><li class="src short"><a href="#v:abs">abs</a> :: <span class="keyword">forall</span> gradient layout device dataType shape. <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> gradient layout device dataType shape -&gt; <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> gradient layout device dataType shape</li><li class="src short"><a href="#v:absolute">absolute</a> :: <span class="keyword">forall</span> gradient layout device dataType shape. <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> gradient layout device dataType shape -&gt; <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> gradient layout device dataType shape</li><li class="src short"><a href="#v:acos">acos</a> :: <span class="keyword">forall</span> gradient layout device dataType shape. <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> gradient layout device dataType shape -&gt; <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> gradient layout device dataType shape</li><li class="src short"><a href="#v:acosh">acosh</a> :: <span class="keyword">forall</span> gradient layout device dataType shape. <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> gradient layout device dataType shape -&gt; <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> gradient layout device dataType shape</li><li class="src short"><a href="#v:add">add</a> :: <span class="keyword">forall</span> gradient layout device dataType shape gradient' layout' device' dataType' shape'. <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> gradient layout device dataType shape -&gt; <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> gradient' layout' device' dataType' shape' -&gt; <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> (gradient <a href="Torch-GraduallyTyped-Unify.html#t:-60--124--62-" title="Torch.GraduallyTyped.Unify">&lt;|&gt;</a> gradient') (layout <a href="Torch-GraduallyTyped-Unify.html#t:-60--43--62-" title="Torch.GraduallyTyped.Unify">&lt;+&gt;</a> layout') (device <a href="Torch-GraduallyTyped-Unify.html#t:-60--43--62-" title="Torch.GraduallyTyped.Unify">&lt;+&gt;</a> device') (dataType <a href="Torch-GraduallyTyped-Unify.html#t:-60--43--62-" title="Torch.GraduallyTyped.Unify">&lt;+&gt;</a> dataType') (<a href="Torch-GraduallyTyped-Shape-Class.html#t:BroadcastShapesF" title="Torch.GraduallyTyped.Shape.Class">BroadcastShapesF</a> shape shape')</li><li class="src short"><a href="#v:addScalar">addScalar</a> :: <span class="keyword">forall</span> other gradient layout device dataType shape. <a href="Torch-GraduallyTyped-Scalar.html#t:Scalar" title="Torch.GraduallyTyped.Scalar">Scalar</a> other =&gt; <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> gradient layout device dataType shape -&gt; other -&gt; <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> gradient layout device dataType shape</li><li class="src short"><a href="#v:addcdiv">addcdiv</a> :: <span class="keyword">forall</span> value gradient layout device dataType shape. <a href="Torch-GraduallyTyped-Scalar.html#t:Scalar" title="Torch.GraduallyTyped.Scalar">Scalar</a> value =&gt; value -&gt; <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> gradient layout device dataType shape -&gt; <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> gradient layout device dataType shape -&gt; <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> gradient layout device dataType shape -&gt; <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> gradient layout device dataType shape</li><li class="src short"><a href="#v:addcmul">addcmul</a> :: <span class="keyword">forall</span> scalar gradient layout device dataType shape. <a href="Torch-GraduallyTyped-Scalar.html#t:Scalar" title="Torch.GraduallyTyped.Scalar">Scalar</a> scalar =&gt; scalar -&gt; <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> gradient layout device dataType shape -&gt; <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> gradient layout device dataType shape -&gt; <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> gradient layout device dataType shape -&gt; <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> gradient layout device dataType shape</li><li class="src short"><a href="#v:asin">asin</a> :: <span class="keyword">forall</span> gradient layout device dataType shape. <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> gradient layout device dataType shape -&gt; <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> gradient layout device dataType shape</li><li class="src short"><a href="#v:asinh">asinh</a> :: <span class="keyword">forall</span> gradient layout device dataType shape. <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> gradient layout device dataType shape -&gt; <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> gradient layout device dataType shape</li><li class="src short"><a href="#v:atan">atan</a> :: <span class="keyword">forall</span> gradient layout device dataType shape. <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> gradient layout device dataType shape -&gt; <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> gradient layout device dataType shape</li><li class="src short"><a href="#v:atanh">atanh</a> :: <span class="keyword">forall</span> gradient layout device dataType shape. <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> gradient layout device dataType shape -&gt; <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> gradient layout device dataType shape</li><li class="src short"><a href="#v:atan2">atan2</a> :: <span class="keyword">forall</span> gradient layout device dataType shape gradient' layout' device' dataType' shape'. <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> gradient layout device dataType shape -&gt; <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> gradient' layout' device' dataType' shape' -&gt; <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> (gradient <a href="Torch-GraduallyTyped-Unify.html#t:-60--124--62-" title="Torch.GraduallyTyped.Unify">&lt;|&gt;</a> gradient') (layout <a href="Torch-GraduallyTyped-Unify.html#t:-60--43--62-" title="Torch.GraduallyTyped.Unify">&lt;+&gt;</a> layout') (device <a href="Torch-GraduallyTyped-Unify.html#t:-60--43--62-" title="Torch.GraduallyTyped.Unify">&lt;+&gt;</a> device') (dataType <a href="Torch-GraduallyTyped-Unify.html#t:-60--43--62-" title="Torch.GraduallyTyped.Unify">&lt;+&gt;</a> dataType') (<a href="Torch-GraduallyTyped-Shape-Class.html#t:BroadcastShapesF" title="Torch.GraduallyTyped.Shape.Class">BroadcastShapesF</a> shape shape')</li><li class="src short"><a href="#v:bitwiseNot">bitwiseNot</a> :: <span class="keyword">forall</span> gradient layout device dataType shape. <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> gradient layout device dataType shape -&gt; <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> gradient layout device ('<a href="Torch-GraduallyTyped-DType.html#v:DataType" title="Torch.GraduallyTyped.DType">DataType</a> '<a href="Torch-GraduallyTyped-DType.html#v:Bool" title="Torch.GraduallyTyped.DType">Bool</a>) shape</li><li class="src short"><a href="#v:bitwiseAnd">bitwiseAnd</a> :: <span class="keyword">forall</span> gradient layout device dataType shape. <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> gradient layout device dataType shape -&gt; <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> gradient layout device dataType shape -&gt; <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> gradient layout device dataType shape</li><li class="src short"><a href="#v:bitwiseAndScalar">bitwiseAndScalar</a> :: <span class="keyword">forall</span> other gradient layout device dataType shape. <a href="Torch-GraduallyTyped-Scalar.html#t:Scalar" title="Torch.GraduallyTyped.Scalar">Scalar</a> other =&gt; <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> gradient layout device dataType shape -&gt; other -&gt; <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> gradient layout device dataType shape</li><li class="src short"><a href="#v:bitwiseOr">bitwiseOr</a> :: <span class="keyword">forall</span> gradient layout device dataType shape. <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> gradient layout device dataType shape -&gt; <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> gradient layout device dataType shape -&gt; <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> gradient layout device dataType shape</li><li class="src short"><a href="#v:bitwiseOrScalar">bitwiseOrScalar</a> :: <span class="keyword">forall</span> other gradient layout device dataType shape. <a href="Torch-GraduallyTyped-Scalar.html#t:Scalar" title="Torch.GraduallyTyped.Scalar">Scalar</a> other =&gt; <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> gradient layout device dataType shape -&gt; other -&gt; <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> gradient layout device dataType shape</li><li class="src short"><a href="#v:bitwiseXor">bitwiseXor</a> :: <span class="keyword">forall</span> gradient layout device dataType shape. <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> gradient layout device dataType shape -&gt; <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> gradient layout device dataType shape -&gt; <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> gradient layout device dataType shape</li><li class="src short"><a href="#v:bitwiseXorScalar">bitwiseXorScalar</a> :: <span class="keyword">forall</span> other gradient layout device dataType shape. <a href="Torch-GraduallyTyped-Scalar.html#t:Scalar" title="Torch.GraduallyTyped.Scalar">Scalar</a> other =&gt; <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> gradient layout device dataType shape -&gt; other -&gt; <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> gradient layout device dataType shape</li><li class="src short"><a href="#v:ceil">ceil</a> :: <span class="keyword">forall</span> gradient layout device dataType shape. <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> gradient layout device dataType shape -&gt; <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> gradient layout device dataType shape</li><li class="src short"><a href="#v:clamp">clamp</a> :: <span class="keyword">forall</span> min max gradient layout device dataType shape. (<a href="Torch-GraduallyTyped-Scalar.html#t:Scalar" title="Torch.GraduallyTyped.Scalar">Scalar</a> min, <a href="Torch-GraduallyTyped-Scalar.html#t:Scalar" title="Torch.GraduallyTyped.Scalar">Scalar</a> max) =&gt; min -&gt; max -&gt; <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> gradient layout device dataType shape -&gt; <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> gradient layout device dataType shape</li><li class="src short"><a href="#v:cos">cos</a> :: <span class="keyword">forall</span> gradient layout device dataType shape. <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> gradient layout device dataType shape -&gt; <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> gradient layout device dataType shape</li><li class="src short"><a href="#v:cosh">cosh</a> :: <span class="keyword">forall</span> gradient layout device dataType shape. <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> gradient layout device dataType shape -&gt; <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> gradient layout device dataType shape</li><li class="src short"><a href="#v:deg2rad">deg2rad</a> :: <span class="keyword">forall</span> gradient layout device dataType shape. <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> gradient layout device dataType shape -&gt; <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> gradient layout device dataType shape</li><li class="src short"><a href="#v:div">div</a> :: <span class="keyword">forall</span> gradient layout device dataType shape gradient' layout' device' dataType' shape'. <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> gradient layout device dataType shape -&gt; <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> gradient' layout' device' dataType' shape' -&gt; <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> (gradient <a href="Torch-GraduallyTyped-Unify.html#t:-60--124--62-" title="Torch.GraduallyTyped.Unify">&lt;|&gt;</a> gradient') (layout <a href="Torch-GraduallyTyped-Unify.html#t:-60--43--62-" title="Torch.GraduallyTyped.Unify">&lt;+&gt;</a> layout') (device <a href="Torch-GraduallyTyped-Unify.html#t:-60--43--62-" title="Torch.GraduallyTyped.Unify">&lt;+&gt;</a> device') (dataType <a href="Torch-GraduallyTyped-Unify.html#t:-60--43--62-" title="Torch.GraduallyTyped.Unify">&lt;+&gt;</a> dataType') (<a href="Torch-GraduallyTyped-Shape-Class.html#t:BroadcastShapesF" title="Torch.GraduallyTyped.Shape.Class">BroadcastShapesF</a> shape shape')</li><li class="src short"><a href="#v:divScalar">divScalar</a> :: <span class="keyword">forall</span> divisor gradient layout device dataType shape. <a href="Torch-GraduallyTyped-Scalar.html#t:Scalar" title="Torch.GraduallyTyped.Scalar">Scalar</a> divisor =&gt; <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> gradient layout device dataType shape -&gt; divisor -&gt; <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> gradient layout device dataType shape</li><li class="src short"><a href="#v:digamma">digamma</a> :: <span class="keyword">forall</span> gradient layout device dataType shape. <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> gradient layout device dataType shape -&gt; <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> gradient layout device dataType shape</li><li class="src short"><a href="#v:erf">erf</a> :: <span class="keyword">forall</span> gradient layout device dataType shape. <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> gradient layout device dataType shape -&gt; <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> gradient layout device dataType shape</li><li class="src short"><a href="#v:erfc">erfc</a> :: <span class="keyword">forall</span> gradient layout device dataType shape. <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> gradient layout device dataType shape -&gt; <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> gradient layout device dataType shape</li><li class="src short"><a href="#v:erfinv">erfinv</a> :: <span class="keyword">forall</span> gradient layout device dataType shape. <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> gradient layout device dataType shape -&gt; <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> gradient layout device dataType shape</li><li class="src short"><a href="#v:exp">exp</a> :: <span class="keyword">forall</span> gradient layout device dataType shape. <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> gradient layout device dataType shape -&gt; <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> gradient layout device dataType shape</li><li class="src short"><a href="#v:expm1">expm1</a> :: <span class="keyword">forall</span> gradient layout device dataType shape. <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> gradient layout device dataType shape -&gt; <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> gradient layout device dataType shape</li><li class="src short"><a href="#v:floor">floor</a> :: <span class="keyword">forall</span> gradient layout device dataType shape. <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> gradient layout device dataType shape -&gt; <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> gradient layout device dataType shape</li><li class="src short"><a href="#v:floorDivide">floorDivide</a> :: <span class="keyword">forall</span> gradient layout device dataType shape. <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> gradient layout device dataType shape -&gt; <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> gradient layout device dataType shape -&gt; <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> gradient layout device dataType shape</li><li class="src short"><a href="#v:floorDivideScalar">floorDivideScalar</a> :: <span class="keyword">forall</span> divisor gradient layout device dataType shape. <a href="Torch-GraduallyTyped-Scalar.html#t:Scalar" title="Torch.GraduallyTyped.Scalar">Scalar</a> divisor =&gt; <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> gradient layout device dataType shape -&gt; divisor -&gt; <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> gradient layout device dataType shape</li><li class="src short"><a href="#v:fmod">fmod</a> :: <span class="keyword">forall</span> gradient layout device dataType shape. <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> gradient layout device dataType shape -&gt; <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> gradient layout device dataType shape -&gt; <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> gradient layout device dataType shape</li><li class="src short"><a href="#v:fmodScalar">fmodScalar</a> :: <span class="keyword">forall</span> divisor gradient layout device dataType shape. <a href="Torch-GraduallyTyped-Scalar.html#t:Scalar" title="Torch.GraduallyTyped.Scalar">Scalar</a> divisor =&gt; divisor -&gt; <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> gradient layout device dataType shape -&gt; <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> gradient layout device dataType shape</li><li class="src short"><a href="#v:frac">frac</a> :: <span class="keyword">forall</span> gradient layout device dataType shape. <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> gradient layout device dataType shape -&gt; <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> gradient layout device dataType shape</li><li class="src short"><a href="#v:lerp">lerp</a> :: <span class="keyword">forall</span> gradient layout device dataType shape. <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> gradient layout device dataType shape -&gt; <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> gradient layout device dataType shape -&gt; <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> gradient layout device dataType shape -&gt; <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> gradient layout device dataType shape</li><li class="src short"><a href="#v:lerpScalar">lerpScalar</a> :: <span class="keyword">forall</span> weight gradient layout device dataType shape. <a href="Torch-GraduallyTyped-Scalar.html#t:Scalar" title="Torch.GraduallyTyped.Scalar">Scalar</a> weight =&gt; weight -&gt; <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> gradient layout device dataType shape -&gt; <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> gradient layout device dataType shape -&gt; <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> gradient layout device dataType shape</li><li class="src short"><a href="#v:lgamma">lgamma</a> :: <span class="keyword">forall</span> gradient layout device dataType shape. <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> gradient layout device dataType shape -&gt; <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> gradient layout device dataType shape</li><li class="src short"><a href="#v:log">log</a> :: <span class="keyword">forall</span> gradient layout device dataType shape. <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> gradient layout device dataType shape -&gt; <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> gradient layout device dataType shape</li><li class="src short"><a href="#v:log10">log10</a> :: <span class="keyword">forall</span> gradient layout device dataType shape. <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> gradient layout device dataType shape -&gt; <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> gradient layout device dataType shape</li><li class="src short"><a href="#v:log1p">log1p</a> :: <span class="keyword">forall</span> gradient layout device dataType shape. <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> gradient layout device dataType shape -&gt; <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> gradient layout device dataType shape</li><li class="src short"><a href="#v:log2">log2</a> :: <span class="keyword">forall</span> gradient layout device dataType shape. <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> gradient layout device dataType shape -&gt; <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> gradient layout device dataType shape</li><li class="src short"><a href="#v:logaddexp">logaddexp</a> :: <span class="keyword">forall</span> gradient layout device dataType shape. <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> gradient layout device dataType shape -&gt; <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> gradient layout device dataType shape -&gt; <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> gradient layout device dataType shape</li><li class="src short"><a href="#v:logaddexp2">logaddexp2</a> :: <span class="keyword">forall</span> gradient layout device dataType shape. <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> gradient layout device dataType shape -&gt; <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> gradient layout device dataType shape -&gt; <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> gradient layout device dataType shape</li><li class="src short"><a href="#v:logicalAnd">logicalAnd</a> :: <span class="keyword">forall</span> gradient layout device dataType shape. <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> gradient layout device dataType shape -&gt; <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> gradient layout device dataType shape -&gt; <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> gradient layout device ('<a href="Torch-GraduallyTyped-DType.html#v:DataType" title="Torch.GraduallyTyped.DType">DataType</a> '<a href="Torch-GraduallyTyped-DType.html#v:Bool" title="Torch.GraduallyTyped.DType">Bool</a>) shape</li><li class="src short"><a href="#v:logicalNot">logicalNot</a> :: <span class="keyword">forall</span> gradient layout device dataType shape. <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> gradient layout device dataType shape -&gt; <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> ('<a href="Torch-GraduallyTyped-RequiresGradient.html#v:Gradient" title="Torch.GraduallyTyped.RequiresGradient">Gradient</a> '<a href="Torch-GraduallyTyped-RequiresGradient.html#v:WithoutGradient" title="Torch.GraduallyTyped.RequiresGradient">WithoutGradient</a>) layout device ('<a href="Torch-GraduallyTyped-DType.html#v:DataType" title="Torch.GraduallyTyped.DType">DataType</a> '<a href="Torch-GraduallyTyped-DType.html#v:Bool" title="Torch.GraduallyTyped.DType">Bool</a>) shape</li><li class="src short"><a href="#v:logicalOr">logicalOr</a> :: <span class="keyword">forall</span> gradient layout device dataType shape gradient' layout' device' dataType' shape'. <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> gradient layout device dataType shape -&gt; <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> gradient' layout' device' dataType' shape' -&gt; <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> ('<a href="Torch-GraduallyTyped-RequiresGradient.html#v:Gradient" title="Torch.GraduallyTyped.RequiresGradient">Gradient</a> '<a href="Torch-GraduallyTyped-RequiresGradient.html#v:WithoutGradient" title="Torch.GraduallyTyped.RequiresGradient">WithoutGradient</a>) (layout <a href="Torch-GraduallyTyped-Unify.html#t:-60--43--62-" title="Torch.GraduallyTyped.Unify">&lt;+&gt;</a> layout') (device <a href="Torch-GraduallyTyped-Unify.html#t:-60--43--62-" title="Torch.GraduallyTyped.Unify">&lt;+&gt;</a> device') ('<a href="Torch-GraduallyTyped-DType.html#v:DataType" title="Torch.GraduallyTyped.DType">DataType</a> '<a href="Torch-GraduallyTyped-DType.html#v:Bool" title="Torch.GraduallyTyped.DType">Bool</a>) (<a href="Torch-GraduallyTyped-Shape-Class.html#t:BroadcastShapesF" title="Torch.GraduallyTyped.Shape.Class">BroadcastShapesF</a> shape shape')</li><li class="src short"><a href="#v:logicalXor">logicalXor</a> :: <span class="keyword">forall</span> gradient layout device dataType shape. <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> gradient layout device dataType shape -&gt; <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> gradient layout device dataType shape -&gt; <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> gradient layout device ('<a href="Torch-GraduallyTyped-DType.html#v:DataType" title="Torch.GraduallyTyped.DType">DataType</a> '<a href="Torch-GraduallyTyped-DType.html#v:Bool" title="Torch.GraduallyTyped.DType">Bool</a>) shape</li><li class="src short"><a href="#v:mul">mul</a> :: <span class="keyword">forall</span> gradient layout device dataType shape gradient' layout' device' dataType' shape'. <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> gradient layout device dataType shape -&gt; <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> gradient' layout' device' dataType' shape' -&gt; <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> (gradient <a href="Torch-GraduallyTyped-Unify.html#t:-60--124--62-" title="Torch.GraduallyTyped.Unify">&lt;|&gt;</a> gradient') (layout <a href="Torch-GraduallyTyped-Unify.html#t:-60--43--62-" title="Torch.GraduallyTyped.Unify">&lt;+&gt;</a> layout') (device <a href="Torch-GraduallyTyped-Unify.html#t:-60--43--62-" title="Torch.GraduallyTyped.Unify">&lt;+&gt;</a> device') (dataType <a href="Torch-GraduallyTyped-Unify.html#t:-60--43--62-" title="Torch.GraduallyTyped.Unify">&lt;+&gt;</a> dataType') (<a href="Torch-GraduallyTyped-Shape-Class.html#t:BroadcastShapesF" title="Torch.GraduallyTyped.Shape.Class">BroadcastShapesF</a> shape shape')</li><li class="src short"><a href="#v:mulScalar">mulScalar</a> :: <span class="keyword">forall</span> other gradient layout device dataType shape. <a href="Torch-GraduallyTyped-Scalar.html#t:Scalar" title="Torch.GraduallyTyped.Scalar">Scalar</a> other =&gt; <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> gradient layout device dataType shape -&gt; other -&gt; <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> gradient layout device dataType shape</li><li class="src short"><a href="#v:mvlgamma">mvlgamma</a> :: <span class="keyword">forall</span> gradient layout device dataType shape. Int -&gt; <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> gradient layout device dataType shape -&gt; <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> gradient layout device dataType shape</li><li class="src short"><a href="#v:neg">neg</a> :: <span class="keyword">forall</span> gradient layout device dataType shape. <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> gradient layout device dataType shape -&gt; <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> gradient layout device dataType shape</li><li class="src short"><a href="#v:polygamma">polygamma</a> :: <span class="keyword">forall</span> gradient layout device dataType shape. Int -&gt; <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> gradient layout device dataType shape -&gt; <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> gradient layout device dataType shape</li><li class="src short"><a href="#v:pow">pow</a> :: <span class="keyword">forall</span> gradient layout device dataType shape gradient' layout' device' dataType' shape'. <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> gradient' layout' device' dataType' shape' -&gt; <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> gradient layout device dataType shape -&gt; <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> (gradient <a href="Torch-GraduallyTyped-Unify.html#t:-60--124--62-" title="Torch.GraduallyTyped.Unify">&lt;|&gt;</a> gradient') (layout <a href="Torch-GraduallyTyped-Unify.html#t:-60--43--62-" title="Torch.GraduallyTyped.Unify">&lt;+&gt;</a> layout') (device <a href="Torch-GraduallyTyped-Unify.html#t:-60--43--62-" title="Torch.GraduallyTyped.Unify">&lt;+&gt;</a> device') (dataType <a href="Torch-GraduallyTyped-Unify.html#t:-60--43--62-" title="Torch.GraduallyTyped.Unify">&lt;+&gt;</a> dataType') (<a href="Torch-GraduallyTyped-Shape-Class.html#t:BroadcastShapesF" title="Torch.GraduallyTyped.Shape.Class">BroadcastShapesF</a> shape shape')</li><li class="src short"><a href="#v:powScalar">powScalar</a> :: <span class="keyword">forall</span> exponent gradient layout device dataType shape. <a href="Torch-GraduallyTyped-Scalar.html#t:Scalar" title="Torch.GraduallyTyped.Scalar">Scalar</a> exponent =&gt; <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> gradient layout device dataType shape -&gt; exponent -&gt; <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> gradient layout device dataType shape</li><li class="src short"><a href="#v:powTensor">powTensor</a> :: <span class="keyword">forall</span> input gradient layout device dataType shape. <a href="Torch-GraduallyTyped-Scalar.html#t:Scalar" title="Torch.GraduallyTyped.Scalar">Scalar</a> input =&gt; input -&gt; <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> gradient layout device dataType shape -&gt; <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> gradient layout device dataType shape</li><li class="src short"><a href="#v:rad2deg">rad2deg</a> :: <span class="keyword">forall</span> gradient layout device dataType shape. <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> gradient layout device dataType shape -&gt; <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> gradient layout device dataType shape</li><li class="src short"><a href="#v:reciprocal">reciprocal</a> :: <span class="keyword">forall</span> gradient layout device dataType shape. <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> gradient layout device dataType shape -&gt; <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> gradient layout device dataType shape</li><li class="src short"><a href="#v:remainder">remainder</a> :: <span class="keyword">forall</span> gradient layout device dataType shape. <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> gradient layout device dataType shape -&gt; <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> gradient layout device dataType shape -&gt; <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> gradient layout device dataType shape</li><li class="src short"><a href="#v:round">round</a> :: <span class="keyword">forall</span> gradient layout device dataType shape. <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> gradient layout device dataType shape -&gt; <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> gradient layout device dataType shape</li><li class="src short"><a href="#v:rsqrt">rsqrt</a> :: <span class="keyword">forall</span> gradient layout device dataType shape. <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> gradient layout device dataType shape -&gt; <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> gradient layout device dataType shape</li><li class="src short"><a href="#v:sigmoid">sigmoid</a> :: <span class="keyword">forall</span> gradient layout device dataType shape. <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> gradient layout device dataType shape -&gt; <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> gradient layout device dataType shape</li><li class="src short"><a href="#v:sign">sign</a> :: <span class="keyword">forall</span> gradient layout device dataType shape. <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> gradient layout device dataType shape -&gt; <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> gradient layout device dataType shape</li><li class="src short"><a href="#v:sin">sin</a> :: <span class="keyword">forall</span> gradient layout device dataType shape. <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> gradient layout device dataType shape -&gt; <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> gradient layout device dataType shape</li><li class="src short"><a href="#v:sinh">sinh</a> :: <span class="keyword">forall</span> gradient layout device dataType shape. <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> gradient layout device dataType shape -&gt; <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> gradient layout device dataType shape</li><li class="src short"><a href="#v:sub">sub</a> :: <span class="keyword">forall</span> gradient layout device dataType shape gradient' layout' device' dataType' shape'. <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> gradient layout device dataType shape -&gt; <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> gradient' layout' device' dataType' shape' -&gt; <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> (gradient <a href="Torch-GraduallyTyped-Unify.html#t:-60--124--62-" title="Torch.GraduallyTyped.Unify">&lt;|&gt;</a> gradient) (layout <a href="Torch-GraduallyTyped-Unify.html#t:-60--43--62-" title="Torch.GraduallyTyped.Unify">&lt;+&gt;</a> layout') (device <a href="Torch-GraduallyTyped-Unify.html#t:-60--43--62-" title="Torch.GraduallyTyped.Unify">&lt;+&gt;</a> device') (dataType <a href="Torch-GraduallyTyped-Unify.html#t:-60--43--62-" title="Torch.GraduallyTyped.Unify">&lt;+&gt;</a> dataType') (<a href="Torch-GraduallyTyped-Shape-Class.html#t:BroadcastShapesF" title="Torch.GraduallyTyped.Shape.Class">BroadcastShapesF</a> shape shape')</li><li class="src short"><a href="#v:subScalar">subScalar</a> :: <span class="keyword">forall</span> other gradient layout device dataType shape. <a href="Torch-GraduallyTyped-Scalar.html#t:Scalar" title="Torch.GraduallyTyped.Scalar">Scalar</a> other =&gt; <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> gradient layout device dataType shape -&gt; other -&gt; <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> gradient layout device dataType shape</li><li class="src short"><a href="#v:sqrt">sqrt</a> :: <span class="keyword">forall</span> gradient layout device dataType shape. <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> gradient layout device dataType shape -&gt; <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> gradient layout device dataType shape</li><li class="src short"><a href="#v:square">square</a> :: <span class="keyword">forall</span> gradient layout device dataType shape. <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> gradient layout device dataType shape -&gt; <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> gradient layout device dataType shape</li><li class="src short"><a href="#v:tan">tan</a> :: <span class="keyword">forall</span> gradient layout device dataType shape. <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> gradient layout device dataType shape -&gt; <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> gradient layout device dataType shape</li><li class="src short"><a href="#v:tanh">tanh</a> :: <span class="keyword">forall</span> gradient layout device dataType shape. <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> gradient layout device dataType shape -&gt; <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> gradient layout device dataType shape</li><li class="src short"><a href="#v:trueDivide">trueDivide</a> :: <span class="keyword">forall</span> gradient layout device dataType shape gradient' layout' device' dataType' shape'. <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> gradient layout device dataType shape -&gt; <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> gradient' layout' device' dataType' shape' -&gt; <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> (gradient <a href="Torch-GraduallyTyped-Unify.html#t:-60--124--62-" title="Torch.GraduallyTyped.Unify">&lt;|&gt;</a> gradient') (layout <a href="Torch-GraduallyTyped-Unify.html#t:-60--43--62-" title="Torch.GraduallyTyped.Unify">&lt;+&gt;</a> layout') (device <a href="Torch-GraduallyTyped-Unify.html#t:-60--43--62-" title="Torch.GraduallyTyped.Unify">&lt;+&gt;</a> device') (dataType <a href="Torch-GraduallyTyped-Unify.html#t:-60--43--62-" title="Torch.GraduallyTyped.Unify">&lt;+&gt;</a> dataType') (shape <a href="Torch-GraduallyTyped-Unify.html#t:-60--43--62-" title="Torch.GraduallyTyped.Unify">&lt;+&gt;</a> shape')</li><li class="src short"><a href="#v:trueDivideScalar">trueDivideScalar</a> :: <span class="keyword">forall</span> other gradient layout device dataType shape. <a href="Torch-GraduallyTyped-Scalar.html#t:Scalar" title="Torch.GraduallyTyped.Scalar">Scalar</a> other =&gt; <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> gradient layout device dataType shape -&gt; other -&gt; <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> gradient layout device dataType shape</li><li class="src short"><a href="#v:trunc">trunc</a> :: <span class="keyword">forall</span> gradient layout device dataType shape. <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> gradient layout device dataType shape -&gt; <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> gradient layout device dataType shape</li></ul></details></div><div id="interface"><h1>Documentation</h1><div class="doc"><pre class="screen"><code class="prompt">&gt;&gt;&gt; </code><strong class="userinput"><code>import Data.Singletons.Prelude.List (SList (..))
</code></strong><code class="prompt">&gt;&gt;&gt; </code><strong class="userinput"><code>import Torch.GraduallyTyped
</code></strong></pre></div><div class="top"><p class="src"><a id="v:abs" class="def">abs</a> <a href="src/Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#abs" class="link">Source</a> <a href="#v:abs" class="selflink">#</a></p><div class="subs arguments"><p class="caption">Arguments</p><table><tr><td class="src">:: <span class="keyword">forall</span> gradient layout device dataType shape. <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> gradient layout device dataType shape</td><td class="doc"><p>input</p></td></tr><tr><td class="src">-&gt; <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> gradient layout device dataType shape</td><td class="doc"><p>output</p></td></tr></table></div><div class="doc"><p>Computes the element-wise absolute value of the given <code>input</code> tensor:
 <span class="mathjax">\[
 \mathrm{output}_i = \left|\mathrm{input}_i\right|.
 \]</span>
 The result is returned as a new tensor.</p></div></div><div class="top"><p class="src"><a id="v:absolute" class="def">absolute</a> <a href="src/Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#absolute" class="link">Source</a> <a href="#v:absolute" class="selflink">#</a></p><div class="subs arguments"><p class="caption">Arguments</p><table><tr><td class="src">:: <span class="keyword">forall</span> gradient layout device dataType shape. <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> gradient layout device dataType shape</td><td class="doc"><p>input</p></td></tr><tr><td class="src">-&gt; <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> gradient layout device dataType shape</td><td class="doc"><p>output</p></td></tr></table></div><div class="doc"><p>Alias for <code><a href="Torch-GraduallyTyped-Tensor-MathOperations-Pointwise.html#v:abs" title="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise">abs</a></code>.</p></div></div><div class="top"><p class="src"><a id="v:acos" class="def">acos</a> <a href="src/Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#acos" class="link">Source</a> <a href="#v:acos" class="selflink">#</a></p><div class="subs arguments"><p class="caption">Arguments</p><table><tr><td class="src">:: <span class="keyword">forall</span> gradient layout device dataType shape. <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> gradient layout device dataType shape</td><td class="doc"><p>input</p></td></tr><tr><td class="src">-&gt; <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> gradient layout device dataType shape</td><td class="doc"><p>output</p></td></tr></table></div><div class="doc"><p>Returns a new tensor with the arccosine of the elements of <code>input</code>:
 <span class="mathjax">\[
 \mathrm{output}_i = \cos^{-1} \left(\mathrm{input}_i\right).
 \]</span></p></div></div><div class="top"><p class="src"><a id="v:acosh" class="def">acosh</a> <a href="src/Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#acosh" class="link">Source</a> <a href="#v:acosh" class="selflink">#</a></p><div class="subs arguments"><p class="caption">Arguments</p><table><tr><td class="src">:: <span class="keyword">forall</span> gradient layout device dataType shape. <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> gradient layout device dataType shape</td><td class="doc"><p>input</p></td></tr><tr><td class="src">-&gt; <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> gradient layout device dataType shape</td><td class="doc"><p>output</p></td></tr></table></div><div class="doc"><p>Returns a new tensor with the arccosine of the elements of <code>input</code>:
 <span class="mathjax">\[
 \mathrm{output}_i = \cosh^{-1} \left(\mathrm{input}_i\right).
 \]</span></p><p>Note that the domain of the inverse hyperbolic cosine is <span class="mathjax">\([1, \infty)\)</span>, and
 values outside this range will be mapped to <span class="mathjax">\(\mathrm{NaN}\)</span>,
 except for <span class="mathjax">\(+\infty\)</span> for which the output is mapped to <span class="mathjax">\(+\infty\)</span>.</p></div></div><div class="top"><p class="src"><a id="v:add" class="def">add</a> <a href="src/Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#add" class="link">Source</a> <a href="#v:add" class="selflink">#</a></p><div class="subs arguments"><p class="caption">Arguments</p><table><tr><td class="src">:: <span class="keyword">forall</span> gradient layout device dataType shape gradient' layout' device' dataType' shape'. <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> gradient layout device dataType shape</td><td class="doc"><p>input tensor</p></td></tr><tr><td class="src">-&gt; <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> gradient' layout' device' dataType' shape'</td><td class="doc"><p>other tensor</p></td></tr><tr><td class="src">-&gt; <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> (gradient <a href="Torch-GraduallyTyped-Unify.html#t:-60--124--62-" title="Torch.GraduallyTyped.Unify">&lt;|&gt;</a> gradient') (layout <a href="Torch-GraduallyTyped-Unify.html#t:-60--43--62-" title="Torch.GraduallyTyped.Unify">&lt;+&gt;</a> layout') (device <a href="Torch-GraduallyTyped-Unify.html#t:-60--43--62-" title="Torch.GraduallyTyped.Unify">&lt;+&gt;</a> device') (dataType <a href="Torch-GraduallyTyped-Unify.html#t:-60--43--62-" title="Torch.GraduallyTyped.Unify">&lt;+&gt;</a> dataType') (<a href="Torch-GraduallyTyped-Shape-Class.html#t:BroadcastShapesF" title="Torch.GraduallyTyped.Shape.Class">BroadcastShapesF</a> shape shape')</td><td class="doc"><p>output tensor</p></td></tr></table></div><div class="doc"><p>Element-wise addition of one tensor and another:
 <span class="mathjax">\[
 \mathrm{output}_i = \mathrm{input}_i + \mathrm{other}_i.
 \]</span>
 The result is returned as a new tensor.</p><p>The shape of <code>other</code> must be broadcastable with the shape of <code>input</code>.
 See <code><a href="Torch-GraduallyTyped-Tensor-MathOperations-Pointwise.html#v:addScalar" title="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise">addScalar</a></code> for a version of this function where
 the <code>other</code> input is a scalar.</p><pre class="screen"><code class="prompt">&gt;&gt;&gt; </code><strong class="userinput"><code>g = sMkGenerator (SDevice SCPU) 0
</code></strong><code class="prompt">&gt;&gt;&gt; </code><strong class="userinput"><code>sRandn' = sRandn . TensorSpec (SGradient SWithGradient) (SLayout SDense) (SDevice SCPU) (SDataType SFloat)
</code></strong><code class="prompt">&gt;&gt;&gt; </code><strong class="userinput"><code>(a, g') &lt;- sRandn' (SShape $ SName @&quot;feature&quot; :&amp;: SSize @4 :|: SNil) g
</code></strong><code class="prompt">&gt;&gt;&gt; </code><strong class="userinput"><code>(b, _) &lt;- sRandn' (SShape $ SName @&quot;*&quot; :&amp;: SSize @4 :|: SName @&quot;*&quot; :&amp;: SSize @1 :|: SNil) g'
</code></strong><code class="prompt">&gt;&gt;&gt; </code><strong class="userinput"><code>:type a `add` b
</code></strong>a `add` b
  :: Tensor
       ('Gradient 'WithGradient)
       ('Layout 'Dense)
       ('Device 'CPU)
       ('DataType 'Float)
       ('Shape
          '[ 'Dim ('Name &quot;*&quot;) ('Size 4), 'Dim ('Name &quot;feature&quot;) ('Size 4)])
</pre></div></div><div class="top"><p class="src"><a id="v:addScalar" class="def">addScalar</a> <a href="src/Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#addScalar" class="link">Source</a> <a href="#v:addScalar" class="selflink">#</a></p><div class="subs arguments"><p class="caption">Arguments</p><table><tr><td class="src">:: <span class="keyword">forall</span> other gradient layout device dataType shape. <a href="Torch-GraduallyTyped-Scalar.html#t:Scalar" title="Torch.GraduallyTyped.Scalar">Scalar</a> other</td><td class="doc empty">&nbsp;</td></tr><tr><td class="src">=&gt; <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> gradient layout device dataType shape</td><td class="doc"><p>input tensor</p></td></tr><tr><td class="src">-&gt; other</td><td class="doc"><p>input scalar</p></td></tr><tr><td class="src">-&gt; <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> gradient layout device dataType shape</td><td class="doc"><p>output</p></td></tr></table></div><div class="doc"><p>Adds a scalar <code>other</code> to a tensor <code>input</code>:
 <span class="mathjax">\[
 \mathrm{output}_i = \mathrm{input}_i + \mathrm{other}.
 \]</span>
 The result is returned as a new tensor.
 See <code><a href="Torch-GraduallyTyped-Tensor-MathOperations-Pointwise.html#v:add" title="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise">add</a></code> for a version of this function where
 the second argument is a tensor.</p><p>TODO: add data type unification of <code>other</code> and <code>dataType</code>.</p></div></div><div class="top"><p class="src"><a id="v:addcdiv" class="def">addcdiv</a> <a href="src/Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#addcdiv" class="link">Source</a> <a href="#v:addcdiv" class="selflink">#</a></p><div class="subs arguments"><p class="caption">Arguments</p><table><tr><td class="src">:: <span class="keyword">forall</span> value gradient layout device dataType shape. <a href="Torch-GraduallyTyped-Scalar.html#t:Scalar" title="Torch.GraduallyTyped.Scalar">Scalar</a> value</td><td class="doc empty">&nbsp;</td></tr><tr><td class="src">=&gt; value</td><td class="doc"><p>input scalar</p></td></tr><tr><td class="src">-&gt; <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> gradient layout device dataType shape</td><td class="doc"><p>first other tensor</p></td></tr><tr><td class="src">-&gt; <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> gradient layout device dataType shape</td><td class="doc"><p>second other tensor</p></td></tr><tr><td class="src">-&gt; <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> gradient layout device dataType shape</td><td class="doc"><p>input tensor</p></td></tr><tr><td class="src">-&gt; <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> gradient layout device dataType shape</td><td class="doc"><p>output tensor</p></td></tr></table></div><div class="doc"><p>Performs the element-wise division of <code>tensor1</code> by <code>tensor2</code>,
 multiply the result by a scalar <code>value</code> and add it to <code>input</code>:
 <span class="mathjax">\[
 \mathrm{output}_i = \mathrm{input}_i + \mathrm{value} \times \frac{\mathrm{tensor1}_i}{\mathrm{tensor2}_i}.
 \]</span></p><p>See <code><a href="Torch-GraduallyTyped-Tensor-MathOperations-Pointwise.html#v:addcmul" title="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise">addcmul</a></code> for a version of this function where <code>tensor1</code> and <code>tensor2</code>
 are multiplied rather than divided.</p><p>Note further that for inputs of type <code>Float</code> or <code>Double</code>,
 <code>value</code> must be a real number, otherwise it must be an integer.</p></div></div><div class="top"><p class="src"><a id="v:addcmul" class="def">addcmul</a> <a href="src/Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#addcmul" class="link">Source</a> <a href="#v:addcmul" class="selflink">#</a></p><div class="subs arguments"><p class="caption">Arguments</p><table><tr><td class="src">:: <span class="keyword">forall</span> scalar gradient layout device dataType shape. <a href="Torch-GraduallyTyped-Scalar.html#t:Scalar" title="Torch.GraduallyTyped.Scalar">Scalar</a> scalar</td><td class="doc empty">&nbsp;</td></tr><tr><td class="src">=&gt; scalar</td><td class="doc"><p>input scalar</p></td></tr><tr><td class="src">-&gt; <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> gradient layout device dataType shape</td><td class="doc"><p>first other tensor</p></td></tr><tr><td class="src">-&gt; <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> gradient layout device dataType shape</td><td class="doc"><p>second other tensor</p></td></tr><tr><td class="src">-&gt; <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> gradient layout device dataType shape</td><td class="doc"><p>input tensor</p></td></tr><tr><td class="src">-&gt; <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> gradient layout device dataType shape</td><td class="doc"><p>output</p></td></tr></table></div><div class="doc"><p>Performs the element-wise multiplication of <code>tensor1</code> by <code>tensor2</code>,
 multiply the result by the scalar <code>value</code> and add it to <code>input</code>:
 <span class="mathjax">\[
 \mathrm{output}_i = \mathrm{input}_i + \mathrm{value} \times \mathrm{tensor1}_i \times \mathrm{tensor2}_i.
 \]</span></p><p>See <code><a href="Torch-GraduallyTyped-Tensor-MathOperations-Pointwise.html#v:addcdiv" title="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise">addcdiv</a></code> for a version of this function where <code>tensor1</code> and <code>tensor2</code>
 are divided rather than multiplied.</p><p>Note further that for inputs of type <code>Float</code> or <code>Double</code>,
 <code>value</code> must be a real number, otherwise it must be an integer.</p></div></div><div class="top"><p class="src"><a id="v:asin" class="def">asin</a> <a href="src/Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#asin" class="link">Source</a> <a href="#v:asin" class="selflink">#</a></p><div class="subs arguments"><p class="caption">Arguments</p><table><tr><td class="src">:: <span class="keyword">forall</span> gradient layout device dataType shape. <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> gradient layout device dataType shape</td><td class="doc"><p>input</p></td></tr><tr><td class="src">-&gt; <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> gradient layout device dataType shape</td><td class="doc"><p>output</p></td></tr></table></div><div class="doc"><p>Returns a new tensor with the arcsine of the elements of <code>input</code>:
 <span class="mathjax">\[
 \mathrm{output}_i = \sin^{-1} \left(\mathrm{input}_i\right).
 \]</span></p></div></div><div class="top"><p class="src"><a id="v:asinh" class="def">asinh</a> <a href="src/Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#asinh" class="link">Source</a> <a href="#v:asinh" class="selflink">#</a></p><div class="subs arguments"><p class="caption">Arguments</p><table><tr><td class="src">:: <span class="keyword">forall</span> gradient layout device dataType shape. <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> gradient layout device dataType shape</td><td class="doc"><p>input</p></td></tr><tr><td class="src">-&gt; <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> gradient layout device dataType shape</td><td class="doc"><p>output</p></td></tr></table></div><div class="doc"><p>Returns a new tensor with the inverse hyperbolic sine of the elements of <code>input</code>:
 <span class="mathjax">\[
 \mathrm{output}_i = \sinh^{-1} \left(\mathrm{input}_i\right).
 \]</span></p></div></div><div class="top"><p class="src"><a id="v:atan" class="def">atan</a> <a href="src/Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#atan" class="link">Source</a> <a href="#v:atan" class="selflink">#</a></p><div class="subs arguments"><p class="caption">Arguments</p><table><tr><td class="src">:: <span class="keyword">forall</span> gradient layout device dataType shape. <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> gradient layout device dataType shape</td><td class="doc"><p>input</p></td></tr><tr><td class="src">-&gt; <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> gradient layout device dataType shape</td><td class="doc"><p>output</p></td></tr></table></div><div class="doc"><p>Returns a new tensor with the arctangent of the elements of <code>input</code>:
 <span class="mathjax">\[
 \mathrm{output}_i = \tan^{-1} \left(\mathrm{input}_i\right).
 \]</span></p></div></div><div class="top"><p class="src"><a id="v:atanh" class="def">atanh</a> <a href="src/Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#atanh" class="link">Source</a> <a href="#v:atanh" class="selflink">#</a></p><div class="subs arguments"><p class="caption">Arguments</p><table><tr><td class="src">:: <span class="keyword">forall</span> gradient layout device dataType shape. <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> gradient layout device dataType shape</td><td class="doc"><p>input</p></td></tr><tr><td class="src">-&gt; <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> gradient layout device dataType shape</td><td class="doc"><p>output</p></td></tr></table></div><div class="doc"><p>Returns a new tensor with the inverse hyperbolic tangent of the elements of <code>input</code>:
 <span class="mathjax">\[
 \mathrm{output}_i = \tanh^{-1} \left(\mathrm{input}_i\right).
 \]</span></p><p>Note that the domain of the inverse hyperbolic tangent is <span class="mathjax">\((-1, 1)\)</span>, and
 values outside this range will be mapped to <span class="mathjax">\(\mathrm{NaN}\)</span>,
 except for the values <span class="mathjax">\(1\)</span> and <span class="mathjax">\(-1\)</span> for which the output is mapped to
 <span class="mathjax">\(\pm \infty\)</span> respectively.</p></div></div><div class="top"><p class="src"><a id="v:atan2" class="def">atan2</a> <a href="src/Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#atan2" class="link">Source</a> <a href="#v:atan2" class="selflink">#</a></p><div class="subs arguments"><p class="caption">Arguments</p><table><tr><td class="src">:: <span class="keyword">forall</span> gradient layout device dataType shape gradient' layout' device' dataType' shape'. <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> gradient layout device dataType shape</td><td class="doc"><p>input tensor</p></td></tr><tr><td class="src">-&gt; <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> gradient' layout' device' dataType' shape'</td><td class="doc"><p>other input tensor</p></td></tr><tr><td class="src">-&gt; <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> (gradient <a href="Torch-GraduallyTyped-Unify.html#t:-60--124--62-" title="Torch.GraduallyTyped.Unify">&lt;|&gt;</a> gradient') (layout <a href="Torch-GraduallyTyped-Unify.html#t:-60--43--62-" title="Torch.GraduallyTyped.Unify">&lt;+&gt;</a> layout') (device <a href="Torch-GraduallyTyped-Unify.html#t:-60--43--62-" title="Torch.GraduallyTyped.Unify">&lt;+&gt;</a> device') (dataType <a href="Torch-GraduallyTyped-Unify.html#t:-60--43--62-" title="Torch.GraduallyTyped.Unify">&lt;+&gt;</a> dataType') (<a href="Torch-GraduallyTyped-Shape-Class.html#t:BroadcastShapesF" title="Torch.GraduallyTyped.Shape.Class">BroadcastShapesF</a> shape shape')</td><td class="doc"><p>output tensor</p></td></tr></table></div><div class="doc"><p>Element-wise arctangent of <code>input</code> and <code>other</code> with consideration of the quadrant.
 Returns a new tensor where each element is the signed angle in radians between
 the vectors <span class="mathjax">\(\mathrm{other}_i, \mathrm{input}_i)\)</span> and <span class="mathjax">\((1,0)\)</span>.
 Here $mathrm{other}_i$, the <span class="mathjax">\(i\)</span>-th element of the second argument of this function,
 is the x coordinate while $mathrm{input}_i$, the <span class="mathjax">\(i\)</span>-th element of the first argument,
 is the y coordinate.</p><p>Note that the shapes of <code>input</code> and <code>other</code> must be broadcastable.</p></div></div><div class="top"><p class="src"><a id="v:bitwiseNot" class="def">bitwiseNot</a> <a href="src/Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#bitwiseNot" class="link">Source</a> <a href="#v:bitwiseNot" class="selflink">#</a></p><div class="subs arguments"><p class="caption">Arguments</p><table><tr><td class="src">:: <span class="keyword">forall</span> gradient layout device dataType shape. <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> gradient layout device dataType shape</td><td class="doc"><p>input</p></td></tr><tr><td class="src">-&gt; <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> gradient layout device ('<a href="Torch-GraduallyTyped-DType.html#v:DataType" title="Torch.GraduallyTyped.DType">DataType</a> '<a href="Torch-GraduallyTyped-DType.html#v:Bool" title="Torch.GraduallyTyped.DType">Bool</a>) shape</td><td class="doc"><p>output</p></td></tr></table></div><div class="doc"><p>Computes the bitwise NOT of the given <code>input</code> tensor.
 The data type of the <code>input</code> tensor must be <code>Bool</code> or an integral data type.
 For <code>Bool</code> tensors, the function computes the logical NOT.</p></div></div><div class="top"><p class="src"><a id="v:bitwiseAnd" class="def">bitwiseAnd</a> <a href="src/Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#bitwiseAnd" class="link">Source</a> <a href="#v:bitwiseAnd" class="selflink">#</a></p><div class="subs arguments"><p class="caption">Arguments</p><table><tr><td class="src">:: <span class="keyword">forall</span> gradient layout device dataType shape. <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> gradient layout device dataType shape</td><td class="doc"><p>input tensor</p></td></tr><tr><td class="src">-&gt; <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> gradient layout device dataType shape</td><td class="doc"><p>other tensor</p></td></tr><tr><td class="src">-&gt; <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> gradient layout device dataType shape</td><td class="doc"><p>output tensor</p></td></tr></table></div><div class="doc"><p>Computes the bitwise AND of the <code>input</code> and the <code>other</code> tensor.
 The data type of the tensors must be <code>Bool</code> or an integral data type.
 For <code>Bool</code> tensors, the function computes the logical AND.</p><p>See <code><a href="Torch-GraduallyTyped-Tensor-MathOperations-Pointwise.html#v:bitwiseAndScalar" title="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise">bitwiseAndScalar</a></code> for a version of this function where <code>other</code>
 is a scalar.</p></div></div><div class="top"><p class="src"><a id="v:bitwiseAndScalar" class="def">bitwiseAndScalar</a> <a href="src/Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#bitwiseAndScalar" class="link">Source</a> <a href="#v:bitwiseAndScalar" class="selflink">#</a></p><div class="subs arguments"><p class="caption">Arguments</p><table><tr><td class="src">:: <span class="keyword">forall</span> other gradient layout device dataType shape. <a href="Torch-GraduallyTyped-Scalar.html#t:Scalar" title="Torch.GraduallyTyped.Scalar">Scalar</a> other</td><td class="doc empty">&nbsp;</td></tr><tr><td class="src">=&gt; <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> gradient layout device dataType shape</td><td class="doc"><p>input tensor</p></td></tr><tr><td class="src">-&gt; other</td><td class="doc"><p>other scalar</p></td></tr><tr><td class="src">-&gt; <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> gradient layout device dataType shape</td><td class="doc"><p>output</p></td></tr></table></div><div class="doc"><p>Computes the bitwise AND of the tensor <code>input</code> and the scalar <code>other</code>.
 The data type of the inputs must be <code>Bool</code> or an integral data type.
 If the data type is <code>Bool</code>, then the function computes the logical AND.</p><p>See <code><a href="Torch-GraduallyTyped-Tensor-MathOperations-Pointwise.html#v:bitwiseAnd" title="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise">bitwiseAnd</a></code> for a version of this function where <code>other</code>
 is a tensor.</p></div></div><div class="top"><p class="src"><a id="v:bitwiseOr" class="def">bitwiseOr</a> <a href="src/Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#bitwiseOr" class="link">Source</a> <a href="#v:bitwiseOr" class="selflink">#</a></p><div class="subs arguments"><p class="caption">Arguments</p><table><tr><td class="src">:: <span class="keyword">forall</span> gradient layout device dataType shape. <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> gradient layout device dataType shape</td><td class="doc"><p>input tensor</p></td></tr><tr><td class="src">-&gt; <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> gradient layout device dataType shape</td><td class="doc"><p>other tensor</p></td></tr><tr><td class="src">-&gt; <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> gradient layout device dataType shape</td><td class="doc"><p>output tensor</p></td></tr></table></div><div class="doc"><p>Computes the bitwise OR of the <code>input</code> and the <code>other</code> tensor.
 The data type of the tensors must be <code>Bool</code> or an integral data type.
 For <code>Bool</code> tensors, the function computes the logical OR.</p><p>See <code><a href="Torch-GraduallyTyped-Tensor-MathOperations-Pointwise.html#v:bitwiseOrScalar" title="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise">bitwiseOrScalar</a></code> for a version of this function where <code>other</code>
 is a scalar.</p></div></div><div class="top"><p class="src"><a id="v:bitwiseOrScalar" class="def">bitwiseOrScalar</a> <a href="src/Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#bitwiseOrScalar" class="link">Source</a> <a href="#v:bitwiseOrScalar" class="selflink">#</a></p><div class="subs arguments"><p class="caption">Arguments</p><table><tr><td class="src">:: <span class="keyword">forall</span> other gradient layout device dataType shape. <a href="Torch-GraduallyTyped-Scalar.html#t:Scalar" title="Torch.GraduallyTyped.Scalar">Scalar</a> other</td><td class="doc empty">&nbsp;</td></tr><tr><td class="src">=&gt; <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> gradient layout device dataType shape</td><td class="doc"><p>input tensor</p></td></tr><tr><td class="src">-&gt; other</td><td class="doc"><p>other scalar</p></td></tr><tr><td class="src">-&gt; <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> gradient layout device dataType shape</td><td class="doc"><p>output tensor</p></td></tr></table></div><div class="doc"><p>Computes the bitwise OR of the tensor <code>input</code> and the scalar <code>other</code>.
 The data type of the inputs must be <code>Bool</code> or an integral data type.
 If the data type is <code>Bool</code>, then the function computes the logical OR.</p><p>See <code><a href="Torch-GraduallyTyped-Tensor-MathOperations-Pointwise.html#v:bitwiseOr" title="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise">bitwiseOr</a></code> for a version of this function where <code>other</code>
 is a tensor.</p></div></div><div class="top"><p class="src"><a id="v:bitwiseXor" class="def">bitwiseXor</a> <a href="src/Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#bitwiseXor" class="link">Source</a> <a href="#v:bitwiseXor" class="selflink">#</a></p><div class="subs arguments"><p class="caption">Arguments</p><table><tr><td class="src">:: <span class="keyword">forall</span> gradient layout device dataType shape. <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> gradient layout device dataType shape</td><td class="doc"><p>input tensor</p></td></tr><tr><td class="src">-&gt; <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> gradient layout device dataType shape</td><td class="doc"><p>other tensor</p></td></tr><tr><td class="src">-&gt; <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> gradient layout device dataType shape</td><td class="doc"><p>output tensor</p></td></tr></table></div><div class="doc"><p>Computes the bitwise XOR of the <code>input</code> and the <code>other</code> tensor.
 The data type of the tensors must be <code>Bool</code> or an integral data type.
 For <code>Bool</code> tensors, the function computes the logical XOR.</p><p>See <code><a href="Torch-GraduallyTyped-Tensor-MathOperations-Pointwise.html#v:bitwiseXorScalar" title="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise">bitwiseXorScalar</a></code> for a version of this function where <code>other</code>
 is a scalar.</p></div></div><div class="top"><p class="src"><a id="v:bitwiseXorScalar" class="def">bitwiseXorScalar</a> <a href="src/Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#bitwiseXorScalar" class="link">Source</a> <a href="#v:bitwiseXorScalar" class="selflink">#</a></p><div class="subs arguments"><p class="caption">Arguments</p><table><tr><td class="src">:: <span class="keyword">forall</span> other gradient layout device dataType shape. <a href="Torch-GraduallyTyped-Scalar.html#t:Scalar" title="Torch.GraduallyTyped.Scalar">Scalar</a> other</td><td class="doc empty">&nbsp;</td></tr><tr><td class="src">=&gt; <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> gradient layout device dataType shape</td><td class="doc"><p>input tensor</p></td></tr><tr><td class="src">-&gt; other</td><td class="doc"><p>other scalar</p></td></tr><tr><td class="src">-&gt; <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> gradient layout device dataType shape</td><td class="doc"><p>output tensor</p></td></tr></table></div><div class="doc"><p>Computes the bitwise XOR of the tensor <code>input</code> and the scalar <code>other</code>.
 The data type of the inputs must be <code>Bool</code> or an integral data type.
 If the data type is <code>Bool</code>, then the function computes the logical XOR.</p><p>See <code><a href="Torch-GraduallyTyped-Tensor-MathOperations-Pointwise.html#v:bitwiseXor" title="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise">bitwiseXor</a></code> for a version of this function where <code>other</code>
 is a tensor.</p></div></div><div class="top"><p class="src"><a id="v:ceil" class="def">ceil</a> <a href="src/Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#ceil" class="link">Source</a> <a href="#v:ceil" class="selflink">#</a></p><div class="subs arguments"><p class="caption">Arguments</p><table><tr><td class="src">:: <span class="keyword">forall</span> gradient layout device dataType shape. <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> gradient layout device dataType shape</td><td class="doc"><p>input</p></td></tr><tr><td class="src">-&gt; <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> gradient layout device dataType shape</td><td class="doc"><p>output</p></td></tr></table></div><div class="doc"><p>Returns a new tensor with the ceil of the elements of <code>input</code>,
 that is, the smallest integer greater than or equal to each element:
 <span class="mathjax">\[
 \mathrm{output}_i = \lceil\mathrm{input}_i\rceil = \lfloor\mathrm{input}_i\rfloor + 1,
 \]</span>
 where <span class="mathjax">\(\lfloor\mathrm{input}_i\rfloor\)</span> is the floor of the <span class="mathjax">\(i\)</span>-th element of <code>input</code>
 which can be computed with <code><a href="Torch-GraduallyTyped-Tensor-MathOperations-Pointwise.html#v:floor" title="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise">floor</a></code>.</p></div></div><div class="top"><p class="src"><a id="v:clamp" class="def">clamp</a> <a href="src/Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#clamp" class="link">Source</a> <a href="#v:clamp" class="selflink">#</a></p><div class="subs arguments"><p class="caption">Arguments</p><table><tr><td class="src">:: <span class="keyword">forall</span> min max gradient layout device dataType shape. (<a href="Torch-GraduallyTyped-Scalar.html#t:Scalar" title="Torch.GraduallyTyped.Scalar">Scalar</a> min, <a href="Torch-GraduallyTyped-Scalar.html#t:Scalar" title="Torch.GraduallyTyped.Scalar">Scalar</a> max)</td><td class="doc empty">&nbsp;</td></tr><tr><td class="src">=&gt; min</td><td class="doc"><p>min</p></td></tr><tr><td class="src">-&gt; max</td><td class="doc"><p>max</p></td></tr><tr><td class="src">-&gt; <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> gradient layout device dataType shape</td><td class="doc"><p>input</p></td></tr><tr><td class="src">-&gt; <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> gradient layout device dataType shape</td><td class="doc"><p>output</p></td></tr></table></div><div class="doc"><p>Clamp all elements in input into the range [ min, max ]
 and return the result as a new tensor.</p></div></div><div class="top"><p class="src"><a id="v:cos" class="def">cos</a> <a href="src/Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#cos" class="link">Source</a> <a href="#v:cos" class="selflink">#</a></p><div class="subs arguments"><p class="caption">Arguments</p><table><tr><td class="src">:: <span class="keyword">forall</span> gradient layout device dataType shape. <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> gradient layout device dataType shape</td><td class="doc"><p>input</p></td></tr><tr><td class="src">-&gt; <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> gradient layout device dataType shape</td><td class="doc"><p>output</p></td></tr></table></div></div><div class="top"><p class="src"><a id="v:cosh" class="def">cosh</a> <a href="src/Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#cosh" class="link">Source</a> <a href="#v:cosh" class="selflink">#</a></p><div class="subs arguments"><p class="caption">Arguments</p><table><tr><td class="src">:: <span class="keyword">forall</span> gradient layout device dataType shape. <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> gradient layout device dataType shape</td><td class="doc"><p>input</p></td></tr><tr><td class="src">-&gt; <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> gradient layout device dataType shape</td><td class="doc"><p>output</p></td></tr></table></div></div><div class="top"><p class="src"><a id="v:deg2rad" class="def">deg2rad</a> <a href="src/Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#deg2rad" class="link">Source</a> <a href="#v:deg2rad" class="selflink">#</a></p><div class="subs arguments"><p class="caption">Arguments</p><table><tr><td class="src">:: <span class="keyword">forall</span> gradient layout device dataType shape. <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> gradient layout device dataType shape</td><td class="doc"><p>input</p></td></tr><tr><td class="src">-&gt; <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> gradient layout device dataType shape</td><td class="doc"><p>output</p></td></tr></table></div></div><div class="top"><p class="src"><a id="v:div" class="def">div</a> <a href="src/Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#div" class="link">Source</a> <a href="#v:div" class="selflink">#</a></p><div class="subs arguments"><p class="caption">Arguments</p><table><tr><td class="src">:: <span class="keyword">forall</span> gradient layout device dataType shape gradient' layout' device' dataType' shape'. <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> gradient layout device dataType shape</td><td class="doc"><p>tensor dividend</p></td></tr><tr><td class="src">-&gt; <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> gradient' layout' device' dataType' shape'</td><td class="doc"><p>tensor divisor</p></td></tr><tr><td class="src">-&gt; <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> (gradient <a href="Torch-GraduallyTyped-Unify.html#t:-60--124--62-" title="Torch.GraduallyTyped.Unify">&lt;|&gt;</a> gradient') (layout <a href="Torch-GraduallyTyped-Unify.html#t:-60--43--62-" title="Torch.GraduallyTyped.Unify">&lt;+&gt;</a> layout') (device <a href="Torch-GraduallyTyped-Unify.html#t:-60--43--62-" title="Torch.GraduallyTyped.Unify">&lt;+&gt;</a> device') (dataType <a href="Torch-GraduallyTyped-Unify.html#t:-60--43--62-" title="Torch.GraduallyTyped.Unify">&lt;+&gt;</a> dataType') (<a href="Torch-GraduallyTyped-Shape-Class.html#t:BroadcastShapesF" title="Torch.GraduallyTyped.Shape.Class">BroadcastShapesF</a> shape shape')</td><td class="doc"><p>tensor output</p></td></tr></table></div><div class="doc"><p>Element-wise division of the first input tensor, the <code>dividend</code>,
 by the second input tensor, the <code>divisor</code>.
 <span class="mathjax">\[
 \mathrm{output}_i = \frac{dividend_i}{divisor_i}
 \]</span>
 The result is returned as a new tensor.</p><p>See <code><a href="Torch-GraduallyTyped-Tensor-MathOperations-Pointwise.html#v:divScalar" title="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise">divScalar</a></code> for a version of this function where
 the <code>divisor</code> is a scalar.</p><p>Note further that &quot;true divisions&quot; can be computed with
 <code><a href="Torch-GraduallyTyped-Tensor-MathOperations-Pointwise.html#v:trueDivide" title="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise">trueDivide</a></code> or <code><a href="Torch-GraduallyTyped-Tensor-MathOperations-Pointwise.html#v:trueDivideScalar" title="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise">trueDivideScalar</a></code> which can come in handy
 when both the <code>dividend</code> and the <code>divisor</code> have <code>Bool</code> or integer data types.</p></div></div><div class="top"><p class="src"><a id="v:divScalar" class="def">divScalar</a> <a href="src/Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#divScalar" class="link">Source</a> <a href="#v:divScalar" class="selflink">#</a></p><div class="subs arguments"><p class="caption">Arguments</p><table><tr><td class="src">:: <span class="keyword">forall</span> divisor gradient layout device dataType shape. <a href="Torch-GraduallyTyped-Scalar.html#t:Scalar" title="Torch.GraduallyTyped.Scalar">Scalar</a> divisor</td><td class="doc empty">&nbsp;</td></tr><tr><td class="src">=&gt; <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> gradient layout device dataType shape</td><td class="doc"><p>tensor dividend</p></td></tr><tr><td class="src">-&gt; divisor</td><td class="doc"><p>scalar divisor</p></td></tr><tr><td class="src">-&gt; <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> gradient layout device dataType shape</td><td class="doc"><p>tensor output</p></td></tr></table></div><div class="doc"><p>Element-wise division of the first input, the <code>dividend</code> tensor,
 by the second input, the <code>divisor</code> scalar.
 <span class="mathjax">\[
 \mathrm{output}_i = \frac{dividend_i}{divisor}
 \]</span>
 The result is returned as a new tensor.</p><p>See <code><a href="Torch-GraduallyTyped-Tensor-MathOperations-Pointwise.html#v:div" title="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise">div</a></code> for a version of this function where
 the divisor is a tensor.</p><p>Note further that &quot;true divisions&quot; can be computed with
 <code><a href="Torch-GraduallyTyped-Tensor-MathOperations-Pointwise.html#v:trueDivide" title="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise">trueDivide</a></code> or <code><a href="Torch-GraduallyTyped-Tensor-MathOperations-Pointwise.html#v:trueDivideScalar" title="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise">trueDivideScalar</a></code> which can come in handy
 when both the dividend and the divisor have <code>Bool</code> or integer data types.</p></div></div><div class="top"><p class="src"><a id="v:digamma" class="def">digamma</a> <a href="src/Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#digamma" class="link">Source</a> <a href="#v:digamma" class="selflink">#</a></p><div class="subs arguments"><p class="caption">Arguments</p><table><tr><td class="src">:: <span class="keyword">forall</span> gradient layout device dataType shape. <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> gradient layout device dataType shape</td><td class="doc"><p>input</p></td></tr><tr><td class="src">-&gt; <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> gradient layout device dataType shape</td><td class="doc"><p>output</p></td></tr></table></div><div class="doc"><p>Computes the logarithmic derivative of the gamma function on <code>input</code>:
 <span class="mathjax">\[
 \mathrm{output}_i = \psi\left(\mathrm{input}_i\right) = \frac{d}{d\mathrm{input}_i} \ln\left(\gamma\left(\mathrm{input}_i\right)\right).
 \]</span></p></div></div><div class="top"><p class="src"><a id="v:erf" class="def">erf</a> <a href="src/Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#erf" class="link">Source</a> <a href="#v:erf" class="selflink">#</a></p><div class="subs arguments"><p class="caption">Arguments</p><table><tr><td class="src">:: <span class="keyword">forall</span> gradient layout device dataType shape. <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> gradient layout device dataType shape</td><td class="doc"><p>input</p></td></tr><tr><td class="src">-&gt; <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> gradient layout device dataType shape</td><td class="doc"><p>output</p></td></tr></table></div><div class="doc"><p>Computes and returns the error function of each element of <code>input</code>:
 <span class="mathjax">\[
 \mathrm{output}_i = \mathop{erf}\left(\mathrm{input}_i\right) = \frac{2}{\sqrt{\pi}} \int_0^{\mathrm{output}_i} \exp\left(- t^2\right) dt.
 \]</span></p><p>See also <code><a href="Torch-GraduallyTyped-Tensor-MathOperations-Pointwise.html#v:erfc" title="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise">erfc</a></code> that computes the complementary error function
 to high numerical accuracy
 and <code><a href="Torch-GraduallyTyped-Tensor-MathOperations-Pointwise.html#v:erfinv" title="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise">erfinv</a></code> that computes the inverse of the error function.</p></div></div><div class="top"><p class="src"><a id="v:erfc" class="def">erfc</a> <a href="src/Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#erfc" class="link">Source</a> <a href="#v:erfc" class="selflink">#</a></p><div class="subs arguments"><p class="caption">Arguments</p><table><tr><td class="src">:: <span class="keyword">forall</span> gradient layout device dataType shape. <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> gradient layout device dataType shape</td><td class="doc"><p>input</p></td></tr><tr><td class="src">-&gt; <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> gradient layout device dataType shape</td><td class="doc"><p>output</p></td></tr></table></div><div class="doc"><p>Computes the complementary error function of each element of <code>input</code>:
 <span class="mathjax">\[
 \mathrm{output}_i = 1 - \mathop{erf}\left(\mathrm{input}_i\right) = 1 - \frac{2}{\sqrt{\pi}} \int_0^{\mathrm{output}_i} \exp\left(- t^2\right) dt.
 \]</span></p><p>See also <code><a href="Torch-GraduallyTyped-Tensor-MathOperations-Pointwise.html#v:erf" title="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise">erf</a></code> that computes the error function
 and <code><a href="Torch-GraduallyTyped-Tensor-MathOperations-Pointwise.html#v:erfinv" title="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise">erfinv</a></code> that computes the inverse of the error function.</p></div></div><div class="top"><p class="src"><a id="v:erfinv" class="def">erfinv</a> <a href="src/Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#erfinv" class="link">Source</a> <a href="#v:erfinv" class="selflink">#</a></p><div class="subs arguments"><p class="caption">Arguments</p><table><tr><td class="src">:: <span class="keyword">forall</span> gradient layout device dataType shape. <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> gradient layout device dataType shape</td><td class="doc"><p>input</p></td></tr><tr><td class="src">-&gt; <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> gradient layout device dataType shape</td><td class="doc"><p>output</p></td></tr></table></div><div class="doc"><p>Computes the inverse error function of each element of <code>input</code>:
 <span class="mathjax">\[
 \mathrm{output}_i = \mathop{erfinv}\left(\mathrm{input}_i\right)
 \]</span>
 where <span class="mathjax">\(\mathop{erfinv}\left(\mathop{erf}\left(x\right)\right) = x\)</span>
 for <span class="mathjax">\(x \in (-1, 1)\)</span>. <code><a href="Torch-GraduallyTyped-Tensor-MathOperations-Pointwise.html#v:erfinv" title="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise">erfinv</a></code> is not defined outside this interval.</p><p>See also <code><a href="Torch-GraduallyTyped-Tensor-MathOperations-Pointwise.html#v:erf" title="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise">erf</a></code> that computes the error function
 and <code><a href="Torch-GraduallyTyped-Tensor-MathOperations-Pointwise.html#v:erfc" title="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise">erfc</a></code> that computes the complementary error function.</p></div></div><div class="top"><p class="src"><a id="v:exp" class="def">exp</a> <a href="src/Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#exp" class="link">Source</a> <a href="#v:exp" class="selflink">#</a></p><div class="subs arguments"><p class="caption">Arguments</p><table><tr><td class="src">:: <span class="keyword">forall</span> gradient layout device dataType shape. <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> gradient layout device dataType shape</td><td class="doc"><p>input</p></td></tr><tr><td class="src">-&gt; <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> gradient layout device dataType shape</td><td class="doc"><p>output</p></td></tr></table></div><div class="doc"><p>Returns a new tensor with the exponential of the elements of the input tensor <code>input</code>:
 <span class="mathjax">\[
 \mathrm{output}_i = \exp\left(\mathrm{input}_i\right).
 \]</span></p><p>See also <code><a href="Torch-GraduallyTyped-Tensor-MathOperations-Pointwise.html#v:expm1" title="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise">expm1</a></code> for a high-accuracy calculation of
 the exponential of the elements of <code>input</code> minus 1.</p></div></div><div class="top"><p class="src"><a id="v:expm1" class="def">expm1</a> <a href="src/Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#expm1" class="link">Source</a> <a href="#v:expm1" class="selflink">#</a></p><div class="subs arguments"><p class="caption">Arguments</p><table><tr><td class="src">:: <span class="keyword">forall</span> gradient layout device dataType shape. <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> gradient layout device dataType shape</td><td class="doc"><p>input</p></td></tr><tr><td class="src">-&gt; <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> gradient layout device dataType shape</td><td class="doc"><p>output</p></td></tr></table></div><div class="doc"><p>Returns a new tensor with the exponential of the elements minus 1 of <code>input</code>:
 <span class="mathjax">\[
 \mathrm{output}_i = \exp\left(\mathrm{input}_i\right) - 1.
 \]</span></p><p>See also <code><a href="Torch-GraduallyTyped-Tensor-MathOperations-Pointwise.html#v:exp" title="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise">exp</a></code> for the exponential function.</p></div></div><div class="top"><p class="src"><a id="v:floor" class="def">floor</a> <a href="src/Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#floor" class="link">Source</a> <a href="#v:floor" class="selflink">#</a></p><div class="subs arguments"><p class="caption">Arguments</p><table><tr><td class="src">:: <span class="keyword">forall</span> gradient layout device dataType shape. <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> gradient layout device dataType shape</td><td class="doc"><p>input</p></td></tr><tr><td class="src">-&gt; <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> gradient layout device dataType shape</td><td class="doc"><p>output</p></td></tr></table></div><div class="doc"><p>Returns a new tensor with the floor of the elements of <code>input</code>,
 that is, the largest integer less than or equal to each element.:
 <span class="mathjax">\[
 \mathrm{output}_i = \lfloor\mathrm{input}_i\rfloor = \lceil\mathrm{input}_i\rceil - 1,
 \]</span>
 where <span class="mathjax">\(\lceil\mathrm{input}_i\rceil\)</span> is the ceil of the <span class="mathjax">\(i\)</span>-th element of <code>input</code>
 which can be computed with <code><a href="Torch-GraduallyTyped-Tensor-MathOperations-Pointwise.html#v:ceil" title="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise">ceil</a></code>.</p></div></div><div class="top"><p class="src"><a id="v:floorDivide" class="def">floorDivide</a> <a href="src/Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#floorDivide" class="link">Source</a> <a href="#v:floorDivide" class="selflink">#</a></p><div class="subs arguments"><p class="caption">Arguments</p><table><tr><td class="src">:: <span class="keyword">forall</span> gradient layout device dataType shape. <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> gradient layout device dataType shape</td><td class="doc"><p>dividend tensor</p></td></tr><tr><td class="src">-&gt; <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> gradient layout device dataType shape</td><td class="doc"><p>divisor tensor</p></td></tr><tr><td class="src">-&gt; <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> gradient layout device dataType shape</td><td class="doc"><p>output tensor</p></td></tr></table></div><div class="doc"><p>Return the element-wise division of the tensor <code>dividend</code> by the tensor <code>divisor</code>
 rounded down to the nearest integer:
 <span class="mathjax">\[
 \mathrm{output}_i = \left\lfloor\frac{\mathrm{dividend}_i}{\mathrm{divisor}_i}\right\rfloor.
 \]</span></p><p>See <code><a href="Torch-GraduallyTyped-Tensor-MathOperations-Pointwise.html#v:floorDivideScalar" title="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise">floorDivideScalar</a></code> for a version of this function where
 <code>divisor</code> is a scalar.</p></div></div><div class="top"><p class="src"><a id="v:floorDivideScalar" class="def">floorDivideScalar</a> <a href="src/Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#floorDivideScalar" class="link">Source</a> <a href="#v:floorDivideScalar" class="selflink">#</a></p><div class="subs arguments"><p class="caption">Arguments</p><table><tr><td class="src">:: <span class="keyword">forall</span> divisor gradient layout device dataType shape. <a href="Torch-GraduallyTyped-Scalar.html#t:Scalar" title="Torch.GraduallyTyped.Scalar">Scalar</a> divisor</td><td class="doc empty">&nbsp;</td></tr><tr><td class="src">=&gt; <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> gradient layout device dataType shape</td><td class="doc"><p>dividend tensor</p></td></tr><tr><td class="src">-&gt; divisor</td><td class="doc"><p>divisor scalar</p></td></tr><tr><td class="src">-&gt; <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> gradient layout device dataType shape</td><td class="doc"><p>output tensor</p></td></tr></table></div><div class="doc"><p>Return the division of the tensor <code>dividend</code> by the scalar <code>divisor</code>
 rounded down to the nearest integer:
 <span class="mathjax">\[
 \mathrm{output}_i = \left\lfloor\frac{\mathrm{dividend}_i}{\mathrm{divisor}}\right\rfloor.
 \]</span></p><p>See <code><a href="Torch-GraduallyTyped-Tensor-MathOperations-Pointwise.html#v:floorDivide" title="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise">floorDivide</a></code> for a version of this function where
 <code>divisor</code> is a tensor.</p></div></div><div class="top"><p class="src"><a id="v:fmod" class="def">fmod</a> <a href="src/Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#fmod" class="link">Source</a> <a href="#v:fmod" class="selflink">#</a></p><div class="subs arguments"><p class="caption">Arguments</p><table><tr><td class="src">:: <span class="keyword">forall</span> gradient layout device dataType shape. <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> gradient layout device dataType shape</td><td class="doc"><p>dividend tensor</p></td></tr><tr><td class="src">-&gt; <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> gradient layout device dataType shape</td><td class="doc"><p>divisor scalar</p></td></tr><tr><td class="src">-&gt; <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> gradient layout device dataType shape</td><td class="doc"><p>output tensor</p></td></tr></table></div><div class="doc"><p>Computes the element-wise remainder of the division of
 the tensor <code>dividend</code> by the tensor <code>divisor</code>.
 The dividend and divisor may contain both for integer and floating point numbers.
 The remainder has the same sign as the <code>dividend</code> input.</p><p>See <code><a href="Torch-GraduallyTyped-Tensor-MathOperations-Pointwise.html#v:fmodScalar" title="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise">fmodScalar</a></code> for a version of this function where
 <code>divisor</code> is a scalar.</p></div></div><div class="top"><p class="src"><a id="v:fmodScalar" class="def">fmodScalar</a> <a href="src/Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#fmodScalar" class="link">Source</a> <a href="#v:fmodScalar" class="selflink">#</a></p><div class="subs arguments"><p class="caption">Arguments</p><table><tr><td class="src">:: <span class="keyword">forall</span> divisor gradient layout device dataType shape. <a href="Torch-GraduallyTyped-Scalar.html#t:Scalar" title="Torch.GraduallyTyped.Scalar">Scalar</a> divisor</td><td class="doc empty">&nbsp;</td></tr><tr><td class="src">=&gt; divisor</td><td class="doc"><p>divisor scalar</p></td></tr><tr><td class="src">-&gt; <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> gradient layout device dataType shape</td><td class="doc"><p>dividend tensor</p></td></tr><tr><td class="src">-&gt; <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> gradient layout device dataType shape</td><td class="doc"><p>output tensor</p></td></tr></table></div><div class="doc"><p>Computes the element-wise remainder of the division of
 the tensor <code>dividend</code> by the scalar <code>divisor</code>.
 The dividend and divisor may contain both for integer and floating point numbers.
 The remainder has the same sign as the <code>dividend</code> input.</p><p>See <code><a href="Torch-GraduallyTyped-Tensor-MathOperations-Pointwise.html#v:fmodScalar" title="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise">fmodScalar</a></code> for a version of this function where
 <code>divisor</code> is a scalar.</p></div></div><div class="top"><p class="src"><a id="v:frac" class="def">frac</a> <a href="src/Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#frac" class="link">Source</a> <a href="#v:frac" class="selflink">#</a></p><div class="subs arguments"><p class="caption">Arguments</p><table><tr><td class="src">:: <span class="keyword">forall</span> gradient layout device dataType shape. <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> gradient layout device dataType shape</td><td class="doc"><p>input</p></td></tr><tr><td class="src">-&gt; <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> gradient layout device dataType shape</td><td class="doc"><p>output</p></td></tr></table></div><div class="doc"><p>Computes the fractional portion of each element in <code>input</code>:
 <span class="mathjax">\[
 \mathrm{output}_i = \mathrm{input}_i - \left\lfloor\left|\mathrm{input}_i\right|\right\rfloor \times \sgn\left(\mathrm{input}_i\right).
 \]</span></p></div></div><div class="top"><p class="src"><a id="v:lerp" class="def">lerp</a> <a href="src/Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#lerp" class="link">Source</a> <a href="#v:lerp" class="selflink">#</a></p><div class="subs arguments"><p class="caption">Arguments</p><table><tr><td class="src">:: <span class="keyword">forall</span> gradient layout device dataType shape. <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> gradient layout device dataType shape</td><td class="doc"><p>weight</p></td></tr><tr><td class="src">-&gt; <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> gradient layout device dataType shape</td><td class="doc"><p>start</p></td></tr><tr><td class="src">-&gt; <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> gradient layout device dataType shape</td><td class="doc"><p>end</p></td></tr><tr><td class="src">-&gt; <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> gradient layout device dataType shape</td><td class="doc"><p>output</p></td></tr></table></div><div class="doc"><p>Linear interpolation of two tensors, <code>start</code> and <code>end</code>, based on a tensor <code>weight</code>.
 For linear interpolations based on a scalar see <code><a href="Torch-GraduallyTyped-Tensor-MathOperations-Pointwise.html#v:lerpScalar" title="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise">lerpScalar</a></code>.</p><p>Returned is the result of the following computation as a tensor:
 <span class="mathjax">\[
   \mathrm{output}_i = \mathrm{start}_i + \mathrm{weight}_i \times \left(\mathrm{end}_i - \mathrm{start}_i\right).
 \]</span></p><p>Note that the shapes of <code>start</code>, <code>end</code>, and also <code>weight</code> must be broadcastable.</p></div></div><div class="top"><p class="src"><a id="v:lerpScalar" class="def">lerpScalar</a> <a href="src/Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#lerpScalar" class="link">Source</a> <a href="#v:lerpScalar" class="selflink">#</a></p><div class="subs arguments"><p class="caption">Arguments</p><table><tr><td class="src">:: <span class="keyword">forall</span> weight gradient layout device dataType shape. <a href="Torch-GraduallyTyped-Scalar.html#t:Scalar" title="Torch.GraduallyTyped.Scalar">Scalar</a> weight</td><td class="doc empty">&nbsp;</td></tr><tr><td class="src">=&gt; weight</td><td class="doc"><p>weight</p></td></tr><tr><td class="src">-&gt; <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> gradient layout device dataType shape</td><td class="doc"><p>start</p></td></tr><tr><td class="src">-&gt; <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> gradient layout device dataType shape</td><td class="doc"><p>end</p></td></tr><tr><td class="src">-&gt; <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> gradient layout device dataType shape</td><td class="doc"><p>output</p></td></tr></table></div><div class="doc"><p>Linear interpolation of two tensors, <code>start</code> and <code>end</code>, based on a scalar <code>weight</code>.
 For linear interpolations based on a tensor see <code><a href="Torch-GraduallyTyped-Tensor-MathOperations-Pointwise.html#v:lerp" title="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise">lerp</a></code>.</p><p>Returned is the result of the following computation as a tensor:
 <span class="mathjax">\[
   \mathrm{output}_i = \mathrm{start}_i + \mathrm{weight} \times \left(\mathrm{end}_i - \mathrm{start}_i\right).
 \]</span></p><p>Note that the shapes of <code>start</code> and <code>end</code> must be broadcastable.</p></div></div><div class="top"><p class="src"><a id="v:lgamma" class="def">lgamma</a> <a href="src/Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#lgamma" class="link">Source</a> <a href="#v:lgamma" class="selflink">#</a></p><div class="subs arguments"><p class="caption">Arguments</p><table><tr><td class="src">:: <span class="keyword">forall</span> gradient layout device dataType shape. <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> gradient layout device dataType shape</td><td class="doc"><p>input</p></td></tr><tr><td class="src">-&gt; <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> gradient layout device dataType shape</td><td class="doc"><p>output</p></td></tr></table></div><div class="doc"><p>Computes the logarithm of the gamma function on <code>input</code>:
 <span class="mathjax">\[
 \mathrm{output}_i = \log \Gamma\left(\mathrm{input}_i\right).
 \]</span></p></div></div><div class="top"><p class="src"><a id="v:log" class="def">log</a> <a href="src/Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#log" class="link">Source</a> <a href="#v:log" class="selflink">#</a></p><div class="subs arguments"><p class="caption">Arguments</p><table><tr><td class="src">:: <span class="keyword">forall</span> gradient layout device dataType shape. <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> gradient layout device dataType shape</td><td class="doc"><p>input</p></td></tr><tr><td class="src">-&gt; <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> gradient layout device dataType shape</td><td class="doc"><p>output</p></td></tr></table></div><div class="doc"><p>Returns a new tensor with the natural logarithm of the elements of <code>input</code>:
 <span class="mathjax">\[
 \mathrm{output}_i = \ln \left(\mathrm{input}_i\right) = \log_{\mathrm{e}} \left(\mathrm{input}_i\right).
 \]</span></p></div></div><div class="top"><p class="src"><a id="v:log10" class="def">log10</a> <a href="src/Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#log10" class="link">Source</a> <a href="#v:log10" class="selflink">#</a></p><div class="subs arguments"><p class="caption">Arguments</p><table><tr><td class="src">:: <span class="keyword">forall</span> gradient layout device dataType shape. <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> gradient layout device dataType shape</td><td class="doc"><p>input</p></td></tr><tr><td class="src">-&gt; <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> gradient layout device dataType shape</td><td class="doc"><p>output</p></td></tr></table></div><div class="doc"><p>Returns a new tensor with the decimal logarithm of the elements of <code>input</code>:
 <span class="mathjax">\[
 \mathrm{output}_i = \mathop{lg} \left(\mathrm{input}_i\right) = \log_{10} \left(\mathrm{input}_i\right).
 \]</span></p></div></div><div class="top"><p class="src"><a id="v:log1p" class="def">log1p</a> <a href="src/Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#log1p" class="link">Source</a> <a href="#v:log1p" class="selflink">#</a></p><div class="subs arguments"><p class="caption">Arguments</p><table><tr><td class="src">:: <span class="keyword">forall</span> gradient layout device dataType shape. <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> gradient layout device dataType shape</td><td class="doc"><p>input</p></td></tr><tr><td class="src">-&gt; <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> gradient layout device dataType shape</td><td class="doc"><p>output</p></td></tr></table></div><div class="doc"><p>Returns a new tensor with the natural logarithm of <span class="mathjax">\(1 + \mathrm{input}\)</span>:
 <span class="mathjax">\[
 \mathrm{output}_i = \ln \left(1 + \mathrm{input}_i\right).
 \]</span></p><p>Consider using this function over a literal implementation using <code><a href="Torch-GraduallyTyped-Tensor-MathOperations-Pointwise.html#v:log" title="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise">log</a></code>.
 <code><a href="Torch-GraduallyTyped-Tensor-MathOperations-Pointwise.html#v:log1p" title="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise">log1p</a></code> is much more accurate for small values of <code>input</code>.</p></div></div><div class="top"><p class="src"><a id="v:log2" class="def">log2</a> <a href="src/Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#log2" class="link">Source</a> <a href="#v:log2" class="selflink">#</a></p><div class="subs arguments"><p class="caption">Arguments</p><table><tr><td class="src">:: <span class="keyword">forall</span> gradient layout device dataType shape. <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> gradient layout device dataType shape</td><td class="doc"><p>input</p></td></tr><tr><td class="src">-&gt; <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> gradient layout device dataType shape</td><td class="doc"><p>output</p></td></tr></table></div><div class="doc"><p>Returns a new tensor with the logarithm to the base 2 of the elements of <code>input</code>:
 <span class="mathjax">\[
 \mathrm{output}_i = \log_2 \left(\mathrm{input}_i\right).
 \]</span></p></div></div><div class="top"><p class="src"><a id="v:logaddexp" class="def">logaddexp</a> <a href="src/Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#logaddexp" class="link">Source</a> <a href="#v:logaddexp" class="selflink">#</a></p><div class="subs arguments"><p class="caption">Arguments</p><table><tr><td class="src">:: <span class="keyword">forall</span> gradient layout device dataType shape. <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> gradient layout device dataType shape</td><td class="doc"><p>other</p></td></tr><tr><td class="src">-&gt; <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> gradient layout device dataType shape</td><td class="doc"><p>input</p></td></tr><tr><td class="src">-&gt; <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> gradient layout device dataType shape</td><td class="doc"><p>output</p></td></tr></table></div><div class="doc"><p>Logarithm of the sum of exponentiations of the inputs.
 Calculates pointwise the function <span class="mathjax">\(\log \left(\exp x + \exp y\right)\)</span>.</p><p>This function is useful in statistics where the calculated probabilities of
 events may be so small as to exceed the range of normal floating point numbers.
 In such cases the logarithm of the calculated probability is stored.
 This function allows adding probabilities stored in such a fashion.</p><p><code><a href="Torch-GraduallyTyped-Tensor-MathOperations-Pointwise.html#v:logaddexp" title="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise">logaddexp</a></code> must not be confused with <code>logsumexp</code> which performs a reduction on a single tensor.</p></div></div><div class="top"><p class="src"><a id="v:logaddexp2" class="def">logaddexp2</a> <a href="src/Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#logaddexp2" class="link">Source</a> <a href="#v:logaddexp2" class="selflink">#</a></p><div class="subs arguments"><p class="caption">Arguments</p><table><tr><td class="src">:: <span class="keyword">forall</span> gradient layout device dataType shape. <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> gradient layout device dataType shape</td><td class="doc"><p>other</p></td></tr><tr><td class="src">-&gt; <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> gradient layout device dataType shape</td><td class="doc"><p>input</p></td></tr><tr><td class="src">-&gt; <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> gradient layout device dataType shape</td><td class="doc"><p>output</p></td></tr></table></div><div class="doc"><p>Logarithm of the sum of exponentiations of the inputs in base-2.
 Calculates pointwise the function <span class="mathjax">\(\log_2 \left(2^x + 2^y\right)\)</span>.</p><p>See <code><a href="Torch-GraduallyTyped-Tensor-MathOperations-Pointwise.html#v:logaddexp" title="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise">logaddexp</a></code> for further details.</p></div></div><div class="top"><p class="src"><a id="v:logicalAnd" class="def">logicalAnd</a> <a href="src/Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#logicalAnd" class="link">Source</a> <a href="#v:logicalAnd" class="selflink">#</a></p><div class="subs arguments"><p class="caption">Arguments</p><table><tr><td class="src">:: <span class="keyword">forall</span> gradient layout device dataType shape. <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> gradient layout device dataType shape</td><td class="doc"><p>the input tensor</p></td></tr><tr><td class="src">-&gt; <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> gradient layout device dataType shape</td><td class="doc"><p>the tensor to compute AND with</p></td></tr><tr><td class="src">-&gt; <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> gradient layout device ('<a href="Torch-GraduallyTyped-DType.html#v:DataType" title="Torch.GraduallyTyped.DType">DataType</a> '<a href="Torch-GraduallyTyped-DType.html#v:Bool" title="Torch.GraduallyTyped.DType">Bool</a>) shape</td><td class="doc"><p>the output tensor</p></td></tr></table></div><div class="doc"><p>Computes the element-wise logical AND of the given input tensors.
 The output tensor will have the <code>Bool</code> data type.
 If the input tensors are not a bool tensors,
 then zeros are treated as <code>False</code> and nonzeros are treated as <code>True</code>.</p></div></div><div class="top"><p class="src"><a id="v:logicalNot" class="def">logicalNot</a> <a href="src/Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#logicalNot" class="link">Source</a> <a href="#v:logicalNot" class="selflink">#</a></p><div class="subs arguments"><p class="caption">Arguments</p><table><tr><td class="src">:: <span class="keyword">forall</span> gradient layout device dataType shape. <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> gradient layout device dataType shape</td><td class="doc"><p>the input tensor</p></td></tr><tr><td class="src">-&gt; <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> ('<a href="Torch-GraduallyTyped-RequiresGradient.html#v:Gradient" title="Torch.GraduallyTyped.RequiresGradient">Gradient</a> '<a href="Torch-GraduallyTyped-RequiresGradient.html#v:WithoutGradient" title="Torch.GraduallyTyped.RequiresGradient">WithoutGradient</a>) layout device ('<a href="Torch-GraduallyTyped-DType.html#v:DataType" title="Torch.GraduallyTyped.DType">DataType</a> '<a href="Torch-GraduallyTyped-DType.html#v:Bool" title="Torch.GraduallyTyped.DType">Bool</a>) shape</td><td class="doc"><p>the output tensor</p></td></tr></table></div><div class="doc"><p>Computes the element-wise logical NOT of the given input tensor.
 The output tensor will have the <code>Bool</code> data type.
 If the input tensor is not a bool tensor,
 zeros are treated as <code>False</code> and non-zeros are treated as <code>True</code>.</p></div></div><div class="top"><p class="src"><a id="v:logicalOr" class="def">logicalOr</a> <a href="src/Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#logicalOr" class="link">Source</a> <a href="#v:logicalOr" class="selflink">#</a></p><div class="subs arguments"><p class="caption">Arguments</p><table><tr><td class="src">:: <span class="keyword">forall</span> gradient layout device dataType shape gradient' layout' device' dataType' shape'. <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> gradient layout device dataType shape</td><td class="doc"><p>the input tensor</p></td></tr><tr><td class="src">-&gt; <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> gradient' layout' device' dataType' shape'</td><td class="doc"><p>the tensor to compute OR with</p></td></tr><tr><td class="src">-&gt; <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> ('<a href="Torch-GraduallyTyped-RequiresGradient.html#v:Gradient" title="Torch.GraduallyTyped.RequiresGradient">Gradient</a> '<a href="Torch-GraduallyTyped-RequiresGradient.html#v:WithoutGradient" title="Torch.GraduallyTyped.RequiresGradient">WithoutGradient</a>) (layout <a href="Torch-GraduallyTyped-Unify.html#t:-60--43--62-" title="Torch.GraduallyTyped.Unify">&lt;+&gt;</a> layout') (device <a href="Torch-GraduallyTyped-Unify.html#t:-60--43--62-" title="Torch.GraduallyTyped.Unify">&lt;+&gt;</a> device') ('<a href="Torch-GraduallyTyped-DType.html#v:DataType" title="Torch.GraduallyTyped.DType">DataType</a> '<a href="Torch-GraduallyTyped-DType.html#v:Bool" title="Torch.GraduallyTyped.DType">Bool</a>) (<a href="Torch-GraduallyTyped-Shape-Class.html#t:BroadcastShapesF" title="Torch.GraduallyTyped.Shape.Class">BroadcastShapesF</a> shape shape')</td><td class="doc"><p>the output tensor</p></td></tr></table></div><div class="doc"><p>Computes the element-wise logical OR of the given input tensors.
 The output tensor will have the <code>Bool</code> data type.
 If the input tensors are not a bool tensors,
 then zeros are treated as <code>False</code> and nonzeros are treated as <code>True</code>.</p></div></div><div class="top"><p class="src"><a id="v:logicalXor" class="def">logicalXor</a> <a href="src/Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#logicalXor" class="link">Source</a> <a href="#v:logicalXor" class="selflink">#</a></p><div class="subs arguments"><p class="caption">Arguments</p><table><tr><td class="src">:: <span class="keyword">forall</span> gradient layout device dataType shape. <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> gradient layout device dataType shape</td><td class="doc"><p>the input tensor</p></td></tr><tr><td class="src">-&gt; <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> gradient layout device dataType shape</td><td class="doc"><p>the tensor to compute XOR with</p></td></tr><tr><td class="src">-&gt; <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> gradient layout device ('<a href="Torch-GraduallyTyped-DType.html#v:DataType" title="Torch.GraduallyTyped.DType">DataType</a> '<a href="Torch-GraduallyTyped-DType.html#v:Bool" title="Torch.GraduallyTyped.DType">Bool</a>) shape</td><td class="doc"><p>the output tensor</p></td></tr></table></div><div class="doc"><p>Computes the element-wise logical XOR of the given input tensors.
 The output tensor will have the <code>Bool</code> data type.
 If the input tensors are not a bool tensors,
 then zeros are treated as <code>False</code> and nonzeros are treated as <code>True</code>.</p></div></div><div class="top"><p class="src"><a id="v:mul" class="def">mul</a> <a href="src/Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#mul" class="link">Source</a> <a href="#v:mul" class="selflink">#</a></p><div class="subs arguments"><p class="caption">Arguments</p><table><tr><td class="src">:: <span class="keyword">forall</span> gradient layout device dataType shape gradient' layout' device' dataType' shape'. <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> gradient layout device dataType shape</td><td class="doc"><p>input tensor</p></td></tr><tr><td class="src">-&gt; <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> gradient' layout' device' dataType' shape'</td><td class="doc"><p>other tensor</p></td></tr><tr><td class="src">-&gt; <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> (gradient <a href="Torch-GraduallyTyped-Unify.html#t:-60--124--62-" title="Torch.GraduallyTyped.Unify">&lt;|&gt;</a> gradient') (layout <a href="Torch-GraduallyTyped-Unify.html#t:-60--43--62-" title="Torch.GraduallyTyped.Unify">&lt;+&gt;</a> layout') (device <a href="Torch-GraduallyTyped-Unify.html#t:-60--43--62-" title="Torch.GraduallyTyped.Unify">&lt;+&gt;</a> device') (dataType <a href="Torch-GraduallyTyped-Unify.html#t:-60--43--62-" title="Torch.GraduallyTyped.Unify">&lt;+&gt;</a> dataType') (<a href="Torch-GraduallyTyped-Shape-Class.html#t:BroadcastShapesF" title="Torch.GraduallyTyped.Shape.Class">BroadcastShapesF</a> shape shape')</td><td class="doc"><p>output tensor</p></td></tr></table></div><div class="doc"><p>Element-wise multiplication of two tensors:
 <span class="mathjax">\[
 \mathrm{output}_i = \mathrm{input}_i \times \mathrm{other}_i.
 \]</span>
 The result is returned as a new tensor.</p><p>The shape of <code>other</code> must be broadcastable with the shape of <code>input</code>.
 See <code><a href="Torch-GraduallyTyped-Tensor-MathOperations-Pointwise.html#v:mulScalar" title="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise">mulScalar</a></code> for a version of this function where
 the <code>other</code> input is a scalar.</p></div></div><div class="top"><p class="src"><a id="v:mulScalar" class="def">mulScalar</a> <a href="src/Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#mulScalar" class="link">Source</a> <a href="#v:mulScalar" class="selflink">#</a></p><div class="subs arguments"><p class="caption">Arguments</p><table><tr><td class="src">:: <span class="keyword">forall</span> other gradient layout device dataType shape. <a href="Torch-GraduallyTyped-Scalar.html#t:Scalar" title="Torch.GraduallyTyped.Scalar">Scalar</a> other</td><td class="doc empty">&nbsp;</td></tr><tr><td class="src">=&gt; <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> gradient layout device dataType shape</td><td class="doc"><p>tensor input</p></td></tr><tr><td class="src">-&gt; other</td><td class="doc"><p>scalar other input</p></td></tr><tr><td class="src">-&gt; <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> gradient layout device dataType shape</td><td class="doc"><p>tensor output</p></td></tr></table></div></div><div class="top"><p class="src"><a id="v:mvlgamma" class="def">mvlgamma</a> <a href="src/Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#mvlgamma" class="link">Source</a> <a href="#v:mvlgamma" class="selflink">#</a></p><div class="subs arguments"><p class="caption">Arguments</p><table><tr><td class="src">:: <span class="keyword">forall</span> gradient layout device dataType shape. Int</td><td class="doc"><p>the number of dimensions <code>p</code></p></td></tr><tr><td class="src">-&gt; <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> gradient layout device dataType shape</td><td class="doc"><p>the input tensor to compute the the multivariate log-gamma function for</p></td></tr><tr><td class="src">-&gt; <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> gradient layout device dataType shape</td><td class="doc"><p>the output tensor</p></td></tr></table></div><div class="doc"><p>Computes the multivariate log-gamma function with dimension <code>p</code> element-wise, given by
 <span class="mathjax">\[
 \log(\Gamma_p(\mathrm{input})) = C + \sum_{i=1}^{p} \log \left(\Gamma\left(\mathrm{input} - \frac{i-1}{2}\right)\right)
 \]</span>
 where <span class="mathjax">\(C = \log(\pi) \times \frac{p(p-1)}{4}\)</span> and <span class="mathjax">\(\Gamma(\dot)\)</span> is the gamma function.</p><p>All elements of the input tensor must be greater than <span class="mathjax">\(\frac{p-1}{2}\)</span>.
 Otherwise, the computation is halted and an exception is thrown.</p></div></div><div class="top"><p class="src"><a id="v:neg" class="def">neg</a> <a href="src/Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#neg" class="link">Source</a> <a href="#v:neg" class="selflink">#</a></p><div class="subs arguments"><p class="caption">Arguments</p><table><tr><td class="src">:: <span class="keyword">forall</span> gradient layout device dataType shape. <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> gradient layout device dataType shape</td><td class="doc"><p>input</p></td></tr><tr><td class="src">-&gt; <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> gradient layout device dataType shape</td><td class="doc"><p>output</p></td></tr></table></div><div class="doc"><p>Returns a new tensor with the negative of the elements of <code>input</code>:
 <span class="mathjax">\[
 \mathrm{output}_i = - \mathrm{input}_i.
 \]</span></p></div></div><div class="top"><p class="src"><a id="v:polygamma" class="def">polygamma</a> <a href="src/Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#polygamma" class="link">Source</a> <a href="#v:polygamma" class="selflink">#</a></p><div class="subs arguments"><p class="caption">Arguments</p><table><tr><td class="src">:: <span class="keyword">forall</span> gradient layout device dataType shape. Int</td><td class="doc"><p>the order of the polygamma function</p></td></tr><tr><td class="src">-&gt; <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> gradient layout device dataType shape</td><td class="doc"><p>the input tensor</p></td></tr><tr><td class="src">-&gt; <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> gradient layout device dataType shape</td><td class="doc"><p>the output tensor</p></td></tr></table></div><div class="doc"><p>Computes the <span class="mathjax">\(n\)</span>-th derivative of the digamma function <span class="mathjax">\(\psi\)</span> on the <code>input</code>,
 where <span class="mathjax">\(n \ge 0\)</span>.
 <span class="mathjax">\(n\)</span> is called the order of the polygamma function <span class="mathjax">\(\psi^{(n)}\)</span>
 that is defined as:
 <span class="mathjax">\[
 \psi^{(n)}(\mathrm{input}) = \frac{d^{(n)}}{d\mathrm{input}^{(n)}} \psi(\mathrm{input})
 \]</span>
 where <span class="mathjax">\(\psi(\mathrm{input}) = \log(\Gamma(\mathrm{input}))\)</span>.</p></div></div><div class="top"><p class="src"><a id="v:pow" class="def">pow</a> <a href="src/Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#pow" class="link">Source</a> <a href="#v:pow" class="selflink">#</a></p><div class="subs arguments"><p class="caption">Arguments</p><table><tr><td class="src">:: <span class="keyword">forall</span> gradient layout device dataType shape gradient' layout' device' dataType' shape'. <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> gradient' layout' device' dataType' shape'</td><td class="doc"><p>tensor input</p></td></tr><tr><td class="src">-&gt; <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> gradient layout device dataType shape</td><td class="doc"><p>tensor exponent</p></td></tr><tr><td class="src">-&gt; <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> (gradient <a href="Torch-GraduallyTyped-Unify.html#t:-60--124--62-" title="Torch.GraduallyTyped.Unify">&lt;|&gt;</a> gradient') (layout <a href="Torch-GraduallyTyped-Unify.html#t:-60--43--62-" title="Torch.GraduallyTyped.Unify">&lt;+&gt;</a> layout') (device <a href="Torch-GraduallyTyped-Unify.html#t:-60--43--62-" title="Torch.GraduallyTyped.Unify">&lt;+&gt;</a> device') (dataType <a href="Torch-GraduallyTyped-Unify.html#t:-60--43--62-" title="Torch.GraduallyTyped.Unify">&lt;+&gt;</a> dataType') (<a href="Torch-GraduallyTyped-Shape-Class.html#t:BroadcastShapesF" title="Torch.GraduallyTyped.Shape.Class">BroadcastShapesF</a> shape shape')</td><td class="doc"><p>tensor output</p></td></tr></table></div><div class="doc"><p>Takes the power of each element in the tensor <code>input</code>
 with the corresponding element in the tensor <code>exponent</code> and
 returns a tensor with the result.</p><p>Note that the <code>exponent</code> and the <code>input</code> must be tensors
 with broadcastable shapes.
 See <code><a href="Torch-GraduallyTyped-Tensor-MathOperations-Pointwise.html#v:powScalar" title="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise">powScalar</a></code> for a version that takes a scalar <code>exponent</code> as argument
 and <code><a href="Torch-GraduallyTyped-Tensor-MathOperations-Pointwise.html#v:powTensor" title="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise">powTensor</a></code> for a version where the <code>input</code> is a scalar and the <code>exponent</code> a tensor.</p><p>The following operation is applied:
 <span class="mathjax">\[
 \mathrm{output}_i = \mathrm{input}_i^{\mathrm{exponent}_i}.
 \]</span></p></div></div><div class="top"><p class="src"><a id="v:powScalar" class="def">powScalar</a> <a href="src/Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#powScalar" class="link">Source</a> <a href="#v:powScalar" class="selflink">#</a></p><div class="subs arguments"><p class="caption">Arguments</p><table><tr><td class="src">:: <span class="keyword">forall</span> exponent gradient layout device dataType shape. <a href="Torch-GraduallyTyped-Scalar.html#t:Scalar" title="Torch.GraduallyTyped.Scalar">Scalar</a> exponent</td><td class="doc empty">&nbsp;</td></tr><tr><td class="src">=&gt; <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> gradient layout device dataType shape</td><td class="doc"><p>tensor input</p></td></tr><tr><td class="src">-&gt; exponent</td><td class="doc"><p>scalar exponent</p></td></tr><tr><td class="src">-&gt; <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> gradient layout device dataType shape</td><td class="doc"><p>tensor output</p></td></tr></table></div><div class="doc"><p>Takes the power of each element in the tensor <code>input</code> with the scalar <code>exponent</code> and
 returns a tensor with the result.</p><p>Note that the <code>exponent</code> is a scalar.
 See <code><a href="Torch-GraduallyTyped-Tensor-MathOperations-Pointwise.html#v:pow" title="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise">pow</a></code> for a version that takes a tensor <code>exponent</code> as argument
 and <code><a href="Torch-GraduallyTyped-Tensor-MathOperations-Pointwise.html#v:powTensor" title="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise">powTensor</a></code> for a version where the <code>input</code> is a scalar and the <code>exponent</code> a tensor.</p><p>The following operation is applied:
 <span class="mathjax">\[
 \mathrm{output}_i = \mathrm{input}_i^{\mathrm{exponent}}.
 \]</span></p></div></div><div class="top"><p class="src"><a id="v:powTensor" class="def">powTensor</a> <a href="src/Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#powTensor" class="link">Source</a> <a href="#v:powTensor" class="selflink">#</a></p><div class="subs arguments"><p class="caption">Arguments</p><table><tr><td class="src">:: <span class="keyword">forall</span> input gradient layout device dataType shape. <a href="Torch-GraduallyTyped-Scalar.html#t:Scalar" title="Torch.GraduallyTyped.Scalar">Scalar</a> input</td><td class="doc empty">&nbsp;</td></tr><tr><td class="src">=&gt; input</td><td class="doc"><p>scalar input</p></td></tr><tr><td class="src">-&gt; <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> gradient layout device dataType shape</td><td class="doc"><p>tensor exponent</p></td></tr><tr><td class="src">-&gt; <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> gradient layout device dataType shape</td><td class="doc"><p>tensor output</p></td></tr></table></div><div class="doc"><p>Takes the power of the scalar <code>input</code> with each element in the tensor <code>exponent</code> and
 returns a tensor with the result.</p><p>Note that the <code>exponent</code> is a tensor while the <code>input</code> is a scalar.
 See <code><a href="Torch-GraduallyTyped-Tensor-MathOperations-Pointwise.html#v:pow" title="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise">pow</a></code> for a version that takes a tensor <code>input</code> as argument
 and <code><a href="Torch-GraduallyTyped-Tensor-MathOperations-Pointwise.html#v:powScalar" title="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise">powScalar</a></code> for a version where the <code>input</code> is a tensor and the <code>exponent</code> a scalar.</p><p>The following operation is applied:
 <span class="mathjax">\[
 \mathrm{output}_i = \mathrm{input}^{\mathrm{exponent}_i}.
 \]</span></p></div></div><div class="top"><p class="src"><a id="v:rad2deg" class="def">rad2deg</a> <a href="src/Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#rad2deg" class="link">Source</a> <a href="#v:rad2deg" class="selflink">#</a></p><div class="subs arguments"><p class="caption">Arguments</p><table><tr><td class="src">:: <span class="keyword">forall</span> gradient layout device dataType shape. <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> gradient layout device dataType shape</td><td class="doc"><p>input</p></td></tr><tr><td class="src">-&gt; <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> gradient layout device dataType shape</td><td class="doc"><p>output</p></td></tr></table></div><div class="doc"><p>Returns a new tensor with each of the elements of <code>input</code>
 converted from angles in radians to degrees.</p></div></div><div class="top"><p class="src"><a id="v:reciprocal" class="def">reciprocal</a> <a href="src/Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#reciprocal" class="link">Source</a> <a href="#v:reciprocal" class="selflink">#</a></p><div class="subs arguments"><p class="caption">Arguments</p><table><tr><td class="src">:: <span class="keyword">forall</span> gradient layout device dataType shape. <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> gradient layout device dataType shape</td><td class="doc"><p>input</p></td></tr><tr><td class="src">-&gt; <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> gradient layout device dataType shape</td><td class="doc"><p>output</p></td></tr></table></div><div class="doc"><p>Returns a new tensor with the reciprocal of the elements of <code>input</code>:
 <span class="mathjax">\[
 \mathrm{output}_i = \frac{1}{\mathrm{input}_i}
 \]</span></p></div></div><div class="top"><p class="src"><a id="v:remainder" class="def">remainder</a> <a href="src/Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#remainder" class="link">Source</a> <a href="#v:remainder" class="selflink">#</a></p><div class="subs arguments"><p class="caption">Arguments</p><table><tr><td class="src">:: <span class="keyword">forall</span> gradient layout device dataType shape. <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> gradient layout device dataType shape</td><td class="doc"><p>dividend</p></td></tr><tr><td class="src">-&gt; <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> gradient layout device dataType shape</td><td class="doc"><p>divisor</p></td></tr><tr><td class="src">-&gt; <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> gradient layout device dataType shape</td><td class="doc empty">&nbsp;</td></tr></table></div><div class="doc"><p>Computes the element-wise remainder of division.</p><p>The dividend and divisor may contain integer and floating point numbers.
 The remainder has the same sign as the divisor other.</p><p>When other is a tensor, the shapes of input and other must be broadcastable.</p></div></div><div class="top"><p class="src"><a id="v:round" class="def">round</a> <a href="src/Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#round" class="link">Source</a> <a href="#v:round" class="selflink">#</a></p><div class="subs arguments"><p class="caption">Arguments</p><table><tr><td class="src">:: <span class="keyword">forall</span> gradient layout device dataType shape. <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> gradient layout device dataType shape</td><td class="doc"><p>input</p></td></tr><tr><td class="src">-&gt; <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> gradient layout device dataType shape</td><td class="doc"><p>output</p></td></tr></table></div><div class="doc"><p>Returns a new tensor with each of the elements of <code>input</code> rounded to the closest integer.
 Note that the data type is unchanged.</p></div></div><div class="top"><p class="src"><a id="v:rsqrt" class="def">rsqrt</a> <a href="src/Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#rsqrt" class="link">Source</a> <a href="#v:rsqrt" class="selflink">#</a></p><div class="subs arguments"><p class="caption">Arguments</p><table><tr><td class="src">:: <span class="keyword">forall</span> gradient layout device dataType shape. <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> gradient layout device dataType shape</td><td class="doc"><p>input</p></td></tr><tr><td class="src">-&gt; <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> gradient layout device dataType shape</td><td class="doc"><p>output</p></td></tr></table></div><div class="doc"><p>Returns a new tensor with the reciprocal of the square-root of
 each of the elements of <code>input</code>:
 <span class="mathjax">\[
 \mathrm{output}_i = \frac{1}{\sqrt{\mathrm{input}_i}}.
 \]</span></p></div></div><div class="top"><p class="src"><a id="v:sigmoid" class="def">sigmoid</a> <a href="src/Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#sigmoid" class="link">Source</a> <a href="#v:sigmoid" class="selflink">#</a></p><div class="subs arguments"><p class="caption">Arguments</p><table><tr><td class="src">:: <span class="keyword">forall</span> gradient layout device dataType shape. <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> gradient layout device dataType shape</td><td class="doc"><p>input</p></td></tr><tr><td class="src">-&gt; <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> gradient layout device dataType shape</td><td class="doc"><p>output</p></td></tr></table></div><div class="doc"><p>Returns a new tensor with the sigmoid of the elements of <code>input</code>:
 <span class="mathjax">\[
 \mathrm{output}_i = \frac{1}{1 + \exp \left(-\mathrm{input}_i\right)}
 \]</span></p></div></div><div class="top"><p class="src"><a id="v:sign" class="def">sign</a> <a href="src/Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#sign" class="link">Source</a> <a href="#v:sign" class="selflink">#</a></p><div class="subs arguments"><p class="caption">Arguments</p><table><tr><td class="src">:: <span class="keyword">forall</span> gradient layout device dataType shape. <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> gradient layout device dataType shape</td><td class="doc"><p>input</p></td></tr><tr><td class="src">-&gt; <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> gradient layout device dataType shape</td><td class="doc"><p>output</p></td></tr></table></div><div class="doc"><p>Returns a new tensor with the signs of the elements of <code>input</code>:
 <span class="mathjax">\[
 \mathrm{output}_i = \begin{cases}
   -1 &amp; \text{if } \mathrm{input}_i &lt; 0 \\
   0  &amp; \text{if } \mathrm{input}_i = 0 \\
   1  &amp; \text{if } \mathrm{input}_i &gt; 0.
 \end{cases}
 \]</span></p></div></div><div class="top"><p class="src"><a id="v:sin" class="def">sin</a> <a href="src/Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#sin" class="link">Source</a> <a href="#v:sin" class="selflink">#</a></p><div class="subs arguments"><p class="caption">Arguments</p><table><tr><td class="src">:: <span class="keyword">forall</span> gradient layout device dataType shape. <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> gradient layout device dataType shape</td><td class="doc"><p>input</p></td></tr><tr><td class="src">-&gt; <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> gradient layout device dataType shape</td><td class="doc"><p>output</p></td></tr></table></div><div class="doc"><p>Returns a new tensor with the sine of the elements of <code>input</code>:
 <span class="mathjax">\[
 \mathrm{output}_i = \sin \left(\mathrm{input}_i\right).
 \]</span></p></div></div><div class="top"><p class="src"><a id="v:sinh" class="def">sinh</a> <a href="src/Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#sinh" class="link">Source</a> <a href="#v:sinh" class="selflink">#</a></p><div class="subs arguments"><p class="caption">Arguments</p><table><tr><td class="src">:: <span class="keyword">forall</span> gradient layout device dataType shape. <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> gradient layout device dataType shape</td><td class="doc"><p>input</p></td></tr><tr><td class="src">-&gt; <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> gradient layout device dataType shape</td><td class="doc"><p>output</p></td></tr></table></div><div class="doc"><p>Returns a new tensor with the hyperbolic sine of the elements of <code>input</code>:
 <span class="mathjax">\[
 \mathrm{output}_i = \sinh \left(\mathrm{input}_i\right).
 \]</span></p></div></div><div class="top"><p class="src"><a id="v:sub" class="def">sub</a> <a href="src/Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#sub" class="link">Source</a> <a href="#v:sub" class="selflink">#</a></p><div class="subs arguments"><p class="caption">Arguments</p><table><tr><td class="src">:: <span class="keyword">forall</span> gradient layout device dataType shape gradient' layout' device' dataType' shape'. <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> gradient layout device dataType shape</td><td class="doc"><p>input tensor</p></td></tr><tr><td class="src">-&gt; <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> gradient' layout' device' dataType' shape'</td><td class="doc"><p>other tensor</p></td></tr><tr><td class="src">-&gt; <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> (gradient <a href="Torch-GraduallyTyped-Unify.html#t:-60--124--62-" title="Torch.GraduallyTyped.Unify">&lt;|&gt;</a> gradient) (layout <a href="Torch-GraduallyTyped-Unify.html#t:-60--43--62-" title="Torch.GraduallyTyped.Unify">&lt;+&gt;</a> layout') (device <a href="Torch-GraduallyTyped-Unify.html#t:-60--43--62-" title="Torch.GraduallyTyped.Unify">&lt;+&gt;</a> device') (dataType <a href="Torch-GraduallyTyped-Unify.html#t:-60--43--62-" title="Torch.GraduallyTyped.Unify">&lt;+&gt;</a> dataType') (<a href="Torch-GraduallyTyped-Shape-Class.html#t:BroadcastShapesF" title="Torch.GraduallyTyped.Shape.Class">BroadcastShapesF</a> shape shape')</td><td class="doc"><p>output tensor</p></td></tr></table></div><div class="doc"><p>Element-wise subtraction of one tensor from another:
 <span class="mathjax">\[
 \mathrm{output}_i = \mathrm{input}_i - \mathrm{other}_i.
 \]</span>
 The result is returned as a new tensor.</p><p>The shape of <code>other</code> must be broadcastable with the shape of <code>input</code>.
 See <code><a href="Torch-GraduallyTyped-Tensor-MathOperations-Pointwise.html#v:subScalar" title="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise">subScalar</a></code> for a version of this function where
 the <code>other</code> input is a scalar.</p></div></div><div class="top"><p class="src"><a id="v:subScalar" class="def">subScalar</a> <a href="src/Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#subScalar" class="link">Source</a> <a href="#v:subScalar" class="selflink">#</a></p><div class="subs arguments"><p class="caption">Arguments</p><table><tr><td class="src">:: <span class="keyword">forall</span> other gradient layout device dataType shape. <a href="Torch-GraduallyTyped-Scalar.html#t:Scalar" title="Torch.GraduallyTyped.Scalar">Scalar</a> other</td><td class="doc empty">&nbsp;</td></tr><tr><td class="src">=&gt; <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> gradient layout device dataType shape</td><td class="doc"><p>input tensor</p></td></tr><tr><td class="src">-&gt; other</td><td class="doc"><p>input scalar</p></td></tr><tr><td class="src">-&gt; <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> gradient layout device dataType shape</td><td class="doc"><p>output tensor</p></td></tr></table></div><div class="doc"><p>Subtracts a scalar <code>other</code> from a tensor <code>input</code>:
 <span class="mathjax">\[
 \mathrm{output}_i = \mathrm{input}_i - \mathrm{other}.
 \]</span>
 The result is returned as a new tensor.
 See <code><a href="Torch-GraduallyTyped-Tensor-MathOperations-Pointwise.html#v:sub" title="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise">sub</a></code> for a version of this function where
 the second argument is a tensor.</p></div></div><div class="top"><p class="src"><a id="v:sqrt" class="def">sqrt</a> <a href="src/Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#sqrt" class="link">Source</a> <a href="#v:sqrt" class="selflink">#</a></p><div class="subs arguments"><p class="caption">Arguments</p><table><tr><td class="src">:: <span class="keyword">forall</span> gradient layout device dataType shape. <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> gradient layout device dataType shape</td><td class="doc"><p>input</p></td></tr><tr><td class="src">-&gt; <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> gradient layout device dataType shape</td><td class="doc"><p>output</p></td></tr></table></div><div class="doc"><p>Returns a new tensor with the square-root of the elements of <code>input</code>:
 <span class="mathjax">\[
 \mathrm{output}_i = \sqrt{\mathrm{input}_i}.
 \]</span></p></div></div><div class="top"><p class="src"><a id="v:square" class="def">square</a> <a href="src/Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#square" class="link">Source</a> <a href="#v:square" class="selflink">#</a></p><div class="subs arguments"><p class="caption">Arguments</p><table><tr><td class="src">:: <span class="keyword">forall</span> gradient layout device dataType shape. <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> gradient layout device dataType shape</td><td class="doc"><p>input</p></td></tr><tr><td class="src">-&gt; <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> gradient layout device dataType shape</td><td class="doc"><p>output</p></td></tr></table></div><div class="doc"><p>Returns a new tensor with the square of the elements of <code>input</code>:
 <span class="mathjax">\[
 \mathrm{output}_i = \mathrm{input}_i^2.
 \]</span></p><p>See <code><a href="Torch-GraduallyTyped-Tensor-MathOperations-Pointwise.html#v:pow" title="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise">pow</a></code>, <code><a href="Torch-GraduallyTyped-Tensor-MathOperations-Pointwise.html#v:powScalar" title="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise">powScalar</a></code>, or <code><a href="Torch-GraduallyTyped-Tensor-MathOperations-Pointwise.html#v:powTensor" title="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise">powTensor</a></code> for exponentiation with respect to arbitrary exponents.</p></div></div><div class="top"><p class="src"><a id="v:tan" class="def">tan</a> <a href="src/Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#tan" class="link">Source</a> <a href="#v:tan" class="selflink">#</a></p><div class="subs arguments"><p class="caption">Arguments</p><table><tr><td class="src">:: <span class="keyword">forall</span> gradient layout device dataType shape. <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> gradient layout device dataType shape</td><td class="doc"><p>input</p></td></tr><tr><td class="src">-&gt; <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> gradient layout device dataType shape</td><td class="doc"><p>output</p></td></tr></table></div><div class="doc"><p>Returns a new tensor with the tangent of the elements of <code>input</code>:
 <span class="mathjax">\[
 \mathrm{output}_i = \tan \left(\mathrm{input}_i\right).
 \]</span></p></div></div><div class="top"><p class="src"><a id="v:tanh" class="def">tanh</a> <a href="src/Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#tanh" class="link">Source</a> <a href="#v:tanh" class="selflink">#</a></p><div class="subs arguments"><p class="caption">Arguments</p><table><tr><td class="src">:: <span class="keyword">forall</span> gradient layout device dataType shape. <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> gradient layout device dataType shape</td><td class="doc"><p>input</p></td></tr><tr><td class="src">-&gt; <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> gradient layout device dataType shape</td><td class="doc"><p>output</p></td></tr></table></div><div class="doc"><p>Returns a new tensor with the hyperbolic tangent of the elements of <code>input</code>:
 <span class="mathjax">\[
 \mathrm{output}_i = \tanh \left(\mathrm{input}_i\right).
 \]</span></p></div></div><div class="top"><p class="src"><a id="v:trueDivide" class="def">trueDivide</a> <a href="src/Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#trueDivide" class="link">Source</a> <a href="#v:trueDivide" class="selflink">#</a></p><div class="subs arguments"><p class="caption">Arguments</p><table><tr><td class="src">:: <span class="keyword">forall</span> gradient layout device dataType shape gradient' layout' device' dataType' shape'. <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> gradient layout device dataType shape</td><td class="doc"><p>tensor dividend</p></td></tr><tr><td class="src">-&gt; <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> gradient' layout' device' dataType' shape'</td><td class="doc"><p>tensor divisor</p></td></tr><tr><td class="src">-&gt; <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> (gradient <a href="Torch-GraduallyTyped-Unify.html#t:-60--124--62-" title="Torch.GraduallyTyped.Unify">&lt;|&gt;</a> gradient') (layout <a href="Torch-GraduallyTyped-Unify.html#t:-60--43--62-" title="Torch.GraduallyTyped.Unify">&lt;+&gt;</a> layout') (device <a href="Torch-GraduallyTyped-Unify.html#t:-60--43--62-" title="Torch.GraduallyTyped.Unify">&lt;+&gt;</a> device') (dataType <a href="Torch-GraduallyTyped-Unify.html#t:-60--43--62-" title="Torch.GraduallyTyped.Unify">&lt;+&gt;</a> dataType') (shape <a href="Torch-GraduallyTyped-Unify.html#t:-60--43--62-" title="Torch.GraduallyTyped.Unify">&lt;+&gt;</a> shape')</td><td class="doc"><p>tensor output</p></td></tr></table></div><div class="doc"><p>Performs &#8220;true division&#8221;
 that always computes the division in floating point:
 <span class="mathjax">\[
 \mathrm{output}_i = \frac{\mathrm{dividend}_i}{\mathrm{divisor}_i}.
 \]</span></p><p><code><a href="Torch-GraduallyTyped-Tensor-MathOperations-Pointwise.html#v:trueDivide" title="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise">trueDivide</a></code> is completely equivalent to division using <code><a href="Torch-GraduallyTyped-Tensor-MathOperations-Pointwise.html#v:div" title="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise">div</a></code>
 except when both inputs have <code>Bool</code> or integer data types,
 in which case the inputs are converted to floating data types
 before performing the division.</p><p>See <code><a href="Torch-GraduallyTyped-Tensor-MathOperations-Pointwise.html#v:trueDivideScalar" title="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise">trueDivideScalar</a></code> for a version of this function
 where the divisor is a scalar.</p></div></div><div class="top"><p class="src"><a id="v:trueDivideScalar" class="def">trueDivideScalar</a> <a href="src/Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#trueDivideScalar" class="link">Source</a> <a href="#v:trueDivideScalar" class="selflink">#</a></p><div class="subs arguments"><p class="caption">Arguments</p><table><tr><td class="src">:: <span class="keyword">forall</span> other gradient layout device dataType shape. <a href="Torch-GraduallyTyped-Scalar.html#t:Scalar" title="Torch.GraduallyTyped.Scalar">Scalar</a> other</td><td class="doc empty">&nbsp;</td></tr><tr><td class="src">=&gt; <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> gradient layout device dataType shape</td><td class="doc"><p>tensor dividend</p></td></tr><tr><td class="src">-&gt; other</td><td class="doc"><p>scalar divisor</p></td></tr><tr><td class="src">-&gt; <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> gradient layout device dataType shape</td><td class="doc"><p>tensor output</p></td></tr></table></div><div class="doc"><p>Performs &#8220;true division&#8221;
 that always computes the division in floating point:
 <span class="mathjax">\[
 \mathrm{output}_i = \frac{\mathrm{dividend}_i}{\mathrm{divisor}}.
 \]</span></p><p><code><a href="Torch-GraduallyTyped-Tensor-MathOperations-Pointwise.html#v:trueDivideScalar" title="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise">trueDivideScalar</a></code> is completely equivalent to division using <code><a href="Torch-GraduallyTyped-Tensor-MathOperations-Pointwise.html#v:divScalar" title="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise">divScalar</a></code>
 except when both inputs have <code>Bool</code> or integer data types,
 in which case the inputs are converted to floating data types
 before performing the division.</p><p>See <code><a href="Torch-GraduallyTyped-Tensor-MathOperations-Pointwise.html#v:trueDivide" title="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise">trueDivide</a></code> for a version of this function
 where the divisor is a tensor.</p></div></div><div class="top"><p class="src"><a id="v:trunc" class="def">trunc</a> <a href="src/Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#trunc" class="link">Source</a> <a href="#v:trunc" class="selflink">#</a></p><div class="subs arguments"><p class="caption">Arguments</p><table><tr><td class="src">:: <span class="keyword">forall</span> gradient layout device dataType shape. <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> gradient layout device dataType shape</td><td class="doc"><p>input</p></td></tr><tr><td class="src">-&gt; <a href="Torch-GraduallyTyped-Tensor-Type.html#t:Tensor" title="Torch.GraduallyTyped.Tensor.Type">Tensor</a> gradient layout device dataType shape</td><td class="doc"><p>output</p></td></tr></table></div></div></div></div><div id="footer"><p>Produced by <a href="http://www.haskell.org/haddock/">Haddock</a> version 2.24.0</p></div></body></html>