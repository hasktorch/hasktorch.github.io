<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd"><html xmlns="http://www.w3.org/1999/xhtml"><head><link rel="stylesheet" type="text/css" href="style.css" /><script type="text/javascript" src="highlight.js"></script></head><body><pre><span class="hs-pragma">{-# LANGUAGE DataKinds #-}</span><span>
</span><span id="line-2"></span><span class="hs-pragma">{-# LANGUAGE MultiParamTypeClasses #-}</span><span>
</span><span id="line-3"></span><span class="hs-pragma">{-# LANGUAGE TypeApplications #-}</span><span>
</span><span id="line-4"></span><span class="hs-pragma">{-# LANGUAGE FlexibleInstances #-}</span><span>
</span><span id="line-5"></span><span class="hs-pragma">{-# LANGUAGE FlexibleContexts #-}</span><span>
</span><span id="line-6"></span><span class="hs-pragma">{-# LANGUAGE TypeOperators #-}</span><span>
</span><span id="line-7"></span><span class="hs-pragma">{-# LANGUAGE ScopedTypeVariables #-}</span><span>
</span><span id="line-8"></span><span class="hs-pragma">{-# LANGUAGE AllowAmbiguousTypes #-}</span><span>
</span><span id="line-9"></span><span class="hs-pragma">{-# LANGUAGE TypeFamilies #-}</span><span>
</span><span id="line-10"></span><span class="hs-pragma">{-# LANGUAGE UndecidableInstances #-}</span><span>
</span><span id="line-11"></span><span class="hs-pragma">{-# LANGUAGE UndecidableSuperClasses #-}</span><span>
</span><span id="line-12"></span><span class="hs-pragma">{-# LANGUAGE PolyKinds #-}</span><span>
</span><span id="line-13"></span><span class="hs-pragma">{-# LANGUAGE ConstraintKinds #-}</span><span>
</span><span id="line-14"></span><span class="hs-pragma">{-# LANGUAGE GADTs #-}</span><span>
</span><span id="line-15"></span><span class="hs-pragma">{-# LANGUAGE RankNTypes #-}</span><span>
</span><span id="line-16"></span><span class="hs-pragma">{-# LANGUAGE NoStarIsType #-}</span><span>
</span><span id="line-17"></span><span class="hs-pragma">{-# LANGUAGE DeriveGeneric #-}</span><span>
</span><span id="line-18"></span><span class="hs-pragma">{-# LANGUAGE RecordWildCards #-}</span><span>
</span><span id="line-19"></span><span class="hs-pragma">{-# LANGUAGE OverloadedLists #-}</span><span>
</span><span id="line-20"></span><span class="hs-pragma">{-# LANGUAGE StandaloneDeriving #-}</span><span>
</span><span id="line-21"></span><span class="hs-pragma">{-# OPTIONS_GHC -fplugin GHC.TypeLits.Normalise #-}</span><span>
</span><span id="line-22"></span><span class="hs-pragma">{-# OPTIONS_GHC -fplugin GHC.TypeLits.KnownNat.Solver #-}</span><span>
</span><span id="line-23"></span><span class="hs-pragma">{-# OPTIONS_GHC -fplugin GHC.TypeLits.Extra.Solver #-}</span><span>
</span><span id="line-24"></span><span class="hs-pragma">{-# OPTIONS_GHC -fconstraint-solver-iterations=0 #-}</span><span>
</span><span id="line-25"></span><span>
</span><span id="line-26"></span><span class="hs-keyword">module</span><span> </span><span class="hs-identifier">Torch.Typed.NN.Transformer</span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-27"></span><span>
</span><span id="line-28"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="../file:///nix/store/yi1zp26n2al045qmp9gwpxblhp2c8gs8-ghc-8.8.3-doc/share/doc/ghc/html/libraries/base-4.13.0.0/src"><span class="hs-identifier">Control.Monad</span></a></span><span>
</span><span id="line-29"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="../file:///nix/store/yi1zp26n2al045qmp9gwpxblhp2c8gs8-ghc-8.8.3-doc/share/doc/ghc/html/libraries/base-4.13.0.0/src"><span class="hs-identifier">Data.Proxy</span></a></span><span>
</span><span id="line-30"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="../file:///nix/store/yi1zp26n2al045qmp9gwpxblhp2c8gs8-ghc-8.8.3-doc/share/doc/ghc/html/libraries/base-4.13.0.0/src"><span class="hs-identifier">Foreign.ForeignPtr</span></a></span><span>
</span><span id="line-31"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="../file:///nix/store/yi1zp26n2al045qmp9gwpxblhp2c8gs8-ghc-8.8.3-doc/share/doc/ghc/html/libraries/base-4.13.0.0/src"><span class="hs-identifier">GHC.Generics</span></a></span><span>
</span><span id="line-32"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="../file:///nix/store/yi1zp26n2al045qmp9gwpxblhp2c8gs8-ghc-8.8.3-doc/share/doc/ghc/html/libraries/base-4.13.0.0/src"><span class="hs-identifier">GHC.TypeLits</span></a></span><span>
</span><span id="line-33"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="../file:///nix/store/mw5847q8s80yqzvg64ddkbaydhb7in4i-ghc-typelits-extra-0.3.3-doc/share/doc/ghc-typelits-extra-0.3.3/html/src"><span class="hs-identifier">GHC.TypeLits.Extra</span></a></span><span>
</span><span id="line-34"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="../file:///nix/store/yi1zp26n2al045qmp9gwpxblhp2c8gs8-ghc-8.8.3-doc/share/doc/ghc/html/libraries/base-4.13.0.0/src"><span class="hs-identifier">System.IO.Unsafe</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="../file:///nix/store/yi1zp26n2al045qmp9gwpxblhp2c8gs8-ghc-8.8.3-doc/share/doc/ghc/html/libraries/base-4.13.0.0/src"><span class="hs-identifier">unsafePerformIO</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-35"></span><span class="hs-keyword">import</span><span> </span><span class="hs-keyword">qualified</span><span> </span><span class="annot"><a href="Torch.Autograd.html"><span class="hs-identifier">Torch.Autograd</span></a></span><span> </span><span class="hs-keyword">as</span><span> </span><span class="annot"><span class="hs-identifier">A</span></span><span>
</span><span id="line-36"></span><span class="hs-keyword">import</span><span> </span><span class="hs-keyword">qualified</span><span> </span><span class="annot"><a href="Torch.DType.html"><span class="hs-identifier">Torch.DType</span></a></span><span> </span><span class="hs-keyword">as</span><span> </span><span class="annot"><span class="hs-identifier">D</span></span><span>
</span><span id="line-37"></span><span class="hs-keyword">import</span><span> </span><span class="hs-keyword">qualified</span><span> </span><span class="annot"><a href="Torch.Device.html"><span class="hs-identifier">Torch.Device</span></a></span><span> </span><span class="hs-keyword">as</span><span> </span><span class="annot"><span class="hs-identifier">D</span></span><span>
</span><span id="line-38"></span><span class="hs-keyword">import</span><span> </span><span class="hs-keyword">qualified</span><span> </span><span class="annot"><a href="Torch.Functional.html"><span class="hs-identifier">Torch.Functional</span></a></span><span> </span><span class="hs-keyword">as</span><span> </span><span class="annot"><span class="hs-identifier">D</span></span><span>
</span><span id="line-39"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.HList.html"><span class="hs-identifier">Torch.HList</span></a></span><span>
</span><span id="line-40"></span><span class="hs-keyword">import</span><span> </span><span class="hs-keyword">qualified</span><span> </span><span class="annot"><a href="../../../../libtorch-ffi-1.4.0.0/html/src"><span class="hs-identifier">Torch.Internal.Cast</span></a></span><span> </span><span class="hs-keyword">as</span><span> </span><span class="annot"><span class="hs-identifier">ATen</span></span><span>
</span><span id="line-41"></span><span class="hs-keyword">import</span><span> </span><span class="hs-keyword">qualified</span><span> </span><span class="annot"><a href="../../../../libtorch-ffi-1.4.0.0/html/src"><span class="hs-identifier">Torch.Internal.Class</span></a></span><span> </span><span class="hs-keyword">as</span><span> </span><span class="annot"><span class="hs-identifier">ATen</span></span><span>
</span><span id="line-42"></span><span class="hs-keyword">import</span><span> </span><span class="hs-keyword">qualified</span><span> </span><span class="annot"><a href="../../../../libtorch-ffi-1.4.0.0/html/src"><span class="hs-identifier">Torch.Internal.Managed.Type.Tensor</span></a></span><span> </span><span class="hs-keyword">as</span><span> </span><span class="annot"><span class="hs-identifier">ATen</span></span><span>
</span><span id="line-43"></span><span class="hs-keyword">import</span><span> </span><span class="hs-keyword">qualified</span><span> </span><span class="annot"><a href="../../../../libtorch-ffi-1.4.0.0/html/src"><span class="hs-identifier">Torch.Internal.Type</span></a></span><span> </span><span class="hs-keyword">as</span><span> </span><span class="annot"><span class="hs-identifier">ATen</span></span><span>
</span><span id="line-44"></span><span class="hs-keyword">import</span><span> </span><span class="hs-keyword">qualified</span><span> </span><span class="annot"><a href="Torch.NN.html"><span class="hs-identifier">Torch.NN</span></a></span><span> </span><span class="hs-keyword">as</span><span> </span><span class="annot"><span class="hs-identifier">A</span></span><span>
</span><span id="line-45"></span><span class="hs-keyword">import</span><span> </span><span class="hs-keyword">qualified</span><span> </span><span class="annot"><a href="Torch.Tensor.html"><span class="hs-identifier">Torch.Tensor</span></a></span><span> </span><span class="hs-keyword">as</span><span> </span><span class="annot"><span class="hs-identifier">D</span></span><span>
</span><span id="line-46"></span><span class="hs-keyword">import</span><span> </span><span class="hs-keyword">qualified</span><span> </span><span class="annot"><a href="Torch.TensorFactories.html"><span class="hs-identifier">Torch.TensorFactories</span></a></span><span> </span><span class="hs-keyword">as</span><span> </span><span class="annot"><span class="hs-identifier">D</span></span><span>
</span><span id="line-47"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.Typed.Aux.html"><span class="hs-identifier">Torch.Typed.Aux</span></a></span><span>
</span><span id="line-48"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.Typed.Factories.html"><span class="hs-identifier">Torch.Typed.Factories</span></a></span><span>
</span><span id="line-49"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.Typed.Functional.html"><span class="hs-identifier">Torch.Typed.Functional</span></a></span><span> </span><span class="hs-keyword">hiding</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.Functional.html#linear"><span class="hs-identifier">linear</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.Typed.Functional.html#log"><span class="hs-identifier">log</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-50"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.Typed.NN.html"><span class="hs-identifier">Torch.Typed.NN</span></a></span><span>
</span><span id="line-51"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.Typed.Parameter.html"><span class="hs-identifier">Torch.Typed.Parameter</span></a></span><span>
</span><span id="line-52"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.Typed.Tensor.html"><span class="hs-identifier">Torch.Typed.Tensor</span></a></span><span>
</span><span id="line-53"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="../file:///nix/store/yi1zp26n2al045qmp9gwpxblhp2c8gs8-ghc-8.8.3-doc/share/doc/ghc/html/libraries/base-4.13.0.0/src"><span class="hs-identifier">Prelude</span></a></span><span> </span><span class="hs-keyword">hiding</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="../file:///nix/store/yi1zp26n2al045qmp9gwpxblhp2c8gs8-ghc-8.8.3-doc/share/doc/ghc/html/libraries/base-4.13.0.0/src"><span class="hs-identifier">cos</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="../file:///nix/store/yi1zp26n2al045qmp9gwpxblhp2c8gs8-ghc-8.8.3-doc/share/doc/ghc/html/libraries/base-4.13.0.0/src"><span class="hs-identifier">exp</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="../file:///nix/store/yi1zp26n2al045qmp9gwpxblhp2c8gs8-ghc-8.8.3-doc/share/doc/ghc/html/libraries/base-4.13.0.0/src"><span class="hs-identifier">sin</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-54"></span><span>
</span><span id="line-55"></span><span class="hs-comment">--------------------------------------------------------------------------------</span><span>
</span><span id="line-56"></span><span class="hs-comment">-- Relation-Aware Multi-Headed Attention Layer</span><span>
</span><span id="line-57"></span><span class="hs-comment">--------------------------------------------------------------------------------</span><span>
</span><span id="line-58"></span><span>
</span><span id="line-59"></span><span class="hs-keyword">data</span><span>
</span><span id="line-60"></span><span>  </span><span id="MultiheadAttentionSpec"><span class="annot"><a href="Torch.Typed.NN.Transformer.html#MultiheadAttentionSpec"><span class="hs-identifier hs-var">MultiheadAttentionSpec</span></a></span></span><span>
</span><span id="line-61"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679721442"><span class="annot"><a href="#local-6989586621679721442"><span class="hs-identifier hs-type">embedDim</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="../file:///nix/store/yi1zp26n2al045qmp9gwpxblhp2c8gs8-ghc-8.8.3-doc/share/doc/ghc/html/libraries/ghc-prim-0.5.3/src"><span class="hs-identifier hs-type">Nat</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-62"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679721441"><span class="annot"><a href="#local-6989586621679721441"><span class="hs-identifier hs-type">numHeads</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="../file:///nix/store/yi1zp26n2al045qmp9gwpxblhp2c8gs8-ghc-8.8.3-doc/share/doc/ghc/html/libraries/ghc-prim-0.5.3/src"><span class="hs-identifier hs-type">Nat</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-63"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679721440"><span class="annot"><a href="#local-6989586621679721440"><span class="hs-identifier hs-type">dtype</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.DType.html#DType"><span class="hs-identifier hs-type">D.DType</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-64"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679721439"><span class="annot"><a href="#local-6989586621679721439"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Device.html#DeviceType"><span class="hs-identifier hs-type">D.DeviceType</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="../file:///nix/store/yi1zp26n2al045qmp9gwpxblhp2c8gs8-ghc-8.8.3-doc/share/doc/ghc/html/libraries/ghc-prim-0.5.3/src"><span class="hs-identifier hs-type">Nat</span></a></span><span class="hs-special">)</span><span class="hs-special">)</span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-65"></span><span>  </span><span id="local-6989586621679721893"><span id="local-6989586621679721894"><span id="local-6989586621679721895"><span id="local-6989586621679721896"><span id="MultiheadAttentionSpec"><span class="annot"><a href="Torch.Typed.NN.Transformer.html#MultiheadAttentionSpec"><span class="hs-identifier hs-var">MultiheadAttentionSpec</span></a></span></span><span>
</span><span id="line-66"></span><span>    </span><span class="hs-glyph">::</span><span> </span><span class="hs-special">{</span><span> </span><span id="mhaDropoutSpec"><span class="annot"><span class="annottext">MultiheadAttentionSpec embedDim numHeads dtype device
-&gt; DropoutSpec
</span><a href="Torch.Typed.NN.Transformer.html#mhaDropoutSpec"><span class="hs-identifier hs-var hs-var">mhaDropoutSpec</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.Typed.NN.html#DropoutSpec"><span class="hs-identifier hs-type">DropoutSpec</span></a></span><span> </span><span class="hs-special">}</span><span>
</span><span id="line-67"></span><span>    </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Typed.NN.Transformer.html#MultiheadAttentionSpec"><span class="hs-identifier hs-type">MultiheadAttentionSpec</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679721896"><span class="hs-identifier hs-type">embedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679721895"><span class="hs-identifier hs-type">numHeads</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679721894"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679721893"><span class="hs-identifier hs-type">device</span></a></span></span></span></span></span><span>
</span><span id="line-68"></span><span>  </span><span class="hs-keyword">deriving</span><span> </span><span class="hs-special">(</span><span id="local-6989586621679721431"><span id="local-6989586621679721433"><span id="local-6989586621679721435"><span class="annot"><span class="annottext">Int
-&gt; MultiheadAttentionSpec embedDim numHeads dtype device -&gt; ShowS
[MultiheadAttentionSpec embedDim numHeads dtype device] -&gt; ShowS
MultiheadAttentionSpec embedDim numHeads dtype device -&gt; String
(Int
 -&gt; MultiheadAttentionSpec embedDim numHeads dtype device -&gt; ShowS)
-&gt; (MultiheadAttentionSpec embedDim numHeads dtype device
    -&gt; String)
-&gt; ([MultiheadAttentionSpec embedDim numHeads dtype device]
    -&gt; ShowS)
-&gt; Show (MultiheadAttentionSpec embedDim numHeads dtype device)
forall a.
(Int -&gt; a -&gt; ShowS) -&gt; (a -&gt; String) -&gt; ([a] -&gt; ShowS) -&gt; Show a
forall (embedDim :: Nat) (numHeads :: Nat) (dtype :: DType)
       (device :: (DeviceType, Nat)).
Int
-&gt; MultiheadAttentionSpec embedDim numHeads dtype device -&gt; ShowS
forall (embedDim :: Nat) (numHeads :: Nat) (dtype :: DType)
       (device :: (DeviceType, Nat)).
[MultiheadAttentionSpec embedDim numHeads dtype device] -&gt; ShowS
forall (embedDim :: Nat) (numHeads :: Nat) (dtype :: DType)
       (device :: (DeviceType, Nat)).
MultiheadAttentionSpec embedDim numHeads dtype device -&gt; String
showList :: [MultiheadAttentionSpec embedDim numHeads dtype device] -&gt; ShowS
$cshowList :: forall (embedDim :: Nat) (numHeads :: Nat) (dtype :: DType)
       (device :: (DeviceType, Nat)).
[MultiheadAttentionSpec embedDim numHeads dtype device] -&gt; ShowS
show :: MultiheadAttentionSpec embedDim numHeads dtype device -&gt; String
$cshow :: forall (embedDim :: Nat) (numHeads :: Nat) (dtype :: DType)
       (device :: (DeviceType, Nat)).
MultiheadAttentionSpec embedDim numHeads dtype device -&gt; String
showsPrec :: Int
-&gt; MultiheadAttentionSpec embedDim numHeads dtype device -&gt; ShowS
$cshowsPrec :: forall (embedDim :: Nat) (numHeads :: Nat) (dtype :: DType)
       (device :: (DeviceType, Nat)).
Int
-&gt; MultiheadAttentionSpec embedDim numHeads dtype device -&gt; ShowS
</span><a href="../file:///nix/store/yi1zp26n2al045qmp9gwpxblhp2c8gs8-ghc-8.8.3-doc/share/doc/ghc/html/libraries/base-4.13.0.0/src"><span class="hs-identifier hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var">Show</span></a></span></span></span></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679721426"><span id="local-6989586621679721428"><span class="annot"><span class="annottext">MultiheadAttentionSpec embedDim numHeads dtype device
-&gt; MultiheadAttentionSpec embedDim numHeads dtype device -&gt; Bool
(MultiheadAttentionSpec embedDim numHeads dtype device
 -&gt; MultiheadAttentionSpec embedDim numHeads dtype device -&gt; Bool)
-&gt; (MultiheadAttentionSpec embedDim numHeads dtype device
    -&gt; MultiheadAttentionSpec embedDim numHeads dtype device -&gt; Bool)
-&gt; Eq (MultiheadAttentionSpec embedDim numHeads dtype device)
forall a. (a -&gt; a -&gt; Bool) -&gt; (a -&gt; a -&gt; Bool) -&gt; Eq a
forall (embedDim :: Nat) (numHeads :: Nat) (dtype :: DType)
       (device :: (DeviceType, Nat)).
MultiheadAttentionSpec embedDim numHeads dtype device
-&gt; MultiheadAttentionSpec embedDim numHeads dtype device -&gt; Bool
/= :: MultiheadAttentionSpec embedDim numHeads dtype device
-&gt; MultiheadAttentionSpec embedDim numHeads dtype device -&gt; Bool
$c/= :: forall (embedDim :: Nat) (numHeads :: Nat) (dtype :: DType)
       (device :: (DeviceType, Nat)).
MultiheadAttentionSpec embedDim numHeads dtype device
-&gt; MultiheadAttentionSpec embedDim numHeads dtype device -&gt; Bool
== :: MultiheadAttentionSpec embedDim numHeads dtype device
-&gt; MultiheadAttentionSpec embedDim numHeads dtype device -&gt; Bool
$c== :: forall (embedDim :: Nat) (numHeads :: Nat) (dtype :: DType)
       (device :: (DeviceType, Nat)).
MultiheadAttentionSpec embedDim numHeads dtype device
-&gt; MultiheadAttentionSpec embedDim numHeads dtype device -&gt; Bool
</span><a href="../file:///nix/store/yi1zp26n2al045qmp9gwpxblhp2c8gs8-ghc-8.8.3-doc/share/doc/ghc/html/libraries/ghc-prim-0.5.3/src"><span class="hs-identifier hs-var hs-var hs-var hs-var hs-var hs-var">Eq</span></a></span></span></span><span class="hs-special">)</span><span>
</span><span id="line-69"></span><span>
</span><span id="line-70"></span><span id="local-6989586621679721423"><span id="local-6989586621679721424"></span></span><span class="hs-keyword">data</span><span>
</span><span id="line-71"></span><span>  </span><span id="MultiheadAttention"><span class="annot"><a href="Torch.Typed.NN.Transformer.html#MultiheadAttention"><span class="hs-identifier hs-var">MultiheadAttention</span></a></span></span><span>
</span><span id="line-72"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679721422"><span class="annot"><a href="#local-6989586621679721422"><span class="hs-identifier hs-type">embedDim</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="../file:///nix/store/yi1zp26n2al045qmp9gwpxblhp2c8gs8-ghc-8.8.3-doc/share/doc/ghc/html/libraries/ghc-prim-0.5.3/src"><span class="hs-identifier hs-type">Nat</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-73"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679721421"><span class="annot"><a href="#local-6989586621679721421"><span class="hs-identifier hs-type">numHeads</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="../file:///nix/store/yi1zp26n2al045qmp9gwpxblhp2c8gs8-ghc-8.8.3-doc/share/doc/ghc/html/libraries/ghc-prim-0.5.3/src"><span class="hs-identifier hs-type">Nat</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-74"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679721420"><span class="annot"><a href="#local-6989586621679721420"><span class="hs-identifier hs-type">dtype</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.DType.html#DType"><span class="hs-identifier hs-type">D.DType</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-75"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679721419"><span class="annot"><a href="#local-6989586621679721419"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Device.html#DeviceType"><span class="hs-identifier hs-type">D.DeviceType</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="../file:///nix/store/yi1zp26n2al045qmp9gwpxblhp2c8gs8-ghc-8.8.3-doc/share/doc/ghc/html/libraries/ghc-prim-0.5.3/src"><span class="hs-identifier hs-type">Nat</span></a></span><span class="hs-special">)</span><span class="hs-special">)</span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-76"></span><span>  </span><span id="local-6989586621679722019"><span id="local-6989586621679722020"><span id="local-6989586621679722021"><span id="local-6989586621679722022"><span id="MultiheadAttention"><span class="annot"><a href="Torch.Typed.NN.Transformer.html#MultiheadAttention"><span class="hs-identifier hs-var">MultiheadAttention</span></a></span></span><span>
</span><span id="line-77"></span><span>    </span><span class="hs-glyph">::</span><span> </span><span class="hs-special">{</span><span> </span><span id="mhaInProj"><span class="annot"><span class="annottext">MultiheadAttention embedDim numHeads dtype device
-&gt; Linear embedDim (embedDim * 3) dtype device
</span><a href="Torch.Typed.NN.Transformer.html#mhaInProj"><span class="hs-identifier hs-var hs-var">mhaInProj</span></a></span></span><span>  </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.Typed.NN.html#Linear"><span class="hs-identifier hs-type">Linear</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679722022"><span class="hs-identifier hs-type">embedDim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679722022"><span class="hs-identifier hs-type">embedDim</span></a></span><span> </span><span class="annot"><a href="../file:///nix/store/yi1zp26n2al045qmp9gwpxblhp2c8gs8-ghc-8.8.3-doc/share/doc/ghc/html/libraries/base-4.13.0.0/src"><span class="hs-operator hs-type">*</span></a></span><span> </span><span class="annot"><span class="hs-number">3</span></span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679722020"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679722019"><span class="hs-identifier hs-type">device</span></a></span><span>
</span><span id="line-78"></span><span>       </span><span class="hs-special">,</span><span> </span><span id="mhaOutProj"><span class="annot"><span class="annottext">MultiheadAttention embedDim numHeads dtype device
-&gt; Linear embedDim embedDim dtype device
</span><a href="Torch.Typed.NN.Transformer.html#mhaOutProj"><span class="hs-identifier hs-var hs-var">mhaOutProj</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.Typed.NN.html#Linear"><span class="hs-identifier hs-type">Linear</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679722022"><span class="hs-identifier hs-type">embedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679722022"><span class="hs-identifier hs-type">embedDim</span></a></span><span>       </span><span class="annot"><a href="#local-6989586621679722020"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679722019"><span class="hs-identifier hs-type">device</span></a></span><span>
</span><span id="line-79"></span><span>       </span><span class="hs-special">,</span><span> </span><span id="mhaDropout"><span class="annot"><span class="annottext">MultiheadAttention embedDim numHeads dtype device -&gt; Dropout
</span><a href="Torch.Typed.NN.Transformer.html#mhaDropout"><span class="hs-identifier hs-var hs-var">mhaDropout</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.Typed.NN.html#Dropout"><span class="hs-identifier hs-type">Dropout</span></a></span><span>
</span><span id="line-80"></span><span>       </span><span class="hs-special">}</span><span>
</span><span id="line-81"></span><span>    </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Typed.NN.Transformer.html#MultiheadAttention"><span class="hs-identifier hs-type">MultiheadAttention</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679722022"><span class="hs-identifier hs-type">embedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679722021"><span class="hs-identifier hs-type">numHeads</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679722020"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679722019"><span class="hs-identifier hs-type">device</span></a></span></span></span></span></span><span>
</span><span id="line-82"></span><span>  </span><span class="hs-keyword">deriving</span><span> </span><span class="hs-special">(</span><span id="local-6989586621679721409"><span id="local-6989586621679721411"><span id="local-6989586621679721413"><span class="annot"><span class="annottext">Int -&gt; MultiheadAttention embedDim numHeads dtype device -&gt; ShowS
[MultiheadAttention embedDim numHeads dtype device] -&gt; ShowS
MultiheadAttention embedDim numHeads dtype device -&gt; String
(Int -&gt; MultiheadAttention embedDim numHeads dtype device -&gt; ShowS)
-&gt; (MultiheadAttention embedDim numHeads dtype device -&gt; String)
-&gt; ([MultiheadAttention embedDim numHeads dtype device] -&gt; ShowS)
-&gt; Show (MultiheadAttention embedDim numHeads dtype device)
forall a.
(Int -&gt; a -&gt; ShowS) -&gt; (a -&gt; String) -&gt; ([a] -&gt; ShowS) -&gt; Show a
forall (embedDim :: Nat) (numHeads :: Nat) (dtype :: DType)
       (device :: (DeviceType, Nat)).
Int -&gt; MultiheadAttention embedDim numHeads dtype device -&gt; ShowS
forall (embedDim :: Nat) (numHeads :: Nat) (dtype :: DType)
       (device :: (DeviceType, Nat)).
[MultiheadAttention embedDim numHeads dtype device] -&gt; ShowS
forall (embedDim :: Nat) (numHeads :: Nat) (dtype :: DType)
       (device :: (DeviceType, Nat)).
MultiheadAttention embedDim numHeads dtype device -&gt; String
showList :: [MultiheadAttention embedDim numHeads dtype device] -&gt; ShowS
$cshowList :: forall (embedDim :: Nat) (numHeads :: Nat) (dtype :: DType)
       (device :: (DeviceType, Nat)).
[MultiheadAttention embedDim numHeads dtype device] -&gt; ShowS
show :: MultiheadAttention embedDim numHeads dtype device -&gt; String
$cshow :: forall (embedDim :: Nat) (numHeads :: Nat) (dtype :: DType)
       (device :: (DeviceType, Nat)).
MultiheadAttention embedDim numHeads dtype device -&gt; String
showsPrec :: Int -&gt; MultiheadAttention embedDim numHeads dtype device -&gt; ShowS
$cshowsPrec :: forall (embedDim :: Nat) (numHeads :: Nat) (dtype :: DType)
       (device :: (DeviceType, Nat)).
Int -&gt; MultiheadAttention embedDim numHeads dtype device -&gt; ShowS
</span><a href="../file:///nix/store/yi1zp26n2al045qmp9gwpxblhp2c8gs8-ghc-8.8.3-doc/share/doc/ghc/html/libraries/base-4.13.0.0/src"><span class="hs-identifier hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var">Show</span></a></span></span></span></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">(forall x.
 MultiheadAttention embedDim numHeads dtype device
 -&gt; Rep (MultiheadAttention embedDim numHeads dtype device) x)
-&gt; (forall x.
    Rep (MultiheadAttention embedDim numHeads dtype device) x
    -&gt; MultiheadAttention embedDim numHeads dtype device)
-&gt; Generic (MultiheadAttention embedDim numHeads dtype device)
forall x.
Rep (MultiheadAttention embedDim numHeads dtype device) x
-&gt; MultiheadAttention embedDim numHeads dtype device
forall x.
MultiheadAttention embedDim numHeads dtype device
-&gt; Rep (MultiheadAttention embedDim numHeads dtype device) x
forall a.
(forall x. a -&gt; Rep a x) -&gt; (forall x. Rep a x -&gt; a) -&gt; Generic a
forall (embedDim :: Nat) (numHeads :: Nat) (dtype :: DType)
       (device :: (DeviceType, Nat)) x.
Rep (MultiheadAttention embedDim numHeads dtype device) x
-&gt; MultiheadAttention embedDim numHeads dtype device
forall (embedDim :: Nat) (numHeads :: Nat) (dtype :: DType)
       (device :: (DeviceType, Nat)) x.
MultiheadAttention embedDim numHeads dtype device
-&gt; Rep (MultiheadAttention embedDim numHeads dtype device) x
$cto :: forall (embedDim :: Nat) (numHeads :: Nat) (dtype :: DType)
       (device :: (DeviceType, Nat)) x.
Rep (MultiheadAttention embedDim numHeads dtype device) x
-&gt; MultiheadAttention embedDim numHeads dtype device
$cfrom :: forall (embedDim :: Nat) (numHeads :: Nat) (dtype :: DType)
       (device :: (DeviceType, Nat)) x.
MultiheadAttention embedDim numHeads dtype device
-&gt; Rep (MultiheadAttention embedDim numHeads dtype device) x
</span><a href="../file:///nix/store/yi1zp26n2al045qmp9gwpxblhp2c8gs8-ghc-8.8.3-doc/share/doc/ghc/html/libraries/base-4.13.0.0/src"><span class="hs-identifier hs-var hs-var hs-var hs-var">Generic</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-83"></span><span>
</span><span id="line-84"></span><span class="annot"><a href="Torch.Typed.NN.Transformer.html#multiheadAttention"><span class="hs-identifier hs-type">multiheadAttention</span></a></span><span>
</span><span id="line-85"></span><span>  </span><span class="hs-glyph">::</span><span> </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679721736"><span class="annot"><a href="#local-6989586621679721736"><span class="hs-identifier hs-type">embedDim</span></a></span></span><span> </span><span id="local-6989586621679721738"><span class="annot"><a href="#local-6989586621679721738"><span class="hs-identifier hs-type">numHeads</span></a></span></span><span> </span><span id="local-6989586621679721734"><span class="annot"><a href="#local-6989586621679721734"><span class="hs-identifier hs-type">seqLen</span></a></span></span><span> </span><span id="local-6989586621679721733"><span class="annot"><a href="#local-6989586621679721733"><span class="hs-identifier hs-type">batchSize</span></a></span></span><span> </span><span id="local-6989586621679721735"><span class="annot"><a href="#local-6989586621679721735"><span class="hs-identifier hs-type">headDim</span></a></span></span><span> </span><span id="local-6989586621679721732"><span class="annot"><a href="#local-6989586621679721732"><span class="hs-identifier hs-type">dtype</span></a></span></span><span> </span><span id="local-6989586621679721731"><span class="annot"><a href="#local-6989586621679721731"><span class="hs-identifier hs-type">device</span></a></span></span><span>
</span><span id="line-86"></span><span>   </span><span class="hs-operator">.</span><span> </span><span class="hs-special">(</span><span> </span><span class="annot"><span class="hs-number">1</span></span><span> </span><span class="annot"><a href="../file:///nix/store/yi1zp26n2al045qmp9gwpxblhp2c8gs8-ghc-8.8.3-doc/share/doc/ghc/html/libraries/base-4.13.0.0/src"><span class="hs-operator hs-type">&lt;=</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679721738"><span class="hs-identifier hs-type">numHeads</span></a></span><span>
</span><span id="line-87"></span><span>     </span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679721736"><span class="hs-identifier hs-type">embedDim</span></a></span><span> </span><span class="annot"><a href="../file:///nix/store/yi1zp26n2al045qmp9gwpxblhp2c8gs8-ghc-8.8.3-doc/share/doc/ghc/html/libraries/ghc-prim-0.5.3/src"><span class="hs-glyph hs-type">~</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679721735"><span class="hs-identifier hs-type">headDim</span></a></span><span> </span><span class="annot"><a href="../file:///nix/store/yi1zp26n2al045qmp9gwpxblhp2c8gs8-ghc-8.8.3-doc/share/doc/ghc/html/libraries/base-4.13.0.0/src"><span class="hs-operator hs-type">*</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679721738"><span class="hs-identifier hs-type">numHeads</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-88"></span><span>     </span><span class="hs-special">,</span><span> </span><span class="annot"><a href="../file:///nix/store/yi1zp26n2al045qmp9gwpxblhp2c8gs8-ghc-8.8.3-doc/share/doc/ghc/html/libraries/base-4.13.0.0/src"><span class="hs-identifier hs-type">Mod</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679721736"><span class="hs-identifier hs-type">embedDim</span></a></span><span> </span><span class="annot"><a href="../file:///nix/store/yi1zp26n2al045qmp9gwpxblhp2c8gs8-ghc-8.8.3-doc/share/doc/ghc/html/libraries/base-4.13.0.0/src"><span class="hs-operator hs-type">*</span></a></span><span> </span><span class="annot"><span class="hs-number">3</span></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="hs-number">3</span></span><span> </span><span class="annot"><a href="../file:///nix/store/yi1zp26n2al045qmp9gwpxblhp2c8gs8-ghc-8.8.3-doc/share/doc/ghc/html/libraries/ghc-prim-0.5.3/src"><span class="hs-glyph hs-type">~</span></a></span><span> </span><span class="annot"><span class="hs-number">0</span></span><span>
</span><span id="line-89"></span><span>     </span><span class="hs-special">,</span><span> </span><span class="annot"><a href="../file:///nix/store/yi1zp26n2al045qmp9gwpxblhp2c8gs8-ghc-8.8.3-doc/share/doc/ghc/html/libraries/base-4.13.0.0/src"><span class="hs-identifier hs-type">Div</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679721736"><span class="hs-identifier hs-type">embedDim</span></a></span><span> </span><span class="annot"><a href="../file:///nix/store/yi1zp26n2al045qmp9gwpxblhp2c8gs8-ghc-8.8.3-doc/share/doc/ghc/html/libraries/base-4.13.0.0/src"><span class="hs-operator hs-type">*</span></a></span><span> </span><span class="annot"><span class="hs-number">3</span></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="hs-number">3</span></span><span> </span><span class="annot"><a href="../file:///nix/store/yi1zp26n2al045qmp9gwpxblhp2c8gs8-ghc-8.8.3-doc/share/doc/ghc/html/libraries/ghc-prim-0.5.3/src"><span class="hs-glyph hs-type">~</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679721736"><span class="hs-identifier hs-type">embedDim</span></a></span><span>
</span><span id="line-90"></span><span>     </span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.Typed.Tensor.html#All"><span class="hs-identifier hs-type">All</span></a></span><span> </span><span class="annot"><a href="../file:///nix/store/yi1zp26n2al045qmp9gwpxblhp2c8gs8-ghc-8.8.3-doc/share/doc/ghc/html/libraries/base-4.13.0.0/src"><span class="hs-identifier hs-type">KnownNat</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="annot"><a href="#local-6989586621679721736"><span class="hs-identifier hs-type">embedDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679721738"><span class="hs-identifier hs-type">numHeads</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679721734"><span class="hs-identifier hs-type">seqLen</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679721733"><span class="hs-identifier hs-type">batchSize</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679721735"><span class="hs-identifier hs-type">headDim</span></a></span><span class="hs-special">]</span><span>
</span><span id="line-91"></span><span>     </span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.Typed.Tensor.html#KnownDType"><span class="hs-identifier hs-type">KnownDType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679721732"><span class="hs-identifier hs-type">dtype</span></a></span><span>
</span><span id="line-92"></span><span>     </span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.Typed.Aux.html#StandardFloatingPointDTypeValidation"><span class="hs-identifier hs-type">StandardFloatingPointDTypeValidation</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679721731"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679721732"><span class="hs-identifier hs-type">dtype</span></a></span><span>
</span><span id="line-93"></span><span>     </span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.Typed.Tensor.html#MatMulDTypeIsValid"><span class="hs-identifier hs-type">MatMulDTypeIsValid</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679721731"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679721732"><span class="hs-identifier hs-type">dtype</span></a></span><span>
</span><span id="line-94"></span><span>     </span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.Typed.Tensor.html#BasicArithmeticDTypeIsValid"><span class="hs-identifier hs-type">BasicArithmeticDTypeIsValid</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679721731"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679721732"><span class="hs-identifier hs-type">dtype</span></a></span><span>
</span><span id="line-95"></span><span>     </span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679721732"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="../file:///nix/store/yi1zp26n2al045qmp9gwpxblhp2c8gs8-ghc-8.8.3-doc/share/doc/ghc/html/libraries/ghc-prim-0.5.3/src"><span class="hs-glyph hs-type">~</span></a></span><span> </span><span class="annot"><a href="Torch.Typed.Functional.html#SumDType"><span class="hs-identifier hs-type">SumDType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679721732"><span class="hs-identifier hs-type">dtype</span></a></span><span>
</span><span id="line-96"></span><span>     </span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.Typed.Functional.html#SumDTypeIsValid"><span class="hs-identifier hs-type">SumDTypeIsValid</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679721731"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679721732"><span class="hs-identifier hs-type">dtype</span></a></span><span>
</span><span id="line-97"></span><span>     </span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.Typed.Tensor.html#KnownDevice"><span class="hs-identifier hs-type">KnownDevice</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679721731"><span class="hs-identifier hs-type">device</span></a></span><span>
</span><span id="line-98"></span><span>     </span><span class="hs-special">)</span><span>
</span><span id="line-99"></span><span>  </span><span class="hs-glyph">=&gt;</span><span> </span><span class="annot"><a href="Torch.Typed.NN.Transformer.html#MultiheadAttention"><span class="hs-identifier hs-type">MultiheadAttention</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679721736"><span class="hs-identifier hs-type">embedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679721738"><span class="hs-identifier hs-type">numHeads</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679721732"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679721731"><span class="hs-identifier hs-type">device</span></a></span><span>
</span><span id="line-100"></span><span>  </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="../file:///nix/store/yi1zp26n2al045qmp9gwpxblhp2c8gs8-ghc-8.8.3-doc/share/doc/ghc/html/libraries/ghc-prim-0.5.3/src"><span class="hs-identifier hs-type">Bool</span></a></span><span>
</span><span id="line-101"></span><span>  </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679721731"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679721732"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="annot"><a href="#local-6989586621679721733"><span class="hs-identifier hs-type">batchSize</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679721734"><span class="hs-identifier hs-type">seqLen</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679721734"><span class="hs-identifier hs-type">seqLen</span></a></span><span class="hs-special">]</span><span>
</span><span id="line-102"></span><span>  </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679721731"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.DType.html#Bool"><span class="hs-identifier hs-type">D.Bool</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="annot"><a href="#local-6989586621679721733"><span class="hs-identifier hs-type">batchSize</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679721734"><span class="hs-identifier hs-type">seqLen</span></a></span><span class="hs-special">]</span><span>
</span><span id="line-103"></span><span>  </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="../file:///nix/store/yi1zp26n2al045qmp9gwpxblhp2c8gs8-ghc-8.8.3-doc/share/doc/ghc/html/libraries/base-4.13.0.0/src"><span class="hs-identifier hs-type">Maybe</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679721731"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679721732"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="annot"><a href="#local-6989586621679721733"><span class="hs-identifier hs-type">batchSize</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679721734"><span class="hs-identifier hs-type">seqLen</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679721734"><span class="hs-identifier hs-type">seqLen</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679721735"><span class="hs-identifier hs-type">headDim</span></a></span><span class="hs-special">]</span><span class="hs-special">)</span><span>
</span><span id="line-104"></span><span>  </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="../file:///nix/store/yi1zp26n2al045qmp9gwpxblhp2c8gs8-ghc-8.8.3-doc/share/doc/ghc/html/libraries/base-4.13.0.0/src"><span class="hs-identifier hs-type">Maybe</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679721731"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679721732"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="annot"><a href="#local-6989586621679721733"><span class="hs-identifier hs-type">batchSize</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679721734"><span class="hs-identifier hs-type">seqLen</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679721734"><span class="hs-identifier hs-type">seqLen</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679721735"><span class="hs-identifier hs-type">headDim</span></a></span><span class="hs-special">]</span><span class="hs-special">)</span><span>
</span><span id="line-105"></span><span>  </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679721731"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679721732"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="annot"><a href="#local-6989586621679721733"><span class="hs-identifier hs-type">batchSize</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679721734"><span class="hs-identifier hs-type">seqLen</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679721736"><span class="hs-identifier hs-type">embedDim</span></a></span><span class="hs-special">]</span><span>
</span><span id="line-106"></span><span>  </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="../file:///nix/store/yi1zp26n2al045qmp9gwpxblhp2c8gs8-ghc-8.8.3-doc/share/doc/ghc/html/libraries/ghc-prim-0.5.3/src"><span class="hs-identifier hs-type">IO</span></a></span><span> </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679721731"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679721732"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="annot"><a href="#local-6989586621679721733"><span class="hs-identifier hs-type">batchSize</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679721734"><span class="hs-identifier hs-type">seqLen</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679721736"><span class="hs-identifier hs-type">embedDim</span></a></span><span class="hs-special">]</span><span>
</span><span id="line-107"></span><span>        </span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679721731"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679721732"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="annot"><a href="#local-6989586621679721733"><span class="hs-identifier hs-type">batchSize</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679721734"><span class="hs-identifier hs-type">seqLen</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679721734"><span class="hs-identifier hs-type">seqLen</span></a></span><span class="hs-special">]</span><span>
</span><span id="line-108"></span><span>        </span><span class="hs-special">)</span><span>
</span><span id="line-109"></span><span id="multiheadAttention"><span class="annot"><span class="annottext">multiheadAttention :: MultiheadAttention embedDim numHeads dtype device
-&gt; Bool
-&gt; Tensor device dtype '[batchSize, seqLen, seqLen]
-&gt; Tensor device 'Bool '[batchSize, seqLen]
-&gt; Maybe
     (Tensor device dtype '[batchSize, seqLen, seqLen, headDim])
-&gt; Maybe
     (Tensor device dtype '[batchSize, seqLen, seqLen, headDim])
-&gt; Tensor device dtype '[batchSize, seqLen, embedDim]
-&gt; IO
     (Tensor device dtype '[batchSize, seqLen, embedDim],
      Tensor device dtype '[batchSize, seqLen, seqLen])
</span><a href="Torch.Typed.NN.Transformer.html#multiheadAttention"><span class="hs-identifier hs-var hs-var">multiheadAttention</span></a></span></span><span> </span><span id="local-6989586621679721402"><span id="local-6989586621679721403"><span id="local-6989586621679721404"><span class="annot"><a href="Torch.Typed.NN.Transformer.html#MultiheadAttention"><span class="hs-identifier hs-type">MultiheadAttention</span></a></span><span> </span><span class="hs-special">{</span><span class="hs-glyph">..</span><span class="hs-special">}</span></span></span></span><span> </span><span id="local-6989586621679721401"><span class="annot"><span class="annottext">train :: Bool
</span><a href="#local-6989586621679721401"><span class="hs-identifier hs-var">train</span></a></span></span><span> </span><span id="local-6989586621679721400"><span class="annot"><span class="annottext">attentionMask :: Tensor device dtype '[batchSize, seqLen, seqLen]
</span><a href="#local-6989586621679721400"><span class="hs-identifier hs-var">attentionMask</span></a></span></span><span> </span><span id="local-6989586621679721399"><span class="annot"><span class="annottext">keyPaddingMask :: Tensor device 'Bool '[batchSize, seqLen]
</span><a href="#local-6989586621679721399"><span class="hs-identifier hs-var">keyPaddingMask</span></a></span></span><span> </span><span id="local-6989586621679721398"><span class="annot"><span class="annottext">maybeRelationsK :: Maybe (Tensor device dtype '[batchSize, seqLen, seqLen, headDim])
</span><a href="#local-6989586621679721398"><span class="hs-identifier hs-var">maybeRelationsK</span></a></span></span><span> </span><span id="local-6989586621679721397"><span class="annot"><span class="annottext">maybeRelationsV :: Maybe (Tensor device dtype '[batchSize, seqLen, seqLen, headDim])
</span><a href="#local-6989586621679721397"><span class="hs-identifier hs-var">maybeRelationsV</span></a></span></span><span> </span><span id="local-6989586621679721396"><span class="annot"><span class="annottext">x :: Tensor device dtype '[batchSize, seqLen, embedDim]
</span><a href="#local-6989586621679721396"><span class="hs-identifier hs-var">x</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="hs-keyword">do</span><span>
</span><span id="line-110"></span><span>  </span><span class="hs-keyword">let</span><span> </span><span id="local-6989586621679721395"><span class="annot"><span class="annottext">q :: Tensor device dtype '[batchSize, seqLen, embedDim]
</span><a href="#local-6989586621679721395"><span class="hs-identifier hs-var">q</span></a></span></span><span> </span><span class="annot"><a href="Torch.HList.html#%3A."><span class="hs-operator hs-type">:.</span></a></span><span> </span><span id="local-6989586621679721393"><span class="annot"><span class="annottext">k :: Tensor device dtype '[batchSize, seqLen, embedDim]
</span><a href="#local-6989586621679721393"><span class="hs-identifier hs-var">k</span></a></span></span><span> </span><span class="annot"><a href="Torch.HList.html#%3A."><span class="hs-operator hs-type">:.</span></a></span><span> </span><span id="local-6989586621679721392"><span class="annot"><span class="annottext">v :: Tensor device dtype '[batchSize, seqLen, embedDim]
</span><a href="#local-6989586621679721392"><span class="hs-identifier hs-var">v</span></a></span></span><span> </span><span class="annot"><a href="Torch.HList.html#%3A."><span class="hs-operator hs-type">:.</span></a></span><span> </span><span class="annot"><a href="Torch.HList.html#HNil"><span class="hs-identifier hs-type">HNil</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">forall (shape :: [Nat]) (dtype :: DType)
       (device :: (DeviceType, Nat)) (tensorChunks :: [Type]).
(KnownNat 3, KnownNat 2,
 tensorChunks ~ Chunk 3 2 shape dtype device,
 Castable (HList tensorChunks) [ATenTensor]) =&gt;
Tensor device dtype shape -&gt; HList tensorChunks
forall k (chunks :: Nat) (dim :: Nat) (shape :: [Nat])
       (dtype :: DType) (device :: (DeviceType, Nat))
       (tensorChunks :: [k]).
(KnownNat chunks, KnownNat dim,
 tensorChunks ~ Chunk chunks dim shape dtype device,
 Castable (HList tensorChunks) [ATenTensor]) =&gt;
Tensor device dtype shape -&gt; HList tensorChunks
</span><a href="Torch.Typed.Functional.html#chunk"><span class="hs-identifier hs-var">chunk</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><span class="hs-number">3</span></span><span> </span><span class="hs-glyph">@</span><span class="annot"><span class="hs-number">2</span></span><span> </span><span class="annot"><span class="annottext">(Tensor device dtype '[batchSize, seqLen, embedDim * 3]
 -&gt; HList
      '[Tensor device dtype '[batchSize, seqLen, embedDim],
        Tensor device dtype '[batchSize, seqLen, embedDim],
        Tensor device dtype '[batchSize, seqLen, embedDim]])
-&gt; (Tensor device dtype '[batchSize, seqLen, embedDim]
    -&gt; Tensor device dtype '[batchSize, seqLen, embedDim * 3])
-&gt; Tensor device dtype '[batchSize, seqLen, embedDim]
-&gt; HList
     '[Tensor device dtype '[batchSize, seqLen, embedDim],
       Tensor device dtype '[batchSize, seqLen, embedDim],
       Tensor device dtype '[batchSize, seqLen, embedDim]]
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><a href="../file:///nix/store/yi1zp26n2al045qmp9gwpxblhp2c8gs8-ghc-8.8.3-doc/share/doc/ghc/html/libraries/base-4.13.0.0/src"><span class="hs-operator hs-var">.</span></a></span><span> </span><span class="annot"><span class="annottext">Linear embedDim (embedDim * 3) dtype device
-&gt; Tensor device dtype '[batchSize, seqLen, embedDim]
-&gt; Tensor
     device
     dtype
     (CheckBroadcast
        (CheckMatMul
           '[batchSize, seqLen, embedDim]
           '[embedDim, embedDim * 3]
           (ComputeMatMul
              (ReverseImpl '[batchSize, seqLen, embedDim] '[])
              '[embedDim * 3, embedDim]))
        (CheckMatMul
           '[batchSize, seqLen, embedDim]
           '[embedDim, embedDim * 3]
           (ComputeMatMul
              (ReverseImpl '[batchSize, seqLen, embedDim] '[])
              '[embedDim * 3, embedDim]))
        (ComputeBroadcast
           (ReverseImpl
              (CheckMatMul
                 '[batchSize, seqLen, embedDim]
                 '[embedDim, embedDim * 3]
                 (ComputeMatMul
                    (ReverseImpl '[batchSize, seqLen, embedDim] '[])
                    '[embedDim * 3, embedDim]))
              '[])
           (ReverseImpl
              (CheckMatMul
                 '[batchSize, seqLen, embedDim]
                 '[embedDim, embedDim * 3]
                 (ComputeMatMul
                    (ReverseImpl '[batchSize, seqLen, embedDim] '[])
                    '[embedDim * 3, embedDim]))
              '[])))
forall (inputFeatures :: Nat) (outputFeatures :: Nat) (_1 :: DType)
       (_2 :: (DeviceType, Nat)) (shape :: [Nat]).
Linear inputFeatures outputFeatures _1 _2
-&gt; Tensor _2 _1 shape
-&gt; Tensor
     _2
     _1
     (CheckBroadcast
        (CheckMatMul
           shape
           '[inputFeatures, outputFeatures]
           (ComputeMatMul
              (ReverseImpl shape '[]) '[outputFeatures, inputFeatures]))
        (CheckMatMul
           shape
           '[inputFeatures, outputFeatures]
           (ComputeMatMul
              (ReverseImpl shape '[]) '[outputFeatures, inputFeatures]))
        (ComputeBroadcast
           (ReverseImpl
              (CheckMatMul
                 shape
                 '[inputFeatures, outputFeatures]
                 (ComputeMatMul
                    (ReverseImpl shape '[]) '[outputFeatures, inputFeatures]))
              '[])
           (ReverseImpl
              (CheckMatMul
                 shape
                 '[inputFeatures, outputFeatures]
                 (ComputeMatMul
                    (ReverseImpl shape '[]) '[outputFeatures, inputFeatures]))
              '[])))
</span><a href="Torch.Typed.NN.html#linear"><span class="hs-identifier hs-var">linear</span></a></span><span> </span><span class="annot"><span class="annottext">Linear embedDim (embedDim * 3) dtype device
</span><a href="#local-6989586621679721404"><span class="hs-identifier hs-var">mhaInProj</span></a></span><span> </span><span class="annot"><span class="annottext">(Tensor device dtype '[batchSize, seqLen, embedDim]
 -&gt; HList
      '[Tensor device dtype '[batchSize, seqLen, embedDim],
        Tensor device dtype '[batchSize, seqLen, embedDim],
        Tensor device dtype '[batchSize, seqLen, embedDim]])
-&gt; Tensor device dtype '[batchSize, seqLen, embedDim]
-&gt; HList
     '[Tensor device dtype '[batchSize, seqLen, embedDim],
       Tensor device dtype '[batchSize, seqLen, embedDim],
       Tensor device dtype '[batchSize, seqLen, embedDim]]
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><a href="../file:///nix/store/yi1zp26n2al045qmp9gwpxblhp2c8gs8-ghc-8.8.3-doc/share/doc/ghc/html/libraries/base-4.13.0.0/src"><span class="hs-operator hs-var">$</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor device dtype '[batchSize, seqLen, embedDim]
</span><a href="#local-6989586621679721396"><span class="hs-identifier hs-var">x</span></a></span><span>
</span><span id="line-111"></span><span>      </span><span id="local-6989586621679721387"><span class="annot"><span class="annottext">q' :: Tensor device dtype '[batchSize, numHeads, seqLen, headDim]
</span><a href="#local-6989586621679721387"><span class="hs-identifier hs-var hs-var">q'</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Tensor device dtype '[batchSize, seqLen, embedDim]
-&gt; Tensor device dtype '[batchSize, numHeads, seqLen, headDim]
</span><a href="#local-6989586621679721386"><span class="hs-identifier hs-var">reshape'</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor device dtype '[batchSize, seqLen, embedDim]
</span><a href="#local-6989586621679721395"><span class="hs-identifier hs-var">q</span></a></span><span>
</span><span id="line-112"></span><span>      </span><span id="local-6989586621679721385"><span class="annot"><span class="annottext">k' :: Tensor device dtype '[batchSize, numHeads, seqLen, headDim]
</span><a href="#local-6989586621679721385"><span class="hs-identifier hs-var hs-var">k'</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Tensor device dtype '[batchSize, seqLen, embedDim]
-&gt; Tensor device dtype '[batchSize, numHeads, seqLen, headDim]
</span><a href="#local-6989586621679721386"><span class="hs-identifier hs-var">reshape'</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor device dtype '[batchSize, seqLen, embedDim]
</span><a href="#local-6989586621679721393"><span class="hs-identifier hs-var">k</span></a></span><span>
</span><span id="line-113"></span><span>      </span><span id="local-6989586621679721384"><span class="annot"><span class="annottext">v' :: Tensor device dtype '[batchSize, numHeads, seqLen, headDim]
</span><a href="#local-6989586621679721384"><span class="hs-identifier hs-var hs-var">v'</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Tensor device dtype '[batchSize, seqLen, embedDim]
-&gt; Tensor device dtype '[batchSize, numHeads, seqLen, headDim]
</span><a href="#local-6989586621679721386"><span class="hs-identifier hs-var">reshape'</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor device dtype '[batchSize, seqLen, embedDim]
</span><a href="#local-6989586621679721392"><span class="hs-identifier hs-var">v</span></a></span><span>
</span><span id="line-114"></span><span>  </span><span id="local-6989586621679721383"><span class="annot"><span class="annottext">Tensor device dtype '[batchSize, numHeads, seqLen, seqLen]
</span><a href="#local-6989586621679721383"><span class="hs-identifier hs-var">coefficients</span></a></span></span><span> </span><span class="hs-glyph">&lt;-</span><span> </span><span class="annot"><span class="annottext">Tensor device dtype '[batchSize, numHeads, seqLen, headDim]
-&gt; Tensor device dtype '[batchSize, numHeads, seqLen, headDim]
-&gt; IO (Tensor device dtype '[batchSize, numHeads, seqLen, seqLen])
</span><a href="#local-6989586621679721382"><span class="hs-identifier hs-var">weightCoefficients</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor device dtype '[batchSize, numHeads, seqLen, headDim]
</span><a href="#local-6989586621679721387"><span class="hs-identifier hs-var">q'</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor device dtype '[batchSize, numHeads, seqLen, headDim]
</span><a href="#local-6989586621679721385"><span class="hs-identifier hs-var">k'</span></a></span><span>
</span><span id="line-115"></span><span>  </span><span class="annot"><span class="annottext">(Tensor device dtype '[batchSize, seqLen, embedDim],
 Tensor device dtype '[batchSize, seqLen, seqLen])
-&gt; IO
     (Tensor device dtype '[batchSize, seqLen, embedDim],
      Tensor device dtype '[batchSize, seqLen, seqLen])
forall (m :: Type -&gt; Type) a. Monad m =&gt; a -&gt; m a
</span><a href="../file:///nix/store/yi1zp26n2al045qmp9gwpxblhp2c8gs8-ghc-8.8.3-doc/share/doc/ghc/html/libraries/base-4.13.0.0/src"><span class="hs-identifier hs-var">return</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">Tensor device dtype '[batchSize, numHeads, seqLen, seqLen]
-&gt; Tensor device dtype '[batchSize, numHeads, seqLen, headDim]
-&gt; Tensor device dtype '[batchSize, seqLen, embedDim]
</span><a href="#local-6989586621679721381"><span class="hs-identifier hs-var">attention</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor device dtype '[batchSize, numHeads, seqLen, seqLen]
</span><a href="#local-6989586621679721383"><span class="hs-identifier hs-var">coefficients</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor device dtype '[batchSize, numHeads, seqLen, headDim]
</span><a href="#local-6989586621679721384"><span class="hs-identifier hs-var">v'</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">Tensor device dtype '[batchSize, numHeads, seqLen, seqLen]
-&gt; Tensor device dtype '[batchSize, seqLen, seqLen]
</span><a href="#local-6989586621679721380"><span class="hs-identifier hs-var">averageOverHeads</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor device dtype '[batchSize, numHeads, seqLen, seqLen]
</span><a href="#local-6989586621679721383"><span class="hs-identifier hs-var">coefficients</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-116"></span><span>  </span><span class="hs-keyword">where</span><span>
</span><span id="line-117"></span><span>    </span><span id="local-6989586621679721382"><span class="annot"><span class="annottext">weightCoefficients :: Tensor device dtype '[batchSize, numHeads, seqLen, headDim]
-&gt; Tensor device dtype '[batchSize, numHeads, seqLen, headDim]
-&gt; IO (Tensor device dtype '[batchSize, numHeads, seqLen, seqLen])
</span><a href="#local-6989586621679721382"><span class="hs-identifier hs-var hs-var">weightCoefficients</span></a></span></span><span> </span><span id="local-6989586621679721379"><span class="annot"><span class="annottext">q :: Tensor device dtype '[batchSize, numHeads, seqLen, headDim]
</span><a href="#local-6989586621679721379"><span class="hs-identifier hs-var">q</span></a></span></span><span> </span><span id="local-6989586621679721378"><span class="annot"><span class="annottext">k :: Tensor device dtype '[batchSize, numHeads, seqLen, headDim]
</span><a href="#local-6989586621679721378"><span class="hs-identifier hs-var">k</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-118"></span><span>      </span><span class="annot"><span class="annottext">Dropout
-&gt; Bool
-&gt; Tensor device dtype '[batchSize, numHeads, seqLen, seqLen]
-&gt; IO (Tensor device dtype '[batchSize, numHeads, seqLen, seqLen])
forall (shape :: [Nat]) (dtype :: DType)
       (device :: (DeviceType, Nat)).
Dropout
-&gt; Bool
-&gt; Tensor device dtype shape
-&gt; IO (Tensor device dtype shape)
</span><a href="Torch.Typed.NN.html#dropout"><span class="hs-identifier hs-var">Torch.Typed.NN.dropout</span></a></span><span> </span><span class="annot"><span class="annottext">Dropout
</span><a href="#local-6989586621679721402"><span class="hs-identifier hs-var">mhaDropout</span></a></span><span> </span><span class="annot"><span class="annottext">Bool
</span><a href="#local-6989586621679721401"><span class="hs-identifier hs-var">train</span></a></span><span>
</span><span id="line-119"></span><span>        </span><span class="annot"><span class="annottext">(Tensor device dtype '[batchSize, numHeads, seqLen, seqLen]
 -&gt; IO (Tensor device dtype '[batchSize, numHeads, seqLen, seqLen]))
-&gt; (Maybe
      (Tensor device dtype '[batchSize, seqLen, seqLen, headDim])
    -&gt; Tensor device dtype '[batchSize, numHeads, seqLen, seqLen])
-&gt; Maybe
     (Tensor device dtype '[batchSize, seqLen, seqLen, headDim])
-&gt; IO (Tensor device dtype '[batchSize, numHeads, seqLen, seqLen])
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><a href="../file:///nix/store/yi1zp26n2al045qmp9gwpxblhp2c8gs8-ghc-8.8.3-doc/share/doc/ghc/html/libraries/base-4.13.0.0/src"><span class="hs-operator hs-var">.</span></a></span><span> </span><span class="annot"><span class="annottext">forall (shape :: [Nat]) (dtype :: DType)
       (device :: (DeviceType, Nat)).
(KnownNat 3, DimOutOfBoundCheck shape 3, KnownDType dtype,
 StandardFloatingPointDTypeValidation device dtype) =&gt;
Tensor device dtype shape -&gt; Tensor device dtype shape
forall (dim :: Nat) (shape :: [Nat]) (dtype :: DType)
       (device :: (DeviceType, Nat)).
(KnownNat dim, DimOutOfBoundCheck shape dim, KnownDType dtype,
 StandardFloatingPointDTypeValidation device dtype) =&gt;
Tensor device dtype shape -&gt; Tensor device dtype shape
</span><a href="Torch.Typed.Functional.html#softmax"><span class="hs-identifier hs-var">softmax</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><span class="hs-number">3</span></span><span>
</span><span id="line-120"></span><span>        </span><span class="annot"><span class="annottext">(Tensor device dtype '[batchSize, numHeads, seqLen, seqLen]
 -&gt; Tensor device dtype '[batchSize, numHeads, seqLen, seqLen])
-&gt; (Maybe
      (Tensor device dtype '[batchSize, seqLen, seqLen, headDim])
    -&gt; Tensor device dtype '[batchSize, numHeads, seqLen, seqLen])
-&gt; Maybe
     (Tensor device dtype '[batchSize, seqLen, seqLen, headDim])
-&gt; Tensor device dtype '[batchSize, numHeads, seqLen, seqLen]
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><a href="../file:///nix/store/yi1zp26n2al045qmp9gwpxblhp2c8gs8-ghc-8.8.3-doc/share/doc/ghc/html/libraries/base-4.13.0.0/src"><span class="hs-operator hs-var">.</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor device dtype '[batchSize, numHeads, seqLen, seqLen]
-&gt; Tensor device dtype '[batchSize, numHeads, seqLen, seqLen]
</span><a href="#local-6989586621679721375"><span class="hs-identifier hs-var">maskKeyPaddings</span></a></span><span>
</span><span id="line-121"></span><span>        </span><span class="annot"><span class="annottext">(Tensor device dtype '[batchSize, numHeads, seqLen, seqLen]
 -&gt; Tensor device dtype '[batchSize, numHeads, seqLen, seqLen])
-&gt; (Maybe
      (Tensor device dtype '[batchSize, seqLen, seqLen, headDim])
    -&gt; Tensor device dtype '[batchSize, numHeads, seqLen, seqLen])
-&gt; Maybe
     (Tensor device dtype '[batchSize, seqLen, seqLen, headDim])
-&gt; Tensor device dtype '[batchSize, numHeads, seqLen, seqLen]
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><a href="../file:///nix/store/yi1zp26n2al045qmp9gwpxblhp2c8gs8-ghc-8.8.3-doc/share/doc/ghc/html/libraries/base-4.13.0.0/src"><span class="hs-operator hs-var">.</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor device dtype '[batchSize, numHeads, seqLen, seqLen]
-&gt; Tensor device dtype '[batchSize, numHeads, seqLen, seqLen]
</span><a href="#local-6989586621679721374"><span class="hs-identifier hs-var">maskAttention</span></a></span><span>
</span><span id="line-122"></span><span>        </span><span class="annot"><span class="annottext">(Tensor device dtype '[batchSize, numHeads, seqLen, seqLen]
 -&gt; Tensor device dtype '[batchSize, numHeads, seqLen, seqLen])
-&gt; (Maybe
      (Tensor device dtype '[batchSize, seqLen, seqLen, headDim])
    -&gt; Tensor device dtype '[batchSize, numHeads, seqLen, seqLen])
-&gt; Maybe
     (Tensor device dtype '[batchSize, seqLen, seqLen, headDim])
-&gt; Tensor device dtype '[batchSize, numHeads, seqLen, seqLen]
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><a href="../file:///nix/store/yi1zp26n2al045qmp9gwpxblhp2c8gs8-ghc-8.8.3-doc/share/doc/ghc/html/libraries/base-4.13.0.0/src"><span class="hs-operator hs-var">.</span></a></span><span> </span><span class="annot"><span class="annottext">Double
-&gt; Tensor device dtype '[batchSize, numHeads, seqLen, seqLen]
-&gt; Tensor device dtype '[batchSize, numHeads, seqLen, seqLen]
forall a (shape :: [Nat]) (dtype :: DType)
       (device :: (DeviceType, Nat)).
Scalar a =&gt;
a -&gt; Tensor device dtype shape -&gt; Tensor device dtype shape
</span><a href="Torch.Typed.Functional.html#divScalar"><span class="hs-identifier hs-var">divScalar</span></a></span><span> </span><span class="annot"><span class="annottext">Double
</span><a href="#local-6989586621679721372"><span class="hs-identifier hs-var">scaling</span></a></span><span>
</span><span id="line-123"></span><span>        </span><span class="annot"><span class="annottext">(Tensor device dtype '[batchSize, numHeads, seqLen, seqLen]
 -&gt; Tensor device dtype '[batchSize, numHeads, seqLen, seqLen])
-&gt; (Maybe
      (Tensor device dtype '[batchSize, seqLen, seqLen, headDim])
    -&gt; Tensor device dtype '[batchSize, numHeads, seqLen, seqLen])
-&gt; Maybe
     (Tensor device dtype '[batchSize, seqLen, seqLen, headDim])
-&gt; Tensor device dtype '[batchSize, numHeads, seqLen, seqLen]
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><a href="../file:///nix/store/yi1zp26n2al045qmp9gwpxblhp2c8gs8-ghc-8.8.3-doc/share/doc/ghc/html/libraries/base-4.13.0.0/src"><span class="hs-operator hs-var">.</span></a></span><span> </span><span class="annot"><span class="annottext">(Tensor device dtype '[batchSize, numHeads, seqLen, seqLen]
 -&gt; (Tensor device dtype '[batchSize, numHeads, seqLen, seqLen]
     -&gt; Tensor device dtype '[batchSize, numHeads, seqLen, seqLen])
 -&gt; Maybe
      (Tensor device dtype '[batchSize, numHeads, seqLen, seqLen])
 -&gt; Tensor device dtype '[batchSize, numHeads, seqLen, seqLen])
-&gt; (Tensor device dtype '[batchSize, numHeads, seqLen, seqLen]
    -&gt; Tensor device dtype '[batchSize, numHeads, seqLen, seqLen]
    -&gt; Tensor device dtype '[batchSize, numHeads, seqLen, seqLen])
-&gt; Tensor device dtype '[batchSize, numHeads, seqLen, seqLen]
-&gt; Maybe
     (Tensor device dtype '[batchSize, numHeads, seqLen, seqLen])
-&gt; Tensor device dtype '[batchSize, numHeads, seqLen, seqLen]
forall (m :: Type -&gt; Type) a b. Monad m =&gt; m (a -&gt; b) -&gt; m a -&gt; m b
</span><a href="../file:///nix/store/yi1zp26n2al045qmp9gwpxblhp2c8gs8-ghc-8.8.3-doc/share/doc/ghc/html/libraries/base-4.13.0.0/src"><span class="hs-identifier hs-var">ap</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor device dtype '[batchSize, numHeads, seqLen, seqLen]
-&gt; (Tensor device dtype '[batchSize, numHeads, seqLen, seqLen]
    -&gt; Tensor device dtype '[batchSize, numHeads, seqLen, seqLen])
-&gt; Maybe
     (Tensor device dtype '[batchSize, numHeads, seqLen, seqLen])
-&gt; Tensor device dtype '[batchSize, numHeads, seqLen, seqLen]
forall b a. b -&gt; (a -&gt; b) -&gt; Maybe a -&gt; b
</span><a href="../file:///nix/store/yi1zp26n2al045qmp9gwpxblhp2c8gs8-ghc-8.8.3-doc/share/doc/ghc/html/libraries/base-4.13.0.0/src"><span class="hs-identifier hs-var">maybe</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor device dtype '[batchSize, numHeads, seqLen, seqLen]
-&gt; Tensor device dtype '[batchSize, numHeads, seqLen, seqLen]
-&gt; Tensor device dtype '[batchSize, numHeads, seqLen, seqLen]
forall (shape'' :: [Nat]) (shape :: [Nat]) (shape' :: [Nat])
       (dtype :: DType) (dtype' :: DType) (dtype'' :: DType)
       (device :: (DeviceType, Nat)).
(dtype'' ~ DTypePromotion dtype dtype',
 shape'' ~ Broadcast shape shape',
 BasicArithmeticDTypeIsValid device dtype,
 BasicArithmeticDTypeIsValid device dtype',
 BasicArithmeticDTypeIsValid device dtype'') =&gt;
Tensor device dtype shape
-&gt; Tensor device dtype' shape' -&gt; Tensor device dtype'' shape''
</span><a href="Torch.Typed.Tensor.html#add"><span class="hs-identifier hs-var">add</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">Tensor device dtype '[batchSize, numHeads, seqLen, headDim]
-&gt; Tensor device dtype '[batchSize, numHeads, headDim, seqLen]
-&gt; Tensor device dtype '[batchSize, numHeads, seqLen, seqLen]
forall (shape'' :: [Nat]) (shape :: [Nat]) (shape' :: [Nat])
       (dtype :: DType) (device :: (DeviceType, Nat)).
(shape'' ~ MatMul shape shape', MatMulDTypeIsValid device dtype) =&gt;
Tensor device dtype shape
-&gt; Tensor device dtype shape' -&gt; Tensor device dtype shape''
</span><a href="Torch.Typed.Tensor.html#matmul"><span class="hs-identifier hs-var">matmul</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor device dtype '[batchSize, numHeads, seqLen, headDim]
</span><a href="#local-6989586621679721379"><span class="hs-identifier hs-var">q</span></a></span><span> </span><span class="annot"><span class="annottext">(Tensor device dtype '[batchSize, numHeads, headDim, seqLen]
 -&gt; Tensor device dtype '[batchSize, numHeads, seqLen, seqLen])
-&gt; (Tensor device dtype '[batchSize, numHeads, seqLen, headDim]
    -&gt; Tensor device dtype '[batchSize, numHeads, headDim, seqLen])
-&gt; Tensor device dtype '[batchSize, numHeads, seqLen, headDim]
-&gt; Tensor device dtype '[batchSize, numHeads, seqLen, seqLen]
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><a href="../file:///nix/store/yi1zp26n2al045qmp9gwpxblhp2c8gs8-ghc-8.8.3-doc/share/doc/ghc/html/libraries/base-4.13.0.0/src"><span class="hs-operator hs-var">.</span></a></span><span> </span><span class="annot"><span class="annottext">forall (shape :: [Nat]) (shape' :: [Nat]) (dtype :: DType)
       (device :: (DeviceType, Nat)).
(KnownNat 2, KnownNat 3, shape' ~ Transpose shape 2 3) =&gt;
Tensor device dtype shape -&gt; Tensor device dtype shape'
forall (n :: Nat) (m :: Nat) (shape :: [Nat]) (shape' :: [Nat])
       (dtype :: DType) (device :: (DeviceType, Nat)).
(KnownNat n, KnownNat m, shape' ~ Transpose shape n m) =&gt;
Tensor device dtype shape -&gt; Tensor device dtype shape'
</span><a href="Torch.Typed.Functional.html#transpose"><span class="hs-identifier hs-var">transpose</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><span class="hs-number">2</span></span><span> </span><span class="hs-glyph">@</span><span class="annot"><span class="hs-number">3</span></span><span> </span><span class="annot"><span class="annottext">(Tensor device dtype '[batchSize, numHeads, seqLen, headDim]
 -&gt; Tensor device dtype '[batchSize, numHeads, seqLen, seqLen])
-&gt; Tensor device dtype '[batchSize, numHeads, seqLen, headDim]
-&gt; Tensor device dtype '[batchSize, numHeads, seqLen, seqLen]
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><a href="../file:///nix/store/yi1zp26n2al045qmp9gwpxblhp2c8gs8-ghc-8.8.3-doc/share/doc/ghc/html/libraries/base-4.13.0.0/src"><span class="hs-operator hs-var">$</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor device dtype '[batchSize, numHeads, seqLen, headDim]
</span><a href="#local-6989586621679721378"><span class="hs-identifier hs-var">k</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-124"></span><span>        </span><span class="annot"><span class="annottext">(Maybe (Tensor device dtype '[batchSize, numHeads, seqLen, seqLen])
 -&gt; Tensor device dtype '[batchSize, numHeads, seqLen, seqLen])
-&gt; (Maybe
      (Tensor device dtype '[batchSize, seqLen, seqLen, headDim])
    -&gt; Maybe
         (Tensor device dtype '[batchSize, numHeads, seqLen, seqLen]))
-&gt; Maybe
     (Tensor device dtype '[batchSize, seqLen, seqLen, headDim])
-&gt; Tensor device dtype '[batchSize, numHeads, seqLen, seqLen]
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><a href="../file:///nix/store/yi1zp26n2al045qmp9gwpxblhp2c8gs8-ghc-8.8.3-doc/share/doc/ghc/html/libraries/base-4.13.0.0/src"><span class="hs-operator hs-var">.</span></a></span><span> </span><span class="annot"><span class="annottext">(Tensor device dtype '[batchSize, seqLen, seqLen, headDim]
 -&gt; Tensor device dtype '[batchSize, numHeads, seqLen, seqLen])
-&gt; Maybe
     (Tensor device dtype '[batchSize, seqLen, seqLen, headDim])
-&gt; Maybe
     (Tensor device dtype '[batchSize, numHeads, seqLen, seqLen])
forall (f :: Type -&gt; Type) a b. Functor f =&gt; (a -&gt; b) -&gt; f a -&gt; f b
</span><a href="../file:///nix/store/yi1zp26n2al045qmp9gwpxblhp2c8gs8-ghc-8.8.3-doc/share/doc/ghc/html/libraries/base-4.13.0.0/src"><span class="hs-identifier hs-var">fmap</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">forall (shape :: [Nat]) (shape' :: [Nat]) (dtype :: DType)
       (device :: (DeviceType, Nat)).
(KnownNat 1, KnownNat 2, shape' ~ Transpose shape 1 2) =&gt;
Tensor device dtype shape -&gt; Tensor device dtype shape'
forall (n :: Nat) (m :: Nat) (shape :: [Nat]) (shape' :: [Nat])
       (dtype :: DType) (device :: (DeviceType, Nat)).
(KnownNat n, KnownNat m, shape' ~ Transpose shape n m) =&gt;
Tensor device dtype shape -&gt; Tensor device dtype shape'
</span><a href="Torch.Typed.Functional.html#transpose"><span class="hs-identifier hs-var">transpose</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><span class="hs-number">1</span></span><span> </span><span class="hs-glyph">@</span><span class="annot"><span class="hs-number">2</span></span><span> </span><span class="annot"><span class="annottext">(Tensor device dtype '[batchSize, seqLen, numHeads, seqLen]
 -&gt; Tensor device dtype '[batchSize, numHeads, seqLen, seqLen])
-&gt; (Tensor device dtype '[batchSize, seqLen, seqLen, headDim]
    -&gt; Tensor device dtype '[batchSize, seqLen, numHeads, seqLen])
-&gt; Tensor device dtype '[batchSize, seqLen, seqLen, headDim]
-&gt; Tensor device dtype '[batchSize, numHeads, seqLen, seqLen]
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><a href="../file:///nix/store/yi1zp26n2al045qmp9gwpxblhp2c8gs8-ghc-8.8.3-doc/share/doc/ghc/html/libraries/base-4.13.0.0/src"><span class="hs-operator hs-var">.</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor device dtype '[batchSize, seqLen, numHeads, headDim]
-&gt; Tensor device dtype '[batchSize, seqLen, headDim, seqLen]
-&gt; Tensor device dtype '[batchSize, seqLen, numHeads, seqLen]
forall (shape'' :: [Nat]) (shape :: [Nat]) (shape' :: [Nat])
       (dtype :: DType) (device :: (DeviceType, Nat)).
(shape'' ~ MatMul shape shape', MatMulDTypeIsValid device dtype) =&gt;
Tensor device dtype shape
-&gt; Tensor device dtype shape' -&gt; Tensor device dtype shape''
</span><a href="Torch.Typed.Tensor.html#matmul"><span class="hs-identifier hs-var">matmul</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">Tensor device dtype '[batchSize, numHeads, seqLen, headDim]
-&gt; Tensor device dtype '[batchSize, seqLen, numHeads, headDim]
forall (n :: Nat) (m :: Nat) (shape :: [Nat]) (shape' :: [Nat])
       (dtype :: DType) (device :: (DeviceType, Nat)).
(KnownNat n, KnownNat m, shape' ~ Transpose shape n m) =&gt;
Tensor device dtype shape -&gt; Tensor device dtype shape'
</span><a href="Torch.Typed.Functional.html#transpose"><span class="hs-identifier hs-var">transpose</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><span class="hs-number">1</span></span><span> </span><span class="hs-glyph">@</span><span class="annot"><span class="hs-number">2</span></span><span> </span><span class="annot"><span class="annottext">Tensor device dtype '[batchSize, numHeads, seqLen, headDim]
</span><a href="#local-6989586621679721379"><span class="hs-identifier hs-var">q</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">(Tensor device dtype '[batchSize, seqLen, headDim, seqLen]
 -&gt; Tensor device dtype '[batchSize, seqLen, numHeads, seqLen])
-&gt; (Tensor device dtype '[batchSize, seqLen, seqLen, headDim]
    -&gt; Tensor device dtype '[batchSize, seqLen, headDim, seqLen])
-&gt; Tensor device dtype '[batchSize, seqLen, seqLen, headDim]
-&gt; Tensor device dtype '[batchSize, seqLen, numHeads, seqLen]
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><a href="../file:///nix/store/yi1zp26n2al045qmp9gwpxblhp2c8gs8-ghc-8.8.3-doc/share/doc/ghc/html/libraries/base-4.13.0.0/src"><span class="hs-operator hs-var">.</span></a></span><span> </span><span class="annot"><span class="annottext">forall (shape :: [Nat]) (shape' :: [Nat]) (dtype :: DType)
       (device :: (DeviceType, Nat)).
(KnownNat 2, KnownNat 3, shape' ~ Transpose shape 2 3) =&gt;
Tensor device dtype shape -&gt; Tensor device dtype shape'
forall (n :: Nat) (m :: Nat) (shape :: [Nat]) (shape' :: [Nat])
       (dtype :: DType) (device :: (DeviceType, Nat)).
(KnownNat n, KnownNat m, shape' ~ Transpose shape n m) =&gt;
Tensor device dtype shape -&gt; Tensor device dtype shape'
</span><a href="Torch.Typed.Functional.html#transpose"><span class="hs-identifier hs-var">transpose</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><span class="hs-number">2</span></span><span> </span><span class="hs-glyph">@</span><span class="annot"><span class="hs-number">3</span></span><span class="hs-special">)</span><span>
</span><span id="line-125"></span><span>        </span><span class="annot"><span class="annottext">(Maybe (Tensor device dtype '[batchSize, seqLen, seqLen, headDim])
 -&gt; IO (Tensor device dtype '[batchSize, numHeads, seqLen, seqLen]))
-&gt; Maybe
     (Tensor device dtype '[batchSize, seqLen, seqLen, headDim])
-&gt; IO (Tensor device dtype '[batchSize, numHeads, seqLen, seqLen])
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><a href="../file:///nix/store/yi1zp26n2al045qmp9gwpxblhp2c8gs8-ghc-8.8.3-doc/share/doc/ghc/html/libraries/base-4.13.0.0/src"><span class="hs-operator hs-var">$</span></a></span><span> </span><span class="annot"><span class="annottext">Maybe (Tensor device dtype '[batchSize, seqLen, seqLen, headDim])
</span><a href="#local-6989586621679721398"><span class="hs-identifier hs-var">maybeRelationsK</span></a></span><span>
</span><span id="line-126"></span><span>    </span><span id="local-6989586621679721381"><span class="annot"><span class="annottext">attention :: Tensor device dtype '[batchSize, numHeads, seqLen, seqLen]
-&gt; Tensor device dtype '[batchSize, numHeads, seqLen, headDim]
-&gt; Tensor device dtype '[batchSize, seqLen, embedDim]
</span><a href="#local-6989586621679721381"><span class="hs-identifier hs-var hs-var">attention</span></a></span></span><span> </span><span id="local-6989586621679721366"><span class="annot"><span class="annottext">coefficients :: Tensor device dtype '[batchSize, numHeads, seqLen, seqLen]
</span><a href="#local-6989586621679721366"><span class="hs-identifier hs-var">coefficients</span></a></span></span><span> </span><span id="local-6989586621679721365"><span class="annot"><span class="annottext">v :: Tensor device dtype '[batchSize, numHeads, seqLen, headDim]
</span><a href="#local-6989586621679721365"><span class="hs-identifier hs-var">v</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-127"></span><span>      </span><span class="annot"><span class="annottext">Linear embedDim embedDim dtype device
-&gt; Tensor device dtype '[batchSize, seqLen, embedDim]
-&gt; Tensor device dtype '[batchSize, seqLen, embedDim]
forall f a b. HasForward f a b =&gt; f -&gt; a -&gt; b
</span><a href="Torch.Typed.NN.html#forward"><span class="hs-identifier hs-var">forward</span></a></span><span> </span><span class="annot"><span class="annottext">Linear embedDim embedDim dtype device
</span><a href="#local-6989586621679721403"><span class="hs-identifier hs-var">mhaOutProj</span></a></span><span>
</span><span id="line-128"></span><span>        </span><span class="annot"><span class="annottext">(Tensor device dtype '[batchSize, seqLen, embedDim]
 -&gt; Tensor device dtype '[batchSize, seqLen, embedDim])
-&gt; (Maybe
      (Tensor device dtype '[batchSize, seqLen, seqLen, headDim])
    -&gt; Tensor device dtype '[batchSize, seqLen, embedDim])
-&gt; Maybe
     (Tensor device dtype '[batchSize, seqLen, seqLen, headDim])
-&gt; Tensor device dtype '[batchSize, seqLen, embedDim]
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><a href="../file:///nix/store/yi1zp26n2al045qmp9gwpxblhp2c8gs8-ghc-8.8.3-doc/share/doc/ghc/html/libraries/base-4.13.0.0/src"><span class="hs-operator hs-var">.</span></a></span><span> </span><span class="annot"><span class="annottext">forall (shape' :: [Nat]) (shape :: [Nat]) (dtype :: DType)
       (device :: (DeviceType, Nat)).
(KnownShape shape', Numel shape ~ Numel shape') =&gt;
Tensor device dtype shape -&gt; Tensor device dtype shape'
forall (shape :: [Nat]) (dtype :: DType)
       (device :: (DeviceType, Nat)).
(KnownShape '[batchSize, seqLen, embedDim],
 Numel shape ~ Numel '[batchSize, seqLen, embedDim]) =&gt;
Tensor device dtype shape
-&gt; Tensor device dtype '[batchSize, seqLen, embedDim]
</span><a href="Torch.Typed.Tensor.html#reshape"><span class="hs-identifier hs-var">reshape</span></a></span><span> </span><span class="hs-glyph">@</span><span class="hs-special">'</span><span class="hs-special">[</span><span class="annot"><a href="#local-6989586621679721733"><span class="hs-identifier hs-type">batchSize</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679721734"><span class="hs-identifier hs-type">seqLen</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679721736"><span class="hs-identifier hs-type">embedDim</span></a></span><span class="hs-special">]</span><span>
</span><span id="line-129"></span><span>        </span><span class="annot"><span class="annottext">(Tensor device dtype '[batchSize, seqLen, numHeads, headDim]
 -&gt; Tensor device dtype '[batchSize, seqLen, embedDim])
-&gt; (Maybe
      (Tensor device dtype '[batchSize, seqLen, seqLen, headDim])
    -&gt; Tensor device dtype '[batchSize, seqLen, numHeads, headDim])
-&gt; Maybe
     (Tensor device dtype '[batchSize, seqLen, seqLen, headDim])
-&gt; Tensor device dtype '[batchSize, seqLen, embedDim]
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><a href="../file:///nix/store/yi1zp26n2al045qmp9gwpxblhp2c8gs8-ghc-8.8.3-doc/share/doc/ghc/html/libraries/base-4.13.0.0/src"><span class="hs-operator hs-var">.</span></a></span><span> </span><span class="annot"><span class="annottext">(Tensor device dtype '[batchSize, seqLen, numHeads, headDim]
 -&gt; (Tensor device dtype '[batchSize, seqLen, numHeads, headDim]
     -&gt; Tensor device dtype '[batchSize, seqLen, numHeads, headDim])
 -&gt; Maybe
      (Tensor device dtype '[batchSize, seqLen, numHeads, headDim])
 -&gt; Tensor device dtype '[batchSize, seqLen, numHeads, headDim])
-&gt; (Tensor device dtype '[batchSize, seqLen, numHeads, headDim]
    -&gt; Tensor device dtype '[batchSize, seqLen, numHeads, headDim]
    -&gt; Tensor device dtype '[batchSize, seqLen, numHeads, headDim])
-&gt; Tensor device dtype '[batchSize, seqLen, numHeads, headDim]
-&gt; Maybe
     (Tensor device dtype '[batchSize, seqLen, numHeads, headDim])
-&gt; Tensor device dtype '[batchSize, seqLen, numHeads, headDim]
forall (m :: Type -&gt; Type) a b. Monad m =&gt; m (a -&gt; b) -&gt; m a -&gt; m b
</span><a href="../file:///nix/store/yi1zp26n2al045qmp9gwpxblhp2c8gs8-ghc-8.8.3-doc/share/doc/ghc/html/libraries/base-4.13.0.0/src"><span class="hs-identifier hs-var">ap</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor device dtype '[batchSize, seqLen, numHeads, headDim]
-&gt; (Tensor device dtype '[batchSize, seqLen, numHeads, headDim]
    -&gt; Tensor device dtype '[batchSize, seqLen, numHeads, headDim])
-&gt; Maybe
     (Tensor device dtype '[batchSize, seqLen, numHeads, headDim])
-&gt; Tensor device dtype '[batchSize, seqLen, numHeads, headDim]
forall b a. b -&gt; (a -&gt; b) -&gt; Maybe a -&gt; b
</span><a href="../file:///nix/store/yi1zp26n2al045qmp9gwpxblhp2c8gs8-ghc-8.8.3-doc/share/doc/ghc/html/libraries/base-4.13.0.0/src"><span class="hs-identifier hs-var">maybe</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor device dtype '[batchSize, seqLen, numHeads, headDim]
-&gt; Tensor device dtype '[batchSize, seqLen, numHeads, headDim]
-&gt; Tensor device dtype '[batchSize, seqLen, numHeads, headDim]
forall (shape'' :: [Nat]) (shape :: [Nat]) (shape' :: [Nat])
       (dtype :: DType) (dtype' :: DType) (dtype'' :: DType)
       (device :: (DeviceType, Nat)).
(dtype'' ~ DTypePromotion dtype dtype',
 shape'' ~ Broadcast shape shape',
 BasicArithmeticDTypeIsValid device dtype,
 BasicArithmeticDTypeIsValid device dtype',
 BasicArithmeticDTypeIsValid device dtype'') =&gt;
Tensor device dtype shape
-&gt; Tensor device dtype' shape' -&gt; Tensor device dtype'' shape''
</span><a href="Torch.Typed.Tensor.html#add"><span class="hs-identifier hs-var">add</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">forall (shape :: [Nat]) (shape' :: [Nat]) (dtype :: DType)
       (device :: (DeviceType, Nat)).
(KnownNat 1, KnownNat 2, shape' ~ Transpose shape 1 2) =&gt;
Tensor device dtype shape -&gt; Tensor device dtype shape'
forall (n :: Nat) (m :: Nat) (shape :: [Nat]) (shape' :: [Nat])
       (dtype :: DType) (device :: (DeviceType, Nat)).
(KnownNat n, KnownNat m, shape' ~ Transpose shape n m) =&gt;
Tensor device dtype shape -&gt; Tensor device dtype shape'
</span><a href="Torch.Typed.Functional.html#transpose"><span class="hs-identifier hs-var">transpose</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><span class="hs-number">1</span></span><span> </span><span class="hs-glyph">@</span><span class="annot"><span class="hs-number">2</span></span><span> </span><span class="annot"><span class="annottext">(Tensor device dtype '[batchSize, numHeads, seqLen, headDim]
 -&gt; Tensor device dtype '[batchSize, seqLen, numHeads, headDim])
-&gt; (Tensor device dtype '[batchSize, numHeads, seqLen, headDim]
    -&gt; Tensor device dtype '[batchSize, numHeads, seqLen, headDim])
-&gt; Tensor device dtype '[batchSize, numHeads, seqLen, headDim]
-&gt; Tensor device dtype '[batchSize, seqLen, numHeads, headDim]
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><a href="../file:///nix/store/yi1zp26n2al045qmp9gwpxblhp2c8gs8-ghc-8.8.3-doc/share/doc/ghc/html/libraries/base-4.13.0.0/src"><span class="hs-operator hs-var">.</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor device dtype '[batchSize, numHeads, seqLen, seqLen]
-&gt; Tensor device dtype '[batchSize, numHeads, seqLen, headDim]
-&gt; Tensor device dtype '[batchSize, numHeads, seqLen, headDim]
forall (shape'' :: [Nat]) (shape :: [Nat]) (shape' :: [Nat])
       (dtype :: DType) (device :: (DeviceType, Nat)).
(shape'' ~ MatMul shape shape', MatMulDTypeIsValid device dtype) =&gt;
Tensor device dtype shape
-&gt; Tensor device dtype shape' -&gt; Tensor device dtype shape''
</span><a href="Torch.Typed.Tensor.html#matmul"><span class="hs-identifier hs-var">matmul</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor device dtype '[batchSize, numHeads, seqLen, seqLen]
</span><a href="#local-6989586621679721366"><span class="hs-identifier hs-var">coefficients</span></a></span><span> </span><span class="annot"><span class="annottext">(Tensor device dtype '[batchSize, numHeads, seqLen, headDim]
 -&gt; Tensor device dtype '[batchSize, seqLen, numHeads, headDim])
-&gt; Tensor device dtype '[batchSize, numHeads, seqLen, headDim]
-&gt; Tensor device dtype '[batchSize, seqLen, numHeads, headDim]
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><a href="../file:///nix/store/yi1zp26n2al045qmp9gwpxblhp2c8gs8-ghc-8.8.3-doc/share/doc/ghc/html/libraries/base-4.13.0.0/src"><span class="hs-operator hs-var">$</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor device dtype '[batchSize, numHeads, seqLen, headDim]
</span><a href="#local-6989586621679721365"><span class="hs-identifier hs-var">v</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-130"></span><span>        </span><span class="annot"><span class="annottext">(Maybe
   (Tensor device dtype '[batchSize, seqLen, numHeads, headDim])
 -&gt; Tensor device dtype '[batchSize, seqLen, numHeads, headDim])
-&gt; (Maybe
      (Tensor device dtype '[batchSize, seqLen, seqLen, headDim])
    -&gt; Maybe
         (Tensor device dtype '[batchSize, seqLen, numHeads, headDim]))
-&gt; Maybe
     (Tensor device dtype '[batchSize, seqLen, seqLen, headDim])
-&gt; Tensor device dtype '[batchSize, seqLen, numHeads, headDim]
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><a href="../file:///nix/store/yi1zp26n2al045qmp9gwpxblhp2c8gs8-ghc-8.8.3-doc/share/doc/ghc/html/libraries/base-4.13.0.0/src"><span class="hs-operator hs-var">.</span></a></span><span> </span><span class="annot"><span class="annottext">(Tensor device dtype '[batchSize, seqLen, seqLen, headDim]
 -&gt; Tensor device dtype '[batchSize, seqLen, numHeads, headDim])
-&gt; Maybe
     (Tensor device dtype '[batchSize, seqLen, seqLen, headDim])
-&gt; Maybe
     (Tensor device dtype '[batchSize, seqLen, numHeads, headDim])
forall (f :: Type -&gt; Type) a b. Functor f =&gt; (a -&gt; b) -&gt; f a -&gt; f b
</span><a href="../file:///nix/store/yi1zp26n2al045qmp9gwpxblhp2c8gs8-ghc-8.8.3-doc/share/doc/ghc/html/libraries/base-4.13.0.0/src"><span class="hs-identifier hs-var">fmap</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">Tensor device dtype '[batchSize, seqLen, numHeads, seqLen]
-&gt; Tensor device dtype '[batchSize, seqLen, seqLen, headDim]
-&gt; Tensor device dtype '[batchSize, seqLen, numHeads, headDim]
forall (shape'' :: [Nat]) (shape :: [Nat]) (shape' :: [Nat])
       (dtype :: DType) (device :: (DeviceType, Nat)).
(shape'' ~ MatMul shape shape', MatMulDTypeIsValid device dtype) =&gt;
Tensor device dtype shape
-&gt; Tensor device dtype shape' -&gt; Tensor device dtype shape''
</span><a href="Torch.Typed.Tensor.html#matmul"><span class="hs-identifier hs-var">matmul</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">Tensor device dtype '[batchSize, numHeads, seqLen, seqLen]
-&gt; Tensor device dtype '[batchSize, seqLen, numHeads, seqLen]
forall (n :: Nat) (m :: Nat) (shape :: [Nat]) (shape' :: [Nat])
       (dtype :: DType) (device :: (DeviceType, Nat)).
(KnownNat n, KnownNat m, shape' ~ Transpose shape n m) =&gt;
Tensor device dtype shape -&gt; Tensor device dtype shape'
</span><a href="Torch.Typed.Functional.html#transpose"><span class="hs-identifier hs-var">transpose</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><span class="hs-number">1</span></span><span> </span><span class="hs-glyph">@</span><span class="annot"><span class="hs-number">2</span></span><span> </span><span class="annot"><span class="annottext">Tensor device dtype '[batchSize, numHeads, seqLen, seqLen]
</span><a href="#local-6989586621679721366"><span class="hs-identifier hs-var">coefficients</span></a></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-131"></span><span>        </span><span class="annot"><span class="annottext">(Maybe (Tensor device dtype '[batchSize, seqLen, seqLen, headDim])
 -&gt; Tensor device dtype '[batchSize, seqLen, embedDim])
-&gt; Maybe
     (Tensor device dtype '[batchSize, seqLen, seqLen, headDim])
-&gt; Tensor device dtype '[batchSize, seqLen, embedDim]
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><a href="../file:///nix/store/yi1zp26n2al045qmp9gwpxblhp2c8gs8-ghc-8.8.3-doc/share/doc/ghc/html/libraries/base-4.13.0.0/src"><span class="hs-operator hs-var">$</span></a></span><span> </span><span class="annot"><span class="annottext">Maybe (Tensor device dtype '[batchSize, seqLen, seqLen, headDim])
</span><a href="#local-6989586621679721397"><span class="hs-identifier hs-var">maybeRelationsV</span></a></span><span>
</span><span id="line-132"></span><span>    </span><span id="local-6989586621679721380"><span class="annot"><span class="annottext">averageOverHeads :: Tensor device dtype '[batchSize, numHeads, seqLen, seqLen]
-&gt; Tensor device dtype '[batchSize, seqLen, seqLen]
</span><a href="#local-6989586621679721380"><span class="hs-identifier hs-var hs-var">averageOverHeads</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-133"></span><span>      </span><span class="hs-keyword">let</span><span> </span><span id="local-6989586621679721362"><span class="annot"><span class="annottext">numHeads' :: Int
</span><a href="#local-6989586621679721362"><span class="hs-identifier hs-var hs-var">numHeads'</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">KnownNat numHeads =&gt; Int
forall (n :: Nat). KnownNat n =&gt; Int
</span><a href="Torch.Typed.Aux.html#natValI"><span class="hs-identifier hs-var">natValI</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679721738"><span class="hs-identifier hs-type">numHeads</span></a></span><span>
</span><span id="line-134"></span><span>       </span><span class="hs-keyword">in</span><span> </span><span class="annot"><span class="annottext">Int
-&gt; Tensor device dtype '[batchSize, seqLen, seqLen]
-&gt; Tensor device dtype '[batchSize, seqLen, seqLen]
forall a (shape :: [Nat]) (dtype :: DType)
       (device :: (DeviceType, Nat)).
Scalar a =&gt;
a -&gt; Tensor device dtype shape -&gt; Tensor device dtype shape
</span><a href="Torch.Typed.Functional.html#divScalar"><span class="hs-identifier hs-var">divScalar</span></a></span><span> </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679721362"><span class="hs-identifier hs-var">numHeads'</span></a></span><span> </span><span class="annot"><span class="annottext">(Tensor device dtype '[batchSize, seqLen, seqLen]
 -&gt; Tensor device dtype '[batchSize, seqLen, seqLen])
-&gt; (Tensor device dtype '[batchSize, numHeads, seqLen, seqLen]
    -&gt; Tensor device dtype '[batchSize, seqLen, seqLen])
-&gt; Tensor device dtype '[batchSize, numHeads, seqLen, seqLen]
-&gt; Tensor device dtype '[batchSize, seqLen, seqLen]
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><a href="../file:///nix/store/yi1zp26n2al045qmp9gwpxblhp2c8gs8-ghc-8.8.3-doc/share/doc/ghc/html/libraries/base-4.13.0.0/src"><span class="hs-operator hs-var">.</span></a></span><span> </span><span class="annot"><span class="annottext">forall (shape :: [Nat]) (shape' :: [Nat]) (dtype :: DType)
       (dtype' :: DType) (device :: (DeviceType, Nat)).
(KnownNat 1, shape' ~ DropValue shape 1,
 SumDTypeIsValid device dtype, dtype' ~ SumDType dtype) =&gt;
Tensor device dtype shape -&gt; Tensor device dtype' shape'
forall (d :: Nat) (shape :: [Nat]) (shape' :: [Nat])
       (dtype :: DType) (dtype' :: DType) (device :: (DeviceType, Nat)).
(KnownNat d, shape' ~ DropValue shape d,
 SumDTypeIsValid device dtype, dtype' ~ SumDType dtype) =&gt;
Tensor device dtype shape -&gt; Tensor device dtype' shape'
</span><a href="Torch.Typed.Functional.html#sumDim"><span class="hs-identifier hs-var">sumDim</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><span class="hs-number">1</span></span><span>
</span><span id="line-135"></span><span>    </span><span id="local-6989586621679721374"><span class="annot"><span class="annottext">maskAttention :: Tensor device dtype '[batchSize, numHeads, seqLen, seqLen]
-&gt; Tensor device dtype '[batchSize, numHeads, seqLen, seqLen]
</span><a href="#local-6989586621679721374"><span class="hs-identifier hs-var hs-var">maskAttention</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Tensor device dtype '[batchSize, 1, seqLen, seqLen]
-&gt; Tensor device dtype '[batchSize, numHeads, seqLen, seqLen]
-&gt; Tensor device dtype '[batchSize, numHeads, seqLen, seqLen]
forall (shape'' :: [Nat]) (shape :: [Nat]) (shape' :: [Nat])
       (dtype :: DType) (dtype' :: DType) (dtype'' :: DType)
       (device :: (DeviceType, Nat)).
(dtype'' ~ DTypePromotion dtype dtype',
 shape'' ~ Broadcast shape shape',
 BasicArithmeticDTypeIsValid device dtype,
 BasicArithmeticDTypeIsValid device dtype',
 BasicArithmeticDTypeIsValid device dtype'') =&gt;
Tensor device dtype shape
-&gt; Tensor device dtype' shape' -&gt; Tensor device dtype'' shape''
</span><a href="Torch.Typed.Tensor.html#add"><span class="hs-identifier hs-var">add</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">Tensor device dtype '[batchSize, seqLen, seqLen]
-&gt; Tensor device dtype '[batchSize, 1, seqLen, seqLen]
forall (dim :: Nat) (shape :: [Nat]) (shape' :: [Nat])
       (dtype :: DType) (device :: (DeviceType, Nat)).
(KnownNat dim, shape' ~ Unsqueeze shape dim) =&gt;
Tensor device dtype shape -&gt; Tensor device dtype shape'
</span><a href="Torch.Typed.Functional.html#unsqueeze"><span class="hs-identifier hs-var">unsqueeze</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><span class="hs-number">1</span></span><span> </span><span class="annot"><span class="annottext">Tensor device dtype '[batchSize, seqLen, seqLen]
</span><a href="#local-6989586621679721400"><span class="hs-identifier hs-var">attentionMask</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-136"></span><span>    </span><span id="local-6989586621679721375"><span class="annot"><span class="annottext">maskKeyPaddings :: Tensor device dtype '[batchSize, numHeads, seqLen, seqLen]
-&gt; Tensor device dtype '[batchSize, numHeads, seqLen, seqLen]
</span><a href="#local-6989586621679721375"><span class="hs-identifier hs-var hs-var">maskKeyPaddings</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-137"></span><span>      </span><span class="hs-keyword">let</span><span> </span><span id="local-6989586621679721358"><span class="annot"><span class="annottext">keyPaddingMask' :: Tensor device 'Bool '[batchSize, 1, 1, seqLen]
</span><a href="#local-6989586621679721358"><span class="hs-identifier hs-var hs-var">keyPaddingMask'</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">forall (shape :: [Nat]) (shape' :: [Nat]) (dtype :: DType)
       (device :: (DeviceType, Nat)).
(KnownNat 2, shape' ~ Unsqueeze shape 2) =&gt;
Tensor device dtype shape -&gt; Tensor device dtype shape'
forall (dim :: Nat) (shape :: [Nat]) (shape' :: [Nat])
       (dtype :: DType) (device :: (DeviceType, Nat)).
(KnownNat dim, shape' ~ Unsqueeze shape dim) =&gt;
Tensor device dtype shape -&gt; Tensor device dtype shape'
</span><a href="Torch.Typed.Functional.html#unsqueeze"><span class="hs-identifier hs-var">unsqueeze</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><span class="hs-number">2</span></span><span> </span><span class="annot"><span class="annottext">(Tensor device 'Bool '[batchSize, 1, seqLen]
 -&gt; Tensor device 'Bool '[batchSize, 1, 1, seqLen])
-&gt; (Tensor device 'Bool '[batchSize, seqLen]
    -&gt; Tensor device 'Bool '[batchSize, 1, seqLen])
-&gt; Tensor device 'Bool '[batchSize, seqLen]
-&gt; Tensor device 'Bool '[batchSize, 1, 1, seqLen]
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><a href="../file:///nix/store/yi1zp26n2al045qmp9gwpxblhp2c8gs8-ghc-8.8.3-doc/share/doc/ghc/html/libraries/base-4.13.0.0/src"><span class="hs-operator hs-var">.</span></a></span><span> </span><span class="annot"><span class="annottext">forall (shape :: [Nat]) (shape' :: [Nat]) (dtype :: DType)
       (device :: (DeviceType, Nat)).
(KnownNat 1, shape' ~ Unsqueeze shape 1) =&gt;
Tensor device dtype shape -&gt; Tensor device dtype shape'
forall (dim :: Nat) (shape :: [Nat]) (shape' :: [Nat])
       (dtype :: DType) (device :: (DeviceType, Nat)).
(KnownNat dim, shape' ~ Unsqueeze shape dim) =&gt;
Tensor device dtype shape -&gt; Tensor device dtype shape'
</span><a href="Torch.Typed.Functional.html#unsqueeze"><span class="hs-identifier hs-var">unsqueeze</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><span class="hs-number">1</span></span><span> </span><span class="annot"><span class="annottext">(Tensor device 'Bool '[batchSize, seqLen]
 -&gt; Tensor device 'Bool '[batchSize, 1, 1, seqLen])
-&gt; Tensor device 'Bool '[batchSize, seqLen]
-&gt; Tensor device 'Bool '[batchSize, 1, 1, seqLen]
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><a href="../file:///nix/store/yi1zp26n2al045qmp9gwpxblhp2c8gs8-ghc-8.8.3-doc/share/doc/ghc/html/libraries/base-4.13.0.0/src"><span class="hs-operator hs-var">$</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor device 'Bool '[batchSize, seqLen]
</span><a href="#local-6989586621679721399"><span class="hs-identifier hs-var">keyPaddingMask</span></a></span><span>
</span><span id="line-138"></span><span>       </span><span class="hs-keyword">in</span><span> </span><span class="annot"><span class="annottext">Tensor device 'Bool '[batchSize, 1, 1, seqLen]
-&gt; Double
-&gt; Tensor device dtype '[batchSize, numHeads, seqLen, seqLen]
-&gt; Tensor device dtype '[batchSize, numHeads, seqLen, seqLen]
forall a (shape :: [Nat]) (shape' :: [Nat]) (shape'' :: [Nat])
       (dtype :: DType) (device :: (DeviceType, Nat)).
(Scalar a, shape'' ~ Broadcast shape shape') =&gt;
Tensor device 'Bool shape'
-&gt; a -&gt; Tensor device dtype shape -&gt; Tensor device dtype shape''
</span><a href="Torch.Typed.Functional.html#maskedFill"><span class="hs-identifier hs-var">maskedFill</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor device 'Bool '[batchSize, 1, 1, seqLen]
</span><a href="#local-6989586621679721358"><span class="hs-identifier hs-var">keyPaddingMask'</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">-</span><span class="annot"><span class="hs-number">1</span></span><span> </span><span class="annot"><span class="annottext">Double -&gt; Double -&gt; Double
forall a. Fractional a =&gt; a -&gt; a -&gt; a
</span><a href="../file:///nix/store/yi1zp26n2al045qmp9gwpxblhp2c8gs8-ghc-8.8.3-doc/share/doc/ghc/html/libraries/base-4.13.0.0/src"><span class="hs-operator hs-var">/</span></a></span><span> </span><span class="annot"><span class="hs-number">0</span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="../file:///nix/store/yi1zp26n2al045qmp9gwpxblhp2c8gs8-ghc-8.8.3-doc/share/doc/ghc/html/libraries/ghc-prim-0.5.3/src"><span class="hs-identifier hs-type">Double</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-139"></span><span>    </span><span id="local-6989586621679721386"><span class="annot"><span class="annottext">reshape' :: Tensor device dtype '[batchSize, seqLen, embedDim]
-&gt; Tensor device dtype '[batchSize, numHeads, seqLen, headDim]
</span><a href="#local-6989586621679721386"><span class="hs-identifier hs-var hs-var">reshape'</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">forall (shape :: [Nat]) (shape' :: [Nat]) (dtype :: DType)
       (device :: (DeviceType, Nat)).
(KnownNat 1, KnownNat 2, shape' ~ Transpose shape 1 2) =&gt;
Tensor device dtype shape -&gt; Tensor device dtype shape'
forall (n :: Nat) (m :: Nat) (shape :: [Nat]) (shape' :: [Nat])
       (dtype :: DType) (device :: (DeviceType, Nat)).
(KnownNat n, KnownNat m, shape' ~ Transpose shape n m) =&gt;
Tensor device dtype shape -&gt; Tensor device dtype shape'
</span><a href="Torch.Typed.Functional.html#transpose"><span class="hs-identifier hs-var">transpose</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><span class="hs-number">1</span></span><span> </span><span class="hs-glyph">@</span><span class="annot"><span class="hs-number">2</span></span><span> </span><span class="annot"><span class="annottext">(Tensor device dtype '[batchSize, seqLen, numHeads, headDim]
 -&gt; Tensor device dtype '[batchSize, numHeads, seqLen, headDim])
-&gt; (Tensor device dtype '[batchSize, seqLen, embedDim]
    -&gt; Tensor device dtype '[batchSize, seqLen, numHeads, headDim])
-&gt; Tensor device dtype '[batchSize, seqLen, embedDim]
-&gt; Tensor device dtype '[batchSize, numHeads, seqLen, headDim]
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><a href="../file:///nix/store/yi1zp26n2al045qmp9gwpxblhp2c8gs8-ghc-8.8.3-doc/share/doc/ghc/html/libraries/base-4.13.0.0/src"><span class="hs-operator hs-var">.</span></a></span><span> </span><span class="annot"><span class="annottext">forall (shape' :: [Nat]) (shape :: [Nat]) (dtype :: DType)
       (device :: (DeviceType, Nat)).
(KnownShape shape', Numel shape ~ Numel shape') =&gt;
Tensor device dtype shape -&gt; Tensor device dtype shape'
forall (shape :: [Nat]) (dtype :: DType)
       (device :: (DeviceType, Nat)).
(KnownShape '[batchSize, seqLen, numHeads, headDim],
 Numel shape ~ Numel '[batchSize, seqLen, numHeads, headDim]) =&gt;
Tensor device dtype shape
-&gt; Tensor device dtype '[batchSize, seqLen, numHeads, headDim]
</span><a href="Torch.Typed.Tensor.html#reshape"><span class="hs-identifier hs-var">reshape</span></a></span><span> </span><span class="hs-glyph">@</span><span class="hs-special">'</span><span class="hs-special">[</span><span class="annot"><a href="#local-6989586621679721733"><span class="hs-identifier hs-type">batchSize</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679721734"><span class="hs-identifier hs-type">seqLen</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679721738"><span class="hs-identifier hs-type">numHeads</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679721735"><span class="hs-identifier hs-type">headDim</span></a></span><span class="hs-special">]</span><span>
</span><span id="line-140"></span><span>    </span><span id="local-6989586621679721372"><span class="annot"><span class="annottext">scaling :: Double
</span><a href="#local-6989586621679721372"><span class="hs-identifier hs-var hs-var">scaling</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Double -&gt; Double
forall a. Floating a =&gt; a -&gt; a
</span><a href="../file:///nix/store/yi1zp26n2al045qmp9gwpxblhp2c8gs8-ghc-8.8.3-doc/share/doc/ghc/html/libraries/base-4.13.0.0/src"><span class="hs-identifier hs-var">Prelude.sqrt</span></a></span><span> </span><span class="annot"><span class="annottext">(Double -&gt; Double) -&gt; (Int -&gt; Double) -&gt; Int -&gt; Double
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><a href="../file:///nix/store/yi1zp26n2al045qmp9gwpxblhp2c8gs8-ghc-8.8.3-doc/share/doc/ghc/html/libraries/base-4.13.0.0/src"><span class="hs-operator hs-var">.</span></a></span><span> </span><span class="annot"><span class="annottext">Int -&gt; Double
forall a b. (Integral a, Num b) =&gt; a -&gt; b
</span><a href="../file:///nix/store/yi1zp26n2al045qmp9gwpxblhp2c8gs8-ghc-8.8.3-doc/share/doc/ghc/html/libraries/base-4.13.0.0/src"><span class="hs-identifier hs-var">fromIntegral</span></a></span><span> </span><span class="annot"><span class="annottext">(Int -&gt; Double) -&gt; Int -&gt; Double
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><a href="../file:///nix/store/yi1zp26n2al045qmp9gwpxblhp2c8gs8-ghc-8.8.3-doc/share/doc/ghc/html/libraries/base-4.13.0.0/src"><span class="hs-operator hs-var">$</span></a></span><span> </span><span class="annot"><span class="annottext">KnownNat headDim =&gt; Int
forall (n :: Nat). KnownNat n =&gt; Int
</span><a href="Torch.Typed.Aux.html#natValI"><span class="hs-identifier hs-var">natValI</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679721735"><span class="hs-identifier hs-type">headDim</span></a></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="../file:///nix/store/yi1zp26n2al045qmp9gwpxblhp2c8gs8-ghc-8.8.3-doc/share/doc/ghc/html/libraries/ghc-prim-0.5.3/src"><span class="hs-identifier hs-type">Double</span></a></span><span>
</span><span id="line-141"></span><span>
</span><span id="line-142"></span><span id="local-6989586621679721351"><span id="local-6989586621679721352"><span id="local-6989586621679721353"><span id="local-6989586621679721354"><span class="hs-keyword">instance</span><span> </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="Torch.Typed.Tensor.html#All"><span class="hs-identifier hs-type">All</span></a></span><span> </span><span class="annot"><a href="../file:///nix/store/yi1zp26n2al045qmp9gwpxblhp2c8gs8-ghc-8.8.3-doc/share/doc/ghc/html/libraries/base-4.13.0.0/src"><span class="hs-identifier hs-type">KnownNat</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="annot"><a href="#local-6989586621679721354"><span class="hs-identifier hs-type">embedDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679721353"><span class="hs-identifier hs-type">numHeads</span></a></span><span class="hs-special">]</span><span>
</span><span id="line-143"></span><span>         </span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.Typed.Tensor.html#KnownDType"><span class="hs-identifier hs-type">KnownDType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679721352"><span class="hs-identifier hs-type">dtype</span></a></span><span>
</span><span id="line-144"></span><span>         </span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.Typed.Tensor.html#KnownDevice"><span class="hs-identifier hs-type">KnownDevice</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679721351"><span class="hs-identifier hs-type">device</span></a></span><span>
</span><span id="line-145"></span><span>         </span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.Typed.Factories.html#RandDTypeIsValid"><span class="hs-identifier hs-type">RandDTypeIsValid</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679721351"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679721352"><span class="hs-identifier hs-type">dtype</span></a></span><span>
</span><span id="line-146"></span><span>         </span><span class="hs-special">)</span><span>
</span><span id="line-147"></span><span>  </span><span class="hs-glyph">=&gt;</span><span> </span><span class="annot"><a href="Torch.NN.html#Randomizable"><span class="hs-identifier hs-type">A.Randomizable</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.NN.Transformer.html#MultiheadAttentionSpec"><span class="hs-identifier hs-type">MultiheadAttentionSpec</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679721354"><span class="hs-identifier hs-type">embedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679721353"><span class="hs-identifier hs-type">numHeads</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679721352"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679721351"><span class="hs-identifier hs-type">device</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-148"></span><span>                    </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.NN.Transformer.html#MultiheadAttention"><span class="hs-identifier hs-type">MultiheadAttention</span></a></span><span>     </span><span class="annot"><a href="#local-6989586621679721354"><span class="hs-identifier hs-type">embedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679721353"><span class="hs-identifier hs-type">numHeads</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679721352"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679721351"><span class="hs-identifier hs-type">device</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-149"></span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-150"></span><span>  </span><span id="local-6989586621679721348"><span class="annot"><span class="annottext">sample :: MultiheadAttentionSpec embedDim numHeads dtype device
-&gt; IO (MultiheadAttention embedDim numHeads dtype device)
</span><a href="Torch.NN.html#sample"><span class="hs-identifier hs-var hs-var hs-var hs-var">sample</span></a></span></span><span> </span><span id="local-6989586621679721346"><span class="annot"><a href="Torch.Typed.NN.Transformer.html#MultiheadAttentionSpec"><span class="hs-identifier hs-type">MultiheadAttentionSpec</span></a></span><span> </span><span class="hs-special">{</span><span class="hs-glyph">..</span><span class="hs-special">}</span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-151"></span><span>    </span><span class="annot"><span class="annottext">Linear embedDim (embedDim * 3) dtype device
-&gt; Linear embedDim embedDim dtype device
-&gt; Dropout
-&gt; MultiheadAttention embedDim numHeads dtype device
forall (embedDim :: Nat) (dtype :: DType)
       (device :: (DeviceType, Nat)) (numHeads :: Nat).
Linear embedDim (embedDim * 3) dtype device
-&gt; Linear embedDim embedDim dtype device
-&gt; Dropout
-&gt; MultiheadAttention embedDim numHeads dtype device
</span><a href="Torch.Typed.NN.Transformer.html#MultiheadAttention"><span class="hs-identifier hs-var">MultiheadAttention</span></a></span><span>
</span><span id="line-152"></span><span>      </span><span class="annot"><span class="annottext">(Linear embedDim (embedDim * 3) dtype device
 -&gt; Linear embedDim embedDim dtype device
 -&gt; Dropout
 -&gt; MultiheadAttention embedDim numHeads dtype device)
-&gt; IO (Linear embedDim (embedDim * 3) dtype device)
-&gt; IO
     (Linear embedDim embedDim dtype device
      -&gt; Dropout -&gt; MultiheadAttention embedDim numHeads dtype device)
forall (f :: Type -&gt; Type) a b. Functor f =&gt; (a -&gt; b) -&gt; f a -&gt; f b
</span><a href="../file:///nix/store/yi1zp26n2al045qmp9gwpxblhp2c8gs8-ghc-8.8.3-doc/share/doc/ghc/html/libraries/base-4.13.0.0/src"><span class="hs-operator hs-var">&lt;$&gt;</span></a></span><span> </span><span class="annot"><span class="annottext">LinearSpec embedDim (embedDim * 3) dtype device
-&gt; IO (Linear embedDim (embedDim * 3) dtype device)
forall spec f. Randomizable spec f =&gt; spec -&gt; IO f
</span><a href="Torch.NN.html#sample"><span class="hs-identifier hs-var">A.sample</span></a></span><span> </span><span class="annot"><span class="annottext">LinearSpec embedDim (embedDim * 3) dtype device
forall (inputFeatures :: Nat) (outputFeatures :: Nat)
       (dtype :: DType) (device :: (DeviceType, Nat)).
LinearSpec inputFeatures outputFeatures dtype device
</span><a href="Torch.Typed.NN.html#LinearSpec"><span class="hs-identifier hs-var">LinearSpec</span></a></span><span>
</span><span id="line-153"></span><span>      </span><span class="annot"><span class="annottext">IO
  (Linear embedDim embedDim dtype device
   -&gt; Dropout -&gt; MultiheadAttention embedDim numHeads dtype device)
-&gt; IO (Linear embedDim embedDim dtype device)
-&gt; IO
     (Dropout -&gt; MultiheadAttention embedDim numHeads dtype device)
forall (f :: Type -&gt; Type) a b.
Applicative f =&gt;
f (a -&gt; b) -&gt; f a -&gt; f b
</span><a href="../file:///nix/store/yi1zp26n2al045qmp9gwpxblhp2c8gs8-ghc-8.8.3-doc/share/doc/ghc/html/libraries/base-4.13.0.0/src"><span class="hs-operator hs-var">&lt;*&gt;</span></a></span><span> </span><span class="annot"><span class="annottext">LinearSpec embedDim embedDim dtype device
-&gt; IO (Linear embedDim embedDim dtype device)
forall spec f. Randomizable spec f =&gt; spec -&gt; IO f
</span><a href="Torch.NN.html#sample"><span class="hs-identifier hs-var">A.sample</span></a></span><span> </span><span class="annot"><span class="annottext">LinearSpec embedDim embedDim dtype device
forall (inputFeatures :: Nat) (outputFeatures :: Nat)
       (dtype :: DType) (device :: (DeviceType, Nat)).
LinearSpec inputFeatures outputFeatures dtype device
</span><a href="Torch.Typed.NN.html#LinearSpec"><span class="hs-identifier hs-var">LinearSpec</span></a></span><span>
</span><span id="line-154"></span><span>      </span><span class="annot"><span class="annottext">IO (Dropout -&gt; MultiheadAttention embedDim numHeads dtype device)
-&gt; IO Dropout
-&gt; IO (MultiheadAttention embedDim numHeads dtype device)
forall (f :: Type -&gt; Type) a b.
Applicative f =&gt;
f (a -&gt; b) -&gt; f a -&gt; f b
</span><a href="../file:///nix/store/yi1zp26n2al045qmp9gwpxblhp2c8gs8-ghc-8.8.3-doc/share/doc/ghc/html/libraries/base-4.13.0.0/src"><span class="hs-operator hs-var">&lt;*&gt;</span></a></span><span> </span><span class="annot"><span class="annottext">DropoutSpec -&gt; IO Dropout
forall spec f. Randomizable spec f =&gt; spec -&gt; IO f
</span><a href="Torch.NN.html#sample"><span class="hs-identifier hs-var">A.sample</span></a></span><span> </span><span class="annot"><span class="annottext">DropoutSpec
</span><a href="#local-6989586621679721346"><span class="hs-identifier hs-var">mhaDropoutSpec</span></a></span></span></span></span></span><span>
</span><span id="line-155"></span><span>
</span><span id="line-156"></span><span class="hs-comment">--------------------------------------------------------------------------------</span><span>
</span><span id="line-157"></span><span class="hs-comment">-- Transformer MLP Layer</span><span>
</span><span id="line-158"></span><span class="hs-comment">--------------------------------------------------------------------------------</span><span>
</span><span id="line-159"></span><span>
</span><span id="line-160"></span><span class="hs-keyword">data</span><span>
</span><span id="line-161"></span><span>  </span><span id="TransformerMLPSpec"><span class="annot"><a href="Torch.Typed.NN.Transformer.html#TransformerMLPSpec"><span class="hs-identifier hs-var">TransformerMLPSpec</span></a></span></span><span>
</span><span id="line-162"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679721343"><span class="annot"><a href="#local-6989586621679721343"><span class="hs-identifier hs-type">embedDim</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="../file:///nix/store/yi1zp26n2al045qmp9gwpxblhp2c8gs8-ghc-8.8.3-doc/share/doc/ghc/html/libraries/ghc-prim-0.5.3/src"><span class="hs-identifier hs-type">Nat</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-163"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679721342"><span class="annot"><a href="#local-6989586621679721342"><span class="hs-identifier hs-type">ffnDim</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="../file:///nix/store/yi1zp26n2al045qmp9gwpxblhp2c8gs8-ghc-8.8.3-doc/share/doc/ghc/html/libraries/ghc-prim-0.5.3/src"><span class="hs-identifier hs-type">Nat</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-164"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679721341"><span class="annot"><a href="#local-6989586621679721341"><span class="hs-identifier hs-type">dtype</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.DType.html#DType"><span class="hs-identifier hs-type">D.DType</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-165"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679721340"><span class="annot"><a href="#local-6989586621679721340"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Device.html#DeviceType"><span class="hs-identifier hs-type">D.DeviceType</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="../file:///nix/store/yi1zp26n2al045qmp9gwpxblhp2c8gs8-ghc-8.8.3-doc/share/doc/ghc/html/libraries/ghc-prim-0.5.3/src"><span class="hs-identifier hs-type">Nat</span></a></span><span class="hs-special">)</span><span class="hs-special">)</span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-166"></span><span>  </span><span id="TransformerMLPSpec"><span class="annot"><a href="Torch.Typed.NN.Transformer.html#TransformerMLPSpec"><span class="hs-identifier hs-var">TransformerMLPSpec</span></a></span></span><span>
</span><span id="line-167"></span><span>    </span><span class="hs-glyph">::</span><span> </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679721820"><span class="annot"><a href="#local-6989586621679721820"><span class="hs-identifier hs-type">embedDim</span></a></span></span><span> </span><span id="local-6989586621679721819"><span class="annot"><a href="#local-6989586621679721819"><span class="hs-identifier hs-type">ffnDim</span></a></span></span><span> </span><span id="local-6989586621679721818"><span class="annot"><a href="#local-6989586621679721818"><span class="hs-identifier hs-type">dtype</span></a></span></span><span> </span><span id="local-6989586621679721817"><span class="annot"><a href="#local-6989586621679721817"><span class="hs-identifier hs-type">device</span></a></span></span><span>
</span><span id="line-168"></span><span>     </span><span class="hs-operator">.</span><span> </span><span class="hs-special">{</span><span> </span><span id="dropout0Spec"><span class="annot"><span class="annottext">TransformerMLPSpec embedDim ffnDim dtype device -&gt; DropoutSpec
</span><a href="Torch.Typed.NN.Transformer.html#dropout0Spec"><span class="hs-identifier hs-var hs-var">dropout0Spec</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.Typed.NN.html#DropoutSpec"><span class="hs-identifier hs-type">DropoutSpec</span></a></span><span>
</span><span id="line-169"></span><span>       </span><span class="hs-special">,</span><span> </span><span id="dropout1Spec"><span class="annot"><span class="annottext">TransformerMLPSpec embedDim ffnDim dtype device -&gt; DropoutSpec
</span><a href="Torch.Typed.NN.Transformer.html#dropout1Spec"><span class="hs-identifier hs-var hs-var">dropout1Spec</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.Typed.NN.html#DropoutSpec"><span class="hs-identifier hs-type">DropoutSpec</span></a></span><span>
</span><span id="line-170"></span><span>       </span><span class="hs-special">}</span><span>
</span><span id="line-171"></span><span>    </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Typed.NN.Transformer.html#TransformerMLPSpec"><span class="hs-identifier hs-type">TransformerMLPSpec</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679721820"><span class="hs-identifier hs-type">embedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679721819"><span class="hs-identifier hs-type">ffnDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679721818"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679721817"><span class="hs-identifier hs-type">device</span></a></span><span>
</span><span id="line-172"></span><span>  </span><span class="hs-keyword">deriving</span><span> </span><span id="local-6989586621679721331"><span id="local-6989586621679721333"><span id="local-6989586621679721335"><span class="annot"><span class="annottext">Int -&gt; TransformerMLPSpec embedDim ffnDim dtype device -&gt; ShowS
[TransformerMLPSpec embedDim ffnDim dtype device] -&gt; ShowS
TransformerMLPSpec embedDim ffnDim dtype device -&gt; String
(Int -&gt; TransformerMLPSpec embedDim ffnDim dtype device -&gt; ShowS)
-&gt; (TransformerMLPSpec embedDim ffnDim dtype device -&gt; String)
-&gt; ([TransformerMLPSpec embedDim ffnDim dtype device] -&gt; ShowS)
-&gt; Show (TransformerMLPSpec embedDim ffnDim dtype device)
forall a.
(Int -&gt; a -&gt; ShowS) -&gt; (a -&gt; String) -&gt; ([a] -&gt; ShowS) -&gt; Show a
forall (embedDim :: Nat) (ffnDim :: Nat) (dtype :: DType)
       (device :: (DeviceType, Nat)).
Int -&gt; TransformerMLPSpec embedDim ffnDim dtype device -&gt; ShowS
forall (embedDim :: Nat) (ffnDim :: Nat) (dtype :: DType)
       (device :: (DeviceType, Nat)).
[TransformerMLPSpec embedDim ffnDim dtype device] -&gt; ShowS
forall (embedDim :: Nat) (ffnDim :: Nat) (dtype :: DType)
       (device :: (DeviceType, Nat)).
TransformerMLPSpec embedDim ffnDim dtype device -&gt; String
showList :: [TransformerMLPSpec embedDim ffnDim dtype device] -&gt; ShowS
$cshowList :: forall (embedDim :: Nat) (ffnDim :: Nat) (dtype :: DType)
       (device :: (DeviceType, Nat)).
[TransformerMLPSpec embedDim ffnDim dtype device] -&gt; ShowS
show :: TransformerMLPSpec embedDim ffnDim dtype device -&gt; String
$cshow :: forall (embedDim :: Nat) (ffnDim :: Nat) (dtype :: DType)
       (device :: (DeviceType, Nat)).
TransformerMLPSpec embedDim ffnDim dtype device -&gt; String
showsPrec :: Int -&gt; TransformerMLPSpec embedDim ffnDim dtype device -&gt; ShowS
$cshowsPrec :: forall (embedDim :: Nat) (ffnDim :: Nat) (dtype :: DType)
       (device :: (DeviceType, Nat)).
Int -&gt; TransformerMLPSpec embedDim ffnDim dtype device -&gt; ShowS
</span><a href="../file:///nix/store/yi1zp26n2al045qmp9gwpxblhp2c8gs8-ghc-8.8.3-doc/share/doc/ghc/html/libraries/base-4.13.0.0/src"><span class="hs-identifier hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var">Show</span></a></span></span></span></span><span>
</span><span id="line-173"></span><span>
</span><span id="line-174"></span><span id="local-6989586621679721329"><span id="local-6989586621679721330"></span></span><span class="hs-keyword">data</span><span>
</span><span id="line-175"></span><span>  </span><span id="TransformerMLP"><span class="annot"><a href="Torch.Typed.NN.Transformer.html#TransformerMLP"><span class="hs-identifier hs-var">TransformerMLP</span></a></span></span><span>
</span><span id="line-176"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679721328"><span class="annot"><a href="#local-6989586621679721328"><span class="hs-identifier hs-type">embedDim</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="../file:///nix/store/yi1zp26n2al045qmp9gwpxblhp2c8gs8-ghc-8.8.3-doc/share/doc/ghc/html/libraries/ghc-prim-0.5.3/src"><span class="hs-identifier hs-type">Nat</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-177"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679721327"><span class="annot"><a href="#local-6989586621679721327"><span class="hs-identifier hs-type">ffnDim</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="../file:///nix/store/yi1zp26n2al045qmp9gwpxblhp2c8gs8-ghc-8.8.3-doc/share/doc/ghc/html/libraries/ghc-prim-0.5.3/src"><span class="hs-identifier hs-type">Nat</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-178"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679721326"><span class="annot"><a href="#local-6989586621679721326"><span class="hs-identifier hs-type">dtype</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.DType.html#DType"><span class="hs-identifier hs-type">D.DType</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-179"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679721325"><span class="annot"><a href="#local-6989586621679721325"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Device.html#DeviceType"><span class="hs-identifier hs-type">D.DeviceType</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="../file:///nix/store/yi1zp26n2al045qmp9gwpxblhp2c8gs8-ghc-8.8.3-doc/share/doc/ghc/html/libraries/ghc-prim-0.5.3/src"><span class="hs-identifier hs-type">Nat</span></a></span><span class="hs-special">)</span><span class="hs-special">)</span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-180"></span><span>  </span><span id="TransformerMLP"><span class="annot"><a href="Torch.Typed.NN.Transformer.html#TransformerMLP"><span class="hs-identifier hs-var">TransformerMLP</span></a></span></span><span>
</span><span id="line-181"></span><span>    </span><span class="hs-glyph">::</span><span> </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679721835"><span class="annot"><a href="#local-6989586621679721835"><span class="hs-identifier hs-type">embedDim</span></a></span></span><span> </span><span id="local-6989586621679721834"><span class="annot"><a href="#local-6989586621679721834"><span class="hs-identifier hs-type">ffnDim</span></a></span></span><span> </span><span id="local-6989586621679721833"><span class="annot"><a href="#local-6989586621679721833"><span class="hs-identifier hs-type">dtype</span></a></span></span><span> </span><span id="local-6989586621679721832"><span class="annot"><a href="#local-6989586621679721832"><span class="hs-identifier hs-type">device</span></a></span></span><span>
</span><span id="line-182"></span><span>     </span><span class="hs-operator">.</span><span> </span><span class="hs-special">{</span><span> </span><span id="linear0"><span class="annot"><span class="annottext">TransformerMLP embedDim ffnDim dtype device
-&gt; Linear embedDim ffnDim dtype device
</span><a href="Torch.Typed.NN.Transformer.html#linear0"><span class="hs-identifier hs-var hs-var">linear0</span></a></span></span><span>     </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.Typed.NN.html#Linear"><span class="hs-identifier hs-type">Linear</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679721835"><span class="hs-identifier hs-type">embedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679721834"><span class="hs-identifier hs-type">ffnDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679721833"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679721832"><span class="hs-identifier hs-type">device</span></a></span><span>
</span><span id="line-183"></span><span>       </span><span class="hs-special">,</span><span> </span><span id="linear1"><span class="annot"><span class="annottext">TransformerMLP embedDim ffnDim dtype device
-&gt; Linear ffnDim embedDim dtype device
</span><a href="Torch.Typed.NN.Transformer.html#linear1"><span class="hs-identifier hs-var hs-var">linear1</span></a></span></span><span>     </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.Typed.NN.html#Linear"><span class="hs-identifier hs-type">Linear</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679721834"><span class="hs-identifier hs-type">ffnDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679721835"><span class="hs-identifier hs-type">embedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679721833"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679721832"><span class="hs-identifier hs-type">device</span></a></span><span>
</span><span id="line-184"></span><span>       </span><span class="hs-special">,</span><span> </span><span id="dropout0"><span class="annot"><span class="annottext">TransformerMLP embedDim ffnDim dtype device -&gt; Dropout
</span><a href="Torch.Typed.NN.Transformer.html#dropout0"><span class="hs-identifier hs-var hs-var">dropout0</span></a></span></span><span>    </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.Typed.NN.html#Dropout"><span class="hs-identifier hs-type">Dropout</span></a></span><span>
</span><span id="line-185"></span><span>       </span><span class="hs-special">,</span><span> </span><span id="dropout1"><span class="annot"><span class="annottext">TransformerMLP embedDim ffnDim dtype device -&gt; Dropout
</span><a href="Torch.Typed.NN.Transformer.html#dropout1"><span class="hs-identifier hs-var hs-var">dropout1</span></a></span></span><span>    </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.Typed.NN.html#Dropout"><span class="hs-identifier hs-type">Dropout</span></a></span><span>
</span><span id="line-186"></span><span>       </span><span class="hs-special">}</span><span>
</span><span id="line-187"></span><span>    </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Typed.NN.Transformer.html#TransformerMLP"><span class="hs-identifier hs-type">TransformerMLP</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679721835"><span class="hs-identifier hs-type">embedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679721834"><span class="hs-identifier hs-type">ffnDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679721833"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679721832"><span class="hs-identifier hs-type">device</span></a></span><span>
</span><span id="line-188"></span><span> </span><span class="hs-keyword">deriving</span><span> </span><span class="hs-special">(</span><span id="local-6989586621679721314"><span id="local-6989586621679721316"><span id="local-6989586621679721318"><span class="annot"><span class="annottext">Int -&gt; TransformerMLP embedDim ffnDim dtype device -&gt; ShowS
[TransformerMLP embedDim ffnDim dtype device] -&gt; ShowS
TransformerMLP embedDim ffnDim dtype device -&gt; String
(Int -&gt; TransformerMLP embedDim ffnDim dtype device -&gt; ShowS)
-&gt; (TransformerMLP embedDim ffnDim dtype device -&gt; String)
-&gt; ([TransformerMLP embedDim ffnDim dtype device] -&gt; ShowS)
-&gt; Show (TransformerMLP embedDim ffnDim dtype device)
forall a.
(Int -&gt; a -&gt; ShowS) -&gt; (a -&gt; String) -&gt; ([a] -&gt; ShowS) -&gt; Show a
forall (embedDim :: Nat) (ffnDim :: Nat) (dtype :: DType)
       (device :: (DeviceType, Nat)).
Int -&gt; TransformerMLP embedDim ffnDim dtype device -&gt; ShowS
forall (embedDim :: Nat) (ffnDim :: Nat) (dtype :: DType)
       (device :: (DeviceType, Nat)).
[TransformerMLP embedDim ffnDim dtype device] -&gt; ShowS
forall (embedDim :: Nat) (ffnDim :: Nat) (dtype :: DType)
       (device :: (DeviceType, Nat)).
TransformerMLP embedDim ffnDim dtype device -&gt; String
showList :: [TransformerMLP embedDim ffnDim dtype device] -&gt; ShowS
$cshowList :: forall (embedDim :: Nat) (ffnDim :: Nat) (dtype :: DType)
       (device :: (DeviceType, Nat)).
[TransformerMLP embedDim ffnDim dtype device] -&gt; ShowS
show :: TransformerMLP embedDim ffnDim dtype device -&gt; String
$cshow :: forall (embedDim :: Nat) (ffnDim :: Nat) (dtype :: DType)
       (device :: (DeviceType, Nat)).
TransformerMLP embedDim ffnDim dtype device -&gt; String
showsPrec :: Int -&gt; TransformerMLP embedDim ffnDim dtype device -&gt; ShowS
$cshowsPrec :: forall (embedDim :: Nat) (ffnDim :: Nat) (dtype :: DType)
       (device :: (DeviceType, Nat)).
Int -&gt; TransformerMLP embedDim ffnDim dtype device -&gt; ShowS
</span><a href="../file:///nix/store/yi1zp26n2al045qmp9gwpxblhp2c8gs8-ghc-8.8.3-doc/share/doc/ghc/html/libraries/base-4.13.0.0/src"><span class="hs-identifier hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var">Show</span></a></span></span></span></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">(forall x.
 TransformerMLP embedDim ffnDim dtype device
 -&gt; Rep (TransformerMLP embedDim ffnDim dtype device) x)
-&gt; (forall x.
    Rep (TransformerMLP embedDim ffnDim dtype device) x
    -&gt; TransformerMLP embedDim ffnDim dtype device)
-&gt; Generic (TransformerMLP embedDim ffnDim dtype device)
forall x.
Rep (TransformerMLP embedDim ffnDim dtype device) x
-&gt; TransformerMLP embedDim ffnDim dtype device
forall x.
TransformerMLP embedDim ffnDim dtype device
-&gt; Rep (TransformerMLP embedDim ffnDim dtype device) x
forall a.
(forall x. a -&gt; Rep a x) -&gt; (forall x. Rep a x -&gt; a) -&gt; Generic a
forall (embedDim :: Nat) (ffnDim :: Nat) (dtype :: DType)
       (device :: (DeviceType, Nat)) x.
Rep (TransformerMLP embedDim ffnDim dtype device) x
-&gt; TransformerMLP embedDim ffnDim dtype device
forall (embedDim :: Nat) (ffnDim :: Nat) (dtype :: DType)
       (device :: (DeviceType, Nat)) x.
TransformerMLP embedDim ffnDim dtype device
-&gt; Rep (TransformerMLP embedDim ffnDim dtype device) x
$cto :: forall (embedDim :: Nat) (ffnDim :: Nat) (dtype :: DType)
       (device :: (DeviceType, Nat)) x.
Rep (TransformerMLP embedDim ffnDim dtype device) x
-&gt; TransformerMLP embedDim ffnDim dtype device
$cfrom :: forall (embedDim :: Nat) (ffnDim :: Nat) (dtype :: DType)
       (device :: (DeviceType, Nat)) x.
TransformerMLP embedDim ffnDim dtype device
-&gt; Rep (TransformerMLP embedDim ffnDim dtype device) x
</span><a href="../file:///nix/store/yi1zp26n2al045qmp9gwpxblhp2c8gs8-ghc-8.8.3-doc/share/doc/ghc/html/libraries/base-4.13.0.0/src"><span class="hs-identifier hs-var hs-var hs-var hs-var">Generic</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-189"></span><span>
</span><span id="line-190"></span><span class="annot"><a href="Torch.Typed.NN.Transformer.html#transformerMLP"><span class="hs-identifier hs-type">transformerMLP</span></a></span><span>
</span><span id="line-191"></span><span>  </span><span class="hs-glyph">::</span><span> </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679721728"><span class="annot"><a href="#local-6989586621679721728"><span class="hs-identifier hs-type">embedDim</span></a></span></span><span> </span><span id="local-6989586621679721727"><span class="annot"><a href="#local-6989586621679721727"><span class="hs-identifier hs-type">ffnDim</span></a></span></span><span> </span><span id="local-6989586621679721726"><span class="annot"><a href="#local-6989586621679721726"><span class="hs-identifier hs-type">seqLen</span></a></span></span><span> </span><span id="local-6989586621679721725"><span class="annot"><a href="#local-6989586621679721725"><span class="hs-identifier hs-type">batchSize</span></a></span></span><span> </span><span id="local-6989586621679721729"><span class="annot"><a href="#local-6989586621679721729"><span class="hs-identifier hs-type">dtype</span></a></span></span><span> </span><span id="local-6989586621679721730"><span class="annot"><a href="#local-6989586621679721730"><span class="hs-identifier hs-type">device</span></a></span></span><span>
</span><span id="line-192"></span><span>   </span><span class="hs-operator">.</span><span> </span><span class="annot"><a href="Torch.Typed.Aux.html#StandardFloatingPointDTypeValidation"><span class="hs-identifier hs-type">StandardFloatingPointDTypeValidation</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679721730"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679721729"><span class="hs-identifier hs-type">dtype</span></a></span><span>
</span><span id="line-193"></span><span>  </span><span class="hs-glyph">=&gt;</span><span> </span><span class="annot"><a href="Torch.Typed.NN.Transformer.html#TransformerMLP"><span class="hs-identifier hs-type">TransformerMLP</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679721728"><span class="hs-identifier hs-type">embedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679721727"><span class="hs-identifier hs-type">ffnDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679721729"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679721730"><span class="hs-identifier hs-type">device</span></a></span><span>
</span><span id="line-194"></span><span>  </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="../file:///nix/store/yi1zp26n2al045qmp9gwpxblhp2c8gs8-ghc-8.8.3-doc/share/doc/ghc/html/libraries/ghc-prim-0.5.3/src"><span class="hs-identifier hs-type">Bool</span></a></span><span>
</span><span id="line-195"></span><span>  </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679721730"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679721729"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="annot"><a href="#local-6989586621679721726"><span class="hs-identifier hs-type">seqLen</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679721725"><span class="hs-identifier hs-type">batchSize</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679721728"><span class="hs-identifier hs-type">embedDim</span></a></span><span class="hs-special">]</span><span>
</span><span id="line-196"></span><span>  </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="../file:///nix/store/yi1zp26n2al045qmp9gwpxblhp2c8gs8-ghc-8.8.3-doc/share/doc/ghc/html/libraries/ghc-prim-0.5.3/src"><span class="hs-identifier hs-type">IO</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679721730"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679721729"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="annot"><a href="#local-6989586621679721726"><span class="hs-identifier hs-type">seqLen</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679721725"><span class="hs-identifier hs-type">batchSize</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679721728"><span class="hs-identifier hs-type">embedDim</span></a></span><span class="hs-special">]</span><span class="hs-special">)</span><span>
</span><span id="line-197"></span><span id="transformerMLP"><span class="annot"><span class="annottext">transformerMLP :: TransformerMLP embedDim ffnDim dtype device
-&gt; Bool
-&gt; Tensor device dtype '[seqLen, batchSize, embedDim]
-&gt; IO (Tensor device dtype '[seqLen, batchSize, embedDim])
</span><a href="Torch.Typed.NN.Transformer.html#transformerMLP"><span class="hs-identifier hs-var hs-var">transformerMLP</span></a></span></span><span> </span><span id="local-6989586621679721307"><span id="local-6989586621679721308"><span id="local-6989586621679721309"><span id="local-6989586621679721310"><span class="annot"><a href="Torch.Typed.NN.Transformer.html#TransformerMLP"><span class="hs-identifier hs-type">TransformerMLP</span></a></span><span> </span><span class="hs-special">{</span><span class="hs-glyph">..</span><span class="hs-special">}</span></span></span></span></span><span> </span><span id="local-6989586621679721306"><span class="annot"><span class="annottext">train :: Bool
</span><a href="#local-6989586621679721306"><span class="hs-identifier hs-var">train</span></a></span></span><span> </span><span id="local-6989586621679721305"><span class="annot"><span class="annottext">input :: Tensor device dtype '[seqLen, batchSize, embedDim]
</span><a href="#local-6989586621679721305"><span class="hs-identifier hs-var">input</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-198"></span><span>  </span><span class="annot"><span class="annottext">Dropout
-&gt; Bool
-&gt; Tensor device dtype '[seqLen, batchSize, embedDim]
-&gt; IO (Tensor device dtype '[seqLen, batchSize, embedDim])
forall (shape :: [Nat]) (dtype :: DType)
       (device :: (DeviceType, Nat)).
Dropout
-&gt; Bool
-&gt; Tensor device dtype shape
-&gt; IO (Tensor device dtype shape)
</span><a href="Torch.Typed.NN.html#dropout"><span class="hs-identifier hs-var">Torch.Typed.NN.dropout</span></a></span><span> </span><span class="annot"><span class="annottext">Dropout
</span><a href="#local-6989586621679721307"><span class="hs-identifier hs-var">dropout1</span></a></span><span> </span><span class="annot"><span class="annottext">Bool
</span><a href="#local-6989586621679721306"><span class="hs-identifier hs-var">train</span></a></span><span>
</span><span id="line-199"></span><span>    </span><span class="annot"><span class="annottext">(Tensor device dtype '[seqLen, batchSize, embedDim]
 -&gt; IO (Tensor device dtype '[seqLen, batchSize, embedDim]))
-&gt; (Tensor device dtype '[seqLen, batchSize, ffnDim]
    -&gt; Tensor device dtype '[seqLen, batchSize, embedDim])
-&gt; Tensor device dtype '[seqLen, batchSize, ffnDim]
-&gt; IO (Tensor device dtype '[seqLen, batchSize, embedDim])
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><a href="../file:///nix/store/yi1zp26n2al045qmp9gwpxblhp2c8gs8-ghc-8.8.3-doc/share/doc/ghc/html/libraries/base-4.13.0.0/src"><span class="hs-operator hs-var">.</span></a></span><span>   </span><span class="annot"><span class="annottext">Tensor device dtype '[seqLen, batchSize, embedDim]
-&gt; Tensor device dtype '[seqLen, batchSize, embedDim]
forall (shape :: [Nat]) (dtype :: DType)
       (device :: (DeviceType, Nat)).
StandardFloatingPointDTypeValidation device dtype =&gt;
Tensor device dtype shape -&gt; Tensor device dtype shape
</span><a href="Torch.Typed.Functional.html#relu"><span class="hs-identifier hs-var">relu</span></a></span><span>
</span><span id="line-200"></span><span>    </span><span class="annot"><span class="annottext">(Tensor device dtype '[seqLen, batchSize, embedDim]
 -&gt; Tensor device dtype '[seqLen, batchSize, embedDim])
-&gt; (Tensor device dtype '[seqLen, batchSize, ffnDim]
    -&gt; Tensor device dtype '[seqLen, batchSize, embedDim])
-&gt; Tensor device dtype '[seqLen, batchSize, ffnDim]
-&gt; Tensor device dtype '[seqLen, batchSize, embedDim]
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><a href="../file:///nix/store/yi1zp26n2al045qmp9gwpxblhp2c8gs8-ghc-8.8.3-doc/share/doc/ghc/html/libraries/base-4.13.0.0/src"><span class="hs-operator hs-var">.</span></a></span><span>   </span><span class="annot"><span class="annottext">Linear ffnDim embedDim dtype device
-&gt; Tensor device dtype '[seqLen, batchSize, ffnDim]
-&gt; Tensor device dtype '[seqLen, batchSize, embedDim]
forall f a b. HasForward f a b =&gt; f -&gt; a -&gt; b
</span><a href="Torch.Typed.NN.html#forward"><span class="hs-identifier hs-var">forward</span></a></span><span> </span><span class="annot"><span class="annottext">Linear ffnDim embedDim dtype device
</span><a href="#local-6989586621679721309"><span class="hs-identifier hs-var">linear1</span></a></span><span>
</span><span id="line-201"></span><span>    </span><span class="annot"><span class="annottext">(Tensor device dtype '[seqLen, batchSize, ffnDim]
 -&gt; IO (Tensor device dtype '[seqLen, batchSize, embedDim]))
-&gt; IO (Tensor device dtype '[seqLen, batchSize, ffnDim])
-&gt; IO (Tensor device dtype '[seqLen, batchSize, embedDim])
forall (m :: Type -&gt; Type) a b. Monad m =&gt; (a -&gt; m b) -&gt; m a -&gt; m b
</span><a href="../file:///nix/store/yi1zp26n2al045qmp9gwpxblhp2c8gs8-ghc-8.8.3-doc/share/doc/ghc/html/libraries/base-4.13.0.0/src"><span class="hs-operator hs-var">=&lt;&lt;</span></a></span><span> </span><span class="annot"><span class="annottext">Dropout
-&gt; Bool
-&gt; Tensor device dtype '[seqLen, batchSize, ffnDim]
-&gt; IO (Tensor device dtype '[seqLen, batchSize, ffnDim])
forall (shape :: [Nat]) (dtype :: DType)
       (device :: (DeviceType, Nat)).
Dropout
-&gt; Bool
-&gt; Tensor device dtype shape
-&gt; IO (Tensor device dtype shape)
</span><a href="Torch.Typed.NN.html#dropout"><span class="hs-identifier hs-var">Torch.Typed.NN.dropout</span></a></span><span> </span><span class="annot"><span class="annottext">Dropout
</span><a href="#local-6989586621679721308"><span class="hs-identifier hs-var">dropout0</span></a></span><span> </span><span class="annot"><span class="annottext">Bool
</span><a href="#local-6989586621679721306"><span class="hs-identifier hs-var">train</span></a></span><span>
</span><span id="line-202"></span><span>    </span><span class="annot"><span class="annottext">(Tensor device dtype '[seqLen, batchSize, ffnDim]
 -&gt; IO (Tensor device dtype '[seqLen, batchSize, ffnDim]))
-&gt; (Tensor device dtype '[seqLen, batchSize, embedDim]
    -&gt; Tensor device dtype '[seqLen, batchSize, ffnDim])
-&gt; Tensor device dtype '[seqLen, batchSize, embedDim]
-&gt; IO (Tensor device dtype '[seqLen, batchSize, ffnDim])
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><a href="../file:///nix/store/yi1zp26n2al045qmp9gwpxblhp2c8gs8-ghc-8.8.3-doc/share/doc/ghc/html/libraries/base-4.13.0.0/src"><span class="hs-operator hs-var">.</span></a></span><span>   </span><span class="annot"><span class="annottext">Tensor device dtype '[seqLen, batchSize, ffnDim]
-&gt; Tensor device dtype '[seqLen, batchSize, ffnDim]
forall (shape :: [Nat]) (dtype :: DType)
       (device :: (DeviceType, Nat)).
StandardFloatingPointDTypeValidation device dtype =&gt;
Tensor device dtype shape -&gt; Tensor device dtype shape
</span><a href="Torch.Typed.Functional.html#relu"><span class="hs-identifier hs-var">relu</span></a></span><span>
</span><span id="line-203"></span><span>    </span><span class="annot"><span class="annottext">(Tensor device dtype '[seqLen, batchSize, ffnDim]
 -&gt; Tensor device dtype '[seqLen, batchSize, ffnDim])
-&gt; (Tensor device dtype '[seqLen, batchSize, embedDim]
    -&gt; Tensor device dtype '[seqLen, batchSize, ffnDim])
-&gt; Tensor device dtype '[seqLen, batchSize, embedDim]
-&gt; Tensor device dtype '[seqLen, batchSize, ffnDim]
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><a href="../file:///nix/store/yi1zp26n2al045qmp9gwpxblhp2c8gs8-ghc-8.8.3-doc/share/doc/ghc/html/libraries/base-4.13.0.0/src"><span class="hs-operator hs-var">.</span></a></span><span>   </span><span class="annot"><span class="annottext">Linear embedDim ffnDim dtype device
-&gt; Tensor device dtype '[seqLen, batchSize, embedDim]
-&gt; Tensor device dtype '[seqLen, batchSize, ffnDim]
forall f a b. HasForward f a b =&gt; f -&gt; a -&gt; b
</span><a href="Torch.Typed.NN.html#forward"><span class="hs-identifier hs-var">forward</span></a></span><span> </span><span class="annot"><span class="annottext">Linear embedDim ffnDim dtype device
</span><a href="#local-6989586621679721310"><span class="hs-identifier hs-var">linear0</span></a></span><span>
</span><span id="line-204"></span><span>    </span><span class="annot"><span class="annottext">(Tensor device dtype '[seqLen, batchSize, embedDim]
 -&gt; IO (Tensor device dtype '[seqLen, batchSize, ffnDim]))
-&gt; IO (Tensor device dtype '[seqLen, batchSize, embedDim])
-&gt; IO (Tensor device dtype '[seqLen, batchSize, ffnDim])
forall (m :: Type -&gt; Type) a b. Monad m =&gt; (a -&gt; m b) -&gt; m a -&gt; m b
</span><a href="../file:///nix/store/yi1zp26n2al045qmp9gwpxblhp2c8gs8-ghc-8.8.3-doc/share/doc/ghc/html/libraries/base-4.13.0.0/src"><span class="hs-operator hs-var">=&lt;&lt;</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor device dtype '[seqLen, batchSize, embedDim]
-&gt; IO (Tensor device dtype '[seqLen, batchSize, embedDim])
forall (f :: Type -&gt; Type) a. Applicative f =&gt; a -&gt; f a
</span><a href="../file:///nix/store/yi1zp26n2al045qmp9gwpxblhp2c8gs8-ghc-8.8.3-doc/share/doc/ghc/html/libraries/base-4.13.0.0/src"><span class="hs-identifier hs-var">pure</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor device dtype '[seqLen, batchSize, embedDim]
</span><a href="#local-6989586621679721305"><span class="hs-identifier hs-var">input</span></a></span><span>
</span><span id="line-205"></span><span>
</span><span id="line-206"></span><span id="local-6989586621679721299"><span id="local-6989586621679721300"><span id="local-6989586621679721301"><span id="local-6989586621679721302"><span class="hs-keyword">instance</span><span> </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="Torch.Typed.Tensor.html#All"><span class="hs-identifier hs-type">All</span></a></span><span> </span><span class="annot"><a href="../file:///nix/store/yi1zp26n2al045qmp9gwpxblhp2c8gs8-ghc-8.8.3-doc/share/doc/ghc/html/libraries/base-4.13.0.0/src"><span class="hs-identifier hs-type">KnownNat</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="annot"><a href="#local-6989586621679721302"><span class="hs-identifier hs-type">embedDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679721301"><span class="hs-identifier hs-type">ffnDim</span></a></span><span class="hs-special">]</span><span>
</span><span id="line-207"></span><span>         </span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.Typed.Tensor.html#KnownDType"><span class="hs-identifier hs-type">KnownDType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679721300"><span class="hs-identifier hs-type">dtype</span></a></span><span>
</span><span id="line-208"></span><span>         </span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.Typed.Tensor.html#KnownDevice"><span class="hs-identifier hs-type">KnownDevice</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679721299"><span class="hs-identifier hs-type">device</span></a></span><span>
</span><span id="line-209"></span><span>         </span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.Typed.Factories.html#RandDTypeIsValid"><span class="hs-identifier hs-type">RandDTypeIsValid</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679721299"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679721300"><span class="hs-identifier hs-type">dtype</span></a></span><span>
</span><span id="line-210"></span><span>         </span><span class="hs-special">)</span><span>
</span><span id="line-211"></span><span>  </span><span class="hs-glyph">=&gt;</span><span> </span><span class="annot"><a href="Torch.NN.html#Randomizable"><span class="hs-identifier hs-type">A.Randomizable</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.NN.Transformer.html#TransformerMLPSpec"><span class="hs-identifier hs-type">TransformerMLPSpec</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679721302"><span class="hs-identifier hs-type">embedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679721301"><span class="hs-identifier hs-type">ffnDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679721300"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679721299"><span class="hs-identifier hs-type">device</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-212"></span><span>                    </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.NN.Transformer.html#TransformerMLP"><span class="hs-identifier hs-type">TransformerMLP</span></a></span><span>     </span><span class="annot"><a href="#local-6989586621679721302"><span class="hs-identifier hs-type">embedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679721301"><span class="hs-identifier hs-type">ffnDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679721300"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679721299"><span class="hs-identifier hs-type">device</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-213"></span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-214"></span><span>  </span><span id="local-6989586621679721297"><span class="annot"><span class="annottext">sample :: TransformerMLPSpec embedDim ffnDim dtype device
-&gt; IO (TransformerMLP embedDim ffnDim dtype device)
</span><a href="#local-6989586621679721297"><span class="hs-identifier hs-var hs-var hs-var hs-var">sample</span></a></span></span><span> </span><span id="local-6989586621679721295"><span id="local-6989586621679721296"><span class="annot"><a href="Torch.Typed.NN.Transformer.html#TransformerMLPSpec"><span class="hs-identifier hs-type">TransformerMLPSpec</span></a></span><span> </span><span class="hs-special">{</span><span class="hs-glyph">..</span><span class="hs-special">}</span></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-215"></span><span>    </span><span class="annot"><span class="annottext">Linear embedDim ffnDim dtype device
-&gt; Linear ffnDim embedDim dtype device
-&gt; Dropout
-&gt; Dropout
-&gt; TransformerMLP embedDim ffnDim dtype device
forall (embedDim :: Nat) (ffnDim :: Nat) (dtype :: DType)
       (device :: (DeviceType, Nat)).
Linear embedDim ffnDim dtype device
-&gt; Linear ffnDim embedDim dtype device
-&gt; Dropout
-&gt; Dropout
-&gt; TransformerMLP embedDim ffnDim dtype device
</span><a href="Torch.Typed.NN.Transformer.html#TransformerMLP"><span class="hs-identifier hs-var">TransformerMLP</span></a></span><span>
</span><span id="line-216"></span><span>      </span><span class="annot"><span class="annottext">(Linear embedDim ffnDim dtype device
 -&gt; Linear ffnDim embedDim dtype device
 -&gt; Dropout
 -&gt; Dropout
 -&gt; TransformerMLP embedDim ffnDim dtype device)
-&gt; IO (Linear embedDim ffnDim dtype device)
-&gt; IO
     (Linear ffnDim embedDim dtype device
      -&gt; Dropout
      -&gt; Dropout
      -&gt; TransformerMLP embedDim ffnDim dtype device)
forall (f :: Type -&gt; Type) a b. Functor f =&gt; (a -&gt; b) -&gt; f a -&gt; f b
</span><a href="../file:///nix/store/yi1zp26n2al045qmp9gwpxblhp2c8gs8-ghc-8.8.3-doc/share/doc/ghc/html/libraries/base-4.13.0.0/src"><span class="hs-operator hs-var">&lt;$&gt;</span></a></span><span> </span><span class="annot"><span class="annottext">LinearSpec embedDim ffnDim dtype device
-&gt; IO (Linear embedDim ffnDim dtype device)
forall spec f. Randomizable spec f =&gt; spec -&gt; IO f
</span><a href="Torch.NN.html#sample"><span class="hs-identifier hs-var">A.sample</span></a></span><span> </span><span class="annot"><span class="annottext">LinearSpec embedDim ffnDim dtype device
forall (inputFeatures :: Nat) (outputFeatures :: Nat)
       (dtype :: DType) (device :: (DeviceType, Nat)).
LinearSpec inputFeatures outputFeatures dtype device
</span><a href="Torch.Typed.NN.html#LinearSpec"><span class="hs-identifier hs-var">LinearSpec</span></a></span><span>
</span><span id="line-217"></span><span>      </span><span class="annot"><span class="annottext">IO
  (Linear ffnDim embedDim dtype device
   -&gt; Dropout
   -&gt; Dropout
   -&gt; TransformerMLP embedDim ffnDim dtype device)
-&gt; IO (Linear ffnDim embedDim dtype device)
-&gt; IO
     (Dropout -&gt; Dropout -&gt; TransformerMLP embedDim ffnDim dtype device)
forall (f :: Type -&gt; Type) a b.
Applicative f =&gt;
f (a -&gt; b) -&gt; f a -&gt; f b
</span><a href="../file:///nix/store/yi1zp26n2al045qmp9gwpxblhp2c8gs8-ghc-8.8.3-doc/share/doc/ghc/html/libraries/base-4.13.0.0/src"><span class="hs-operator hs-var">&lt;*&gt;</span></a></span><span> </span><span class="annot"><span class="annottext">LinearSpec ffnDim embedDim dtype device
-&gt; IO (Linear ffnDim embedDim dtype device)
forall spec f. Randomizable spec f =&gt; spec -&gt; IO f
</span><a href="Torch.NN.html#sample"><span class="hs-identifier hs-var">A.sample</span></a></span><span> </span><span class="annot"><span class="annottext">LinearSpec ffnDim embedDim dtype device
forall (inputFeatures :: Nat) (outputFeatures :: Nat)
       (dtype :: DType) (device :: (DeviceType, Nat)).
LinearSpec inputFeatures outputFeatures dtype device
</span><a href="Torch.Typed.NN.html#LinearSpec"><span class="hs-identifier hs-var">LinearSpec</span></a></span><span>
</span><span id="line-218"></span><span>      </span><span class="annot"><span class="annottext">IO
  (Dropout -&gt; Dropout -&gt; TransformerMLP embedDim ffnDim dtype device)
-&gt; IO Dropout
-&gt; IO (Dropout -&gt; TransformerMLP embedDim ffnDim dtype device)
forall (f :: Type -&gt; Type) a b.
Applicative f =&gt;
f (a -&gt; b) -&gt; f a -&gt; f b
</span><a href="../file:///nix/store/yi1zp26n2al045qmp9gwpxblhp2c8gs8-ghc-8.8.3-doc/share/doc/ghc/html/libraries/base-4.13.0.0/src"><span class="hs-operator hs-var">&lt;*&gt;</span></a></span><span> </span><span class="annot"><span class="annottext">DropoutSpec -&gt; IO Dropout
forall spec f. Randomizable spec f =&gt; spec -&gt; IO f
</span><a href="Torch.NN.html#sample"><span class="hs-identifier hs-var">A.sample</span></a></span><span> </span><span class="annot"><span class="annottext">DropoutSpec
</span><a href="#local-6989586621679721296"><span class="hs-identifier hs-var">dropout0Spec</span></a></span><span>
</span><span id="line-219"></span><span>      </span><span class="annot"><span class="annottext">IO (Dropout -&gt; TransformerMLP embedDim ffnDim dtype device)
-&gt; IO Dropout -&gt; IO (TransformerMLP embedDim ffnDim dtype device)
forall (f :: Type -&gt; Type) a b.
Applicative f =&gt;
f (a -&gt; b) -&gt; f a -&gt; f b
</span><a href="../file:///nix/store/yi1zp26n2al045qmp9gwpxblhp2c8gs8-ghc-8.8.3-doc/share/doc/ghc/html/libraries/base-4.13.0.0/src"><span class="hs-operator hs-var">&lt;*&gt;</span></a></span><span> </span><span class="annot"><span class="annottext">DropoutSpec -&gt; IO Dropout
forall spec f. Randomizable spec f =&gt; spec -&gt; IO f
</span><a href="Torch.NN.html#sample"><span class="hs-identifier hs-var">A.sample</span></a></span><span> </span><span class="annot"><span class="annottext">DropoutSpec
</span><a href="#local-6989586621679721295"><span class="hs-identifier hs-var">dropout1Spec</span></a></span></span></span></span></span><span>
</span><span id="line-220"></span><span>
</span><span id="line-221"></span><span class="hs-comment">--------------------------------------------------------------------------------</span><span>
</span><span id="line-222"></span><span class="hs-comment">-- Relation-Aware Transformer Layer</span><span>
</span><span id="line-223"></span><span class="hs-comment">--------------------------------------------------------------------------------</span><span>
</span><span id="line-224"></span><span>
</span><span id="line-225"></span><span class="hs-keyword">data</span><span>
</span><span id="line-226"></span><span>  </span><span id="TransformerLayerSpec"><span class="annot"><a href="Torch.Typed.NN.Transformer.html#TransformerLayerSpec"><span class="hs-identifier hs-var">TransformerLayerSpec</span></a></span></span><span>
</span><span id="line-227"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679721294"><span class="annot"><a href="#local-6989586621679721294"><span class="hs-identifier hs-type">embedDim</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="../file:///nix/store/yi1zp26n2al045qmp9gwpxblhp2c8gs8-ghc-8.8.3-doc/share/doc/ghc/html/libraries/ghc-prim-0.5.3/src"><span class="hs-identifier hs-type">Nat</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-228"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679721293"><span class="annot"><a href="#local-6989586621679721293"><span class="hs-identifier hs-type">numHeads</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="../file:///nix/store/yi1zp26n2al045qmp9gwpxblhp2c8gs8-ghc-8.8.3-doc/share/doc/ghc/html/libraries/ghc-prim-0.5.3/src"><span class="hs-identifier hs-type">Nat</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-229"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679721292"><span class="annot"><a href="#local-6989586621679721292"><span class="hs-identifier hs-type">ffnDim</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="../file:///nix/store/yi1zp26n2al045qmp9gwpxblhp2c8gs8-ghc-8.8.3-doc/share/doc/ghc/html/libraries/ghc-prim-0.5.3/src"><span class="hs-identifier hs-type">Nat</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-230"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679721291"><span class="annot"><a href="#local-6989586621679721291"><span class="hs-identifier hs-type">dtype</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.DType.html#DType"><span class="hs-identifier hs-type">D.DType</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-231"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679721290"><span class="annot"><a href="#local-6989586621679721290"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Device.html#DeviceType"><span class="hs-identifier hs-type">D.DeviceType</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="../file:///nix/store/yi1zp26n2al045qmp9gwpxblhp2c8gs8-ghc-8.8.3-doc/share/doc/ghc/html/libraries/ghc-prim-0.5.3/src"><span class="hs-identifier hs-type">Nat</span></a></span><span class="hs-special">)</span><span class="hs-special">)</span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-232"></span><span>  </span><span id="TransformerLayerSpec"><span class="annot"><a href="Torch.Typed.NN.Transformer.html#TransformerLayerSpec"><span class="hs-identifier hs-var">TransformerLayerSpec</span></a></span></span><span>
</span><span id="line-233"></span><span>    </span><span class="hs-glyph">::</span><span> </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679721719"><span class="annot"><a href="#local-6989586621679721719"><span class="hs-identifier hs-type">embedDim</span></a></span></span><span> </span><span id="local-6989586621679721718"><span class="annot"><a href="#local-6989586621679721718"><span class="hs-identifier hs-type">numHeads</span></a></span></span><span> </span><span id="local-6989586621679721717"><span class="annot"><a href="#local-6989586621679721717"><span class="hs-identifier hs-type">ffnDim</span></a></span></span><span> </span><span id="local-6989586621679721716"><span class="annot"><a href="#local-6989586621679721716"><span class="hs-identifier hs-type">dtype</span></a></span></span><span> </span><span id="local-6989586621679721715"><span class="annot"><a href="#local-6989586621679721715"><span class="hs-identifier hs-type">device</span></a></span></span><span>
</span><span id="line-234"></span><span>     </span><span class="hs-operator">.</span><span> </span><span class="hs-special">{</span><span> </span><span id="mhaSpec"><span class="annot"><span class="annottext">TransformerLayerSpec embedDim numHeads ffnDim dtype device
-&gt; MultiheadAttentionSpec embedDim numHeads dtype device
</span><a href="Torch.Typed.NN.Transformer.html#mhaSpec"><span class="hs-identifier hs-var hs-var">mhaSpec</span></a></span></span><span>         </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.Typed.NN.Transformer.html#MultiheadAttentionSpec"><span class="hs-identifier hs-type">MultiheadAttentionSpec</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679721719"><span class="hs-identifier hs-type">embedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679721718"><span class="hs-identifier hs-type">numHeads</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679721716"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679721715"><span class="hs-identifier hs-type">device</span></a></span><span>
</span><span id="line-235"></span><span>       </span><span class="hs-special">,</span><span> </span><span id="attnDropoutSpec"><span class="annot"><span class="annottext">TransformerLayerSpec embedDim numHeads ffnDim dtype device
-&gt; DropoutSpec
</span><a href="Torch.Typed.NN.Transformer.html#attnDropoutSpec"><span class="hs-identifier hs-var hs-var">attnDropoutSpec</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.Typed.NN.html#DropoutSpec"><span class="hs-identifier hs-type">DropoutSpec</span></a></span><span>
</span><span id="line-236"></span><span>       </span><span class="hs-special">,</span><span> </span><span id="epsSpec"><span class="annot"><span class="annottext">TransformerLayerSpec embedDim numHeads ffnDim dtype device
-&gt; Double
</span><a href="Torch.Typed.NN.Transformer.html#epsSpec"><span class="hs-identifier hs-var hs-var">epsSpec</span></a></span></span><span>         </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="../file:///nix/store/yi1zp26n2al045qmp9gwpxblhp2c8gs8-ghc-8.8.3-doc/share/doc/ghc/html/libraries/ghc-prim-0.5.3/src"><span class="hs-identifier hs-type">Double</span></a></span><span>
</span><span id="line-237"></span><span>       </span><span class="hs-special">,</span><span> </span><span id="mlpSpec"><span class="annot"><span class="annottext">TransformerLayerSpec embedDim numHeads ffnDim dtype device
-&gt; TransformerMLPSpec embedDim ffnDim dtype device
</span><a href="Torch.Typed.NN.Transformer.html#mlpSpec"><span class="hs-identifier hs-var hs-var">mlpSpec</span></a></span></span><span>         </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.Typed.NN.Transformer.html#TransformerMLPSpec"><span class="hs-identifier hs-type">TransformerMLPSpec</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679721719"><span class="hs-identifier hs-type">embedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679721717"><span class="hs-identifier hs-type">ffnDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679721716"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679721715"><span class="hs-identifier hs-type">device</span></a></span><span>
</span><span id="line-238"></span><span>       </span><span class="hs-special">}</span><span>
</span><span id="line-239"></span><span>    </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Typed.NN.Transformer.html#TransformerLayerSpec"><span class="hs-identifier hs-type">TransformerLayerSpec</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679721719"><span class="hs-identifier hs-type">embedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679721718"><span class="hs-identifier hs-type">numHeads</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679721717"><span class="hs-identifier hs-type">ffnDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679721716"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679721715"><span class="hs-identifier hs-type">device</span></a></span><span>
</span><span id="line-240"></span><span>  </span><span class="hs-keyword">deriving</span><span> </span><span class="hs-special">(</span><span id="local-6989586621679721279"><span id="local-6989586621679721281"><span id="local-6989586621679721283"><span class="annot"><span class="annottext">Int
-&gt; TransformerLayerSpec embedDim numHeads ffnDim dtype device
-&gt; ShowS
[TransformerLayerSpec embedDim numHeads ffnDim dtype device]
-&gt; ShowS
TransformerLayerSpec embedDim numHeads ffnDim dtype device
-&gt; String
(Int
 -&gt; TransformerLayerSpec embedDim numHeads ffnDim dtype device
 -&gt; ShowS)
-&gt; (TransformerLayerSpec embedDim numHeads ffnDim dtype device
    -&gt; String)
-&gt; ([TransformerLayerSpec embedDim numHeads ffnDim dtype device]
    -&gt; ShowS)
-&gt; Show
     (TransformerLayerSpec embedDim numHeads ffnDim dtype device)
forall a.
(Int -&gt; a -&gt; ShowS) -&gt; (a -&gt; String) -&gt; ([a] -&gt; ShowS) -&gt; Show a
forall (embedDim :: Nat) (numHeads :: Nat) (ffnDim :: Nat)
       (dtype :: DType) (device :: (DeviceType, Nat)).
Int
-&gt; TransformerLayerSpec embedDim numHeads ffnDim dtype device
-&gt; ShowS
forall (embedDim :: Nat) (numHeads :: Nat) (ffnDim :: Nat)
       (dtype :: DType) (device :: (DeviceType, Nat)).
[TransformerLayerSpec embedDim numHeads ffnDim dtype device]
-&gt; ShowS
forall (embedDim :: Nat) (numHeads :: Nat) (ffnDim :: Nat)
       (dtype :: DType) (device :: (DeviceType, Nat)).
TransformerLayerSpec embedDim numHeads ffnDim dtype device
-&gt; String
showList :: [TransformerLayerSpec embedDim numHeads ffnDim dtype device]
-&gt; ShowS
$cshowList :: forall (embedDim :: Nat) (numHeads :: Nat) (ffnDim :: Nat)
       (dtype :: DType) (device :: (DeviceType, Nat)).
[TransformerLayerSpec embedDim numHeads ffnDim dtype device]
-&gt; ShowS
show :: TransformerLayerSpec embedDim numHeads ffnDim dtype device
-&gt; String
$cshow :: forall (embedDim :: Nat) (numHeads :: Nat) (ffnDim :: Nat)
       (dtype :: DType) (device :: (DeviceType, Nat)).
TransformerLayerSpec embedDim numHeads ffnDim dtype device
-&gt; String
showsPrec :: Int
-&gt; TransformerLayerSpec embedDim numHeads ffnDim dtype device
-&gt; ShowS
$cshowsPrec :: forall (embedDim :: Nat) (numHeads :: Nat) (ffnDim :: Nat)
       (dtype :: DType) (device :: (DeviceType, Nat)).
Int
-&gt; TransformerLayerSpec embedDim numHeads ffnDim dtype device
-&gt; ShowS
</span><a href="../file:///nix/store/yi1zp26n2al045qmp9gwpxblhp2c8gs8-ghc-8.8.3-doc/share/doc/ghc/html/libraries/base-4.13.0.0/src"><span class="hs-identifier hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var">Show</span></a></span></span></span></span><span class="hs-special">)</span><span>
</span><span id="line-241"></span><span>
</span><span id="line-242"></span><span id="local-6989586621679721277"><span id="local-6989586621679721278"></span></span><span class="hs-keyword">data</span><span>
</span><span id="line-243"></span><span>  </span><span id="TransformerLayer"><span class="annot"><a href="Torch.Typed.NN.Transformer.html#TransformerLayer"><span class="hs-identifier hs-var">TransformerLayer</span></a></span></span><span>
</span><span id="line-244"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679721276"><span class="annot"><a href="#local-6989586621679721276"><span class="hs-identifier hs-type">embedDim</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="../file:///nix/store/yi1zp26n2al045qmp9gwpxblhp2c8gs8-ghc-8.8.3-doc/share/doc/ghc/html/libraries/ghc-prim-0.5.3/src"><span class="hs-identifier hs-type">Nat</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-245"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679721275"><span class="annot"><a href="#local-6989586621679721275"><span class="hs-identifier hs-type">numHeads</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="../file:///nix/store/yi1zp26n2al045qmp9gwpxblhp2c8gs8-ghc-8.8.3-doc/share/doc/ghc/html/libraries/ghc-prim-0.5.3/src"><span class="hs-identifier hs-type">Nat</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-246"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679721274"><span class="annot"><a href="#local-6989586621679721274"><span class="hs-identifier hs-type">ffnDim</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="../file:///nix/store/yi1zp26n2al045qmp9gwpxblhp2c8gs8-ghc-8.8.3-doc/share/doc/ghc/html/libraries/ghc-prim-0.5.3/src"><span class="hs-identifier hs-type">Nat</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-247"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679721273"><span class="annot"><a href="#local-6989586621679721273"><span class="hs-identifier hs-type">dtype</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.DType.html#DType"><span class="hs-identifier hs-type">D.DType</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-248"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679721272"><span class="annot"><a href="#local-6989586621679721272"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Device.html#DeviceType"><span class="hs-identifier hs-type">D.DeviceType</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="../file:///nix/store/yi1zp26n2al045qmp9gwpxblhp2c8gs8-ghc-8.8.3-doc/share/doc/ghc/html/libraries/ghc-prim-0.5.3/src"><span class="hs-identifier hs-type">Nat</span></a></span><span class="hs-special">)</span><span class="hs-special">)</span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-249"></span><span>  </span><span id="TransformerLayer"><span class="annot"><a href="Torch.Typed.NN.Transformer.html#TransformerLayer"><span class="hs-identifier hs-var">TransformerLayer</span></a></span></span><span>
</span><span id="line-250"></span><span>    </span><span class="hs-glyph">::</span><span> </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679721743"><span class="annot"><a href="#local-6989586621679721743"><span class="hs-identifier hs-type">embedDim</span></a></span></span><span> </span><span id="local-6989586621679721742"><span class="annot"><a href="#local-6989586621679721742"><span class="hs-identifier hs-type">numHeads</span></a></span></span><span> </span><span id="local-6989586621679721741"><span class="annot"><a href="#local-6989586621679721741"><span class="hs-identifier hs-type">ffnDim</span></a></span></span><span> </span><span id="local-6989586621679721740"><span class="annot"><a href="#local-6989586621679721740"><span class="hs-identifier hs-type">dtype</span></a></span></span><span> </span><span id="local-6989586621679721739"><span class="annot"><a href="#local-6989586621679721739"><span class="hs-identifier hs-type">device</span></a></span></span><span>
</span><span id="line-251"></span><span>     </span><span class="hs-operator">.</span><span> </span><span class="hs-special">{</span><span> </span><span id="mha"><span class="annot"><span class="annottext">TransformerLayer embedDim numHeads ffnDim dtype device
-&gt; MultiheadAttention embedDim numHeads dtype device
</span><a href="Torch.Typed.NN.Transformer.html#mha"><span class="hs-identifier hs-var hs-var">mha</span></a></span></span><span>         </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.Typed.NN.Transformer.html#MultiheadAttention"><span class="hs-identifier hs-type">MultiheadAttention</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679721743"><span class="hs-identifier hs-type">embedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679721742"><span class="hs-identifier hs-type">numHeads</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679721740"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679721739"><span class="hs-identifier hs-type">device</span></a></span><span>
</span><span id="line-252"></span><span>       </span><span class="hs-special">,</span><span> </span><span id="attnDropout"><span class="annot"><span class="annottext">TransformerLayer embedDim numHeads ffnDim dtype device -&gt; Dropout
</span><a href="Torch.Typed.NN.Transformer.html#attnDropout"><span class="hs-identifier hs-var hs-var">attnDropout</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.Typed.NN.html#Dropout"><span class="hs-identifier hs-type">Dropout</span></a></span><span>
</span><span id="line-253"></span><span>       </span><span class="hs-special">,</span><span> </span><span id="ln0"><span class="annot"><span class="annottext">TransformerLayer embedDim numHeads ffnDim dtype device
-&gt; LayerNorm '[embedDim] dtype device
</span><a href="Torch.Typed.NN.Transformer.html#ln0"><span class="hs-identifier hs-var hs-var">ln0</span></a></span></span><span>         </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.Typed.NN.html#LayerNorm"><span class="hs-identifier hs-type">LayerNorm</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="annot"><a href="#local-6989586621679721743"><span class="hs-identifier hs-type">embedDim</span></a></span><span class="hs-special">]</span><span> </span><span class="annot"><a href="#local-6989586621679721740"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679721739"><span class="hs-identifier hs-type">device</span></a></span><span>
</span><span id="line-254"></span><span>       </span><span class="hs-special">,</span><span> </span><span id="ln1"><span class="annot"><span class="annottext">TransformerLayer embedDim numHeads ffnDim dtype device
-&gt; LayerNorm '[embedDim] dtype device
</span><a href="Torch.Typed.NN.Transformer.html#ln1"><span class="hs-identifier hs-var hs-var">ln1</span></a></span></span><span>         </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.Typed.NN.html#LayerNorm"><span class="hs-identifier hs-type">LayerNorm</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="annot"><a href="#local-6989586621679721743"><span class="hs-identifier hs-type">embedDim</span></a></span><span class="hs-special">]</span><span> </span><span class="annot"><a href="#local-6989586621679721740"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679721739"><span class="hs-identifier hs-type">device</span></a></span><span>
</span><span id="line-255"></span><span>       </span><span class="hs-special">,</span><span> </span><span id="mlp"><span class="annot"><span class="annottext">TransformerLayer embedDim numHeads ffnDim dtype device
-&gt; TransformerMLP embedDim ffnDim dtype device
</span><a href="Torch.Typed.NN.Transformer.html#mlp"><span class="hs-identifier hs-var hs-var">mlp</span></a></span></span><span>         </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.Typed.NN.Transformer.html#TransformerMLP"><span class="hs-identifier hs-type">TransformerMLP</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679721743"><span class="hs-identifier hs-type">embedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679721741"><span class="hs-identifier hs-type">ffnDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679721740"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679721739"><span class="hs-identifier hs-type">device</span></a></span><span>
</span><span id="line-256"></span><span>       </span><span class="hs-special">}</span><span>
</span><span id="line-257"></span><span>    </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Typed.NN.Transformer.html#TransformerLayer"><span class="hs-identifier hs-type">TransformerLayer</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679721743"><span class="hs-identifier hs-type">embedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679721742"><span class="hs-identifier hs-type">numHeads</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679721741"><span class="hs-identifier hs-type">ffnDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679721740"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679721739"><span class="hs-identifier hs-type">device</span></a></span><span>
</span><span id="line-258"></span><span>  </span><span class="hs-keyword">deriving</span><span> </span><span class="hs-special">(</span><span id="local-6989586621679721260"><span id="local-6989586621679721262"><span id="local-6989586621679721264"><span class="annot"><span class="annottext">Int
-&gt; TransformerLayer embedDim numHeads ffnDim dtype device -&gt; ShowS
[TransformerLayer embedDim numHeads ffnDim dtype device] -&gt; ShowS
TransformerLayer embedDim numHeads ffnDim dtype device -&gt; String
(Int
 -&gt; TransformerLayer embedDim numHeads ffnDim dtype device -&gt; ShowS)
-&gt; (TransformerLayer embedDim numHeads ffnDim dtype device
    -&gt; String)
-&gt; ([TransformerLayer embedDim numHeads ffnDim dtype device]
    -&gt; ShowS)
-&gt; Show (TransformerLayer embedDim numHeads ffnDim dtype device)
forall a.
(Int -&gt; a -&gt; ShowS) -&gt; (a -&gt; String) -&gt; ([a] -&gt; ShowS) -&gt; Show a
forall (embedDim :: Nat) (numHeads :: Nat) (ffnDim :: Nat)
       (dtype :: DType) (device :: (DeviceType, Nat)).
Int
-&gt; TransformerLayer embedDim numHeads ffnDim dtype device -&gt; ShowS
forall (embedDim :: Nat) (numHeads :: Nat) (ffnDim :: Nat)
       (dtype :: DType) (device :: (DeviceType, Nat)).
[TransformerLayer embedDim numHeads ffnDim dtype device] -&gt; ShowS
forall (embedDim :: Nat) (numHeads :: Nat) (ffnDim :: Nat)
       (dtype :: DType) (device :: (DeviceType, Nat)).
TransformerLayer embedDim numHeads ffnDim dtype device -&gt; String
showList :: [TransformerLayer embedDim numHeads ffnDim dtype device] -&gt; ShowS
$cshowList :: forall (embedDim :: Nat) (numHeads :: Nat) (ffnDim :: Nat)
       (dtype :: DType) (device :: (DeviceType, Nat)).
[TransformerLayer embedDim numHeads ffnDim dtype device] -&gt; ShowS
show :: TransformerLayer embedDim numHeads ffnDim dtype device -&gt; String
$cshow :: forall (embedDim :: Nat) (numHeads :: Nat) (ffnDim :: Nat)
       (dtype :: DType) (device :: (DeviceType, Nat)).
TransformerLayer embedDim numHeads ffnDim dtype device -&gt; String
showsPrec :: Int
-&gt; TransformerLayer embedDim numHeads ffnDim dtype device -&gt; ShowS
$cshowsPrec :: forall (embedDim :: Nat) (numHeads :: Nat) (ffnDim :: Nat)
       (dtype :: DType) (device :: (DeviceType, Nat)).
Int
-&gt; TransformerLayer embedDim numHeads ffnDim dtype device -&gt; ShowS
</span><a href="../file:///nix/store/yi1zp26n2al045qmp9gwpxblhp2c8gs8-ghc-8.8.3-doc/share/doc/ghc/html/libraries/base-4.13.0.0/src"><span class="hs-identifier hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var">Show</span></a></span></span></span></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">(forall x.
 TransformerLayer embedDim numHeads ffnDim dtype device
 -&gt; Rep (TransformerLayer embedDim numHeads ffnDim dtype device) x)
-&gt; (forall x.
    Rep (TransformerLayer embedDim numHeads ffnDim dtype device) x
    -&gt; TransformerLayer embedDim numHeads ffnDim dtype device)
-&gt; Generic (TransformerLayer embedDim numHeads ffnDim dtype device)
forall x.
Rep (TransformerLayer embedDim numHeads ffnDim dtype device) x
-&gt; TransformerLayer embedDim numHeads ffnDim dtype device
forall x.
TransformerLayer embedDim numHeads ffnDim dtype device
-&gt; Rep (TransformerLayer embedDim numHeads ffnDim dtype device) x
forall a.
(forall x. a -&gt; Rep a x) -&gt; (forall x. Rep a x -&gt; a) -&gt; Generic a
forall (embedDim :: Nat) (numHeads :: Nat) (ffnDim :: Nat)
       (dtype :: DType) (device :: (DeviceType, Nat)) x.
Rep (TransformerLayer embedDim numHeads ffnDim dtype device) x
-&gt; TransformerLayer embedDim numHeads ffnDim dtype device
forall (embedDim :: Nat) (numHeads :: Nat) (ffnDim :: Nat)
       (dtype :: DType) (device :: (DeviceType, Nat)) x.
TransformerLayer embedDim numHeads ffnDim dtype device
-&gt; Rep (TransformerLayer embedDim numHeads ffnDim dtype device) x
$cto :: forall (embedDim :: Nat) (numHeads :: Nat) (ffnDim :: Nat)
       (dtype :: DType) (device :: (DeviceType, Nat)) x.
Rep (TransformerLayer embedDim numHeads ffnDim dtype device) x
-&gt; TransformerLayer embedDim numHeads ffnDim dtype device
$cfrom :: forall (embedDim :: Nat) (numHeads :: Nat) (ffnDim :: Nat)
       (dtype :: DType) (device :: (DeviceType, Nat)) x.
TransformerLayer embedDim numHeads ffnDim dtype device
-&gt; Rep (TransformerLayer embedDim numHeads ffnDim dtype device) x
</span><a href="../file:///nix/store/yi1zp26n2al045qmp9gwpxblhp2c8gs8-ghc-8.8.3-doc/share/doc/ghc/html/libraries/base-4.13.0.0/src"><span class="hs-identifier hs-var hs-var hs-var hs-var">Generic</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-259"></span><span>
</span><span id="line-260"></span><span class="annot"><a href="Torch.Typed.NN.Transformer.html#transformerLayer"><span class="hs-identifier hs-type">transformerLayer</span></a></span><span>
</span><span id="line-261"></span><span>  </span><span class="hs-glyph">::</span><span> </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679721598"><span class="annot"><a href="#local-6989586621679721598"><span class="hs-identifier hs-type">numHeads</span></a></span></span><span> </span><span id="local-6989586621679721591"><span class="annot"><a href="#local-6989586621679721591"><span class="hs-identifier hs-type">ffnDim</span></a></span></span><span> </span><span id="local-6989586621679721597"><span class="annot"><a href="#local-6989586621679721597"><span class="hs-identifier hs-type">embedDim</span></a></span></span><span> </span><span id="local-6989586621679721596"><span class="annot"><a href="#local-6989586621679721596"><span class="hs-identifier hs-type">headDim</span></a></span></span><span> </span><span id="local-6989586621679721595"><span class="annot"><a href="#local-6989586621679721595"><span class="hs-identifier hs-type">seqLen</span></a></span></span><span> </span><span id="local-6989586621679721594"><span class="annot"><a href="#local-6989586621679721594"><span class="hs-identifier hs-type">batchSize</span></a></span></span><span> </span><span id="local-6989586621679721593"><span class="annot"><a href="#local-6989586621679721593"><span class="hs-identifier hs-type">dtype</span></a></span></span><span> </span><span id="local-6989586621679721592"><span class="annot"><a href="#local-6989586621679721592"><span class="hs-identifier hs-type">device</span></a></span></span><span>
</span><span id="line-262"></span><span>   </span><span class="hs-operator">.</span><span> </span><span class="hs-special">(</span><span> </span><span class="annot"><span class="hs-number">1</span></span><span> </span><span class="annot"><a href="../file:///nix/store/yi1zp26n2al045qmp9gwpxblhp2c8gs8-ghc-8.8.3-doc/share/doc/ghc/html/libraries/base-4.13.0.0/src"><span class="hs-operator hs-type">&lt;=</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679721598"><span class="hs-identifier hs-type">numHeads</span></a></span><span>
</span><span id="line-263"></span><span>     </span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679721597"><span class="hs-identifier hs-type">embedDim</span></a></span><span> </span><span class="annot"><a href="../file:///nix/store/yi1zp26n2al045qmp9gwpxblhp2c8gs8-ghc-8.8.3-doc/share/doc/ghc/html/libraries/ghc-prim-0.5.3/src"><span class="hs-glyph hs-type">~</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679721596"><span class="hs-identifier hs-type">headDim</span></a></span><span> </span><span class="annot"><a href="../file:///nix/store/yi1zp26n2al045qmp9gwpxblhp2c8gs8-ghc-8.8.3-doc/share/doc/ghc/html/libraries/base-4.13.0.0/src"><span class="hs-operator hs-type">*</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679721598"><span class="hs-identifier hs-type">numHeads</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-264"></span><span>     </span><span class="hs-special">,</span><span> </span><span class="annot"><a href="../file:///nix/store/yi1zp26n2al045qmp9gwpxblhp2c8gs8-ghc-8.8.3-doc/share/doc/ghc/html/libraries/base-4.13.0.0/src"><span class="hs-identifier hs-type">Mod</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679721597"><span class="hs-identifier hs-type">embedDim</span></a></span><span> </span><span class="annot"><a href="../file:///nix/store/yi1zp26n2al045qmp9gwpxblhp2c8gs8-ghc-8.8.3-doc/share/doc/ghc/html/libraries/base-4.13.0.0/src"><span class="hs-operator hs-type">*</span></a></span><span> </span><span class="annot"><span class="hs-number">3</span></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="hs-number">3</span></span><span> </span><span class="annot"><a href="../file:///nix/store/yi1zp26n2al045qmp9gwpxblhp2c8gs8-ghc-8.8.3-doc/share/doc/ghc/html/libraries/ghc-prim-0.5.3/src"><span class="hs-glyph hs-type">~</span></a></span><span> </span><span class="annot"><span class="hs-number">0</span></span><span>
</span><span id="line-265"></span><span>     </span><span class="hs-special">,</span><span> </span><span class="annot"><a href="../file:///nix/store/yi1zp26n2al045qmp9gwpxblhp2c8gs8-ghc-8.8.3-doc/share/doc/ghc/html/libraries/base-4.13.0.0/src"><span class="hs-identifier hs-type">Div</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679721597"><span class="hs-identifier hs-type">embedDim</span></a></span><span> </span><span class="annot"><a href="../file:///nix/store/yi1zp26n2al045qmp9gwpxblhp2c8gs8-ghc-8.8.3-doc/share/doc/ghc/html/libraries/base-4.13.0.0/src"><span class="hs-operator hs-type">*</span></a></span><span> </span><span class="annot"><span class="hs-number">3</span></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="hs-number">3</span></span><span> </span><span class="annot"><a href="../file:///nix/store/yi1zp26n2al045qmp9gwpxblhp2c8gs8-ghc-8.8.3-doc/share/doc/ghc/html/libraries/ghc-prim-0.5.3/src"><span class="hs-glyph hs-type">~</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679721597"><span class="hs-identifier hs-type">embedDim</span></a></span><span>
</span><span id="line-266"></span><span>     </span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.Typed.Tensor.html#All"><span class="hs-identifier hs-type">All</span></a></span><span> </span><span class="annot"><a href="../file:///nix/store/yi1zp26n2al045qmp9gwpxblhp2c8gs8-ghc-8.8.3-doc/share/doc/ghc/html/libraries/base-4.13.0.0/src"><span class="hs-identifier hs-type">KnownNat</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="annot"><a href="#local-6989586621679721597"><span class="hs-identifier hs-type">embedDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679721598"><span class="hs-identifier hs-type">numHeads</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679721595"><span class="hs-identifier hs-type">seqLen</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679721594"><span class="hs-identifier hs-type">batchSize</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679721596"><span class="hs-identifier hs-type">headDim</span></a></span><span class="hs-special">]</span><span>
</span><span id="line-267"></span><span>     </span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.Typed.Functional.html#EndsWith"><span class="hs-identifier hs-type">EndsWith</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="annot"><a href="#local-6989586621679721594"><span class="hs-identifier hs-type">batchSize</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679721595"><span class="hs-identifier hs-type">seqLen</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679721597"><span class="hs-identifier hs-type">embedDim</span></a></span><span class="hs-special">]</span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="annot"><a href="#local-6989586621679721597"><span class="hs-identifier hs-type">embedDim</span></a></span><span class="hs-special">]</span><span>
</span><span id="line-268"></span><span>     </span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.Typed.Tensor.html#KnownDType"><span class="hs-identifier hs-type">KnownDType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679721593"><span class="hs-identifier hs-type">dtype</span></a></span><span>
</span><span id="line-269"></span><span>     </span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679721593"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="../file:///nix/store/yi1zp26n2al045qmp9gwpxblhp2c8gs8-ghc-8.8.3-doc/share/doc/ghc/html/libraries/ghc-prim-0.5.3/src"><span class="hs-glyph hs-type">~</span></a></span><span> </span><span class="annot"><a href="Torch.Typed.Functional.html#SumDType"><span class="hs-identifier hs-type">SumDType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679721593"><span class="hs-identifier hs-type">dtype</span></a></span><span>
</span><span id="line-270"></span><span>     </span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.Typed.Aux.html#StandardFloatingPointDTypeValidation"><span class="hs-identifier hs-type">StandardFloatingPointDTypeValidation</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679721592"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679721593"><span class="hs-identifier hs-type">dtype</span></a></span><span>
</span><span id="line-271"></span><span>     </span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.Typed.Tensor.html#MatMulDTypeIsValid"><span class="hs-identifier hs-type">MatMulDTypeIsValid</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679721592"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679721593"><span class="hs-identifier hs-type">dtype</span></a></span><span>
</span><span id="line-272"></span><span>     </span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.Typed.Tensor.html#BasicArithmeticDTypeIsValid"><span class="hs-identifier hs-type">BasicArithmeticDTypeIsValid</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679721592"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679721593"><span class="hs-identifier hs-type">dtype</span></a></span><span>
</span><span id="line-273"></span><span>     </span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.Typed.Functional.html#SumDTypeIsValid"><span class="hs-identifier hs-type">SumDTypeIsValid</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679721592"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679721593"><span class="hs-identifier hs-type">dtype</span></a></span><span>
</span><span id="line-274"></span><span>     </span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.Typed.Tensor.html#KnownDevice"><span class="hs-identifier hs-type">KnownDevice</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679721592"><span class="hs-identifier hs-type">device</span></a></span><span>
</span><span id="line-275"></span><span>     </span><span class="hs-special">)</span><span>
</span><span id="line-276"></span><span>  </span><span class="hs-glyph">=&gt;</span><span> </span><span class="annot"><a href="Torch.Typed.NN.Transformer.html#TransformerLayer"><span class="hs-identifier hs-type">TransformerLayer</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679721597"><span class="hs-identifier hs-type">embedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679721598"><span class="hs-identifier hs-type">numHeads</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679721591"><span class="hs-identifier hs-type">ffnDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679721593"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679721592"><span class="hs-identifier hs-type">device</span></a></span><span>
</span><span id="line-277"></span><span>  </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="../file:///nix/store/yi1zp26n2al045qmp9gwpxblhp2c8gs8-ghc-8.8.3-doc/share/doc/ghc/html/libraries/ghc-prim-0.5.3/src"><span class="hs-identifier hs-type">Bool</span></a></span><span>
</span><span id="line-278"></span><span>  </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679721592"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679721593"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="annot"><a href="#local-6989586621679721594"><span class="hs-identifier hs-type">batchSize</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679721595"><span class="hs-identifier hs-type">seqLen</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679721595"><span class="hs-identifier hs-type">seqLen</span></a></span><span class="hs-special">]</span><span>
</span><span id="line-279"></span><span>  </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679721592"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.DType.html#Bool"><span class="hs-identifier hs-type">D.Bool</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="annot"><a href="#local-6989586621679721594"><span class="hs-identifier hs-type">batchSize</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679721595"><span class="hs-identifier hs-type">seqLen</span></a></span><span class="hs-special">]</span><span>
</span><span id="line-280"></span><span>  </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="../file:///nix/store/yi1zp26n2al045qmp9gwpxblhp2c8gs8-ghc-8.8.3-doc/share/doc/ghc/html/libraries/base-4.13.0.0/src"><span class="hs-identifier hs-type">Maybe</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679721592"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679721593"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="annot"><a href="#local-6989586621679721594"><span class="hs-identifier hs-type">batchSize</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679721595"><span class="hs-identifier hs-type">seqLen</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679721595"><span class="hs-identifier hs-type">seqLen</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679721596"><span class="hs-identifier hs-type">headDim</span></a></span><span class="hs-special">]</span><span class="hs-special">)</span><span>
</span><span id="line-281"></span><span>  </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="../file:///nix/store/yi1zp26n2al045qmp9gwpxblhp2c8gs8-ghc-8.8.3-doc/share/doc/ghc/html/libraries/base-4.13.0.0/src"><span class="hs-identifier hs-type">Maybe</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679721592"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679721593"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="annot"><a href="#local-6989586621679721594"><span class="hs-identifier hs-type">batchSize</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679721595"><span class="hs-identifier hs-type">seqLen</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679721595"><span class="hs-identifier hs-type">seqLen</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679721596"><span class="hs-identifier hs-type">headDim</span></a></span><span class="hs-special">]</span><span class="hs-special">)</span><span>
</span><span id="line-282"></span><span>  </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679721592"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679721593"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="annot"><a href="#local-6989586621679721594"><span class="hs-identifier hs-type">batchSize</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679721595"><span class="hs-identifier hs-type">seqLen</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679721597"><span class="hs-identifier hs-type">embedDim</span></a></span><span class="hs-special">]</span><span>
</span><span id="line-283"></span><span>  </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="../file:///nix/store/yi1zp26n2al045qmp9gwpxblhp2c8gs8-ghc-8.8.3-doc/share/doc/ghc/html/libraries/ghc-prim-0.5.3/src"><span class="hs-identifier hs-type">IO</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679721592"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679721593"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="annot"><a href="#local-6989586621679721594"><span class="hs-identifier hs-type">batchSize</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679721595"><span class="hs-identifier hs-type">seqLen</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679721597"><span class="hs-identifier hs-type">embedDim</span></a></span><span class="hs-special">]</span><span class="hs-special">)</span><span>
</span><span id="line-284"></span><span id="transformerLayer"><span class="annot"><span class="annottext">transformerLayer :: TransformerLayer embedDim numHeads ffnDim dtype device
-&gt; Bool
-&gt; Tensor device dtype '[batchSize, seqLen, seqLen]
-&gt; Tensor device 'Bool '[batchSize, seqLen]
-&gt; Maybe
     (Tensor device dtype '[batchSize, seqLen, seqLen, headDim])
-&gt; Maybe
     (Tensor device dtype '[batchSize, seqLen, seqLen, headDim])
-&gt; Tensor device dtype '[batchSize, seqLen, embedDim]
-&gt; IO (Tensor device dtype '[batchSize, seqLen, embedDim])
</span><a href="Torch.Typed.NN.Transformer.html#transformerLayer"><span class="hs-identifier hs-var hs-var">transformerLayer</span></a></span></span><span> </span><span id="local-6989586621679721252"><span id="local-6989586621679721253"><span id="local-6989586621679721254"><span id="local-6989586621679721255"><span id="local-6989586621679721256"><span class="annot"><a href="Torch.Typed.NN.Transformer.html#TransformerLayer"><span class="hs-identifier hs-type">TransformerLayer</span></a></span><span> </span><span class="hs-special">{</span><span class="hs-glyph">..</span><span class="hs-special">}</span></span></span></span></span></span><span> </span><span id="local-6989586621679721251"><span class="annot"><span class="annottext">train :: Bool
</span><a href="#local-6989586621679721251"><span class="hs-identifier hs-var">train</span></a></span></span><span> </span><span id="local-6989586621679721250"><span class="annot"><span class="annottext">attentionMask :: Tensor device dtype '[batchSize, seqLen, seqLen]
</span><a href="#local-6989586621679721250"><span class="hs-identifier hs-var">attentionMask</span></a></span></span><span> </span><span id="local-6989586621679721249"><span class="annot"><span class="annottext">keyPaddingMask :: Tensor device 'Bool '[batchSize, seqLen]
</span><a href="#local-6989586621679721249"><span class="hs-identifier hs-var">keyPaddingMask</span></a></span></span><span> </span><span id="local-6989586621679721248"><span class="annot"><span class="annottext">maybeRelationsK :: Maybe (Tensor device dtype '[batchSize, seqLen, seqLen, headDim])
</span><a href="#local-6989586621679721248"><span class="hs-identifier hs-var">maybeRelationsK</span></a></span></span><span> </span><span id="local-6989586621679721247"><span class="annot"><span class="annottext">maybeRelationsV :: Maybe (Tensor device dtype '[batchSize, seqLen, seqLen, headDim])
</span><a href="#local-6989586621679721247"><span class="hs-identifier hs-var">maybeRelationsV</span></a></span></span><span> </span><span id="local-6989586621679721246"><span class="annot"><span class="annottext">x :: Tensor device dtype '[batchSize, seqLen, embedDim]
</span><a href="#local-6989586621679721246"><span class="hs-identifier hs-var">x</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="hs-keyword">do</span><span>
</span><span id="line-285"></span><span>  </span><span class="hs-special">(</span><span id="local-6989586621679721245"><span class="annot"><span class="annottext">z :: Tensor device dtype '[batchSize, seqLen, embedDim]
</span><a href="#local-6989586621679721245"><span class="hs-identifier hs-var">z</span></a></span></span><span class="hs-special">,</span><span> </span><span class="hs-identifier">_</span><span class="hs-special">)</span><span> </span><span class="hs-glyph">&lt;-</span><span> </span><span class="annot"><span class="annottext">MultiheadAttention embedDim numHeads dtype device
-&gt; Bool
-&gt; Tensor device dtype '[batchSize, seqLen, seqLen]
-&gt; Tensor device 'Bool '[batchSize, seqLen]
-&gt; Maybe
     (Tensor device dtype '[batchSize, seqLen, seqLen, headDim])
-&gt; Maybe
     (Tensor device dtype '[batchSize, seqLen, seqLen, headDim])
-&gt; Tensor device dtype '[batchSize, seqLen, embedDim]
-&gt; IO
     (Tensor device dtype '[batchSize, seqLen, embedDim],
      Tensor device dtype '[batchSize, seqLen, seqLen])
forall (embedDim :: Nat) (numHeads :: Nat) (seqLen :: Nat)
       (batchSize :: Nat) (headDim :: Nat) (dtype :: DType)
       (device :: (DeviceType, Nat)).
(1 &lt;= numHeads, embedDim ~ (headDim * numHeads),
 Mod (embedDim * 3) 3 ~ 0, Div (embedDim * 3) 3 ~ embedDim,
 All KnownNat '[embedDim, numHeads, seqLen, batchSize, headDim],
 KnownDType dtype,
 StandardFloatingPointDTypeValidation device dtype,
 MatMulDTypeIsValid device dtype,
 BasicArithmeticDTypeIsValid device dtype, dtype ~ SumDType dtype,
 SumDTypeIsValid device dtype, KnownDevice device) =&gt;
MultiheadAttention embedDim numHeads dtype device
-&gt; Bool
-&gt; Tensor device dtype '[batchSize, seqLen, seqLen]
-&gt; Tensor device 'Bool '[batchSize, seqLen]
-&gt; Maybe
     (Tensor device dtype '[batchSize, seqLen, seqLen, headDim])
-&gt; Maybe
     (Tensor device dtype '[batchSize, seqLen, seqLen, headDim])
-&gt; Tensor device dtype '[batchSize, seqLen, embedDim]
-&gt; IO
     (Tensor device dtype '[batchSize, seqLen, embedDim],
      Tensor device dtype '[batchSize, seqLen, seqLen])
</span><a href="Torch.Typed.NN.Transformer.html#multiheadAttention"><span class="hs-identifier hs-var">multiheadAttention</span></a></span><span> </span><span class="annot"><span class="annottext">MultiheadAttention embedDim numHeads dtype device
</span><a href="#local-6989586621679721256"><span class="hs-identifier hs-var">mha</span></a></span><span> </span><span class="annot"><span class="annottext">Bool
</span><a href="#local-6989586621679721251"><span class="hs-identifier hs-var">train</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor device dtype '[batchSize, seqLen, seqLen]
</span><a href="#local-6989586621679721250"><span class="hs-identifier hs-var">attentionMask</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor device 'Bool '[batchSize, seqLen]
</span><a href="#local-6989586621679721249"><span class="hs-identifier hs-var">keyPaddingMask</span></a></span><span> </span><span class="annot"><span class="annottext">Maybe (Tensor device dtype '[batchSize, seqLen, seqLen, headDim])
</span><a href="#local-6989586621679721248"><span class="hs-identifier hs-var">maybeRelationsK</span></a></span><span> </span><span class="annot"><span class="annottext">Maybe (Tensor device dtype '[batchSize, seqLen, seqLen, headDim])
</span><a href="#local-6989586621679721247"><span class="hs-identifier hs-var">maybeRelationsV</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor device dtype '[batchSize, seqLen, embedDim]
</span><a href="#local-6989586621679721246"><span class="hs-identifier hs-var">x</span></a></span><span>
</span><span id="line-286"></span><span>  </span><span id="local-6989586621679721244"><span class="annot"><span class="annottext">Tensor device dtype '[batchSize, seqLen, embedDim]
</span><a href="#local-6989586621679721244"><span class="hs-identifier hs-var">z'</span></a></span></span><span> </span><span class="hs-glyph">&lt;-</span><span> </span><span class="annot"><span class="annottext">Dropout
-&gt; Bool
-&gt; Tensor device dtype '[batchSize, seqLen, embedDim]
-&gt; IO (Tensor device dtype '[batchSize, seqLen, embedDim])
forall (shape :: [Nat]) (dtype :: DType)
       (device :: (DeviceType, Nat)).
Dropout
-&gt; Bool
-&gt; Tensor device dtype shape
-&gt; IO (Tensor device dtype shape)
</span><a href="Torch.Typed.NN.html#dropout"><span class="hs-identifier hs-var">Torch.Typed.NN.dropout</span></a></span><span> </span><span class="annot"><span class="annottext">Dropout
</span><a href="#local-6989586621679721255"><span class="hs-identifier hs-var">attnDropout</span></a></span><span> </span><span class="annot"><span class="annottext">Bool
</span><a href="#local-6989586621679721251"><span class="hs-identifier hs-var">train</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor device dtype '[batchSize, seqLen, embedDim]
</span><a href="#local-6989586621679721245"><span class="hs-identifier hs-var">z</span></a></span><span>
</span><span id="line-287"></span><span>  </span><span class="hs-keyword">let</span><span> </span><span id="local-6989586621679721243"><span class="annot"><span class="annottext">y :: Tensor device dtype '[batchSize, seqLen, embedDim]
</span><a href="#local-6989586621679721243"><span class="hs-identifier hs-var hs-var">y</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">LayerNorm '[embedDim] dtype device
-&gt; Tensor device dtype '[batchSize, seqLen, embedDim]
-&gt; Tensor device dtype '[batchSize, seqLen, embedDim]
forall f a b. HasForward f a b =&gt; f -&gt; a -&gt; b
</span><a href="Torch.Typed.NN.html#forward"><span class="hs-identifier hs-var">forward</span></a></span><span> </span><span class="annot"><span class="annottext">LayerNorm '[embedDim] dtype device
</span><a href="#local-6989586621679721254"><span class="hs-identifier hs-var">ln0</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">Tensor device dtype '[batchSize, seqLen, embedDim]
</span><a href="#local-6989586621679721246"><span class="hs-identifier hs-var">x</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor device dtype '[batchSize, seqLen, embedDim]
-&gt; Tensor device dtype '[batchSize, seqLen, embedDim]
-&gt; Tensor device dtype '[batchSize, seqLen, embedDim]
forall (shape'' :: [Nat]) (shape :: [Nat]) (shape' :: [Nat])
       (dtype :: DType) (dtype' :: DType) (dtype'' :: DType)
       (device :: (DeviceType, Nat)).
(dtype'' ~ DTypePromotion dtype dtype',
 shape'' ~ Broadcast shape shape',
 BasicArithmeticDTypeIsValid device dtype,
 BasicArithmeticDTypeIsValid device dtype',
 BasicArithmeticDTypeIsValid device dtype'') =&gt;
Tensor device dtype shape
-&gt; Tensor device dtype' shape' -&gt; Tensor device dtype'' shape''
</span><a href="Torch.Typed.Tensor.html#add"><span class="hs-operator hs-var">`add`</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor device dtype '[batchSize, seqLen, embedDim]
</span><a href="#local-6989586621679721244"><span class="hs-identifier hs-var">z'</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-288"></span><span>  </span><span id="local-6989586621679721242"><span class="annot"><span class="annottext">Tensor device dtype '[batchSize, seqLen, embedDim]
</span><a href="#local-6989586621679721242"><span class="hs-identifier hs-var">y'</span></a></span></span><span> </span><span class="hs-glyph">&lt;-</span><span> </span><span class="annot"><span class="annottext">TransformerMLP embedDim ffnDim dtype device
-&gt; Bool
-&gt; Tensor device dtype '[batchSize, seqLen, embedDim]
-&gt; IO (Tensor device dtype '[batchSize, seqLen, embedDim])
forall (embedDim :: Nat) (ffnDim :: Nat) (seqLen :: Nat)
       (batchSize :: Nat) (dtype :: DType) (device :: (DeviceType, Nat)).
StandardFloatingPointDTypeValidation device dtype =&gt;
TransformerMLP embedDim ffnDim dtype device
-&gt; Bool
-&gt; Tensor device dtype '[seqLen, batchSize, embedDim]
-&gt; IO (Tensor device dtype '[seqLen, batchSize, embedDim])
</span><a href="Torch.Typed.NN.Transformer.html#transformerMLP"><span class="hs-identifier hs-var">transformerMLP</span></a></span><span> </span><span class="annot"><span class="annottext">TransformerMLP embedDim ffnDim dtype device
</span><a href="#local-6989586621679721252"><span class="hs-identifier hs-var">mlp</span></a></span><span> </span><span class="annot"><span class="annottext">Bool
</span><a href="#local-6989586621679721251"><span class="hs-identifier hs-var">train</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor device dtype '[batchSize, seqLen, embedDim]
</span><a href="#local-6989586621679721243"><span class="hs-identifier hs-var">y</span></a></span><span>
</span><span id="line-289"></span><span>  </span><span class="annot"><span class="annottext">Tensor device dtype '[batchSize, seqLen, embedDim]
-&gt; IO (Tensor device dtype '[batchSize, seqLen, embedDim])
forall (m :: Type -&gt; Type) a. Monad m =&gt; a -&gt; m a
</span><a href="../file:///nix/store/yi1zp26n2al045qmp9gwpxblhp2c8gs8-ghc-8.8.3-doc/share/doc/ghc/html/libraries/base-4.13.0.0/src"><span class="hs-identifier hs-var">return</span></a></span><span> </span><span class="annot"><span class="annottext">(Tensor device dtype '[batchSize, seqLen, embedDim]
 -&gt; IO (Tensor device dtype '[batchSize, seqLen, embedDim]))
-&gt; Tensor device dtype '[batchSize, seqLen, embedDim]
-&gt; IO (Tensor device dtype '[batchSize, seqLen, embedDim])
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><a href="../file:///nix/store/yi1zp26n2al045qmp9gwpxblhp2c8gs8-ghc-8.8.3-doc/share/doc/ghc/html/libraries/base-4.13.0.0/src"><span class="hs-operator hs-var">$</span></a></span><span> </span><span class="annot"><span class="annottext">LayerNorm '[embedDim] dtype device
-&gt; Tensor device dtype '[batchSize, seqLen, embedDim]
-&gt; Tensor device dtype '[batchSize, seqLen, embedDim]
forall f a b. HasForward f a b =&gt; f -&gt; a -&gt; b
</span><a href="Torch.Typed.NN.html#forward"><span class="hs-identifier hs-var">forward</span></a></span><span> </span><span class="annot"><span class="annottext">LayerNorm '[embedDim] dtype device
</span><a href="#local-6989586621679721253"><span class="hs-identifier hs-var">ln1</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">Tensor device dtype '[batchSize, seqLen, embedDim]
</span><a href="#local-6989586621679721243"><span class="hs-identifier hs-var">y</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor device dtype '[batchSize, seqLen, embedDim]
-&gt; Tensor device dtype '[batchSize, seqLen, embedDim]
-&gt; Tensor device dtype '[batchSize, seqLen, embedDim]
forall (shape'' :: [Nat]) (shape :: [Nat]) (shape' :: [Nat])
       (dtype :: DType) (dtype' :: DType) (dtype'' :: DType)
       (device :: (DeviceType, Nat)).
(dtype'' ~ DTypePromotion dtype dtype',
 shape'' ~ Broadcast shape shape',
 BasicArithmeticDTypeIsValid device dtype,
 BasicArithmeticDTypeIsValid device dtype',
 BasicArithmeticDTypeIsValid device dtype'') =&gt;
Tensor device dtype shape
-&gt; Tensor device dtype' shape' -&gt; Tensor device dtype'' shape''
</span><a href="Torch.Typed.Tensor.html#add"><span class="hs-operator hs-var">`add`</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor device dtype '[batchSize, seqLen, embedDim]
</span><a href="#local-6989586621679721242"><span class="hs-identifier hs-var">y'</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-290"></span><span>
</span><span id="line-291"></span><span id="local-6989586621679721237"><span id="local-6989586621679721238"><span id="local-6989586621679721239"><span id="local-6989586621679721240"><span id="local-6989586621679721241"><span class="hs-keyword">instance</span><span> </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="Torch.Typed.Tensor.html#All"><span class="hs-identifier hs-type">All</span></a></span><span> </span><span class="annot"><a href="../file:///nix/store/yi1zp26n2al045qmp9gwpxblhp2c8gs8-ghc-8.8.3-doc/share/doc/ghc/html/libraries/base-4.13.0.0/src"><span class="hs-identifier hs-type">KnownNat</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="annot"><a href="#local-6989586621679721241"><span class="hs-identifier hs-type">embedDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679721240"><span class="hs-identifier hs-type">numHeads</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679721239"><span class="hs-identifier hs-type">ffnDim</span></a></span><span class="hs-special">]</span><span>
</span><span id="line-292"></span><span>         </span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.Typed.Tensor.html#KnownDType"><span class="hs-identifier hs-type">KnownDType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679721238"><span class="hs-identifier hs-type">dtype</span></a></span><span>
</span><span id="line-293"></span><span>         </span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.Typed.Tensor.html#KnownDevice"><span class="hs-identifier hs-type">KnownDevice</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679721237"><span class="hs-identifier hs-type">device</span></a></span><span>
</span><span id="line-294"></span><span>         </span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.Typed.Factories.html#RandDTypeIsValid"><span class="hs-identifier hs-type">RandDTypeIsValid</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679721237"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679721238"><span class="hs-identifier hs-type">dtype</span></a></span><span>
</span><span id="line-295"></span><span>         </span><span class="hs-special">)</span><span>
</span><span id="line-296"></span><span>  </span><span class="hs-glyph">=&gt;</span><span> </span><span class="annot"><a href="Torch.NN.html#Randomizable"><span class="hs-identifier hs-type">A.Randomizable</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.NN.Transformer.html#TransformerLayerSpec"><span class="hs-identifier hs-type">TransformerLayerSpec</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679721241"><span class="hs-identifier hs-type">embedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679721240"><span class="hs-identifier hs-type">numHeads</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679721239"><span class="hs-identifier hs-type">ffnDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679721238"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679721237"><span class="hs-identifier hs-type">device</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-297"></span><span>                    </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.NN.Transformer.html#TransformerLayer"><span class="hs-identifier hs-type">TransformerLayer</span></a></span><span>     </span><span class="annot"><a href="#local-6989586621679721241"><span class="hs-identifier hs-type">embedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679721240"><span class="hs-identifier hs-type">numHeads</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679721239"><span class="hs-identifier hs-type">ffnDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679721238"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679721237"><span class="hs-identifier hs-type">device</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-298"></span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-299"></span><span>  </span><span id="local-6989586621679721235"><span class="annot"><span class="annottext">sample :: TransformerLayerSpec embedDim numHeads ffnDim dtype device
-&gt; IO (TransformerLayer embedDim numHeads ffnDim dtype device)
</span><a href="#local-6989586621679721235"><span class="hs-identifier hs-var hs-var hs-var hs-var">sample</span></a></span></span><span> </span><span id="local-6989586621679721231"><span id="local-6989586621679721232"><span id="local-6989586621679721233"><span id="local-6989586621679721234"><span class="annot"><a href="Torch.Typed.NN.Transformer.html#TransformerLayerSpec"><span class="hs-identifier hs-type">TransformerLayerSpec</span></a></span><span> </span><span class="hs-special">{</span><span class="hs-glyph">..</span><span class="hs-special">}</span></span></span></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-300"></span><span>    </span><span class="annot"><span class="annottext">MultiheadAttention embedDim numHeads dtype device
-&gt; Dropout
-&gt; LayerNorm '[embedDim] dtype device
-&gt; LayerNorm '[embedDim] dtype device
-&gt; TransformerMLP embedDim ffnDim dtype device
-&gt; TransformerLayer embedDim numHeads ffnDim dtype device
forall (embedDim :: Nat) (numHeads :: Nat) (ffnDim :: Nat)
       (dtype :: DType) (device :: (DeviceType, Nat)).
MultiheadAttention embedDim numHeads dtype device
-&gt; Dropout
-&gt; LayerNorm '[embedDim] dtype device
-&gt; LayerNorm '[embedDim] dtype device
-&gt; TransformerMLP embedDim ffnDim dtype device
-&gt; TransformerLayer embedDim numHeads ffnDim dtype device
</span><a href="Torch.Typed.NN.Transformer.html#TransformerLayer"><span class="hs-identifier hs-var">TransformerLayer</span></a></span><span>
</span><span id="line-301"></span><span>      </span><span class="annot"><span class="annottext">(MultiheadAttention embedDim numHeads dtype device
 -&gt; Dropout
 -&gt; LayerNorm '[embedDim] dtype device
 -&gt; LayerNorm '[embedDim] dtype device
 -&gt; TransformerMLP embedDim ffnDim dtype device
 -&gt; TransformerLayer embedDim numHeads ffnDim dtype device)
-&gt; IO (MultiheadAttention embedDim numHeads dtype device)
-&gt; IO
     (Dropout
      -&gt; LayerNorm '[embedDim] dtype device
      -&gt; LayerNorm '[embedDim] dtype device
      -&gt; TransformerMLP embedDim ffnDim dtype device
      -&gt; TransformerLayer embedDim numHeads ffnDim dtype device)
forall (f :: Type -&gt; Type) a b. Functor f =&gt; (a -&gt; b) -&gt; f a -&gt; f b
</span><a href="../file:///nix/store/yi1zp26n2al045qmp9gwpxblhp2c8gs8-ghc-8.8.3-doc/share/doc/ghc/html/libraries/base-4.13.0.0/src"><span class="hs-operator hs-var">&lt;$&gt;</span></a></span><span> </span><span class="annot"><span class="annottext">MultiheadAttentionSpec embedDim numHeads dtype device
-&gt; IO (MultiheadAttention embedDim numHeads dtype device)
forall spec f. Randomizable spec f =&gt; spec -&gt; IO f
</span><a href="Torch.NN.html#sample"><span class="hs-identifier hs-var">A.sample</span></a></span><span> </span><span class="annot"><span class="annottext">MultiheadAttentionSpec embedDim numHeads dtype device
</span><a href="#local-6989586621679721234"><span class="hs-identifier hs-var">mhaSpec</span></a></span><span>
</span><span id="line-302"></span><span>      </span><span class="annot"><span class="annottext">IO
  (Dropout
   -&gt; LayerNorm '[embedDim] dtype device
   -&gt; LayerNorm '[embedDim] dtype device
   -&gt; TransformerMLP embedDim ffnDim dtype device
   -&gt; TransformerLayer embedDim numHeads ffnDim dtype device)
-&gt; IO Dropout
-&gt; IO
     (LayerNorm '[embedDim] dtype device
      -&gt; LayerNorm '[embedDim] dtype device
      -&gt; TransformerMLP embedDim ffnDim dtype device
      -&gt; TransformerLayer embedDim numHeads ffnDim dtype device)
forall (f :: Type -&gt; Type) a b.
Applicative f =&gt;
f (a -&gt; b) -&gt; f a -&gt; f b
</span><a href="../file:///nix/store/yi1zp26n2al045qmp9gwpxblhp2c8gs8-ghc-8.8.3-doc/share/doc/ghc/html/libraries/base-4.13.0.0/src"><span class="hs-operator hs-var">&lt;*&gt;</span></a></span><span> </span><span class="annot"><span class="annottext">DropoutSpec -&gt; IO Dropout
forall spec f. Randomizable spec f =&gt; spec -&gt; IO f
</span><a href="Torch.NN.html#sample"><span class="hs-identifier hs-var">A.sample</span></a></span><span> </span><span class="annot"><span class="annottext">DropoutSpec
</span><a href="#local-6989586621679721233"><span class="hs-identifier hs-var">attnDropoutSpec</span></a></span><span>
</span><span id="line-303"></span><span>      </span><span class="annot"><span class="annottext">IO
  (LayerNorm '[embedDim] dtype device
   -&gt; LayerNorm '[embedDim] dtype device
   -&gt; TransformerMLP embedDim ffnDim dtype device
   -&gt; TransformerLayer embedDim numHeads ffnDim dtype device)
-&gt; IO (LayerNorm '[embedDim] dtype device)
-&gt; IO
     (LayerNorm '[embedDim] dtype device
      -&gt; TransformerMLP embedDim ffnDim dtype device
      -&gt; TransformerLayer embedDim numHeads ffnDim dtype device)
forall (f :: Type -&gt; Type) a b.
Applicative f =&gt;
f (a -&gt; b) -&gt; f a -&gt; f b
</span><a href="../file:///nix/store/yi1zp26n2al045qmp9gwpxblhp2c8gs8-ghc-8.8.3-doc/share/doc/ghc/html/libraries/base-4.13.0.0/src"><span class="hs-operator hs-var">&lt;*&gt;</span></a></span><span> </span><span class="annot"><span class="annottext">LayerNormSpec '[embedDim] dtype device
-&gt; IO (LayerNorm '[embedDim] dtype device)
forall spec f. Randomizable spec f =&gt; spec -&gt; IO f
</span><a href="Torch.NN.html#sample"><span class="hs-identifier hs-var">A.sample</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">Double -&gt; LayerNormSpec '[embedDim] dtype device
forall (normalizedShape :: [Nat]) (dtype :: DType)
       (device :: (DeviceType, Nat)).
Double -&gt; LayerNormSpec normalizedShape dtype device
</span><a href="Torch.Typed.NN.html#LayerNormSpec"><span class="hs-identifier hs-var">LayerNormSpec</span></a></span><span> </span><span class="annot"><span class="annottext">Double
</span><a href="#local-6989586621679721232"><span class="hs-identifier hs-var">epsSpec</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-304"></span><span>      </span><span class="annot"><span class="annottext">IO
  (LayerNorm '[embedDim] dtype device
   -&gt; TransformerMLP embedDim ffnDim dtype device
   -&gt; TransformerLayer embedDim numHeads ffnDim dtype device)
-&gt; IO (LayerNorm '[embedDim] dtype device)
-&gt; IO
     (TransformerMLP embedDim ffnDim dtype device
      -&gt; TransformerLayer embedDim numHeads ffnDim dtype device)
forall (f :: Type -&gt; Type) a b.
Applicative f =&gt;
f (a -&gt; b) -&gt; f a -&gt; f b
</span><a href="../file:///nix/store/yi1zp26n2al045qmp9gwpxblhp2c8gs8-ghc-8.8.3-doc/share/doc/ghc/html/libraries/base-4.13.0.0/src"><span class="hs-operator hs-var">&lt;*&gt;</span></a></span><span> </span><span class="annot"><span class="annottext">LayerNormSpec '[embedDim] dtype device
-&gt; IO (LayerNorm '[embedDim] dtype device)
forall spec f. Randomizable spec f =&gt; spec -&gt; IO f
</span><a href="Torch.NN.html#sample"><span class="hs-identifier hs-var">A.sample</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">Double -&gt; LayerNormSpec '[embedDim] dtype device
forall (normalizedShape :: [Nat]) (dtype :: DType)
       (device :: (DeviceType, Nat)).
Double -&gt; LayerNormSpec normalizedShape dtype device
</span><a href="Torch.Typed.NN.html#LayerNormSpec"><span class="hs-identifier hs-var">LayerNormSpec</span></a></span><span> </span><span class="annot"><span class="annottext">Double
</span><a href="#local-6989586621679721232"><span class="hs-identifier hs-var">epsSpec</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-305"></span><span>      </span><span class="annot"><span class="annottext">IO
  (TransformerMLP embedDim ffnDim dtype device
   -&gt; TransformerLayer embedDim numHeads ffnDim dtype device)
-&gt; IO (TransformerMLP embedDim ffnDim dtype device)
-&gt; IO (TransformerLayer embedDim numHeads ffnDim dtype device)
forall (f :: Type -&gt; Type) a b.
Applicative f =&gt;
f (a -&gt; b) -&gt; f a -&gt; f b
</span><a href="../file:///nix/store/yi1zp26n2al045qmp9gwpxblhp2c8gs8-ghc-8.8.3-doc/share/doc/ghc/html/libraries/base-4.13.0.0/src"><span class="hs-operator hs-var">&lt;*&gt;</span></a></span><span> </span><span class="annot"><span class="annottext">TransformerMLPSpec embedDim ffnDim dtype device
-&gt; IO (TransformerMLP embedDim ffnDim dtype device)
forall spec f. Randomizable spec f =&gt; spec -&gt; IO f
</span><a href="Torch.NN.html#sample"><span class="hs-identifier hs-var">A.sample</span></a></span><span> </span><span class="annot"><span class="annottext">TransformerMLPSpec embedDim ffnDim dtype device
</span><a href="#local-6989586621679721231"><span class="hs-identifier hs-var">mlpSpec</span></a></span></span></span></span></span></span><span>
</span><span id="line-306"></span><span>
</span><span id="line-307"></span><span class="hs-comment">--------------------------------------------------------------------------------</span><span>
</span><span id="line-308"></span><span class="hs-comment">-- Transformer Language Model (GPT-2)</span><span>
</span><span id="line-309"></span><span class="hs-comment">--------------------------------------------------------------------------------</span><span>
</span><span id="line-310"></span><span>
</span><span id="line-311"></span><span class="hs-keyword">data</span><span>
</span><span id="line-312"></span><span>  </span><span id="TransformerLMSpec"><span class="annot"><a href="Torch.Typed.NN.Transformer.html#TransformerLMSpec"><span class="hs-identifier hs-var">TransformerLMSpec</span></a></span></span><span>
</span><span id="line-313"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679721229"><span class="annot"><a href="#local-6989586621679721229"><span class="hs-identifier hs-type">numAttnLayers</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="../file:///nix/store/yi1zp26n2al045qmp9gwpxblhp2c8gs8-ghc-8.8.3-doc/share/doc/ghc/html/libraries/ghc-prim-0.5.3/src"><span class="hs-identifier hs-type">Nat</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-314"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679721228"><span class="annot"><a href="#local-6989586621679721228"><span class="hs-identifier hs-type">numHeads</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="../file:///nix/store/yi1zp26n2al045qmp9gwpxblhp2c8gs8-ghc-8.8.3-doc/share/doc/ghc/html/libraries/ghc-prim-0.5.3/src"><span class="hs-identifier hs-type">Nat</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-315"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679721227"><span class="annot"><a href="#local-6989586621679721227"><span class="hs-identifier hs-type">ffnDim</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="../file:///nix/store/yi1zp26n2al045qmp9gwpxblhp2c8gs8-ghc-8.8.3-doc/share/doc/ghc/html/libraries/ghc-prim-0.5.3/src"><span class="hs-identifier hs-type">Nat</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-316"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679721226"><span class="annot"><a href="#local-6989586621679721226"><span class="hs-identifier hs-type">paddingIdx</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="../file:///nix/store/yi1zp26n2al045qmp9gwpxblhp2c8gs8-ghc-8.8.3-doc/share/doc/ghc/html/libraries/ghc-prim-0.5.3/src"><span class="hs-identifier hs-type">Nat</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-317"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679721225"><span class="annot"><a href="#local-6989586621679721225"><span class="hs-identifier hs-type">numEmbeds</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="../file:///nix/store/yi1zp26n2al045qmp9gwpxblhp2c8gs8-ghc-8.8.3-doc/share/doc/ghc/html/libraries/ghc-prim-0.5.3/src"><span class="hs-identifier hs-type">Nat</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-318"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679721224"><span class="annot"><a href="#local-6989586621679721224"><span class="hs-identifier hs-type">embedDim</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="../file:///nix/store/yi1zp26n2al045qmp9gwpxblhp2c8gs8-ghc-8.8.3-doc/share/doc/ghc/html/libraries/ghc-prim-0.5.3/src"><span class="hs-identifier hs-type">Nat</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-319"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679721223"><span class="annot"><a href="#local-6989586621679721223"><span class="hs-identifier hs-type">dtype</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.DType.html#DType"><span class="hs-identifier hs-type">D.DType</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-320"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679721222"><span class="annot"><a href="#local-6989586621679721222"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Device.html#DeviceType"><span class="hs-identifier hs-type">D.DeviceType</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="../file:///nix/store/yi1zp26n2al045qmp9gwpxblhp2c8gs8-ghc-8.8.3-doc/share/doc/ghc/html/libraries/ghc-prim-0.5.3/src"><span class="hs-identifier hs-type">Nat</span></a></span><span class="hs-special">)</span><span class="hs-special">)</span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-321"></span><span>  </span><span id="TransformerLMSpec"><span class="annot"><a href="Torch.Typed.NN.Transformer.html#TransformerLMSpec"><span class="hs-identifier hs-var">TransformerLMSpec</span></a></span></span><span>
</span><span id="line-322"></span><span>    </span><span class="hs-glyph">::</span><span> </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679721472"><span class="annot"><a href="#local-6989586621679721472"><span class="hs-identifier hs-type">numAttnLayers</span></a></span></span><span> </span><span id="local-6989586621679721471"><span class="annot"><a href="#local-6989586621679721471"><span class="hs-identifier hs-type">numHeads</span></a></span></span><span> </span><span id="local-6989586621679721470"><span class="annot"><a href="#local-6989586621679721470"><span class="hs-identifier hs-type">ffnDim</span></a></span></span><span> </span><span id="local-6989586621679721469"><span class="annot"><a href="#local-6989586621679721469"><span class="hs-identifier hs-type">paddingIdx</span></a></span></span><span> </span><span id="local-6989586621679721468"><span class="annot"><a href="#local-6989586621679721468"><span class="hs-identifier hs-type">numEmbeds</span></a></span></span><span> </span><span id="local-6989586621679721467"><span class="annot"><a href="#local-6989586621679721467"><span class="hs-identifier hs-type">embedDim</span></a></span></span><span> </span><span id="local-6989586621679721466"><span class="annot"><a href="#local-6989586621679721466"><span class="hs-identifier hs-type">dtype</span></a></span></span><span> </span><span id="local-6989586621679721465"><span class="annot"><a href="#local-6989586621679721465"><span class="hs-identifier hs-type">device</span></a></span></span><span>
</span><span id="line-323"></span><span>     </span><span class="hs-operator">.</span><span> </span><span class="hs-special">{</span><span> </span><span id="lmDropoutSpec"><span class="annot"><span class="annottext">TransformerLMSpec
  numAttnLayers
  numHeads
  ffnDim
  paddingIdx
  numEmbeds
  embedDim
  dtype
  device
-&gt; DropoutSpec
</span><a href="Torch.Typed.NN.Transformer.html#lmDropoutSpec"><span class="hs-identifier hs-var hs-var">lmDropoutSpec</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.Typed.NN.html#DropoutSpec"><span class="hs-identifier hs-type">DropoutSpec</span></a></span><span>
</span><span id="line-324"></span><span>       </span><span class="hs-special">,</span><span> </span><span id="lmLayerSpec"><span class="annot"><span class="annottext">TransformerLMSpec
  numAttnLayers
  numHeads
  ffnDim
  paddingIdx
  numEmbeds
  embedDim
  dtype
  device
-&gt; TransformerLayerSpec embedDim numHeads ffnDim dtype device
</span><a href="Torch.Typed.NN.Transformer.html#lmLayerSpec"><span class="hs-identifier hs-var hs-var">lmLayerSpec</span></a></span></span><span>   </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.Typed.NN.Transformer.html#TransformerLayerSpec"><span class="hs-identifier hs-type">TransformerLayerSpec</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679721467"><span class="hs-identifier hs-type">embedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679721471"><span class="hs-identifier hs-type">numHeads</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679721470"><span class="hs-identifier hs-type">ffnDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679721466"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679721465"><span class="hs-identifier hs-type">device</span></a></span><span>
</span><span id="line-325"></span><span>       </span><span class="hs-special">}</span><span>
</span><span id="line-326"></span><span>    </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Typed.NN.Transformer.html#TransformerLMSpec"><span class="hs-identifier hs-type">TransformerLMSpec</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679721472"><span class="hs-identifier hs-type">numAttnLayers</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679721471"><span class="hs-identifier hs-type">numHeads</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679721470"><span class="hs-identifier hs-type">ffnDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679721469"><span class="hs-identifier hs-type">paddingIdx</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679721468"><span class="hs-identifier hs-type">numEmbeds</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679721467"><span class="hs-identifier hs-type">embedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679721466"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679721465"><span class="hs-identifier hs-type">device</span></a></span><span>
</span><span id="line-327"></span><span>  </span><span class="hs-keyword">deriving</span><span> </span><span class="hs-special">(</span><span id="local-6989586621679721213"><span id="local-6989586621679721215"><span id="local-6989586621679721217"><span class="annot"><span class="annottext">Int
-&gt; TransformerLMSpec
     numAttnLayers
     numHeads
     ffnDim
     paddingIdx
     numEmbeds
     embedDim
     dtype
     device
-&gt; ShowS
[TransformerLMSpec
   numAttnLayers
   numHeads
   ffnDim
   paddingIdx
   numEmbeds
   embedDim
   dtype
   device]
-&gt; ShowS
TransformerLMSpec
  numAttnLayers
  numHeads
  ffnDim
  paddingIdx
  numEmbeds
  embedDim
  dtype
  device
-&gt; String
(Int
 -&gt; TransformerLMSpec
      numAttnLayers
      numHeads
      ffnDim
      paddingIdx
      numEmbeds
      embedDim
      dtype
      device
 -&gt; ShowS)
-&gt; (TransformerLMSpec
      numAttnLayers
      numHeads
      ffnDim
      paddingIdx
      numEmbeds
      embedDim
      dtype
      device
    -&gt; String)
-&gt; ([TransformerLMSpec
       numAttnLayers
       numHeads
       ffnDim
       paddingIdx
       numEmbeds
       embedDim
       dtype
       device]
    -&gt; ShowS)
-&gt; Show
     (TransformerLMSpec
        numAttnLayers
        numHeads
        ffnDim
        paddingIdx
        numEmbeds
        embedDim
        dtype
        device)
forall a.
(Int -&gt; a -&gt; ShowS) -&gt; (a -&gt; String) -&gt; ([a] -&gt; ShowS) -&gt; Show a
forall (numAttnLayers :: Nat) (numHeads :: Nat) (ffnDim :: Nat)
       (paddingIdx :: Nat) (numEmbeds :: Nat) (embedDim :: Nat)
       (dtype :: DType) (device :: (DeviceType, Nat)).
Int
-&gt; TransformerLMSpec
     numAttnLayers
     numHeads
     ffnDim
     paddingIdx
     numEmbeds
     embedDim
     dtype
     device
-&gt; ShowS
forall (numAttnLayers :: Nat) (numHeads :: Nat) (ffnDim :: Nat)
       (paddingIdx :: Nat) (numEmbeds :: Nat) (embedDim :: Nat)
       (dtype :: DType) (device :: (DeviceType, Nat)).
[TransformerLMSpec
   numAttnLayers
   numHeads
   ffnDim
   paddingIdx
   numEmbeds
   embedDim
   dtype
   device]
-&gt; ShowS
forall (numAttnLayers :: Nat) (numHeads :: Nat) (ffnDim :: Nat)
       (paddingIdx :: Nat) (numEmbeds :: Nat) (embedDim :: Nat)
       (dtype :: DType) (device :: (DeviceType, Nat)).
TransformerLMSpec
  numAttnLayers
  numHeads
  ffnDim
  paddingIdx
  numEmbeds
  embedDim
  dtype
  device
-&gt; String
showList :: [TransformerLMSpec
   numAttnLayers
   numHeads
   ffnDim
   paddingIdx
   numEmbeds
   embedDim
   dtype
   device]
-&gt; ShowS
$cshowList :: forall (numAttnLayers :: Nat) (numHeads :: Nat) (ffnDim :: Nat)
       (paddingIdx :: Nat) (numEmbeds :: Nat) (embedDim :: Nat)
       (dtype :: DType) (device :: (DeviceType, Nat)).
[TransformerLMSpec
   numAttnLayers
   numHeads
   ffnDim
   paddingIdx
   numEmbeds
   embedDim
   dtype
   device]
-&gt; ShowS
show :: TransformerLMSpec
  numAttnLayers
  numHeads
  ffnDim
  paddingIdx
  numEmbeds
  embedDim
  dtype
  device
-&gt; String
$cshow :: forall (numAttnLayers :: Nat) (numHeads :: Nat) (ffnDim :: Nat)
       (paddingIdx :: Nat) (numEmbeds :: Nat) (embedDim :: Nat)
       (dtype :: DType) (device :: (DeviceType, Nat)).
TransformerLMSpec
  numAttnLayers
  numHeads
  ffnDim
  paddingIdx
  numEmbeds
  embedDim
  dtype
  device
-&gt; String
showsPrec :: Int
-&gt; TransformerLMSpec
     numAttnLayers
     numHeads
     ffnDim
     paddingIdx
     numEmbeds
     embedDim
     dtype
     device
-&gt; ShowS
$cshowsPrec :: forall (numAttnLayers :: Nat) (numHeads :: Nat) (ffnDim :: Nat)
       (paddingIdx :: Nat) (numEmbeds :: Nat) (embedDim :: Nat)
       (dtype :: DType) (device :: (DeviceType, Nat)).
Int
-&gt; TransformerLMSpec
     numAttnLayers
     numHeads
     ffnDim
     paddingIdx
     numEmbeds
     embedDim
     dtype
     device
-&gt; ShowS
</span><a href="../file:///nix/store/yi1zp26n2al045qmp9gwpxblhp2c8gs8-ghc-8.8.3-doc/share/doc/ghc/html/libraries/base-4.13.0.0/src"><span class="hs-identifier hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var">Show</span></a></span></span></span></span><span class="hs-special">)</span><span>
</span><span id="line-328"></span><span>
</span><span id="line-329"></span><span id="local-6989586621679721211"><span id="local-6989586621679721212"></span></span><span class="hs-keyword">data</span><span>
</span><span id="line-330"></span><span>  </span><span id="TransformerLM"><span class="annot"><a href="Torch.Typed.NN.Transformer.html#TransformerLM"><span class="hs-identifier hs-var">TransformerLM</span></a></span></span><span>
</span><span id="line-331"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679721210"><span class="annot"><a href="#local-6989586621679721210"><span class="hs-identifier hs-type">numAttnLayers</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="../file:///nix/store/yi1zp26n2al045qmp9gwpxblhp2c8gs8-ghc-8.8.3-doc/share/doc/ghc/html/libraries/ghc-prim-0.5.3/src"><span class="hs-identifier hs-type">Nat</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-332"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679721209"><span class="annot"><a href="#local-6989586621679721209"><span class="hs-identifier hs-type">numHeads</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="../file:///nix/store/yi1zp26n2al045qmp9gwpxblhp2c8gs8-ghc-8.8.3-doc/share/doc/ghc/html/libraries/ghc-prim-0.5.3/src"><span class="hs-identifier hs-type">Nat</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-333"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679721208"><span class="annot"><a href="#local-6989586621679721208"><span class="hs-identifier hs-type">ffnDim</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="../file:///nix/store/yi1zp26n2al045qmp9gwpxblhp2c8gs8-ghc-8.8.3-doc/share/doc/ghc/html/libraries/ghc-prim-0.5.3/src"><span class="hs-identifier hs-type">Nat</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-334"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679721207"><span class="annot"><a href="#local-6989586621679721207"><span class="hs-identifier hs-type">paddingIdx</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="../file:///nix/store/yi1zp26n2al045qmp9gwpxblhp2c8gs8-ghc-8.8.3-doc/share/doc/ghc/html/libraries/ghc-prim-0.5.3/src"><span class="hs-identifier hs-type">Nat</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-335"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679721206"><span class="annot"><a href="#local-6989586621679721206"><span class="hs-identifier hs-type">numEmbeds</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="../file:///nix/store/yi1zp26n2al045qmp9gwpxblhp2c8gs8-ghc-8.8.3-doc/share/doc/ghc/html/libraries/ghc-prim-0.5.3/src"><span class="hs-identifier hs-type">Nat</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-336"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679721205"><span class="annot"><a href="#local-6989586621679721205"><span class="hs-identifier hs-type">embedDim</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="../file:///nix/store/yi1zp26n2al045qmp9gwpxblhp2c8gs8-ghc-8.8.3-doc/share/doc/ghc/html/libraries/ghc-prim-0.5.3/src"><span class="hs-identifier hs-type">Nat</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-337"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679721204"><span class="annot"><a href="#local-6989586621679721204"><span class="hs-identifier hs-type">dtype</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.DType.html#DType"><span class="hs-identifier hs-type">D.DType</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-338"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679721203"><span class="annot"><a href="#local-6989586621679721203"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Device.html#DeviceType"><span class="hs-identifier hs-type">D.DeviceType</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="../file:///nix/store/yi1zp26n2al045qmp9gwpxblhp2c8gs8-ghc-8.8.3-doc/share/doc/ghc/html/libraries/ghc-prim-0.5.3/src"><span class="hs-identifier hs-type">Nat</span></a></span><span class="hs-special">)</span><span class="hs-special">)</span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-339"></span><span>  </span><span id="TransformerLM"><span class="annot"><a href="Torch.Typed.NN.Transformer.html#TransformerLM"><span class="hs-identifier hs-var">TransformerLM</span></a></span></span><span>
</span><span id="line-340"></span><span>    </span><span class="hs-glyph">::</span><span> </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679721578"><span class="annot"><a href="#local-6989586621679721578"><span class="hs-identifier hs-type">numAttnLayers</span></a></span></span><span> </span><span id="local-6989586621679721577"><span class="annot"><a href="#local-6989586621679721577"><span class="hs-identifier hs-type">numHeads</span></a></span></span><span> </span><span id="local-6989586621679721576"><span class="annot"><a href="#local-6989586621679721576"><span class="hs-identifier hs-type">ffnDim</span></a></span></span><span> </span><span id="local-6989586621679721575"><span class="annot"><a href="#local-6989586621679721575"><span class="hs-identifier hs-type">paddingIdx</span></a></span></span><span> </span><span id="local-6989586621679721574"><span class="annot"><a href="#local-6989586621679721574"><span class="hs-identifier hs-type">numEmbeds</span></a></span></span><span> </span><span id="local-6989586621679721573"><span class="annot"><a href="#local-6989586621679721573"><span class="hs-identifier hs-type">embedDim</span></a></span></span><span> </span><span id="local-6989586621679721572"><span class="annot"><a href="#local-6989586621679721572"><span class="hs-identifier hs-type">dtype</span></a></span></span><span> </span><span id="local-6989586621679721571"><span class="annot"><a href="#local-6989586621679721571"><span class="hs-identifier hs-type">device</span></a></span></span><span>
</span><span id="line-341"></span><span>     </span><span class="hs-operator">.</span><span> </span><span class="hs-special">{</span><span> </span><span id="tEmbedding"><span class="annot"><span class="annottext">TransformerLM
  numAttnLayers
  numHeads
  ffnDim
  paddingIdx
  numEmbeds
  embedDim
  dtype
  device
-&gt; Embedding
     ('Just paddingIdx) numEmbeds embedDim 'Learned dtype device
</span><a href="Torch.Typed.NN.Transformer.html#tEmbedding"><span class="hs-identifier hs-var hs-var">tEmbedding</span></a></span></span><span>    </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.Typed.NN.html#Embedding"><span class="hs-identifier hs-type">Embedding</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="../file:///nix/store/yi1zp26n2al045qmp9gwpxblhp2c8gs8-ghc-8.8.3-doc/share/doc/ghc/html/libraries/base-4.13.0.0/src"><span class="hs-identifier hs-type">Just</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679721575"><span class="hs-identifier hs-type">paddingIdx</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679721574"><span class="hs-identifier hs-type">numEmbeds</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679721573"><span class="hs-identifier hs-type">embedDim</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.Typed.NN.html#Learned"><span class="hs-identifier hs-type">Learned</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679721572"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679721571"><span class="hs-identifier hs-type">device</span></a></span><span>
</span><span id="line-342"></span><span>       </span><span class="hs-special">,</span><span> </span><span id="tPosEmbedding"><span class="annot"><span class="annottext">TransformerLM
  numAttnLayers
  numHeads
  ffnDim
  paddingIdx
  numEmbeds
  embedDim
  dtype
  device
-&gt; Embedding 'Nothing 2048 embedDim 'Constant dtype device
</span><a href="Torch.Typed.NN.Transformer.html#tPosEmbedding"><span class="hs-identifier hs-var hs-var">tPosEmbedding</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.Typed.NN.html#Embedding"><span class="hs-identifier hs-type">Embedding</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="../file:///nix/store/yi1zp26n2al045qmp9gwpxblhp2c8gs8-ghc-8.8.3-doc/share/doc/ghc/html/libraries/base-4.13.0.0/src"><span class="hs-identifier hs-type">Nothing</span></a></span><span>           </span><span class="annot"><span class="hs-number">2048</span></span><span>      </span><span class="annot"><a href="#local-6989586621679721573"><span class="hs-identifier hs-type">embedDim</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.Typed.NN.html#Constant"><span class="hs-identifier hs-type">Constant</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679721572"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679721571"><span class="hs-identifier hs-type">device</span></a></span><span>
</span><span id="line-343"></span><span>       </span><span class="hs-special">,</span><span> </span><span id="tDropout"><span class="annot"><span class="annottext">TransformerLM
  numAttnLayers
  numHeads
  ffnDim
  paddingIdx
  numEmbeds
  embedDim
  dtype
  device
-&gt; Dropout
</span><a href="Torch.Typed.NN.Transformer.html#tDropout"><span class="hs-identifier hs-var hs-var">tDropout</span></a></span></span><span>      </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.Typed.NN.html#Dropout"><span class="hs-identifier hs-type">Dropout</span></a></span><span>
</span><span id="line-344"></span><span>       </span><span class="hs-special">,</span><span> </span><span id="tLayers"><span class="annot"><span class="annottext">TransformerLM
  numAttnLayers
  numHeads
  ffnDim
  paddingIdx
  numEmbeds
  embedDim
  dtype
  device
-&gt; HList
     (HReplicateR
        numAttnLayers
        (TransformerLayer embedDim numHeads ffnDim dtype device))
</span><a href="Torch.Typed.NN.Transformer.html#tLayers"><span class="hs-identifier hs-var hs-var">tLayers</span></a></span></span><span>       </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.HList.html#HList"><span class="hs-identifier hs-type">HList</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.HList.html#HReplicateR"><span class="hs-identifier hs-type">HReplicateR</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679721578"><span class="hs-identifier hs-type">numAttnLayers</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.NN.Transformer.html#TransformerLayer"><span class="hs-identifier hs-type">TransformerLayer</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679721573"><span class="hs-identifier hs-type">embedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679721577"><span class="hs-identifier hs-type">numHeads</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679721576"><span class="hs-identifier hs-type">ffnDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679721572"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679721571"><span class="hs-identifier hs-type">device</span></a></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-345"></span><span>       </span><span class="hs-special">,</span><span> </span><span id="tProj"><span class="annot"><span class="annottext">TransformerLM
  numAttnLayers
  numHeads
  ffnDim
  paddingIdx
  numEmbeds
  embedDim
  dtype
  device
-&gt; Linear embedDim numEmbeds dtype device
</span><a href="Torch.Typed.NN.Transformer.html#tProj"><span class="hs-identifier hs-var hs-var">tProj</span></a></span></span><span>         </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.Typed.NN.html#Linear"><span class="hs-identifier hs-type">Linear</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679721573"><span class="hs-identifier hs-type">embedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679721574"><span class="hs-identifier hs-type">numEmbeds</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679721572"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679721571"><span class="hs-identifier hs-type">device</span></a></span><span>
</span><span id="line-346"></span><span>       </span><span class="hs-special">}</span><span>
</span><span id="line-347"></span><span>    </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Typed.NN.Transformer.html#TransformerLM"><span class="hs-identifier hs-type">TransformerLM</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679721578"><span class="hs-identifier hs-type">numAttnLayers</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679721577"><span class="hs-identifier hs-type">numHeads</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679721576"><span class="hs-identifier hs-type">ffnDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679721575"><span class="hs-identifier hs-type">paddingIdx</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679721574"><span class="hs-identifier hs-type">numEmbeds</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679721573"><span class="hs-identifier hs-type">embedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679721572"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679721571"><span class="hs-identifier hs-type">device</span></a></span><span>
</span><span id="line-348"></span><span>  </span><span class="hs-keyword">deriving</span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">(forall x.
 TransformerLM
   numAttnLayers
   numHeads
   ffnDim
   paddingIdx
   numEmbeds
   embedDim
   dtype
   device
 -&gt; Rep
      (TransformerLM
         numAttnLayers
         numHeads
         ffnDim
         paddingIdx
         numEmbeds
         embedDim
         dtype
         device)
      x)
-&gt; (forall x.
    Rep
      (TransformerLM
         numAttnLayers
         numHeads
         ffnDim
         paddingIdx
         numEmbeds
         embedDim
         dtype
         device)
      x
    -&gt; TransformerLM
         numAttnLayers
         numHeads
         ffnDim
         paddingIdx
         numEmbeds
         embedDim
         dtype
         device)
-&gt; Generic
     (TransformerLM
        numAttnLayers
        numHeads
        ffnDim
        paddingIdx
        numEmbeds
        embedDim
        dtype
        device)
forall x.
Rep
  (TransformerLM
     numAttnLayers
     numHeads
     ffnDim
     paddingIdx
     numEmbeds
     embedDim
     dtype
     device)
  x
-&gt; TransformerLM
     numAttnLayers
     numHeads
     ffnDim
     paddingIdx
     numEmbeds
     embedDim
     dtype
     device
forall x.
TransformerLM
  numAttnLayers
  numHeads
  ffnDim
  paddingIdx
  numEmbeds
  embedDim
  dtype
  device
-&gt; Rep
     (TransformerLM
        numAttnLayers
        numHeads
        ffnDim
        paddingIdx
        numEmbeds
        embedDim
        dtype
        device)
     x
forall a.
(forall x. a -&gt; Rep a x) -&gt; (forall x. Rep a x -&gt; a) -&gt; Generic a
forall (numAttnLayers :: Nat) (numHeads :: Nat) (ffnDim :: Nat)
       (paddingIdx :: Nat) (numEmbeds :: Nat) (embedDim :: Nat)
       (dtype :: DType) (device :: (DeviceType, Nat)) x.
Rep
  (TransformerLM
     numAttnLayers
     numHeads
     ffnDim
     paddingIdx
     numEmbeds
     embedDim
     dtype
     device)
  x
-&gt; TransformerLM
     numAttnLayers
     numHeads
     ffnDim
     paddingIdx
     numEmbeds
     embedDim
     dtype
     device
forall (numAttnLayers :: Nat) (numHeads :: Nat) (ffnDim :: Nat)
       (paddingIdx :: Nat) (numEmbeds :: Nat) (embedDim :: Nat)
       (dtype :: DType) (device :: (DeviceType, Nat)) x.
TransformerLM
  numAttnLayers
  numHeads
  ffnDim
  paddingIdx
  numEmbeds
  embedDim
  dtype
  device
-&gt; Rep
     (TransformerLM
        numAttnLayers
        numHeads
        ffnDim
        paddingIdx
        numEmbeds
        embedDim
        dtype
        device)
     x
$cto :: forall (numAttnLayers :: Nat) (numHeads :: Nat) (ffnDim :: Nat)
       (paddingIdx :: Nat) (numEmbeds :: Nat) (embedDim :: Nat)
       (dtype :: DType) (device :: (DeviceType, Nat)) x.
Rep
  (TransformerLM
     numAttnLayers
     numHeads
     ffnDim
     paddingIdx
     numEmbeds
     embedDim
     dtype
     device)
  x
-&gt; TransformerLM
     numAttnLayers
     numHeads
     ffnDim
     paddingIdx
     numEmbeds
     embedDim
     dtype
     device
$cfrom :: forall (numAttnLayers :: Nat) (numHeads :: Nat) (ffnDim :: Nat)
       (paddingIdx :: Nat) (numEmbeds :: Nat) (embedDim :: Nat)
       (dtype :: DType) (device :: (DeviceType, Nat)) x.
TransformerLM
  numAttnLayers
  numHeads
  ffnDim
  paddingIdx
  numEmbeds
  embedDim
  dtype
  device
-&gt; Rep
     (TransformerLM
        numAttnLayers
        numHeads
        ffnDim
        paddingIdx
        numEmbeds
        embedDim
        dtype
        device)
     x
</span><a href="../file:///nix/store/yi1zp26n2al045qmp9gwpxblhp2c8gs8-ghc-8.8.3-doc/share/doc/ghc/html/libraries/base-4.13.0.0/src"><span class="hs-identifier hs-var hs-var hs-var hs-var">Generic</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-349"></span><span>
</span><span id="line-350"></span><span class="hs-keyword">data</span><span>
</span><span id="line-351"></span><span>  </span><span id="FoldLayers"><span class="annot"><a href="Torch.Typed.NN.Transformer.html#FoldLayers"><span class="hs-identifier hs-var">FoldLayers</span></a></span></span><span>
</span><span id="line-352"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679721604"><span class="annot"><a href="#local-6989586621679721604"><span class="hs-identifier hs-type">batchSize</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="../file:///nix/store/yi1zp26n2al045qmp9gwpxblhp2c8gs8-ghc-8.8.3-doc/share/doc/ghc/html/libraries/ghc-prim-0.5.3/src"><span class="hs-identifier hs-type">Nat</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-353"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679721603"><span class="annot"><a href="#local-6989586621679721603"><span class="hs-identifier hs-type">seqLen</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="../file:///nix/store/yi1zp26n2al045qmp9gwpxblhp2c8gs8-ghc-8.8.3-doc/share/doc/ghc/html/libraries/ghc-prim-0.5.3/src"><span class="hs-identifier hs-type">Nat</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-354"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679721602"><span class="annot"><a href="#local-6989586621679721602"><span class="hs-identifier hs-type">dtype</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.DType.html#DType"><span class="hs-identifier hs-type">D.DType</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-355"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679721601"><span class="annot"><a href="#local-6989586621679721601"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Device.html#DeviceType"><span class="hs-identifier hs-type">D.DeviceType</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="../file:///nix/store/yi1zp26n2al045qmp9gwpxblhp2c8gs8-ghc-8.8.3-doc/share/doc/ghc/html/libraries/ghc-prim-0.5.3/src"><span class="hs-identifier hs-type">Nat</span></a></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-356"></span><span>  </span><span class="hs-glyph">=</span><span> </span><span id="FoldLayers"><span class="annot"><a href="Torch.Typed.NN.Transformer.html#FoldLayers"><span class="hs-identifier hs-var">FoldLayers</span></a></span></span><span>
</span><span id="line-357"></span><span>      </span><span class="hs-special">{</span><span> </span><span id="flTrain"><span class="annot"><span class="annottext">FoldLayers batchSize seqLen dtype device -&gt; Bool
</span><a href="Torch.Typed.NN.Transformer.html#flTrain"><span class="hs-identifier hs-var hs-var">flTrain</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="../file:///nix/store/yi1zp26n2al045qmp9gwpxblhp2c8gs8-ghc-8.8.3-doc/share/doc/ghc/html/libraries/ghc-prim-0.5.3/src"><span class="hs-identifier hs-type">Bool</span></a></span><span>
</span><span id="line-358"></span><span>      </span><span class="hs-special">,</span><span> </span><span id="flAttentionMask"><span class="annot"><span class="annottext">FoldLayers batchSize seqLen dtype device
-&gt; Tensor device dtype '[batchSize, seqLen, seqLen]
</span><a href="Torch.Typed.NN.Transformer.html#flAttentionMask"><span class="hs-identifier hs-var hs-var">flAttentionMask</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679721601"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679721602"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="annot"><a href="#local-6989586621679721604"><span class="hs-identifier hs-type">batchSize</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679721603"><span class="hs-identifier hs-type">seqLen</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679721603"><span class="hs-identifier hs-type">seqLen</span></a></span><span class="hs-special">]</span><span>
</span><span id="line-359"></span><span>      </span><span class="hs-special">,</span><span> </span><span id="flKeyPaddingMask"><span class="annot"><span class="annottext">FoldLayers batchSize seqLen dtype device
-&gt; Tensor device 'Bool '[batchSize, seqLen]
</span><a href="Torch.Typed.NN.Transformer.html#flKeyPaddingMask"><span class="hs-identifier hs-var hs-var">flKeyPaddingMask</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679721601"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.DType.html#Bool"><span class="hs-identifier hs-type">D.Bool</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="annot"><a href="#local-6989586621679721604"><span class="hs-identifier hs-type">batchSize</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679721603"><span class="hs-identifier hs-type">seqLen</span></a></span><span class="hs-special">]</span><span>
</span><span id="line-360"></span><span>      </span><span class="hs-special">}</span><span>
</span><span id="line-361"></span><span>
</span><span id="line-362"></span><span id="local-6989586621679721183"><span id="local-6989586621679721184"><span id="local-6989586621679721185"><span id="local-6989586621679721186"><span id="local-6989586621679721187"><span id="local-6989586621679721188"><span id="local-6989586621679721189"><span id="local-6989586621679721190"><span class="hs-keyword">instance</span><span>
</span><span id="line-363"></span><span>  </span><span class="hs-special">(</span><span> </span><span class="annot"><span class="hs-number">1</span></span><span> </span><span class="annot"><a href="../file:///nix/store/yi1zp26n2al045qmp9gwpxblhp2c8gs8-ghc-8.8.3-doc/share/doc/ghc/html/libraries/base-4.13.0.0/src"><span class="hs-operator hs-type">&lt;=</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679721190"><span class="hs-identifier hs-type">numHeads</span></a></span><span>
</span><span id="line-364"></span><span>  </span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679721189"><span class="hs-identifier hs-type">embedDim</span></a></span><span> </span><span class="annot"><a href="../file:///nix/store/yi1zp26n2al045qmp9gwpxblhp2c8gs8-ghc-8.8.3-doc/share/doc/ghc/html/libraries/ghc-prim-0.5.3/src"><span class="hs-glyph hs-type">~</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679721188"><span class="hs-identifier hs-type">headDim</span></a></span><span> </span><span class="annot"><a href="../file:///nix/store/yi1zp26n2al045qmp9gwpxblhp2c8gs8-ghc-8.8.3-doc/share/doc/ghc/html/libraries/base-4.13.0.0/src"><span class="hs-operator hs-type">*</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679721190"><span class="hs-identifier hs-type">numHeads</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-365"></span><span>  </span><span class="hs-special">,</span><span> </span><span class="annot"><a href="../file:///nix/store/yi1zp26n2al045qmp9gwpxblhp2c8gs8-ghc-8.8.3-doc/share/doc/ghc/html/libraries/base-4.13.0.0/src"><span class="hs-identifier hs-type">Mod</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679721189"><span class="hs-identifier hs-type">embedDim</span></a></span><span> </span><span class="annot"><a href="../file:///nix/store/yi1zp26n2al045qmp9gwpxblhp2c8gs8-ghc-8.8.3-doc/share/doc/ghc/html/libraries/base-4.13.0.0/src"><span class="hs-operator hs-type">*</span></a></span><span> </span><span class="annot"><span class="hs-number">3</span></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="hs-number">3</span></span><span> </span><span class="annot"><a href="../file:///nix/store/yi1zp26n2al045qmp9gwpxblhp2c8gs8-ghc-8.8.3-doc/share/doc/ghc/html/libraries/ghc-prim-0.5.3/src"><span class="hs-glyph hs-type">~</span></a></span><span> </span><span class="annot"><span class="hs-number">0</span></span><span>
</span><span id="line-366"></span><span>  </span><span class="hs-special">,</span><span> </span><span class="annot"><a href="../file:///nix/store/yi1zp26n2al045qmp9gwpxblhp2c8gs8-ghc-8.8.3-doc/share/doc/ghc/html/libraries/base-4.13.0.0/src"><span class="hs-identifier hs-type">Div</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679721189"><span class="hs-identifier hs-type">embedDim</span></a></span><span> </span><span class="annot"><a href="../file:///nix/store/yi1zp26n2al045qmp9gwpxblhp2c8gs8-ghc-8.8.3-doc/share/doc/ghc/html/libraries/base-4.13.0.0/src"><span class="hs-operator hs-type">*</span></a></span><span> </span><span class="annot"><span class="hs-number">3</span></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="hs-number">3</span></span><span> </span><span class="annot"><a href="../file:///nix/store/yi1zp26n2al045qmp9gwpxblhp2c8gs8-ghc-8.8.3-doc/share/doc/ghc/html/libraries/ghc-prim-0.5.3/src"><span class="hs-glyph hs-type">~</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679721189"><span class="hs-identifier hs-type">embedDim</span></a></span><span>
</span><span id="line-367"></span><span>  </span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.Typed.Tensor.html#All"><span class="hs-identifier hs-type">All</span></a></span><span> </span><span class="annot"><a href="../file:///nix/store/yi1zp26n2al045qmp9gwpxblhp2c8gs8-ghc-8.8.3-doc/share/doc/ghc/html/libraries/base-4.13.0.0/src"><span class="hs-identifier hs-type">KnownNat</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="annot"><a href="#local-6989586621679721189"><span class="hs-identifier hs-type">embedDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679721190"><span class="hs-identifier hs-type">numHeads</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679721187"><span class="hs-identifier hs-type">seqLen</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679721186"><span class="hs-identifier hs-type">batchSize</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679721188"><span class="hs-identifier hs-type">headDim</span></a></span><span class="hs-special">]</span><span>
</span><span id="line-368"></span><span>  </span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.Typed.Functional.html#EndsWith"><span class="hs-identifier hs-type">EndsWith</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="annot"><a href="#local-6989586621679721186"><span class="hs-identifier hs-type">batchSize</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679721187"><span class="hs-identifier hs-type">seqLen</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679721189"><span class="hs-identifier hs-type">embedDim</span></a></span><span class="hs-special">]</span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="annot"><a href="#local-6989586621679721189"><span class="hs-identifier hs-type">embedDim</span></a></span><span class="hs-special">]</span><span>
</span><span id="line-369"></span><span>  </span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.Typed.Tensor.html#KnownDType"><span class="hs-identifier hs-type">KnownDType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679721185"><span class="hs-identifier hs-type">dtype</span></a></span><span>
</span><span id="line-370"></span><span>  </span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679721185"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="../file:///nix/store/yi1zp26n2al045qmp9gwpxblhp2c8gs8-ghc-8.8.3-doc/share/doc/ghc/html/libraries/ghc-prim-0.5.3/src"><span class="hs-glyph hs-type">~</span></a></span><span> </span><span class="annot"><a href="Torch.Typed.Functional.html#SumDType"><span class="hs-identifier hs-type">SumDType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679721185"><span class="hs-identifier hs-type">dtype</span></a></span><span>
</span><span id="line-371"></span><span>  </span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.Typed.Aux.html#StandardFloatingPointDTypeValidation"><span class="hs-identifier hs-type">StandardFloatingPointDTypeValidation</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679721184"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679721185"><span class="hs-identifier hs-type">dtype</span></a></span><span>
</span><span id="line-372"></span><span>  </span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.Typed.Tensor.html#MatMulDTypeIsValid"><span class="hs-identifier hs-type">MatMulDTypeIsValid</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679721184"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679721185"><span class="hs-identifier hs-type">dtype</span></a></span><span>
</span><span id="line-373"></span><span>  </span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.Typed.Tensor.html#BasicArithmeticDTypeIsValid"><span class="hs-identifier hs-type">BasicArithmeticDTypeIsValid</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679721184"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679721185"><span class="hs-identifier hs-type">dtype</span></a></span><span>
</span><span id="line-374"></span><span>  </span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.Typed.Functional.html#SumDTypeIsValid"><span class="hs-identifier hs-type">SumDTypeIsValid</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679721184"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679721185"><span class="hs-identifier hs-type">dtype</span></a></span><span>
</span><span id="line-375"></span><span>  </span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.Typed.Tensor.html#KnownDevice"><span class="hs-identifier hs-type">KnownDevice</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679721184"><span class="hs-identifier hs-type">device</span></a></span><span>
</span><span id="line-376"></span><span>  </span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span> </span><span class="annot"><a href="Torch.HList.html#Apply%27"><span class="hs-identifier hs-type">Apply'</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.NN.Transformer.html#FoldLayers"><span class="hs-identifier hs-type">FoldLayers</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679721186"><span class="hs-identifier hs-type">batchSize</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679721187"><span class="hs-identifier hs-type">seqLen</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679721185"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679721184"><span class="hs-identifier hs-type">device</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.NN.Transformer.html#TransformerLayer"><span class="hs-identifier hs-type">TransformerLayer</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679721189"><span class="hs-identifier hs-type">embedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679721190"><span class="hs-identifier hs-type">numHeads</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679721183"><span class="hs-identifier hs-type">ffnDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679721185"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679721184"><span class="hs-identifier hs-type">device</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="../file:///nix/store/yi1zp26n2al045qmp9gwpxblhp2c8gs8-ghc-8.8.3-doc/share/doc/ghc/html/libraries/ghc-prim-0.5.3/src"><span class="hs-identifier hs-type">IO</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679721184"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679721185"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="annot"><a href="#local-6989586621679721186"><span class="hs-identifier hs-type">batchSize</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679721187"><span class="hs-identifier hs-type">seqLen</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679721189"><span class="hs-identifier hs-type">embedDim</span></a></span><span class="hs-special">]</span><span class="hs-special">)</span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="../file:///nix/store/yi1zp26n2al045qmp9gwpxblhp2c8gs8-ghc-8.8.3-doc/share/doc/ghc/html/libraries/ghc-prim-0.5.3/src"><span class="hs-identifier hs-type">IO</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679721184"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679721185"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="annot"><a href="#local-6989586621679721186"><span class="hs-identifier hs-type">batchSize</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679721187"><span class="hs-identifier hs-type">seqLen</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679721189"><span class="hs-identifier hs-type">embedDim</span></a></span><span class="hs-special">]</span><span class="hs-special">)</span><span class="hs-special">)</span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-377"></span><span>  </span><span id="local-6989586621679721180"><span class="annot"><span class="annottext">apply' :: FoldLayers batchSize seqLen dtype device
-&gt; (TransformerLayer embedDim numHeads ffnDim dtype device,
    IO (Tensor device dtype '[batchSize, seqLen, embedDim]))
-&gt; IO (Tensor device dtype '[batchSize, seqLen, embedDim])
</span><a href="Torch.HList.html#apply%27"><span class="hs-identifier hs-var hs-var hs-var hs-var">apply'</span></a></span></span><span> </span><span id="local-6989586621679721176"><span id="local-6989586621679721177"><span id="local-6989586621679721178"><span class="annot"><a href="Torch.Typed.NN.Transformer.html#FoldLayers"><span class="hs-identifier hs-type">FoldLayers</span></a></span><span> </span><span class="hs-special">{</span><span class="hs-glyph">..</span><span class="hs-special">}</span></span></span></span><span> </span><span class="hs-special">(</span><span id="local-6989586621679721175"><span class="annot"><span class="annottext">layer :: TransformerLayer embedDim numHeads ffnDim dtype device
</span><a href="#local-6989586621679721175"><span class="hs-identifier hs-var">layer</span></a></span></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679721174"><span class="annot"><span class="annottext">mx :: IO (Tensor device dtype '[batchSize, seqLen, embedDim])
</span><a href="#local-6989586621679721174"><span class="hs-identifier hs-var">mx</span></a></span></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO (Tensor device dtype '[batchSize, seqLen, embedDim])
</span><a href="#local-6989586621679721174"><span class="hs-identifier hs-var">mx</span></a></span><span> </span><span class="annot"><span class="annottext">IO (Tensor device dtype '[batchSize, seqLen, embedDim])
-&gt; (Tensor device dtype '[batchSize, seqLen, embedDim]
    -&gt; IO (Tensor device dtype '[batchSize, seqLen, embedDim]))
-&gt; IO (Tensor device dtype '[batchSize, seqLen, embedDim])
forall (m :: Type -&gt; Type) a b. Monad m =&gt; m a -&gt; (a -&gt; m b) -&gt; m b
</span><a href="../file:///nix/store/yi1zp26n2al045qmp9gwpxblhp2c8gs8-ghc-8.8.3-doc/share/doc/ghc/html/libraries/base-4.13.0.0/src"><span class="hs-operator hs-var">&gt;&gt;=</span></a></span><span> </span><span class="annot"><span class="annottext">TransformerLayer embedDim numHeads ffnDim dtype device
-&gt; Bool
-&gt; Tensor device dtype '[batchSize, seqLen, seqLen]
-&gt; Tensor device 'Bool '[batchSize, seqLen]
-&gt; Maybe
     (Tensor device dtype '[batchSize, seqLen, seqLen, headDim])
-&gt; Maybe
     (Tensor device dtype '[batchSize, seqLen, seqLen, headDim])
-&gt; Tensor device dtype '[batchSize, seqLen, embedDim]
-&gt; IO (Tensor device dtype '[batchSize, seqLen, embedDim])
forall (numHeads :: Nat) (ffnDim :: Nat) (embedDim :: Nat)
       (headDim :: Nat) (seqLen :: Nat) (batchSize :: Nat)
       (dtype :: DType) (device :: (DeviceType, Nat)).
(1 &lt;= numHeads, embedDim ~ (headDim * numHeads),
 Mod (embedDim * 3) 3 ~ 0, Div (embedDim * 3) 3 ~ embedDim,
 All KnownNat '[embedDim, numHeads, seqLen, batchSize, headDim],
 EndsWith '[batchSize, seqLen, embedDim] '[embedDim],
 KnownDType dtype, dtype ~ SumDType dtype,
 StandardFloatingPointDTypeValidation device dtype,
 MatMulDTypeIsValid device dtype,
 BasicArithmeticDTypeIsValid device dtype,
 SumDTypeIsValid device dtype, KnownDevice device) =&gt;
TransformerLayer embedDim numHeads ffnDim dtype device
-&gt; Bool
-&gt; Tensor device dtype '[batchSize, seqLen, seqLen]
-&gt; Tensor device 'Bool '[batchSize, seqLen]
-&gt; Maybe
     (Tensor device dtype '[batchSize, seqLen, seqLen, headDim])
-&gt; Maybe
     (Tensor device dtype '[batchSize, seqLen, seqLen, headDim])
-&gt; Tensor device dtype '[batchSize, seqLen, embedDim]
-&gt; IO (Tensor device dtype '[batchSize, seqLen, embedDim])
</span><a href="Torch.Typed.NN.Transformer.html#transformerLayer"><span class="hs-identifier hs-var">transformerLayer</span></a></span><span> </span><span class="annot"><span class="annottext">TransformerLayer embedDim numHeads ffnDim dtype device
</span><a href="#local-6989586621679721175"><span class="hs-identifier hs-var">layer</span></a></span><span> </span><span class="annot"><span class="annottext">Bool
</span><a href="#local-6989586621679721178"><span class="hs-identifier hs-var">flTrain</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor device dtype '[batchSize, seqLen, seqLen]
</span><a href="#local-6989586621679721177"><span class="hs-identifier hs-var">flAttentionMask</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor device 'Bool '[batchSize, seqLen]
</span><a href="#local-6989586621679721176"><span class="hs-identifier hs-var">flKeyPaddingMask</span></a></span><span> </span><span class="annot"><span class="annottext">Maybe (Tensor device dtype '[batchSize, seqLen, seqLen, headDim])
forall a. Maybe a
</span><a href="../file:///nix/store/yi1zp26n2al045qmp9gwpxblhp2c8gs8-ghc-8.8.3-doc/share/doc/ghc/html/libraries/base-4.13.0.0/src"><span class="hs-identifier hs-var">Nothing</span></a></span><span> </span><span class="annot"><span class="annottext">Maybe (Tensor device dtype '[batchSize, seqLen, seqLen, headDim])
forall a. Maybe a
</span><a href="../file:///nix/store/yi1zp26n2al045qmp9gwpxblhp2c8gs8-ghc-8.8.3-doc/share/doc/ghc/html/libraries/base-4.13.0.0/src"><span class="hs-identifier hs-var">Nothing</span></a></span></span></span></span></span></span></span></span></span><span>
</span><span id="line-378"></span><span>
</span><span id="line-379"></span><span class="annot"><a href="Torch.Typed.NN.Transformer.html#transformerLM"><span class="hs-identifier hs-type">transformerLM</span></a></span><span>
</span><span id="line-380"></span><span>  </span><span class="hs-glyph">::</span><span> </span><span class="hs-keyword">forall</span><span>
</span><span id="line-381"></span><span>       </span><span id="local-6989586621679721497"><span class="annot"><a href="#local-6989586621679721497"><span class="hs-identifier hs-type">numAttnLayers</span></a></span></span><span>
</span><span id="line-382"></span><span>       </span><span id="local-6989586621679721496"><span class="annot"><a href="#local-6989586621679721496"><span class="hs-identifier hs-type">numHeads</span></a></span></span><span>
</span><span id="line-383"></span><span>       </span><span id="local-6989586621679721495"><span class="annot"><a href="#local-6989586621679721495"><span class="hs-identifier hs-type">ffnDim</span></a></span></span><span>
</span><span id="line-384"></span><span>       </span><span id="local-6989586621679721504"><span class="annot"><a href="#local-6989586621679721504"><span class="hs-identifier hs-type">paddingIdx</span></a></span></span><span>
</span><span id="line-385"></span><span>       </span><span id="local-6989586621679721500"><span class="annot"><a href="#local-6989586621679721500"><span class="hs-identifier hs-type">numEmbeds</span></a></span></span><span>
</span><span id="line-386"></span><span>       </span><span id="local-6989586621679721503"><span class="annot"><a href="#local-6989586621679721503"><span class="hs-identifier hs-type">embedDim</span></a></span></span><span>
</span><span id="line-387"></span><span>       </span><span id="local-6989586621679721502"><span class="annot"><a href="#local-6989586621679721502"><span class="hs-identifier hs-type">seqLen</span></a></span></span><span>
</span><span id="line-388"></span><span>       </span><span id="local-6989586621679721501"><span class="annot"><a href="#local-6989586621679721501"><span class="hs-identifier hs-type">batchSize</span></a></span></span><span>
</span><span id="line-389"></span><span>       </span><span id="local-6989586621679721499"><span class="annot"><a href="#local-6989586621679721499"><span class="hs-identifier hs-type">dtype</span></a></span></span><span>
</span><span id="line-390"></span><span>       </span><span id="local-6989586621679721498"><span class="annot"><a href="#local-6989586621679721498"><span class="hs-identifier hs-type">device</span></a></span></span><span>
</span><span id="line-391"></span><span>   </span><span class="hs-operator">.</span><span> </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="Torch.Typed.Tensor.html#All"><span class="hs-identifier hs-type">All</span></a></span><span> </span><span class="annot"><a href="../file:///nix/store/yi1zp26n2al045qmp9gwpxblhp2c8gs8-ghc-8.8.3-doc/share/doc/ghc/html/libraries/base-4.13.0.0/src"><span class="hs-identifier hs-type">KnownNat</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="annot"><a href="#local-6989586621679721504"><span class="hs-identifier hs-type">paddingIdx</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679721503"><span class="hs-identifier hs-type">embedDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679721502"><span class="hs-identifier hs-type">seqLen</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679721501"><span class="hs-identifier hs-type">batchSize</span></a></span><span class="hs-special">]</span><span>
</span><span id="line-392"></span><span>     </span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679721504"><span class="hs-identifier hs-type">paddingIdx</span></a></span><span> </span><span class="annot"><a href="../file:///nix/store/yi1zp26n2al045qmp9gwpxblhp2c8gs8-ghc-8.8.3-doc/share/doc/ghc/html/libraries/base-4.13.0.0/src"><span class="hs-operator hs-type">+</span></a></span><span> </span><span class="annot"><span class="hs-number">1</span></span><span> </span><span class="annot"><a href="../file:///nix/store/yi1zp26n2al045qmp9gwpxblhp2c8gs8-ghc-8.8.3-doc/share/doc/ghc/html/libraries/base-4.13.0.0/src"><span class="hs-operator hs-type">&lt;=</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679721500"><span class="hs-identifier hs-type">numEmbeds</span></a></span><span>
</span><span id="line-393"></span><span>     </span><span class="hs-special">,</span><span> </span><span class="annot"><span class="hs-number">1</span></span><span> </span><span class="annot"><a href="../file:///nix/store/yi1zp26n2al045qmp9gwpxblhp2c8gs8-ghc-8.8.3-doc/share/doc/ghc/html/libraries/base-4.13.0.0/src"><span class="hs-operator hs-type">&lt;=</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679721502"><span class="hs-identifier hs-type">seqLen</span></a></span><span>
</span><span id="line-394"></span><span>     </span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.HList.html#HFoldrM"><span class="hs-identifier hs-type">HFoldrM</span></a></span><span>
</span><span id="line-395"></span><span>         </span><span class="annot"><a href="../file:///nix/store/yi1zp26n2al045qmp9gwpxblhp2c8gs8-ghc-8.8.3-doc/share/doc/ghc/html/libraries/ghc-prim-0.5.3/src"><span class="hs-identifier hs-type">IO</span></a></span><span>
</span><span id="line-396"></span><span>         </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.NN.Transformer.html#FoldLayers"><span class="hs-identifier hs-type">FoldLayers</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679721501"><span class="hs-identifier hs-type">batchSize</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679721502"><span class="hs-identifier hs-type">seqLen</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679721499"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679721498"><span class="hs-identifier hs-type">device</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-397"></span><span>         </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679721498"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679721499"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="annot"><a href="#local-6989586621679721501"><span class="hs-identifier hs-type">batchSize</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679721502"><span class="hs-identifier hs-type">seqLen</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679721503"><span class="hs-identifier hs-type">embedDim</span></a></span><span class="hs-special">]</span><span class="hs-special">)</span><span>
</span><span id="line-398"></span><span>         </span><span class="hs-special">(</span><span class="annot"><a href="Torch.HList.html#HReplicateR"><span class="hs-identifier hs-type">HReplicateR</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679721497"><span class="hs-identifier hs-type">numAttnLayers</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.NN.Transformer.html#TransformerLayer"><span class="hs-identifier hs-type">TransformerLayer</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679721503"><span class="hs-identifier hs-type">embedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679721496"><span class="hs-identifier hs-type">numHeads</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679721495"><span class="hs-identifier hs-type">ffnDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679721499"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679721498"><span class="hs-identifier hs-type">device</span></a></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-399"></span><span>         </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679721498"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679721499"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="annot"><a href="#local-6989586621679721501"><span class="hs-identifier hs-type">batchSize</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679721502"><span class="hs-identifier hs-type">seqLen</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679721503"><span class="hs-identifier hs-type">embedDim</span></a></span><span class="hs-special">]</span><span class="hs-special">)</span><span>
</span><span id="line-400"></span><span>     </span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.Typed.Tensor.html#BasicArithmeticDTypeIsValid"><span class="hs-identifier hs-type">BasicArithmeticDTypeIsValid</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679721498"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679721499"><span class="hs-identifier hs-type">dtype</span></a></span><span>
</span><span id="line-401"></span><span>     </span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.Typed.Tensor.html#ComparisonDTypeIsValid"><span class="hs-identifier hs-type">ComparisonDTypeIsValid</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679721498"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679721499"><span class="hs-identifier hs-type">dtype</span></a></span><span>
</span><span id="line-402"></span><span>     </span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.Typed.Tensor.html#ComparisonDTypeIsValid"><span class="hs-identifier hs-type">ComparisonDTypeIsValid</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679721498"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.DType.html#Int64"><span class="hs-identifier hs-type">D.Int64</span></a></span><span>
</span><span id="line-403"></span><span>     </span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.Typed.Tensor.html#KnownDType"><span class="hs-identifier hs-type">KnownDType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679721499"><span class="hs-identifier hs-type">dtype</span></a></span><span>
</span><span id="line-404"></span><span>     </span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.Typed.Tensor.html#KnownDevice"><span class="hs-identifier hs-type">KnownDevice</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679721498"><span class="hs-identifier hs-type">device</span></a></span><span>
</span><span id="line-405"></span><span>     </span><span class="hs-special">)</span><span>
</span><span id="line-406"></span><span>  </span><span class="hs-glyph">=&gt;</span><span> </span><span class="annot"><a href="Torch.Typed.NN.Transformer.html#TransformerLM"><span class="hs-identifier hs-type">TransformerLM</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679721497"><span class="hs-identifier hs-type">numAttnLayers</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679721496"><span class="hs-identifier hs-type">numHeads</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679721495"><span class="hs-identifier hs-type">ffnDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679721504"><span class="hs-identifier hs-type">paddingIdx</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679721500"><span class="hs-identifier hs-type">numEmbeds</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679721503"><span class="hs-identifier hs-type">embedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679721499"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679721498"><span class="hs-identifier hs-type">device</span></a></span><span>
</span><span id="line-407"></span><span>  </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="../file:///nix/store/yi1zp26n2al045qmp9gwpxblhp2c8gs8-ghc-8.8.3-doc/share/doc/ghc/html/libraries/ghc-prim-0.5.3/src"><span class="hs-identifier hs-type">Bool</span></a></span><span>
</span><span id="line-408"></span><span>  </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679721498"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.DType.html#Int64"><span class="hs-identifier hs-type">D.Int64</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="annot"><a href="#local-6989586621679721501"><span class="hs-identifier hs-type">batchSize</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679721502"><span class="hs-identifier hs-type">seqLen</span></a></span><span class="hs-special">]</span><span>
</span><span id="line-409"></span><span>  </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="../file:///nix/store/yi1zp26n2al045qmp9gwpxblhp2c8gs8-ghc-8.8.3-doc/share/doc/ghc/html/libraries/ghc-prim-0.5.3/src"><span class="hs-identifier hs-type">IO</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679721498"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679721499"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="annot"><a href="#local-6989586621679721501"><span class="hs-identifier hs-type">batchSize</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679721502"><span class="hs-identifier hs-type">seqLen</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679721500"><span class="hs-identifier hs-type">numEmbeds</span></a></span><span class="hs-special">]</span><span class="hs-special">)</span><span>
</span><span id="line-410"></span><span id="transformerLM"><span class="annot"><span class="annottext">transformerLM :: TransformerLM
  numAttnLayers
  numHeads
  ffnDim
  paddingIdx
  numEmbeds
  embedDim
  dtype
  device
-&gt; Bool
-&gt; Tensor device 'Int64 '[batchSize, seqLen]
-&gt; IO (Tensor device dtype '[batchSize, seqLen, numEmbeds])
</span><a href="Torch.Typed.NN.Transformer.html#transformerLM"><span class="hs-identifier hs-var hs-var">transformerLM</span></a></span></span><span> </span><span id="local-6989586621679721168"><span id="local-6989586621679721169"><span id="local-6989586621679721170"><span id="local-6989586621679721171"><span id="local-6989586621679721172"><span class="annot"><a href="Torch.Typed.NN.Transformer.html#TransformerLM"><span class="hs-identifier hs-type">TransformerLM</span></a></span><span> </span><span class="hs-special">{</span><span class="hs-glyph">..</span><span class="hs-special">}</span></span></span></span></span></span><span> </span><span id="local-6989586621679721167"><span class="annot"><span class="annottext">train :: Bool
</span><a href="#local-6989586621679721167"><span class="hs-identifier hs-var">train</span></a></span></span><span> </span><span id="local-6989586621679721166"><span class="annot"><span class="annottext">xTokens :: Tensor device 'Int64 '[batchSize, seqLen]
</span><a href="#local-6989586621679721166"><span class="hs-identifier hs-var">xTokens</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="hs-keyword">do</span><span>
</span><span id="line-411"></span><span>  </span><span class="hs-keyword">let</span><span> </span><span id="local-6989586621679721165"><span class="annot"><span class="annottext">x :: Tensor device dtype '[batchSize, seqLen, embedDim]
</span><a href="#local-6989586621679721165"><span class="hs-identifier hs-var hs-var">x</span></a></span></span><span>         </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Embedding
  ('Just paddingIdx) numEmbeds embedDim 'Learned dtype device
-&gt; Tensor device 'Int64 '[batchSize, seqLen]
-&gt; Tensor device dtype '[batchSize, seqLen, embedDim]
forall (paddingIdx :: Maybe Nat) (shape :: [Nat])
       (numEmbeds :: Nat) (embedSize :: Nat)
       (embeddingType :: EmbeddingType) (dtype :: DType)
       (device :: (DeviceType, Nat)) (shape' :: [Nat]).
(KnownMaybeNat paddingIdx, PaddingIdxCheck paddingIdx numEmbeds,
 shape' ~ Reverse (embedSize : Reverse shape)) =&gt;
Embedding paddingIdx numEmbeds embedSize embeddingType dtype device
-&gt; Tensor device 'Int64 shape -&gt; Tensor device dtype shape'
</span><a href="Torch.Typed.NN.html#embed"><span class="hs-identifier hs-var">embed</span></a></span><span> </span><span class="annot"><span class="annottext">Embedding
  ('Just paddingIdx) numEmbeds embedDim 'Learned dtype device
</span><a href="#local-6989586621679721172"><span class="hs-identifier hs-var">tEmbedding</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor device 'Int64 '[batchSize, seqLen]
</span><a href="#local-6989586621679721166"><span class="hs-identifier hs-var">xTokens</span></a></span><span>
</span><span id="line-412"></span><span>      </span><span id="local-6989586621679721163"><span class="annot"><span class="annottext">positions :: Tensor device dtype '[batchSize, seqLen, embedDim]
</span><a href="#local-6989586621679721163"><span class="hs-identifier hs-var hs-var">positions</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Bool
-&gt; Tensor device dtype '[seqLen, embedDim]
-&gt; Tensor device dtype '[batchSize, seqLen, embedDim]
forall (shape' :: [Nat]) (shape :: [Nat]) (dtype :: DType)
       (device :: (DeviceType, Nat)).
(KnownShape shape', shape' ~ Broadcast shape shape') =&gt;
Bool -&gt; Tensor device dtype shape -&gt; Tensor device dtype shape'
</span><a href="Torch.Typed.Functional.html#expand"><span class="hs-identifier hs-var">expand</span></a></span><span> </span><span class="hs-glyph">@</span><span class="hs-special">'</span><span class="hs-special">[</span><span class="annot"><a href="#local-6989586621679721501"><span class="hs-identifier hs-type">batchSize</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679721502"><span class="hs-identifier hs-type">seqLen</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679721503"><span class="hs-identifier hs-type">embedDim</span></a></span><span class="hs-special">]</span><span> </span><span class="annot"><span class="annottext">Bool
</span><a href="../file:///nix/store/yi1zp26n2al045qmp9gwpxblhp2c8gs8-ghc-8.8.3-doc/share/doc/ghc/html/libraries/ghc-prim-0.5.3/src"><span class="hs-identifier hs-var">True</span></a></span><span>
</span><span id="line-413"></span><span>                    </span><span class="annot"><span class="annottext">(Tensor device dtype '[seqLen, embedDim]
 -&gt; Tensor device dtype '[batchSize, seqLen, embedDim])
-&gt; (Int -&gt; Tensor device dtype '[seqLen, embedDim])
-&gt; Int
-&gt; Tensor device dtype '[batchSize, seqLen, embedDim]
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><a href="../file:///nix/store/yi1zp26n2al045qmp9gwpxblhp2c8gs8-ghc-8.8.3-doc/share/doc/ghc/html/libraries/base-4.13.0.0/src"><span class="hs-operator hs-var">.</span></a></span><span> </span><span class="annot"><span class="annottext">Embedding 'Nothing 2048 embedDim 'Constant dtype device
-&gt; Tensor device 'Int64 '[seqLen]
-&gt; Tensor device dtype '[seqLen, embedDim]
forall (paddingIdx :: Maybe Nat) (shape :: [Nat])
       (numEmbeds :: Nat) (embedSize :: Nat)
       (embeddingType :: EmbeddingType) (dtype :: DType)
       (device :: (DeviceType, Nat)) (shape' :: [Nat]).
(KnownMaybeNat paddingIdx, PaddingIdxCheck paddingIdx numEmbeds,
 shape' ~ Reverse (embedSize : Reverse shape)) =&gt;
Embedding paddingIdx numEmbeds embedSize embeddingType dtype device
-&gt; Tensor device 'Int64 shape -&gt; Tensor device dtype shape'
</span><a href="Torch.Typed.NN.html#embed"><span class="hs-identifier hs-var">embed</span></a></span><span> </span><span class="annot"><span class="annottext">Embedding 'Nothing 2048 embedDim 'Constant dtype device
</span><a href="#local-6989586621679721171"><span class="hs-identifier hs-var">tPosEmbedding</span></a></span><span>
</span><span id="line-414"></span><span>                    </span><span class="annot"><span class="annottext">(Tensor device 'Int64 '[seqLen]
 -&gt; Tensor device dtype '[seqLen, embedDim])
-&gt; (Int -&gt; Tensor device 'Int64 '[seqLen])
-&gt; Int
-&gt; Tensor device dtype '[seqLen, embedDim]
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><a href="../file:///nix/store/yi1zp26n2al045qmp9gwpxblhp2c8gs8-ghc-8.8.3-doc/share/doc/ghc/html/libraries/base-4.13.0.0/src"><span class="hs-operator hs-var">.</span></a></span><span> </span><span class="annot"><span class="annottext">forall (dtype :: DType) (device :: (DeviceType, Nat))
       (shape :: [Nat]).
KnownDType 'Int64 =&gt;
Tensor device dtype shape -&gt; Tensor device 'Int64 shape
forall (dtype' :: DType) (dtype :: DType)
       (device :: (DeviceType, Nat)) (shape :: [Nat]).
KnownDType dtype' =&gt;
Tensor device dtype shape -&gt; Tensor device dtype' shape
</span><a href="Torch.Typed.Tensor.html#toDType"><span class="hs-identifier hs-var">Torch.Typed.Tensor.toDType</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><a href="Torch.DType.html#Int64"><span class="hs-identifier hs-type">D.Int64</span></a></span><span>
</span><span id="line-415"></span><span>                    </span><span class="annot"><span class="annottext">(Tensor device 'Float '[seqLen] -&gt; Tensor device 'Int64 '[seqLen])
-&gt; (Int -&gt; Tensor device 'Float '[seqLen])
-&gt; Int
-&gt; Tensor device 'Int64 '[seqLen]
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><a href="../file:///nix/store/yi1zp26n2al045qmp9gwpxblhp2c8gs8-ghc-8.8.3-doc/share/doc/ghc/html/libraries/base-4.13.0.0/src"><span class="hs-operator hs-var">.</span></a></span><span> </span><span class="annot"><span class="annottext">Int -&gt; Int -&gt; Tensor device 'Float '[seqLen]
forall (steps :: Nat) (device :: (DeviceType, Nat)) start end.
(Scalar start, Scalar end, KnownNat steps,
 TensorOptions '[steps] 'Float device) =&gt;
start -&gt; end -&gt; Tensor device 'Float '[steps]
</span><a href="Torch.Typed.Factories.html#linspace"><span class="hs-identifier hs-var">linspace</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679721502"><span class="hs-identifier hs-type">seqLen</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="hs-number">0</span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="../file:///nix/store/yi1zp26n2al045qmp9gwpxblhp2c8gs8-ghc-8.8.3-doc/share/doc/ghc/html/libraries/ghc-prim-0.5.3/src"><span class="hs-identifier hs-type">Int</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-416"></span><span>                    </span><span class="annot"><span class="annottext">(Int -&gt; Tensor device dtype '[batchSize, seqLen, embedDim])
-&gt; Int -&gt; Tensor device dtype '[batchSize, seqLen, embedDim]
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><a href="../file:///nix/store/yi1zp26n2al045qmp9gwpxblhp2c8gs8-ghc-8.8.3-doc/share/doc/ghc/html/libraries/base-4.13.0.0/src"><span class="hs-operator hs-var">$</span></a></span><span> </span><span class="annot"><span class="annottext">KnownNat (seqLen - 1) =&gt; Int
forall (n :: Nat). KnownNat n =&gt; Int
</span><a href="Torch.Typed.Aux.html#natValI"><span class="hs-identifier hs-var">natValI</span></a></span><span> </span><span class="hs-glyph">@</span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679721502"><span class="hs-identifier hs-type">seqLen</span></a></span><span> </span><span class="annot"><a href="../file:///nix/store/yi1zp26n2al045qmp9gwpxblhp2c8gs8-ghc-8.8.3-doc/share/doc/ghc/html/libraries/base-4.13.0.0/src"><span class="hs-glyph hs-type">-</span></a></span><span> </span><span class="annot"><span class="hs-number">1</span></span><span class="hs-special">)</span><span>
</span><span id="line-417"></span><span>  </span><span id="local-6989586621679721159"><span class="annot"><span class="annottext">Tensor device dtype '[batchSize, seqLen, embedDim]
</span><a href="#local-6989586621679721159"><span class="hs-identifier hs-var">x'</span></a></span></span><span> </span><span class="hs-glyph">&lt;-</span><span> </span><span class="annot"><span class="annottext">Dropout
-&gt; Bool
-&gt; Tensor device dtype '[batchSize, seqLen, embedDim]
-&gt; IO (Tensor device dtype '[batchSize, seqLen, embedDim])
forall (shape :: [Nat]) (dtype :: DType)
       (device :: (DeviceType, Nat)).
Dropout
-&gt; Bool
-&gt; Tensor device dtype shape
-&gt; IO (Tensor device dtype shape)
</span><a href="Torch.Typed.NN.html#dropout"><span class="hs-identifier hs-var">Torch.Typed.NN.dropout</span></a></span><span> </span><span class="annot"><span class="annottext">Dropout
</span><a href="#local-6989586621679721170"><span class="hs-identifier hs-var">tDropout</span></a></span><span> </span><span class="annot"><span class="annottext">Bool
</span><a href="#local-6989586621679721167"><span class="hs-identifier hs-var">train</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">Tensor device dtype '[batchSize, seqLen, embedDim]
</span><a href="#local-6989586621679721165"><span class="hs-identifier hs-var">x</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor device dtype '[batchSize, seqLen, embedDim]
-&gt; Tensor device dtype '[batchSize, seqLen, embedDim]
-&gt; Tensor device dtype '[batchSize, seqLen, embedDim]
forall (shape'' :: [Nat]) (shape :: [Nat]) (shape' :: [Nat])
       (dtype :: DType) (dtype' :: DType) (dtype'' :: DType)
       (device :: (DeviceType, Nat)).
(dtype'' ~ DTypePromotion dtype dtype',
 shape'' ~ Broadcast shape shape',
 BasicArithmeticDTypeIsValid device dtype,
 BasicArithmeticDTypeIsValid device dtype',
 BasicArithmeticDTypeIsValid device dtype'') =&gt;
Tensor device dtype shape
-&gt; Tensor device dtype' shape' -&gt; Tensor device dtype'' shape''
</span><a href="Torch.Typed.Tensor.html#add"><span class="hs-operator hs-var">`add`</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor device dtype '[batchSize, seqLen, embedDim]
</span><a href="#local-6989586621679721163"><span class="hs-identifier hs-var">positions</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-418"></span><span>  </span><span class="hs-keyword">let</span><span> </span><span id="local-6989586621679721158"><span class="annot"><span class="annottext">attentionMask :: Tensor device 'Bool '[1, seqLen, seqLen]
</span><a href="#local-6989586621679721158"><span class="hs-identifier hs-var hs-var">attentionMask</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">forall (shape :: [Nat]) (shape' :: [Nat]) (dtype :: DType)
       (device :: (DeviceType, Nat)).
(KnownNat 0, shape' ~ Unsqueeze shape 0) =&gt;
Tensor device dtype shape -&gt; Tensor device dtype shape'
forall (dim :: Nat) (shape :: [Nat]) (shape' :: [Nat])
       (dtype :: DType) (device :: (DeviceType, Nat)).
(KnownNat dim, shape' ~ Unsqueeze shape dim) =&gt;
Tensor device dtype shape -&gt; Tensor device dtype shape'
</span><a href="Torch.Typed.Functional.html#unsqueeze"><span class="hs-identifier hs-var">unsqueeze</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><span class="hs-number">0</span></span><span>
</span><span id="line-419"></span><span>                        </span><span class="annot"><span class="annottext">(Tensor device 'Bool '[seqLen, seqLen]
 -&gt; Tensor device 'Bool '[1, seqLen, seqLen])
-&gt; (Tensor device 'Int8 '[seqLen, seqLen]
    -&gt; Tensor device 'Bool '[seqLen, seqLen])
-&gt; Tensor device 'Int8 '[seqLen, seqLen]
-&gt; Tensor device 'Bool '[1, seqLen, seqLen]
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><a href="../file:///nix/store/yi1zp26n2al045qmp9gwpxblhp2c8gs8-ghc-8.8.3-doc/share/doc/ghc/html/libraries/base-4.13.0.0/src"><span class="hs-operator hs-var">.</span></a></span><span> </span><span class="annot"><span class="annottext">forall (dtype :: DType) (device :: (DeviceType, Nat))
       (shape :: [Nat]).
KnownDType 'Bool =&gt;
Tensor device dtype shape -&gt; Tensor device 'Bool shape
forall (dtype' :: DType) (dtype :: DType)
       (device :: (DeviceType, Nat)) (shape :: [Nat]).
KnownDType dtype' =&gt;
Tensor device dtype shape -&gt; Tensor device dtype' shape
</span><a href="Torch.Typed.Tensor.html#toDType"><span class="hs-identifier hs-var">Torch.Typed.Tensor.toDType</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><a href="Torch.DType.html#Bool"><span class="hs-identifier hs-type">D.Bool</span></a></span><span>
</span><span id="line-420"></span><span>                        </span><span class="annot"><span class="annottext">(Tensor device 'Int8 '[seqLen, seqLen]
 -&gt; Tensor device 'Bool '[seqLen, seqLen])
-&gt; (Tensor device 'Int8 '[seqLen, seqLen]
    -&gt; Tensor device 'Int8 '[seqLen, seqLen])
-&gt; Tensor device 'Int8 '[seqLen, seqLen]
-&gt; Tensor device 'Bool '[seqLen, seqLen]
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><a href="../file:///nix/store/yi1zp26n2al045qmp9gwpxblhp2c8gs8-ghc-8.8.3-doc/share/doc/ghc/html/libraries/base-4.13.0.0/src"><span class="hs-operator hs-var">.</span></a></span><span> </span><span class="annot"><span class="annottext">Int
-&gt; Tensor device 'Int8 '[seqLen, seqLen]
-&gt; Tensor device 'Int8 '[seqLen, seqLen]
forall (shape :: [Nat]) (dtype :: DType)
       (device :: (DeviceType, Nat)).
(shape ~ MatrixOrMatrixBatch shape) =&gt;
Int -&gt; Tensor device dtype shape -&gt; Tensor device dtype shape
</span><a href="Torch.Typed.Functional.html#triu"><span class="hs-identifier hs-var">triu</span></a></span><span> </span><span class="annot"><span class="hs-number">1</span></span><span>
</span><span id="line-421"></span><span>                        </span><span class="annot"><span class="annottext">(Tensor device 'Int8 '[seqLen, seqLen]
 -&gt; Tensor device 'Bool '[1, seqLen, seqLen])
-&gt; Tensor device 'Int8 '[seqLen, seqLen]
-&gt; Tensor device 'Bool '[1, seqLen, seqLen]
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><a href="../file:///nix/store/yi1zp26n2al045qmp9gwpxblhp2c8gs8-ghc-8.8.3-doc/share/doc/ghc/html/libraries/base-4.13.0.0/src"><span class="hs-operator hs-var">$</span></a></span><span> </span><span class="annot"><span class="annottext">TensorOptions '[seqLen, seqLen] 'Int8 device =&gt;
Tensor device 'Int8 '[seqLen, seqLen]
forall (shape :: [Nat]) (dtype :: DType)
       (device :: (DeviceType, Nat)).
TensorOptions shape dtype device =&gt;
Tensor device dtype shape
</span><a href="Torch.Typed.Factories.html#ones"><span class="hs-identifier hs-var">ones</span></a></span><span> </span><span class="hs-glyph">@</span><span class="hs-special">'</span><span class="hs-special">[</span><span class="annot"><a href="#local-6989586621679721502"><span class="hs-identifier hs-type">seqLen</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679721502"><span class="hs-identifier hs-type">seqLen</span></a></span><span class="hs-special">]</span><span> </span><span class="hs-glyph">@</span><span class="annot"><a href="Torch.DType.html#Int8"><span class="hs-identifier hs-type">D.Int8</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679721498"><span class="hs-identifier hs-type">device</span></a></span><span>
</span><span id="line-422"></span><span>      </span><span id="local-6989586621679721155"><span class="annot"><span class="annottext">attentionMask' :: Tensor device dtype '[batchSize, seqLen, seqLen]
</span><a href="#local-6989586621679721155"><span class="hs-identifier hs-var hs-var">attentionMask'</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Tensor device 'Bool '[1, seqLen, seqLen]
-&gt; Double
-&gt; Tensor device dtype '[batchSize, seqLen, seqLen]
-&gt; Tensor device dtype '[batchSize, seqLen, seqLen]
forall a (shape :: [Nat]) (shape' :: [Nat]) (shape'' :: [Nat])
       (dtype :: DType) (device :: (DeviceType, Nat)).
(Scalar a, shape'' ~ Broadcast shape shape') =&gt;
Tensor device 'Bool shape'
-&gt; a -&gt; Tensor device dtype shape -&gt; Tensor device dtype shape''
</span><a href="Torch.Typed.Functional.html#maskedFill"><span class="hs-identifier hs-var">maskedFill</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor device 'Bool '[1, seqLen, seqLen]
</span><a href="#local-6989586621679721158"><span class="hs-identifier hs-var">attentionMask</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">-</span><span class="annot"><span class="hs-number">1</span></span><span> </span><span class="annot"><span class="annottext">Double -&gt; Double -&gt; Double
forall a. Fractional a =&gt; a -&gt; a -&gt; a
</span><a href="../file:///nix/store/yi1zp26n2al045qmp9gwpxblhp2c8gs8-ghc-8.8.3-doc/share/doc/ghc/html/libraries/base-4.13.0.0/src"><span class="hs-operator hs-var">/</span></a></span><span> </span><span class="annot"><span class="hs-number">0</span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="../file:///nix/store/yi1zp26n2al045qmp9gwpxblhp2c8gs8-ghc-8.8.3-doc/share/doc/ghc/html/libraries/ghc-prim-0.5.3/src"><span class="hs-identifier hs-type">Double</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-423"></span><span>                         </span><span class="annot"><span class="annottext">(Tensor device dtype '[batchSize, seqLen, seqLen]
 -&gt; Tensor device dtype '[batchSize, seqLen, seqLen])
-&gt; Tensor device dtype '[batchSize, seqLen, seqLen]
-&gt; Tensor device dtype '[batchSize, seqLen, seqLen]
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><a href="../file:///nix/store/yi1zp26n2al045qmp9gwpxblhp2c8gs8-ghc-8.8.3-doc/share/doc/ghc/html/libraries/base-4.13.0.0/src"><span class="hs-operator hs-var">$</span></a></span><span> </span><span class="annot"><span class="annottext">TensorOptions '[batchSize, seqLen, seqLen] dtype device =&gt;
Tensor device dtype '[batchSize, seqLen, seqLen]
forall (shape :: [Nat]) (dtype :: DType)
       (device :: (DeviceType, Nat)).
TensorOptions shape dtype device =&gt;
Tensor device dtype shape
</span><a href="Torch.Typed.Factories.html#zeros"><span class="hs-identifier hs-var">zeros</span></a></span><span> </span><span class="hs-glyph">@</span><span class="hs-special">'</span><span class="hs-special">[</span><span class="annot"><a href="#local-6989586621679721501"><span class="hs-identifier hs-type">batchSize</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679721502"><span class="hs-identifier hs-type">seqLen</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679721502"><span class="hs-identifier hs-type">seqLen</span></a></span><span class="hs-special">]</span><span> </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679721499"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679721498"><span class="hs-identifier hs-type">device</span></a></span><span>
</span><span id="line-424"></span><span>  </span><span class="hs-keyword">let</span><span> </span><span id="local-6989586621679721153"><span class="annot"><span class="annottext">keyPaddingMask :: Tensor device 'Bool '[batchSize, seqLen]
</span><a href="#local-6989586621679721153"><span class="hs-identifier hs-var hs-var">keyPaddingMask</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Tensor device 'Int64 '[batchSize, seqLen]
</span><a href="#local-6989586621679721166"><span class="hs-identifier hs-var">xTokens</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor device 'Int64 '[batchSize, seqLen]
-&gt; Tensor device 'Int64 '[]
-&gt; Tensor device 'Bool '[batchSize, seqLen]
forall (shape'' :: [Nat]) (shape :: [Nat]) (shape' :: [Nat])
       (dtype :: DType) (dtype' :: DType) (device :: (DeviceType, Nat)).
(shape'' ~ Broadcast shape shape',
 ComparisonDTypeIsValid device dtype,
 ComparisonDTypeIsValid device dtype') =&gt;
Tensor device dtype shape
-&gt; Tensor device dtype' shape' -&gt; Tensor device 'Bool shape''
</span><a href="Torch.Typed.Tensor.html#%3D%3D."><span class="hs-operator hs-var">==.</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">Integer -&gt; Tensor device 'Int64 '[]
forall a. Num a =&gt; Integer -&gt; a
</span><a href="../file:///nix/store/yi1zp26n2al045qmp9gwpxblhp2c8gs8-ghc-8.8.3-doc/share/doc/ghc/html/libraries/base-4.13.0.0/src"><span class="hs-identifier hs-var">fromInteger</span></a></span><span> </span><span class="annot"><span class="annottext">(Integer -&gt; Tensor device 'Int64 '[])
-&gt; (Proxy paddingIdx -&gt; Integer)
-&gt; Proxy paddingIdx
-&gt; Tensor device 'Int64 '[]
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><a href="../file:///nix/store/yi1zp26n2al045qmp9gwpxblhp2c8gs8-ghc-8.8.3-doc/share/doc/ghc/html/libraries/base-4.13.0.0/src"><span class="hs-operator hs-var">.</span></a></span><span> </span><span class="annot"><span class="annottext">Proxy paddingIdx -&gt; Integer
forall (n :: Nat) (proxy :: Nat -&gt; Type).
KnownNat n =&gt;
proxy n -&gt; Integer
</span><a href="../file:///nix/store/yi1zp26n2al045qmp9gwpxblhp2c8gs8-ghc-8.8.3-doc/share/doc/ghc/html/libraries/base-4.13.0.0/src"><span class="hs-identifier hs-var">natVal</span></a></span><span> </span><span class="annot"><span class="annottext">(Proxy paddingIdx -&gt; Tensor device 'Int64 '[])
-&gt; Proxy paddingIdx -&gt; Tensor device 'Int64 '[]
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><a href="../file:///nix/store/yi1zp26n2al045qmp9gwpxblhp2c8gs8-ghc-8.8.3-doc/share/doc/ghc/html/libraries/base-4.13.0.0/src"><span class="hs-operator hs-var">$</span></a></span><span> </span><span class="annot"><span class="annottext">Proxy paddingIdx
forall k (t :: k). Proxy t
</span><a href="../file:///nix/store/yi1zp26n2al045qmp9gwpxblhp2c8gs8-ghc-8.8.3-doc/share/doc/ghc/html/libraries/base-4.13.0.0/src"><span class="hs-identifier hs-var">Proxy</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679721504"><span class="hs-identifier hs-type">paddingIdx</span></a></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679721498"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.DType.html#Int64"><span class="hs-identifier hs-type">D.Int64</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="hs-special">]</span><span class="hs-special">)</span><span>
</span><span id="line-425"></span><span>  </span><span id="local-6989586621679721149"><span class="annot"><span class="annottext">Tensor device dtype '[batchSize, seqLen, embedDim]
</span><a href="#local-6989586621679721149"><span class="hs-identifier hs-var">y</span></a></span></span><span> </span><span class="hs-glyph">&lt;-</span><span> </span><span class="annot"><span class="annottext">FoldLayers batchSize seqLen dtype device
-&gt; Tensor device dtype '[batchSize, seqLen, embedDim]
-&gt; HList
     (HReplicateR
        numAttnLayers
        (TransformerLayer embedDim numHeads ffnDim dtype device))
-&gt; IO (Tensor device dtype '[batchSize, seqLen, embedDim])
forall k k (m :: k -&gt; Type) f acc (xs :: [k]) (res :: k).
HFoldrM m f acc xs res =&gt;
f -&gt; acc -&gt; HList xs -&gt; m res
</span><a href="Torch.HList.html#hfoldrM"><span class="hs-identifier hs-var">hfoldrM</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">Bool
-&gt; Tensor device dtype '[batchSize, seqLen, seqLen]
-&gt; Tensor device 'Bool '[batchSize, seqLen]
-&gt; FoldLayers batchSize seqLen dtype device
forall (batchSize :: Nat) (seqLen :: Nat) (dtype :: DType)
       (device :: (DeviceType, Nat)).
Bool
-&gt; Tensor device dtype '[batchSize, seqLen, seqLen]
-&gt; Tensor device 'Bool '[batchSize, seqLen]
-&gt; FoldLayers batchSize seqLen dtype device
</span><a href="Torch.Typed.NN.Transformer.html#FoldLayers"><span class="hs-identifier hs-var">FoldLayers</span></a></span><span> </span><span class="annot"><span class="annottext">Bool
</span><a href="#local-6989586621679721167"><span class="hs-identifier hs-var">train</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor device dtype '[batchSize, seqLen, seqLen]
</span><a href="#local-6989586621679721155"><span class="hs-identifier hs-var">attentionMask'</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor device 'Bool '[batchSize, seqLen]
</span><a href="#local-6989586621679721153"><span class="hs-identifier hs-var">keyPaddingMask</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">Tensor device dtype '[batchSize, seqLen, embedDim]
</span><a href="#local-6989586621679721159"><span class="hs-identifier hs-var">x'</span></a></span><span> </span><span class="annot"><span class="annottext">HList
  (HReplicateR
     numAttnLayers
     (TransformerLayer embedDim numHeads ffnDim dtype device))
</span><a href="#local-6989586621679721169"><span class="hs-identifier hs-var">tLayers</span></a></span><span>
</span><span id="line-426"></span><span>  </span><span class="annot"><span class="annottext">Tensor device dtype '[batchSize, seqLen, numEmbeds]
-&gt; IO (Tensor device dtype '[batchSize, seqLen, numEmbeds])
forall (m :: Type -&gt; Type) a. Monad m =&gt; a -&gt; m a
</span><a href="../file:///nix/store/yi1zp26n2al045qmp9gwpxblhp2c8gs8-ghc-8.8.3-doc/share/doc/ghc/html/libraries/base-4.13.0.0/src"><span class="hs-identifier hs-var">return</span></a></span><span> </span><span class="annot"><span class="annottext">(Tensor device dtype '[batchSize, seqLen, numEmbeds]
 -&gt; IO (Tensor device dtype '[batchSize, seqLen, numEmbeds]))
-&gt; Tensor device dtype '[batchSize, seqLen, numEmbeds]
-&gt; IO (Tensor device dtype '[batchSize, seqLen, numEmbeds])
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><a href="../file:///nix/store/yi1zp26n2al045qmp9gwpxblhp2c8gs8-ghc-8.8.3-doc/share/doc/ghc/html/libraries/base-4.13.0.0/src"><span class="hs-operator hs-var">$</span></a></span><span> </span><span class="annot"><span class="annottext">Linear embedDim numEmbeds dtype device
-&gt; Tensor device dtype '[batchSize, seqLen, embedDim]
-&gt; Tensor device dtype '[batchSize, seqLen, numEmbeds]
forall f a b. HasForward f a b =&gt; f -&gt; a -&gt; b
</span><a href="Torch.Typed.NN.html#forward"><span class="hs-identifier hs-var">forward</span></a></span><span> </span><span class="annot"><span class="annottext">Linear embedDim numEmbeds dtype device
</span><a href="#local-6989586621679721168"><span class="hs-identifier hs-var">tProj</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor device dtype '[batchSize, seqLen, embedDim]
</span><a href="#local-6989586621679721149"><span class="hs-identifier hs-var">y</span></a></span><span>
</span><span id="line-427"></span><span>
</span><span id="line-428"></span><span id="local-6989586621679721138"><span id="local-6989586621679721139"><span id="local-6989586621679721140"><span id="local-6989586621679721141"><span id="local-6989586621679721142"><span id="local-6989586621679721143"><span id="local-6989586621679721144"><span id="local-6989586621679721145"><span id="local-6989586621679721146"><span id="local-6989586621679721147"><span class="hs-keyword">instance</span><span>
</span><span id="line-429"></span><span>  </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="Torch.Typed.Tensor.html#All"><span class="hs-identifier hs-type">All</span></a></span><span> </span><span class="annot"><a href="../file:///nix/store/yi1zp26n2al045qmp9gwpxblhp2c8gs8-ghc-8.8.3-doc/share/doc/ghc/html/libraries/base-4.13.0.0/src"><span class="hs-identifier hs-type">KnownNat</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="annot"><a href="#local-6989586621679721147"><span class="hs-identifier hs-type">paddingIdx</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679721146"><span class="hs-identifier hs-type">embedDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679721145"><span class="hs-identifier hs-type">seqLen</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679721144"><span class="hs-identifier hs-type">batchSize</span></a></span><span class="hs-special">]</span><span>
</span><span id="line-430"></span><span>  </span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679721147"><span class="hs-identifier hs-type">paddingIdx</span></a></span><span> </span><span class="annot"><a href="../file:///nix/store/yi1zp26n2al045qmp9gwpxblhp2c8gs8-ghc-8.8.3-doc/share/doc/ghc/html/libraries/base-4.13.0.0/src"><span class="hs-operator hs-type">+</span></a></span><span> </span><span class="annot"><span class="hs-number">1</span></span><span> </span><span class="annot"><a href="../file:///nix/store/yi1zp26n2al045qmp9gwpxblhp2c8gs8-ghc-8.8.3-doc/share/doc/ghc/html/libraries/base-4.13.0.0/src"><span class="hs-operator hs-type">&lt;=</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679721143"><span class="hs-identifier hs-type">numEmbeds</span></a></span><span>
</span><span id="line-431"></span><span>  </span><span class="hs-special">,</span><span> </span><span class="annot"><span class="hs-number">1</span></span><span> </span><span class="annot"><a href="../file:///nix/store/yi1zp26n2al045qmp9gwpxblhp2c8gs8-ghc-8.8.3-doc/share/doc/ghc/html/libraries/base-4.13.0.0/src"><span class="hs-operator hs-type">&lt;=</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679721145"><span class="hs-identifier hs-type">seqLen</span></a></span><span>
</span><span id="line-432"></span><span>  </span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.HList.html#HFoldrM"><span class="hs-identifier hs-type">HFoldrM</span></a></span><span>
</span><span id="line-433"></span><span>      </span><span class="annot"><a href="../file:///nix/store/yi1zp26n2al045qmp9gwpxblhp2c8gs8-ghc-8.8.3-doc/share/doc/ghc/html/libraries/ghc-prim-0.5.3/src"><span class="hs-identifier hs-type">IO</span></a></span><span>
</span><span id="line-434"></span><span>      </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.NN.Transformer.html#FoldLayers"><span class="hs-identifier hs-type">FoldLayers</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679721144"><span class="hs-identifier hs-type">batchSize</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679721145"><span class="hs-identifier hs-type">seqLen</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679721142"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679721141"><span class="hs-identifier hs-type">device</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-435"></span><span>      </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679721141"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679721142"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="annot"><a href="#local-6989586621679721144"><span class="hs-identifier hs-type">batchSize</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679721145"><span class="hs-identifier hs-type">seqLen</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679721146"><span class="hs-identifier hs-type">embedDim</span></a></span><span class="hs-special">]</span><span class="hs-special">)</span><span>
</span><span id="line-436"></span><span>      </span><span class="hs-special">(</span><span class="annot"><a href="Torch.HList.html#HReplicateR"><span class="hs-identifier hs-type">HReplicateR</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679721140"><span class="hs-identifier hs-type">numAttnLayers</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.NN.Transformer.html#TransformerLayer"><span class="hs-identifier hs-type">TransformerLayer</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679721146"><span class="hs-identifier hs-type">embedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679721139"><span class="hs-identifier hs-type">numHeads</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679721138"><span class="hs-identifier hs-type">ffnDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679721142"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679721141"><span class="hs-identifier hs-type">device</span></a></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-437"></span><span>      </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679721141"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679721142"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="annot"><a href="#local-6989586621679721144"><span class="hs-identifier hs-type">batchSize</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679721145"><span class="hs-identifier hs-type">seqLen</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679721146"><span class="hs-identifier hs-type">embedDim</span></a></span><span class="hs-special">]</span><span class="hs-special">)</span><span>
</span><span id="line-438"></span><span>  </span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.Typed.Tensor.html#BasicArithmeticDTypeIsValid"><span class="hs-identifier hs-type">BasicArithmeticDTypeIsValid</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679721141"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679721142"><span class="hs-identifier hs-type">dtype</span></a></span><span>
</span><span id="line-439"></span><span>  </span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.Typed.Tensor.html#ComparisonDTypeIsValid"><span class="hs-identifier hs-type">ComparisonDTypeIsValid</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679721141"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679721142"><span class="hs-identifier hs-type">dtype</span></a></span><span>
</span><span id="line-440"></span><span>  </span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.Typed.Tensor.html#ComparisonDTypeIsValid"><span class="hs-identifier hs-type">ComparisonDTypeIsValid</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679721141"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.DType.html#Int64"><span class="hs-identifier hs-type">D.Int64</span></a></span><span>
</span><span id="line-441"></span><span>  </span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.Typed.Tensor.html#KnownDType"><span class="hs-identifier hs-type">KnownDType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679721142"><span class="hs-identifier hs-type">dtype</span></a></span><span>
</span><span id="line-442"></span><span>  </span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.Typed.Tensor.html#KnownDevice"><span class="hs-identifier hs-type">KnownDevice</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679721141"><span class="hs-identifier hs-type">device</span></a></span><span>
</span><span id="line-443"></span><span>  </span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span> </span><span class="annot"><a href="Torch.Typed.NN.html#HasForward"><span class="hs-identifier hs-type">HasForward</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.NN.Transformer.html#TransformerLM"><span class="hs-identifier hs-type">TransformerLM</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679721140"><span class="hs-identifier hs-type">numAttnLayers</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679721139"><span class="hs-identifier hs-type">numHeads</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679721138"><span class="hs-identifier hs-type">ffnDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679721147"><span class="hs-identifier hs-type">paddingIdx</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679721143"><span class="hs-identifier hs-type">numEmbeds</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679721146"><span class="hs-identifier hs-type">embedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679721142"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679721141"><span class="hs-identifier hs-type">device</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679721141"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.DType.html#Int64"><span class="hs-identifier hs-type">D.Int64</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="annot"><a href="#local-6989586621679721144"><span class="hs-identifier hs-type">batchSize</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679721145"><span class="hs-identifier hs-type">seqLen</span></a></span><span class="hs-special">]</span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679721141"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679721142"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="annot"><a href="#local-6989586621679721144"><span class="hs-identifier hs-type">batchSize</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679721145"><span class="hs-identifier hs-type">seqLen</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679721143"><span class="hs-identifier hs-type">numEmbeds</span></a></span><span class="hs-special">]</span><span class="hs-special">)</span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-444"></span><span>  </span><span id="local-6989586621679721134"><span class="annot"><span class="annottext">forward :: TransformerLM
  numAttnLayers
  numHeads
  ffnDim
  paddingIdx
  numEmbeds
  embedDim
  dtype
  device
-&gt; Tensor device 'Int64 '[batchSize, seqLen]
-&gt; Tensor device dtype '[batchSize, seqLen, numEmbeds]
</span><a href="#local-6989586621679721134"><span class="hs-identifier hs-var hs-var hs-var hs-var">forward</span></a></span></span><span> </span><span id="local-6989586621679721133"><span class="annot"><span class="annottext">model :: TransformerLM
  numAttnLayers
  numHeads
  ffnDim
  paddingIdx
  numEmbeds
  embedDim
  dtype
  device
</span><a href="#local-6989586621679721133"><span class="hs-identifier hs-var">model</span></a></span></span><span> </span><span id="local-6989586621679721132"><span class="annot"><span class="annottext">input :: Tensor device 'Int64 '[batchSize, seqLen]
</span><a href="#local-6989586621679721132"><span class="hs-identifier hs-var">input</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO (Tensor device dtype '[batchSize, seqLen, numEmbeds])
-&gt; Tensor device dtype '[batchSize, seqLen, numEmbeds]
forall a. IO a -&gt; a
</span><a href="../file:///nix/store/yi1zp26n2al045qmp9gwpxblhp2c8gs8-ghc-8.8.3-doc/share/doc/ghc/html/libraries/base-4.13.0.0/src"><span class="hs-identifier hs-var">unsafePerformIO</span></a></span><span> </span><span class="annot"><span class="annottext">(IO (Tensor device dtype '[batchSize, seqLen, numEmbeds])
 -&gt; Tensor device dtype '[batchSize, seqLen, numEmbeds])
-&gt; IO (Tensor device dtype '[batchSize, seqLen, numEmbeds])
-&gt; Tensor device dtype '[batchSize, seqLen, numEmbeds]
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><a href="../file:///nix/store/yi1zp26n2al045qmp9gwpxblhp2c8gs8-ghc-8.8.3-doc/share/doc/ghc/html/libraries/base-4.13.0.0/src"><span class="hs-operator hs-var">$</span></a></span><span> </span><span class="annot"><span class="annottext">TransformerLM
  numAttnLayers
  numHeads
  ffnDim
  paddingIdx
  numEmbeds
  embedDim
  dtype
  device
-&gt; Bool
-&gt; Tensor device 'Int64 '[batchSize, seqLen]
-&gt; IO (Tensor device dtype '[batchSize, seqLen, numEmbeds])
forall (numAttnLayers :: Nat) (numHeads :: Nat) (ffnDim :: Nat)
       (paddingIdx :: Nat) (numEmbeds :: Nat) (embedDim :: Nat)
       (seqLen :: Nat) (batchSize :: Nat) (dtype :: DType)
       (device :: (DeviceType, Nat)).
(All KnownNat '[paddingIdx, embedDim, seqLen, batchSize],
 (paddingIdx + 1) &lt;= numEmbeds, 1 &lt;= seqLen,
 HFoldrM
   IO
   (FoldLayers batchSize seqLen dtype device)
   (Tensor device dtype '[batchSize, seqLen, embedDim])
   (HReplicateR
      numAttnLayers
      (TransformerLayer embedDim numHeads ffnDim dtype device))
   (Tensor device dtype '[batchSize, seqLen, embedDim]),
 BasicArithmeticDTypeIsValid device dtype,
 ComparisonDTypeIsValid device dtype,
 ComparisonDTypeIsValid device 'Int64, KnownDType dtype,
 KnownDevice device) =&gt;
TransformerLM
  numAttnLayers
  numHeads
  ffnDim
  paddingIdx
  numEmbeds
  embedDim
  dtype
  device
-&gt; Bool
-&gt; Tensor device 'Int64 '[batchSize, seqLen]
-&gt; IO (Tensor device dtype '[batchSize, seqLen, numEmbeds])
</span><a href="Torch.Typed.NN.Transformer.html#transformerLM"><span class="hs-identifier hs-var">transformerLM</span></a></span><span> </span><span class="annot"><span class="annottext">TransformerLM
  numAttnLayers
  numHeads
  ffnDim
  paddingIdx
  numEmbeds
  embedDim
  dtype
  device
</span><a href="#local-6989586621679721133"><span class="hs-identifier hs-var">model</span></a></span><span> </span><span class="annot"><span class="annottext">Bool
</span><a href="../file:///nix/store/yi1zp26n2al045qmp9gwpxblhp2c8gs8-ghc-8.8.3-doc/share/doc/ghc/html/libraries/ghc-prim-0.5.3/src"><span class="hs-identifier hs-var">False</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor device 'Int64 '[batchSize, seqLen]
</span><a href="#local-6989586621679721132"><span class="hs-identifier hs-var">input</span></a></span><span>
</span><span id="line-445"></span><span>  </span><span id="local-6989586621679721131"><span class="annot"><span class="annottext">forwardStoch :: TransformerLM
  numAttnLayers
  numHeads
  ffnDim
  paddingIdx
  numEmbeds
  embedDim
  dtype
  device
-&gt; Tensor device 'Int64 '[batchSize, seqLen]
-&gt; IO (Tensor device dtype '[batchSize, seqLen, numEmbeds])
</span><a href="Torch.Typed.NN.html#forwardStoch"><span class="hs-identifier hs-var hs-var hs-var hs-var">forwardStoch</span></a></span></span><span> </span><span id="local-6989586621679721129"><span class="annot"><span class="annottext">model :: TransformerLM
  numAttnLayers
  numHeads
  ffnDim
  paddingIdx
  numEmbeds
  embedDim
  dtype
  device
</span><a href="#local-6989586621679721129"><span class="hs-identifier hs-var">model</span></a></span></span><span> </span><span id="local-6989586621679721128"><span class="annot"><span class="annottext">input :: Tensor device 'Int64 '[batchSize, seqLen]
</span><a href="#local-6989586621679721128"><span class="hs-identifier hs-var">input</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">TransformerLM
  numAttnLayers
  numHeads
  ffnDim
  paddingIdx
  numEmbeds
  embedDim
  dtype
  device
-&gt; Bool
-&gt; Tensor device 'Int64 '[batchSize, seqLen]
-&gt; IO (Tensor device dtype '[batchSize, seqLen, numEmbeds])
forall (numAttnLayers :: Nat) (numHeads :: Nat) (ffnDim :: Nat)
       (paddingIdx :: Nat) (numEmbeds :: Nat) (embedDim :: Nat)
       (seqLen :: Nat) (batchSize :: Nat) (dtype :: DType)
       (device :: (DeviceType, Nat)).
(All KnownNat '[paddingIdx, embedDim, seqLen, batchSize],
 (paddingIdx + 1) &lt;= numEmbeds, 1 &lt;= seqLen,
 HFoldrM
   IO
   (FoldLayers batchSize seqLen dtype device)
   (Tensor device dtype '[batchSize, seqLen, embedDim])
   (HReplicateR
      numAttnLayers
      (TransformerLayer embedDim numHeads ffnDim dtype device))
   (Tensor device dtype '[batchSize, seqLen, embedDim]),
 BasicArithmeticDTypeIsValid device dtype,
 ComparisonDTypeIsValid device dtype,
 ComparisonDTypeIsValid device 'Int64, KnownDType dtype,
 KnownDevice device) =&gt;
TransformerLM
  numAttnLayers
  numHeads
  ffnDim
  paddingIdx
  numEmbeds
  embedDim
  dtype
  device
-&gt; Bool
-&gt; Tensor device 'Int64 '[batchSize, seqLen]
-&gt; IO (Tensor device dtype '[batchSize, seqLen, numEmbeds])
</span><a href="Torch.Typed.NN.Transformer.html#transformerLM"><span class="hs-identifier hs-var">transformerLM</span></a></span><span> </span><span class="annot"><span class="annottext">TransformerLM
  numAttnLayers
  numHeads
  ffnDim
  paddingIdx
  numEmbeds
  embedDim
  dtype
  device
</span><a href="#local-6989586621679721129"><span class="hs-identifier hs-var">model</span></a></span><span> </span><span class="annot"><span class="annottext">Bool
</span><a href="../file:///nix/store/yi1zp26n2al045qmp9gwpxblhp2c8gs8-ghc-8.8.3-doc/share/doc/ghc/html/libraries/ghc-prim-0.5.3/src"><span class="hs-identifier hs-var">True</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor device 'Int64 '[batchSize, seqLen]
</span><a href="#local-6989586621679721128"><span class="hs-identifier hs-var">input</span></a></span></span></span></span></span></span></span></span></span></span></span><span>
</span><span id="line-446"></span><span>
</span><span id="line-447"></span><span class="annot"><a href="Torch.Typed.NN.Transformer.html#sinusoidal"><span class="hs-identifier hs-type">sinusoidal</span></a></span><span>
</span><span id="line-448"></span><span>  </span><span class="hs-glyph">::</span><span> </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679721453"><span class="annot"><a href="#local-6989586621679721453"><span class="hs-identifier hs-type">numEmbeds</span></a></span></span><span> </span><span id="local-6989586621679721452"><span class="annot"><a href="#local-6989586621679721452"><span class="hs-identifier hs-type">embedDim</span></a></span></span><span> </span><span id="local-6989586621679721451"><span class="annot"><a href="#local-6989586621679721451"><span class="hs-identifier hs-type">device</span></a></span></span><span>
</span><span id="line-449"></span><span>   </span><span class="hs-operator">.</span><span> </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="Torch.Typed.Tensor.html#All"><span class="hs-identifier hs-type">All</span></a></span><span> </span><span class="annot"><a href="../file:///nix/store/yi1zp26n2al045qmp9gwpxblhp2c8gs8-ghc-8.8.3-doc/share/doc/ghc/html/libraries/base-4.13.0.0/src"><span class="hs-identifier hs-type">KnownNat</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="annot"><a href="#local-6989586621679721453"><span class="hs-identifier hs-type">numEmbeds</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679721452"><span class="hs-identifier hs-type">embedDim</span></a></span><span class="hs-special">]</span><span>
</span><span id="line-450"></span><span>     </span><span class="hs-special">,</span><span> </span><span class="annot"><span class="hs-number">1</span></span><span> </span><span class="annot"><a href="../file:///nix/store/yi1zp26n2al045qmp9gwpxblhp2c8gs8-ghc-8.8.3-doc/share/doc/ghc/html/libraries/base-4.13.0.0/src"><span class="hs-operator hs-type">&lt;=</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679721453"><span class="hs-identifier hs-type">numEmbeds</span></a></span><span>
</span><span id="line-451"></span><span>     </span><span class="hs-special">,</span><span> </span><span class="annot"><span class="hs-number">1</span></span><span> </span><span class="annot"><a href="../file:///nix/store/yi1zp26n2al045qmp9gwpxblhp2c8gs8-ghc-8.8.3-doc/share/doc/ghc/html/libraries/base-4.13.0.0/src"><span class="hs-operator hs-type">&lt;=</span></a></span><span> </span><span class="annot"><a href="../file:///nix/store/yi1zp26n2al045qmp9gwpxblhp2c8gs8-ghc-8.8.3-doc/share/doc/ghc/html/libraries/base-4.13.0.0/src"><span class="hs-identifier hs-type">Div</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679721452"><span class="hs-identifier hs-type">embedDim</span></a></span><span> </span><span class="annot"><span class="hs-number">2</span></span><span>
</span><span id="line-452"></span><span>     </span><span class="hs-special">,</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="../file:///nix/store/yi1zp26n2al045qmp9gwpxblhp2c8gs8-ghc-8.8.3-doc/share/doc/ghc/html/libraries/base-4.13.0.0/src"><span class="hs-identifier hs-type">Div</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679721452"><span class="hs-identifier hs-type">embedDim</span></a></span><span> </span><span class="annot"><span class="hs-number">2</span></span><span> </span><span class="annot"><a href="../file:///nix/store/yi1zp26n2al045qmp9gwpxblhp2c8gs8-ghc-8.8.3-doc/share/doc/ghc/html/libraries/base-4.13.0.0/src"><span class="hs-operator hs-type">*</span></a></span><span> </span><span class="annot"><span class="hs-number">2</span></span><span class="hs-special">)</span><span> </span><span class="annot"><a href="../file:///nix/store/yi1zp26n2al045qmp9gwpxblhp2c8gs8-ghc-8.8.3-doc/share/doc/ghc/html/libraries/ghc-prim-0.5.3/src"><span class="hs-glyph hs-type">~</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679721452"><span class="hs-identifier hs-type">embedDim</span></a></span><span>
</span><span id="line-453"></span><span>     </span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.Typed.Aux.html#StandardFloatingPointDTypeValidation"><span class="hs-identifier hs-type">StandardFloatingPointDTypeValidation</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679721451"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.DType.html#Float"><span class="hs-identifier hs-type">D.Float</span></a></span><span>
</span><span id="line-454"></span><span>     </span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.Typed.Tensor.html#BasicArithmeticDTypeIsValid"><span class="hs-identifier hs-type">BasicArithmeticDTypeIsValid</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679721451"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.DType.html#Float"><span class="hs-identifier hs-type">D.Float</span></a></span><span>
</span><span id="line-455"></span><span>     </span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.Typed.Tensor.html#KnownDevice"><span class="hs-identifier hs-type">KnownDevice</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679721451"><span class="hs-identifier hs-type">device</span></a></span><span>
</span><span id="line-456"></span><span>     </span><span class="hs-special">)</span><span>
</span><span id="line-457"></span><span>  </span><span class="hs-glyph">=&gt;</span><span> </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679721451"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.DType.html#Float"><span class="hs-identifier hs-type">D.Float</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="annot"><a href="#local-6989586621679721453"><span class="hs-identifier hs-type">numEmbeds</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679721452"><span class="hs-identifier hs-type">embedDim</span></a></span><span class="hs-special">]</span><span>
</span><span id="line-458"></span><span id="sinusoidal"><span class="annot"><span class="annottext">sinusoidal :: Tensor device 'Float '[numEmbeds, embedDim]
</span><a href="Torch.Typed.NN.Transformer.html#sinusoidal"><span class="hs-identifier hs-var hs-var">sinusoidal</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-459"></span><span>  </span><span class="hs-keyword">let</span><span> </span><span id="local-6989586621679721126"><span class="annot"><span class="annottext">positions :: Tensor device 'Float '[numEmbeds, 1]
</span><a href="#local-6989586621679721126"><span class="hs-identifier hs-var hs-var">positions</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-460"></span><span>        </span><span class="annot"><span class="annottext">forall (shape :: [Nat]) (shape' :: [Nat]) (dtype :: DType)
       (device :: (DeviceType, Nat)).
(KnownNat 1, shape' ~ Unsqueeze shape 1) =&gt;
Tensor device dtype shape -&gt; Tensor device dtype shape'
forall (dim :: Nat) (shape :: [Nat]) (shape' :: [Nat])
       (dtype :: DType) (device :: (DeviceType, Nat)).
(KnownNat dim, shape' ~ Unsqueeze shape dim) =&gt;
Tensor device dtype shape -&gt; Tensor device dtype shape'
</span><a href="Torch.Typed.Functional.html#unsqueeze"><span class="hs-identifier hs-var">unsqueeze</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><span class="hs-number">1</span></span><span>
</span><span id="line-461"></span><span>          </span><span class="annot"><span class="annottext">(Tensor device 'Float '[numEmbeds]
 -&gt; Tensor device 'Float '[numEmbeds, 1])
-&gt; (Int -&gt; Tensor device 'Float '[numEmbeds])
-&gt; Int
-&gt; Tensor device 'Float '[numEmbeds, 1]
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><a href="../file:///nix/store/yi1zp26n2al045qmp9gwpxblhp2c8gs8-ghc-8.8.3-doc/share/doc/ghc/html/libraries/base-4.13.0.0/src"><span class="hs-operator hs-var">.</span></a></span><span> </span><span class="annot"><span class="annottext">Int -&gt; Int -&gt; Tensor device 'Float '[numEmbeds]
forall (steps :: Nat) (device :: (DeviceType, Nat)) start end.
(Scalar start, Scalar end, KnownNat steps,
 TensorOptions '[steps] 'Float device) =&gt;
start -&gt; end -&gt; Tensor device 'Float '[steps]
</span><a href="Torch.Typed.Factories.html#linspace"><span class="hs-identifier hs-var">linspace</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679721453"><span class="hs-identifier hs-type">numEmbeds</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="hs-number">0</span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="../file:///nix/store/yi1zp26n2al045qmp9gwpxblhp2c8gs8-ghc-8.8.3-doc/share/doc/ghc/html/libraries/ghc-prim-0.5.3/src"><span class="hs-identifier hs-type">Int</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-462"></span><span>          </span><span class="annot"><span class="annottext">(Int -&gt; Tensor device 'Float '[numEmbeds, 1])
-&gt; Int -&gt; Tensor device 'Float '[numEmbeds, 1]
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><a href="../file:///nix/store/yi1zp26n2al045qmp9gwpxblhp2c8gs8-ghc-8.8.3-doc/share/doc/ghc/html/libraries/base-4.13.0.0/src"><span class="hs-operator hs-var">$</span></a></span><span> </span><span class="annot"><span class="annottext">KnownNat (numEmbeds - 1) =&gt; Int
forall (n :: Nat). KnownNat n =&gt; Int
</span><a href="Torch.Typed.Aux.html#natValI"><span class="hs-identifier hs-var">natValI</span></a></span><span> </span><span class="hs-glyph">@</span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679721453"><span class="hs-identifier hs-type">numEmbeds</span></a></span><span> </span><span class="annot"><a href="../file:///nix/store/yi1zp26n2al045qmp9gwpxblhp2c8gs8-ghc-8.8.3-doc/share/doc/ghc/html/libraries/base-4.13.0.0/src"><span class="hs-glyph hs-type">-</span></a></span><span> </span><span class="annot"><span class="hs-number">1</span></span><span class="hs-special">)</span><span>
</span><span id="line-463"></span><span>      </span><span id="local-6989586621679721125"><span class="annot"><span class="annottext">scalingFactors :: Tensor device 'Float '[Div embedDim 2]
</span><a href="#local-6989586621679721125"><span class="hs-identifier hs-var hs-var">scalingFactors</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-464"></span><span>        </span><span class="annot"><span class="annottext">Tensor device 'Float '[Div embedDim 2]
-&gt; Tensor device 'Float '[Div embedDim 2]
forall (shape :: [Nat]) (dtype :: DType)
       (device :: (DeviceType, Nat)).
StandardFloatingPointDTypeValidation device dtype =&gt;
Tensor device dtype shape -&gt; Tensor device dtype shape
</span><a href="Torch.Typed.Functional.html#exp"><span class="hs-identifier hs-var">exp</span></a></span><span> </span><span>
</span><span id="line-465"></span><span>          </span><span class="annot"><span class="annottext">(Tensor device 'Float '[Div embedDim 2]
 -&gt; Tensor device 'Float '[Div embedDim 2])
-&gt; (Int -&gt; Tensor device 'Float '[Div embedDim 2])
-&gt; Int
-&gt; Tensor device 'Float '[Div embedDim 2]
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><a href="../file:///nix/store/yi1zp26n2al045qmp9gwpxblhp2c8gs8-ghc-8.8.3-doc/share/doc/ghc/html/libraries/base-4.13.0.0/src"><span class="hs-operator hs-var">.</span></a></span><span> </span><span class="annot"><span class="annottext">Double
-&gt; Tensor device 'Float '[Div embedDim 2]
-&gt; Tensor device 'Float '[Div embedDim 2]
forall a (shape :: [Nat]) (dtype :: DType)
       (device :: (DeviceType, Nat)).
Scalar a =&gt;
a -&gt; Tensor device dtype shape -&gt; Tensor device dtype shape
</span><a href="Torch.Typed.Functional.html#mulScalar"><span class="hs-identifier hs-var">mulScalar</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">-</span><span> </span><span class="annot"><span class="annottext">Double -&gt; Double
forall a. Floating a =&gt; a -&gt; a
</span><a href="../file:///nix/store/yi1zp26n2al045qmp9gwpxblhp2c8gs8-ghc-8.8.3-doc/share/doc/ghc/html/libraries/base-4.13.0.0/src"><span class="hs-identifier hs-var">log</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="hs-number">10000</span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="../file:///nix/store/yi1zp26n2al045qmp9gwpxblhp2c8gs8-ghc-8.8.3-doc/share/doc/ghc/html/libraries/ghc-prim-0.5.3/src"><span class="hs-identifier hs-type">Double</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">Double -&gt; Double -&gt; Double
forall a. Fractional a =&gt; a -&gt; a -&gt; a
</span><a href="../file:///nix/store/yi1zp26n2al045qmp9gwpxblhp2c8gs8-ghc-8.8.3-doc/share/doc/ghc/html/libraries/base-4.13.0.0/src"><span class="hs-operator hs-var">/</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">Integer -&gt; Double
forall a. Num a =&gt; Integer -&gt; a
</span><a href="../file:///nix/store/yi1zp26n2al045qmp9gwpxblhp2c8gs8-ghc-8.8.3-doc/share/doc/ghc/html/libraries/base-4.13.0.0/src"><span class="hs-identifier hs-var">fromInteger</span></a></span><span> </span><span class="annot"><span class="annottext">(Integer -&gt; Double)
-&gt; (Proxy (Div embedDim 2) -&gt; Integer)
-&gt; Proxy (Div embedDim 2)
-&gt; Double
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><a href="../file:///nix/store/yi1zp26n2al045qmp9gwpxblhp2c8gs8-ghc-8.8.3-doc/share/doc/ghc/html/libraries/base-4.13.0.0/src"><span class="hs-operator hs-var">.</span></a></span><span> </span><span class="annot"><span class="annottext">Proxy (Div embedDim 2) -&gt; Integer
forall (n :: Nat) (proxy :: Nat -&gt; Type).
KnownNat n =&gt;
proxy n -&gt; Integer
</span><a href="../file:///nix/store/yi1zp26n2al045qmp9gwpxblhp2c8gs8-ghc-8.8.3-doc/share/doc/ghc/html/libraries/base-4.13.0.0/src"><span class="hs-identifier hs-var">natVal</span></a></span><span> </span><span class="annot"><span class="annottext">(Proxy (Div embedDim 2) -&gt; Double)
-&gt; Proxy (Div embedDim 2) -&gt; Double
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><a href="../file:///nix/store/yi1zp26n2al045qmp9gwpxblhp2c8gs8-ghc-8.8.3-doc/share/doc/ghc/html/libraries/base-4.13.0.0/src"><span class="hs-operator hs-var">$</span></a></span><span> </span><span class="annot"><span class="annottext">Proxy (Div embedDim 2)
forall k (t :: k). Proxy t
</span><a href="../file:///nix/store/yi1zp26n2al045qmp9gwpxblhp2c8gs8-ghc-8.8.3-doc/share/doc/ghc/html/libraries/base-4.13.0.0/src"><span class="hs-identifier hs-var">Proxy</span></a></span><span> </span><span class="hs-glyph">@</span><span class="hs-special">(</span><span class="annot"><a href="../file:///nix/store/yi1zp26n2al045qmp9gwpxblhp2c8gs8-ghc-8.8.3-doc/share/doc/ghc/html/libraries/base-4.13.0.0/src"><span class="hs-identifier hs-type">Div</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679721452"><span class="hs-identifier hs-type">embedDim</span></a></span><span> </span><span class="annot"><span class="hs-number">2</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-466"></span><span>          </span><span class="annot"><span class="annottext">(Tensor device 'Float '[Div embedDim 2]
 -&gt; Tensor device 'Float '[Div embedDim 2])
-&gt; (Int -&gt; Tensor device 'Float '[Div embedDim 2])
-&gt; Int
-&gt; Tensor device 'Float '[Div embedDim 2]
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><a href="../file:///nix/store/yi1zp26n2al045qmp9gwpxblhp2c8gs8-ghc-8.8.3-doc/share/doc/ghc/html/libraries/base-4.13.0.0/src"><span class="hs-operator hs-var">.</span></a></span><span> </span><span class="annot"><span class="annottext">Int -&gt; Int -&gt; Tensor device 'Float '[Div embedDim 2]
forall (steps :: Nat) (device :: (DeviceType, Nat)) start end.
(Scalar start, Scalar end, KnownNat steps,
 TensorOptions '[steps] 'Float device) =&gt;
start -&gt; end -&gt; Tensor device 'Float '[steps]
</span><a href="Torch.Typed.Factories.html#linspace"><span class="hs-identifier hs-var">linspace</span></a></span><span> </span><span class="hs-glyph">@</span><span class="hs-special">(</span><span class="annot"><a href="../file:///nix/store/yi1zp26n2al045qmp9gwpxblhp2c8gs8-ghc-8.8.3-doc/share/doc/ghc/html/libraries/base-4.13.0.0/src"><span class="hs-identifier hs-type">Div</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679721452"><span class="hs-identifier hs-type">embedDim</span></a></span><span> </span><span class="annot"><span class="hs-number">2</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><span class="hs-number">0</span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="../file:///nix/store/yi1zp26n2al045qmp9gwpxblhp2c8gs8-ghc-8.8.3-doc/share/doc/ghc/html/libraries/ghc-prim-0.5.3/src"><span class="hs-identifier hs-type">Int</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-467"></span><span>          </span><span class="annot"><span class="annottext">(Int -&gt; Tensor device 'Float '[Div embedDim 2])
-&gt; Int -&gt; Tensor device 'Float '[Div embedDim 2]
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><a href="../file:///nix/store/yi1zp26n2al045qmp9gwpxblhp2c8gs8-ghc-8.8.3-doc/share/doc/ghc/html/libraries/base-4.13.0.0/src"><span class="hs-operator hs-var">$</span></a></span><span> </span><span class="annot"><span class="annottext">KnownNat (Div embedDim 2 - 1) =&gt; Int
forall (n :: Nat). KnownNat n =&gt; Int
</span><a href="Torch.Typed.Aux.html#natValI"><span class="hs-identifier hs-var">natValI</span></a></span><span> </span><span class="hs-glyph">@</span><span class="hs-special">(</span><span class="hs-special">(</span><span class="annot"><a href="../file:///nix/store/yi1zp26n2al045qmp9gwpxblhp2c8gs8-ghc-8.8.3-doc/share/doc/ghc/html/libraries/base-4.13.0.0/src"><span class="hs-identifier hs-type">Div</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679721452"><span class="hs-identifier hs-type">embedDim</span></a></span><span> </span><span class="annot"><span class="hs-number">2</span></span><span class="hs-special">)</span><span> </span><span class="annot"><a href="../file:///nix/store/yi1zp26n2al045qmp9gwpxblhp2c8gs8-ghc-8.8.3-doc/share/doc/ghc/html/libraries/base-4.13.0.0/src"><span class="hs-glyph hs-type">-</span></a></span><span> </span><span class="annot"><span class="hs-number">1</span></span><span class="hs-special">)</span><span>
</span><span id="line-468"></span><span>      </span><span id="local-6989586621679721121"><span class="annot"><span class="annottext">radians :: Tensor device 'Float '[numEmbeds, Div embedDim 2]
</span><a href="#local-6989586621679721121"><span class="hs-identifier hs-var hs-var">radians</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Tensor device 'Float '[numEmbeds, 1]
-&gt; Tensor device 'Float '[Div embedDim 2]
-&gt; Tensor device 'Float '[numEmbeds, Div embedDim 2]
forall (shape'' :: [Nat]) (shape :: [Nat]) (shape' :: [Nat])
       (dtype :: DType) (dtype' :: DType) (dtype'' :: DType)
       (device :: (DeviceType, Nat)).
(dtype'' ~ DTypePromotion dtype dtype',
 shape'' ~ Broadcast shape shape',
 BasicArithmeticDTypeIsValid device dtype,
 BasicArithmeticDTypeIsValid device dtype',
 BasicArithmeticDTypeIsValid device dtype'') =&gt;
Tensor device dtype shape
-&gt; Tensor device dtype' shape' -&gt; Tensor device dtype'' shape''
</span><a href="Torch.Typed.Tensor.html#mul"><span class="hs-identifier hs-var">mul</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor device 'Float '[numEmbeds, 1]
</span><a href="#local-6989586621679721126"><span class="hs-identifier hs-var">positions</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor device 'Float '[Div embedDim 2]
</span><a href="#local-6989586621679721125"><span class="hs-identifier hs-var">scalingFactors</span></a></span><span>
</span><span id="line-469"></span><span>      </span><span id="local-6989586621679721119"><span class="annot"><span class="annottext">weights :: Tensor device 'Float '[numEmbeds, Div embedDim 2, 2]
</span><a href="#local-6989586621679721119"><span class="hs-identifier hs-var hs-var">weights</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">HList
  '[Tensor device 'Float '[numEmbeds, Div embedDim 2],
    Tensor device 'Float '[numEmbeds, Div embedDim 2]]
-&gt; Tensor device 'Float '[numEmbeds, Div embedDim 2, 2]
forall k (dim :: Nat) (shape :: [Nat]) (dtype :: DType)
       (device :: (DeviceType, Nat)) (tensors :: [k]).
(KnownNat dim, '(shape, dtype, device) ~ Stack dim tensors,
 Castable (HList tensors) [ATenTensor]) =&gt;
HList tensors -&gt; Tensor device dtype shape
</span><a href="Torch.Typed.Functional.html#stack"><span class="hs-identifier hs-var">stack</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><span class="hs-number">2</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">Tensor device 'Float '[numEmbeds, Div embedDim 2]
-&gt; Tensor device 'Float '[numEmbeds, Div embedDim 2]
forall (shape :: [Nat]) (dtype :: DType)
       (device :: (DeviceType, Nat)).
StandardFloatingPointDTypeValidation device dtype =&gt;
Tensor device dtype shape -&gt; Tensor device dtype shape
</span><a href="Torch.Typed.Functional.html#sin"><span class="hs-identifier hs-var">sin</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor device 'Float '[numEmbeds, Div embedDim 2]
</span><a href="#local-6989586621679721121"><span class="hs-identifier hs-var">radians</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor device 'Float '[numEmbeds, Div embedDim 2]
-&gt; HList '[Tensor device 'Float '[numEmbeds, Div embedDim 2]]
-&gt; HList
     '[Tensor device 'Float '[numEmbeds, Div embedDim 2],
       Tensor device 'Float '[numEmbeds, Div embedDim 2]]
forall x (xs :: [Type]). x -&gt; HList xs -&gt; HList (x : xs)
</span><a href="Torch.HList.html#%3A."><span class="hs-operator hs-var">:.</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor device 'Float '[numEmbeds, Div embedDim 2]
-&gt; Tensor device 'Float '[numEmbeds, Div embedDim 2]
forall (shape :: [Nat]) (dtype :: DType)
       (device :: (DeviceType, Nat)).
StandardFloatingPointDTypeValidation device dtype =&gt;
Tensor device dtype shape -&gt; Tensor device dtype shape
</span><a href="Torch.Typed.Functional.html#cos"><span class="hs-identifier hs-var">cos</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor device 'Float '[numEmbeds, Div embedDim 2]
</span><a href="#local-6989586621679721121"><span class="hs-identifier hs-var">radians</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor device 'Float '[numEmbeds, Div embedDim 2]
-&gt; HList '[]
-&gt; HList '[Tensor device 'Float '[numEmbeds, Div embedDim 2]]
forall x (xs :: [Type]). x -&gt; HList xs -&gt; HList (x : xs)
</span><a href="Torch.HList.html#%3A."><span class="hs-operator hs-var">:.</span></a></span><span> </span><span class="annot"><span class="annottext">HList '[]
forall k. HList '[]
</span><a href="Torch.HList.html#HNil"><span class="hs-identifier hs-var">HNil</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-470"></span><span>  </span><span class="hs-keyword">in</span><span>  </span><span class="annot"><span class="annottext">Tensor device 'Float '[numEmbeds, Div embedDim 2, 2]
-&gt; Tensor device 'Float '[numEmbeds, embedDim]
forall (shape' :: [Nat]) (shape :: [Nat]) (dtype :: DType)
       (device :: (DeviceType, Nat)).
(KnownShape shape', Numel shape ~ Numel shape') =&gt;
Tensor device dtype shape -&gt; Tensor device dtype shape'
</span><a href="Torch.Typed.Tensor.html#reshape"><span class="hs-identifier hs-var">reshape</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor device 'Float '[numEmbeds, Div embedDim 2, 2]
</span><a href="#local-6989586621679721119"><span class="hs-identifier hs-var">weights</span></a></span><span>
</span><span id="line-471"></span><span>
</span><span id="line-472"></span><span id="local-6989586621679721108"><span id="local-6989586621679721109"><span id="local-6989586621679721110"><span id="local-6989586621679721111"><span id="local-6989586621679721112"><span id="local-6989586621679721113"><span id="local-6989586621679721114"><span id="local-6989586621679721115"><span class="hs-keyword">instance</span><span>
</span><span id="line-473"></span><span>  </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="#local-6989586621679721115"><span class="hs-identifier hs-type">paddingIdx</span></a></span><span> </span><span class="annot"><a href="../file:///nix/store/yi1zp26n2al045qmp9gwpxblhp2c8gs8-ghc-8.8.3-doc/share/doc/ghc/html/libraries/base-4.13.0.0/src"><span class="hs-operator hs-type">&lt;=</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679721114"><span class="hs-identifier hs-type">numEmbeds</span></a></span><span>
</span><span id="line-474"></span><span>  </span><span class="hs-special">,</span><span> </span><span class="annot"><span class="hs-number">1</span></span><span> </span><span class="annot"><a href="../file:///nix/store/yi1zp26n2al045qmp9gwpxblhp2c8gs8-ghc-8.8.3-doc/share/doc/ghc/html/libraries/base-4.13.0.0/src"><span class="hs-operator hs-type">&lt;=</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679721114"><span class="hs-identifier hs-type">numEmbeds</span></a></span><span> </span><span class="annot"><a href="../file:///nix/store/yi1zp26n2al045qmp9gwpxblhp2c8gs8-ghc-8.8.3-doc/share/doc/ghc/html/libraries/base-4.13.0.0/src"><span class="hs-glyph hs-type">-</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679721115"><span class="hs-identifier hs-type">paddingIdx</span></a></span><span>
</span><span id="line-475"></span><span>  </span><span class="hs-special">,</span><span> </span><span class="hs-special">(</span><span class="hs-special">(</span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679721114"><span class="hs-identifier hs-type">numEmbeds</span></a></span><span> </span><span class="annot"><a href="../file:///nix/store/yi1zp26n2al045qmp9gwpxblhp2c8gs8-ghc-8.8.3-doc/share/doc/ghc/html/libraries/base-4.13.0.0/src"><span class="hs-glyph hs-type">-</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679721115"><span class="hs-identifier hs-type">paddingIdx</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><a href="../file:///nix/store/yi1zp26n2al045qmp9gwpxblhp2c8gs8-ghc-8.8.3-doc/share/doc/ghc/html/libraries/base-4.13.0.0/src"><span class="hs-glyph hs-type">-</span></a></span><span> </span><span class="annot"><span class="hs-number">1</span></span><span class="hs-special">)</span><span> </span><span class="annot"><a href="../file:///nix/store/yi1zp26n2al045qmp9gwpxblhp2c8gs8-ghc-8.8.3-doc/share/doc/ghc/html/libraries/base-4.13.0.0/src"><span class="hs-operator hs-type">+</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="hs-number">1</span></span><span> </span><span class="annot"><a href="../file:///nix/store/yi1zp26n2al045qmp9gwpxblhp2c8gs8-ghc-8.8.3-doc/share/doc/ghc/html/libraries/base-4.13.0.0/src"><span class="hs-operator hs-type">+</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679721115"><span class="hs-identifier hs-type">paddingIdx</span></a></span><span class="hs-special">)</span><span class="hs-special">)</span><span> </span><span class="annot"><a href="../file:///nix/store/yi1zp26n2al045qmp9gwpxblhp2c8gs8-ghc-8.8.3-doc/share/doc/ghc/html/libraries/ghc-prim-0.5.3/src"><span class="hs-glyph hs-type">~</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679721114"><span class="hs-identifier hs-type">numEmbeds</span></a></span><span>
</span><span id="line-476"></span><span>  </span><span class="hs-special">,</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="../file:///nix/store/yi1zp26n2al045qmp9gwpxblhp2c8gs8-ghc-8.8.3-doc/share/doc/ghc/html/libraries/base-4.13.0.0/src"><span class="hs-identifier hs-type">Div</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679721113"><span class="hs-identifier hs-type">embedDim</span></a></span><span> </span><span class="annot"><span class="hs-number">2</span></span><span> </span><span class="annot"><a href="../file:///nix/store/yi1zp26n2al045qmp9gwpxblhp2c8gs8-ghc-8.8.3-doc/share/doc/ghc/html/libraries/base-4.13.0.0/src"><span class="hs-operator hs-type">*</span></a></span><span> </span><span class="annot"><span class="hs-number">2</span></span><span class="hs-special">)</span><span> </span><span class="annot"><a href="../file:///nix/store/yi1zp26n2al045qmp9gwpxblhp2c8gs8-ghc-8.8.3-doc/share/doc/ghc/html/libraries/ghc-prim-0.5.3/src"><span class="hs-glyph hs-type">~</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679721113"><span class="hs-identifier hs-type">embedDim</span></a></span><span>
</span><span id="line-477"></span><span>  </span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.Typed.Tensor.html#All"><span class="hs-identifier hs-type">All</span></a></span><span> </span><span class="annot"><a href="../file:///nix/store/yi1zp26n2al045qmp9gwpxblhp2c8gs8-ghc-8.8.3-doc/share/doc/ghc/html/libraries/base-4.13.0.0/src"><span class="hs-identifier hs-type">KnownNat</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="annot"><a href="#local-6989586621679721112"><span class="hs-identifier hs-type">ffnDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679721115"><span class="hs-identifier hs-type">paddingIdx</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679721114"><span class="hs-identifier hs-type">numEmbeds</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679721113"><span class="hs-identifier hs-type">embedDim</span></a></span><span class="hs-special">]</span><span>
</span><span id="line-478"></span><span>  </span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.HList.html#HReplicate"><span class="hs-identifier hs-type">HReplicate</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679721111"><span class="hs-identifier hs-type">numAttnLayers</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.NN.Transformer.html#TransformerLayerSpec"><span class="hs-identifier hs-type">TransformerLayerSpec</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679721113"><span class="hs-identifier hs-type">embedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679721110"><span class="hs-identifier hs-type">numHeads</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679721112"><span class="hs-identifier hs-type">ffnDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679721109"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679721108"><span class="hs-identifier hs-type">device</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-479"></span><span>  </span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.NN.html#Randomizable"><span class="hs-identifier hs-type">A.Randomizable</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.HList.html#HList"><span class="hs-identifier hs-type">HList</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.HList.html#HReplicateR"><span class="hs-identifier hs-type">HReplicateR</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679721111"><span class="hs-identifier hs-type">numAttnLayers</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.NN.Transformer.html#TransformerLayerSpec"><span class="hs-identifier hs-type">TransformerLayerSpec</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679721113"><span class="hs-identifier hs-type">embedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679721110"><span class="hs-identifier hs-type">numHeads</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679721112"><span class="hs-identifier hs-type">ffnDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679721109"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679721108"><span class="hs-identifier hs-type">device</span></a></span><span class="hs-special">)</span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-480"></span><span>                   </span><span class="hs-special">(</span><span class="annot"><a href="Torch.HList.html#HList"><span class="hs-identifier hs-type">HList</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.HList.html#HReplicateR"><span class="hs-identifier hs-type">HReplicateR</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679721111"><span class="hs-identifier hs-type">numAttnLayers</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.NN.Transformer.html#TransformerLayer"><span class="hs-identifier hs-type">TransformerLayer</span></a></span><span>     </span><span class="annot"><a href="#local-6989586621679721113"><span class="hs-identifier hs-type">embedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679721110"><span class="hs-identifier hs-type">numHeads</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679721112"><span class="hs-identifier hs-type">ffnDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679721109"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679721108"><span class="hs-identifier hs-type">device</span></a></span><span class="hs-special">)</span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-481"></span><span>  </span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.Typed.Tensor.html#KnownDType"><span class="hs-identifier hs-type">KnownDType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679721109"><span class="hs-identifier hs-type">dtype</span></a></span><span>
</span><span id="line-482"></span><span>  </span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.Typed.Factories.html#RandDTypeIsValid"><span class="hs-identifier hs-type">RandDTypeIsValid</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679721108"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679721109"><span class="hs-identifier hs-type">dtype</span></a></span><span>
</span><span id="line-483"></span><span>  </span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.Typed.Aux.html#StandardFloatingPointDTypeValidation"><span class="hs-identifier hs-type">StandardFloatingPointDTypeValidation</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679721108"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.DType.html#Float"><span class="hs-identifier hs-type">D.Float</span></a></span><span>
</span><span id="line-484"></span><span>  </span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.Typed.Tensor.html#BasicArithmeticDTypeIsValid"><span class="hs-identifier hs-type">BasicArithmeticDTypeIsValid</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679721108"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.DType.html#Float"><span class="hs-identifier hs-type">D.Float</span></a></span><span>
</span><span id="line-485"></span><span>  </span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.Typed.Tensor.html#KnownDevice"><span class="hs-identifier hs-type">KnownDevice</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679721108"><span class="hs-identifier hs-type">device</span></a></span><span>
</span><span id="line-486"></span><span>  </span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span> </span><span class="annot"><a href="Torch.NN.html#Randomizable"><span class="hs-identifier hs-type">A.Randomizable</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.NN.Transformer.html#TransformerLMSpec"><span class="hs-identifier hs-type">TransformerLMSpec</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679721111"><span class="hs-identifier hs-type">numAttnLayers</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679721110"><span class="hs-identifier hs-type">numHeads</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679721112"><span class="hs-identifier hs-type">ffnDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679721115"><span class="hs-identifier hs-type">paddingIdx</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679721114"><span class="hs-identifier hs-type">numEmbeds</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679721113"><span class="hs-identifier hs-type">embedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679721109"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679721108"><span class="hs-identifier hs-type">device</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-487"></span><span>                      </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.NN.Transformer.html#TransformerLM"><span class="hs-identifier hs-type">TransformerLM</span></a></span><span>     </span><span class="annot"><a href="#local-6989586621679721111"><span class="hs-identifier hs-type">numAttnLayers</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679721110"><span class="hs-identifier hs-type">numHeads</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679721112"><span class="hs-identifier hs-type">ffnDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679721115"><span class="hs-identifier hs-type">paddingIdx</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679721114"><span class="hs-identifier hs-type">numEmbeds</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679721113"><span class="hs-identifier hs-type">embedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679721109"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679721108"><span class="hs-identifier hs-type">device</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-488"></span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-489"></span><span>  </span><span id="local-6989586621679721106"><span class="annot"><span class="annottext">sample :: TransformerLMSpec
  numAttnLayers
  numHeads
  ffnDim
  paddingIdx
  numEmbeds
  embedDim
  dtype
  device
-&gt; IO
     (TransformerLM
        numAttnLayers
        numHeads
        ffnDim
        paddingIdx
        numEmbeds
        embedDim
        dtype
        device)
</span><a href="#local-6989586621679721106"><span class="hs-identifier hs-var hs-var hs-var hs-var">sample</span></a></span></span><span> </span><span id="local-6989586621679721104"><span id="local-6989586621679721105"><span class="annot"><a href="Torch.Typed.NN.Transformer.html#TransformerLMSpec"><span class="hs-identifier hs-type">TransformerLMSpec</span></a></span><span> </span><span class="hs-special">{</span><span class="hs-glyph">..</span><span class="hs-special">}</span></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-490"></span><span>    </span><span class="annot"><span class="annottext">Embedding
  ('Just paddingIdx) numEmbeds embedDim 'Learned dtype device
-&gt; Embedding 'Nothing 2048 embedDim 'Constant dtype device
-&gt; Dropout
-&gt; HList
     (HReplicateR
        numAttnLayers
        (TransformerLayer embedDim numHeads ffnDim dtype device))
-&gt; Linear embedDim numEmbeds dtype device
-&gt; TransformerLM
     numAttnLayers
     numHeads
     ffnDim
     paddingIdx
     numEmbeds
     embedDim
     dtype
     device
forall (numAttnLayers :: Nat) (numHeads :: Nat) (ffnDim :: Nat)
       (paddingIdx :: Nat) (numEmbeds :: Nat) (embedDim :: Nat)
       (dtype :: DType) (device :: (DeviceType, Nat)).
Embedding
  ('Just paddingIdx) numEmbeds embedDim 'Learned dtype device
-&gt; Embedding 'Nothing 2048 embedDim 'Constant dtype device
-&gt; Dropout
-&gt; HList
     (HReplicateR
        numAttnLayers
        (TransformerLayer embedDim numHeads ffnDim dtype device))
-&gt; Linear embedDim numEmbeds dtype device
-&gt; TransformerLM
     numAttnLayers
     numHeads
     ffnDim
     paddingIdx
     numEmbeds
     embedDim
     dtype
     device
</span><a href="Torch.Typed.NN.Transformer.html#TransformerLM"><span class="hs-identifier hs-var">TransformerLM</span></a></span><span>
</span><span id="line-491"></span><span>      </span><span class="annot"><span class="annottext">(Embedding
   ('Just paddingIdx) numEmbeds embedDim 'Learned dtype device
 -&gt; Embedding 'Nothing 2048 embedDim 'Constant dtype device
 -&gt; Dropout
 -&gt; HList
      (HReplicateR
         numAttnLayers
         (TransformerLayer embedDim numHeads ffnDim dtype device))
 -&gt; Linear embedDim numEmbeds dtype device
 -&gt; TransformerLM
      numAttnLayers
      numHeads
      ffnDim
      paddingIdx
      numEmbeds
      embedDim
      dtype
      device)
-&gt; IO
     (Embedding
        ('Just paddingIdx) numEmbeds embedDim 'Learned dtype device)
-&gt; IO
     (Embedding 'Nothing 2048 embedDim 'Constant dtype device
      -&gt; Dropout
      -&gt; HList
           (HReplicateR
              numAttnLayers
              (TransformerLayer embedDim numHeads ffnDim dtype device))
      -&gt; Linear embedDim numEmbeds dtype device
      -&gt; TransformerLM
           numAttnLayers
           numHeads
           ffnDim
           paddingIdx
           numEmbeds
           embedDim
           dtype
           device)
forall (f :: Type -&gt; Type) a b. Functor f =&gt; (a -&gt; b) -&gt; f a -&gt; f b
</span><a href="../file:///nix/store/yi1zp26n2al045qmp9gwpxblhp2c8gs8-ghc-8.8.3-doc/share/doc/ghc/html/libraries/base-4.13.0.0/src"><span class="hs-operator hs-var">&lt;$&gt;</span></a></span><span> </span><span class="annot"><span class="annottext">EmbeddingSpec
  ('Just paddingIdx) numEmbeds embedDim 'Learned dtype device
-&gt; IO
     (Embedding
        ('Just paddingIdx) numEmbeds embedDim 'Learned dtype device)
forall spec f. Randomizable spec f =&gt; spec -&gt; IO f
</span><a href="Torch.NN.html#sample"><span class="hs-identifier hs-var">A.sample</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">forall (paddingIdx :: Maybe Nat) (numEmbeds :: Nat)
       (embedSize :: Nat) (dtype :: DType) (device :: (DeviceType, Nat)).
EmbeddingSpec paddingIdx numEmbeds embedSize 'Learned dtype device
forall (numEmbeds :: Nat) (embedSize :: Nat) (dtype :: DType)
       (device :: (DeviceType, Nat)).
EmbeddingSpec
  ('Just paddingIdx) numEmbeds embedSize 'Learned dtype device
</span><a href="Torch.Typed.NN.html#LearnedEmbeddingWithRandomInitSpec"><span class="hs-identifier hs-var">LearnedEmbeddingWithRandomInitSpec</span></a></span><span> </span><span class="hs-glyph">@</span><span class="hs-special">(</span><span> </span><span class="hs-special">'</span><span class="annot"><a href="../file:///nix/store/yi1zp26n2al045qmp9gwpxblhp2c8gs8-ghc-8.8.3-doc/share/doc/ghc/html/libraries/base-4.13.0.0/src"><span class="hs-identifier hs-type">Just</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679721115"><span class="hs-identifier hs-type">paddingIdx</span></a></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-492"></span><span>      </span><span class="annot"><span class="annottext">IO
  (Embedding 'Nothing 2048 embedDim 'Constant dtype device
   -&gt; Dropout
   -&gt; HList
        (HReplicateR
           numAttnLayers
           (TransformerLayer embedDim numHeads ffnDim dtype device))
   -&gt; Linear embedDim numEmbeds dtype device
   -&gt; TransformerLM
        numAttnLayers
        numHeads
        ffnDim
        paddingIdx
        numEmbeds
        embedDim
        dtype
        device)
-&gt; IO (Embedding 'Nothing 2048 embedDim 'Constant dtype device)
-&gt; IO
     (Dropout
      -&gt; HList
           (HReplicateR
              numAttnLayers
              (TransformerLayer embedDim numHeads ffnDim dtype device))
      -&gt; Linear embedDim numEmbeds dtype device
      -&gt; TransformerLM
           numAttnLayers
           numHeads
           ffnDim
           paddingIdx
           numEmbeds
           embedDim
           dtype
           device)
forall (f :: Type -&gt; Type) a b.
Applicative f =&gt;
f (a -&gt; b) -&gt; f a -&gt; f b
</span><a href="../file:///nix/store/yi1zp26n2al045qmp9gwpxblhp2c8gs8-ghc-8.8.3-doc/share/doc/ghc/html/libraries/base-4.13.0.0/src"><span class="hs-operator hs-var">&lt;*&gt;</span></a></span><span> </span><span class="annot"><span class="annottext">EmbeddingSpec 'Nothing 2048 embedDim 'Constant dtype device
-&gt; IO (Embedding 'Nothing 2048 embedDim 'Constant dtype device)
forall spec f. Randomizable spec f =&gt; spec -&gt; IO f
</span><a href="Torch.NN.html#sample"><span class="hs-identifier hs-var">A.sample</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">Tensor device dtype '[2048, embedDim]
-&gt; EmbeddingSpec 'Nothing 2048 embedDim 'Constant dtype device
forall (paddingIdx :: Maybe Nat) (numEmbeds :: Nat)
       (embedSize :: Nat) (dtype :: DType) (device :: (DeviceType, Nat)).
Tensor device dtype '[numEmbeds, embedSize]
-&gt; EmbeddingSpec
     paddingIdx numEmbeds embedSize 'Constant dtype device
</span><a href="Torch.Typed.NN.html#ConstEmbeddingSpec"><span class="hs-identifier hs-var">ConstEmbeddingSpec</span></a></span><span> </span><span class="hs-glyph">@</span><span> </span><span class="hs-special">'</span><span class="annot"><a href="../file:///nix/store/yi1zp26n2al045qmp9gwpxblhp2c8gs8-ghc-8.8.3-doc/share/doc/ghc/html/libraries/base-4.13.0.0/src"><span class="hs-identifier hs-type">Nothing</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">Tensor device 'Float '[2048, embedDim]
-&gt; Tensor device dtype '[2048, embedDim]
forall (dtype' :: DType) (dtype :: DType)
       (device :: (DeviceType, Nat)) (shape :: [Nat]).
KnownDType dtype' =&gt;
Tensor device dtype shape -&gt; Tensor device dtype' shape
</span><a href="Torch.Typed.Tensor.html#toDType"><span class="hs-identifier hs-var">Torch.Typed.Tensor.toDType</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor device 'Float '[2048, embedDim]
forall (numEmbeds :: Nat) (embedDim :: Nat)
       (device :: (DeviceType, Nat)).
(All KnownNat '[numEmbeds, embedDim], 1 &lt;= numEmbeds,
 1 &lt;= Div embedDim 2, (Div embedDim 2 * 2) ~ embedDim,
 StandardFloatingPointDTypeValidation device 'Float,
 BasicArithmeticDTypeIsValid device 'Float, KnownDevice device) =&gt;
Tensor device 'Float '[numEmbeds, embedDim]
</span><a href="Torch.Typed.NN.Transformer.html#sinusoidal"><span class="hs-identifier hs-var">sinusoidal</span></a></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-493"></span><span>      </span><span class="annot"><span class="annottext">IO
  (Dropout
   -&gt; HList
        (HReplicateR
           numAttnLayers
           (TransformerLayer embedDim numHeads ffnDim dtype device))
   -&gt; Linear embedDim numEmbeds dtype device
   -&gt; TransformerLM
        numAttnLayers
        numHeads
        ffnDim
        paddingIdx
        numEmbeds
        embedDim
        dtype
        device)
-&gt; IO Dropout
-&gt; IO
     (HList
        (HReplicateR
           numAttnLayers
           (TransformerLayer embedDim numHeads ffnDim dtype device))
      -&gt; Linear embedDim numEmbeds dtype device
      -&gt; TransformerLM
           numAttnLayers
           numHeads
           ffnDim
           paddingIdx
           numEmbeds
           embedDim
           dtype
           device)
forall (f :: Type -&gt; Type) a b.
Applicative f =&gt;
f (a -&gt; b) -&gt; f a -&gt; f b
</span><a href="../file:///nix/store/yi1zp26n2al045qmp9gwpxblhp2c8gs8-ghc-8.8.3-doc/share/doc/ghc/html/libraries/base-4.13.0.0/src"><span class="hs-operator hs-var">&lt;*&gt;</span></a></span><span> </span><span class="annot"><span class="annottext">DropoutSpec -&gt; IO Dropout
forall spec f. Randomizable spec f =&gt; spec -&gt; IO f
</span><a href="Torch.NN.html#sample"><span class="hs-identifier hs-var">A.sample</span></a></span><span> </span><span class="annot"><span class="annottext">DropoutSpec
</span><a href="#local-6989586621679721105"><span class="hs-identifier hs-var">lmDropoutSpec</span></a></span><span>
</span><span id="line-494"></span><span>      </span><span class="annot"><span class="annottext">IO
  (HList
     (HReplicateR
        numAttnLayers
        (TransformerLayer embedDim numHeads ffnDim dtype device))
   -&gt; Linear embedDim numEmbeds dtype device
   -&gt; TransformerLM
        numAttnLayers
        numHeads
        ffnDim
        paddingIdx
        numEmbeds
        embedDim
        dtype
        device)
-&gt; IO
     (HList
        (HReplicateR
           numAttnLayers
           (TransformerLayer embedDim numHeads ffnDim dtype device)))
-&gt; IO
     (Linear embedDim numEmbeds dtype device
      -&gt; TransformerLM
           numAttnLayers
           numHeads
           ffnDim
           paddingIdx
           numEmbeds
           embedDim
           dtype
           device)
forall (f :: Type -&gt; Type) a b.
Applicative f =&gt;
f (a -&gt; b) -&gt; f a -&gt; f b
</span><a href="../file:///nix/store/yi1zp26n2al045qmp9gwpxblhp2c8gs8-ghc-8.8.3-doc/share/doc/ghc/html/libraries/base-4.13.0.0/src"><span class="hs-operator hs-var">&lt;*&gt;</span></a></span><span> </span><span class="annot"><span class="annottext">HList
  (HReplicateR
     numAttnLayers
     (TransformerLayerSpec embedDim numHeads ffnDim dtype device))
-&gt; IO
     (HList
        (HReplicateR
           numAttnLayers
           (TransformerLayer embedDim numHeads ffnDim dtype device)))
forall spec f. Randomizable spec f =&gt; spec -&gt; IO f
</span><a href="Torch.NN.html#sample"><span class="hs-identifier hs-var">A.sample</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">TransformerLayerSpec embedDim numHeads ffnDim dtype device
-&gt; HList
     (HReplicateR
        numAttnLayers
        (TransformerLayerSpec embedDim numHeads ffnDim dtype device))
forall (n :: Nat) e. HReplicate n e =&gt; e -&gt; HList (HReplicateR n e)
</span><a href="Torch.HList.html#hreplicate"><span class="hs-identifier hs-var">hreplicate</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679721111"><span class="hs-identifier hs-type">numAttnLayers</span></a></span><span> </span><span class="annot"><span class="annottext">TransformerLayerSpec embedDim numHeads ffnDim dtype device
</span><a href="#local-6989586621679721104"><span class="hs-identifier hs-var">lmLayerSpec</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-495"></span><span>      </span><span class="annot"><span class="annottext">IO
  (Linear embedDim numEmbeds dtype device
   -&gt; TransformerLM
        numAttnLayers
        numHeads
        ffnDim
        paddingIdx
        numEmbeds
        embedDim
        dtype
        device)
-&gt; IO (Linear embedDim numEmbeds dtype device)
-&gt; IO
     (TransformerLM
        numAttnLayers
        numHeads
        ffnDim
        paddingIdx
        numEmbeds
        embedDim
        dtype
        device)
forall (f :: Type -&gt; Type) a b.
Applicative f =&gt;
f (a -&gt; b) -&gt; f a -&gt; f b
</span><a href="../file:///nix/store/yi1zp26n2al045qmp9gwpxblhp2c8gs8-ghc-8.8.3-doc/share/doc/ghc/html/libraries/base-4.13.0.0/src"><span class="hs-operator hs-var">&lt;*&gt;</span></a></span><span> </span><span class="annot"><span class="annottext">LinearSpec embedDim numEmbeds dtype device
-&gt; IO (Linear embedDim numEmbeds dtype device)
forall spec f. Randomizable spec f =&gt; spec -&gt; IO f
</span><a href="Torch.NN.html#sample"><span class="hs-identifier hs-var">A.sample</span></a></span><span> </span><span class="annot"><span class="annottext">LinearSpec embedDim numEmbeds dtype device
forall (inputFeatures :: Nat) (outputFeatures :: Nat)
       (dtype :: DType) (device :: (DeviceType, Nat)).
LinearSpec inputFeatures outputFeatures dtype device
</span><a href="Torch.Typed.NN.html#LinearSpec"><span class="hs-identifier hs-var">LinearSpec</span></a></span></span></span></span></span></span></span></span></span><span>
</span><span id="line-496"></span></pre></body></html>