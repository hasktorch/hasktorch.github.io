<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd"><html xmlns="http://www.w3.org/1999/xhtml"><head><link rel="stylesheet" type="text/css" href="style.css" /><script type="text/javascript" src="highlight.js"></script></head><body><pre><span class="hs-pragma">{-# LANGUAGE DataKinds #-}</span><span>
</span><span id="line-2"></span><span class="hs-pragma">{-# LANGUAGE RankNTypes #-}</span><span>
</span><span id="line-3"></span><span class="hs-pragma">{-# LANGUAGE ScopedTypeVariables #-}</span><span>
</span><span id="line-4"></span><span class="hs-pragma">{-# LANGUAGE PolyKinds #-}</span><span>
</span><span id="line-5"></span><span class="hs-pragma">{-# LANGUAGE TypeFamilies #-}</span><span>
</span><span id="line-6"></span><span class="hs-pragma">{-# LANGUAGE TypeOperators #-}</span><span>
</span><span id="line-7"></span><span class="hs-pragma">{-# LANGUAGE FunctionalDependencies #-}</span><span>
</span><span id="line-8"></span><span class="hs-pragma">{-# LANGUAGE FlexibleInstances #-}</span><span>
</span><span id="line-9"></span><span class="hs-pragma">{-# LANGUAGE UndecidableInstances #-}</span><span>
</span><span id="line-10"></span><span class="hs-pragma">{-# LANGUAGE TypeApplications #-}</span><span>
</span><span id="line-11"></span><span class="hs-pragma">{-# LANGUAGE AllowAmbiguousTypes #-}</span><span>
</span><span id="line-12"></span><span class="hs-pragma">{-# LANGUAGE DeriveGeneric #-}</span><span>
</span><span id="line-13"></span><span class="hs-pragma">{-# LANGUAGE FlexibleContexts #-}</span><span>
</span><span id="line-14"></span><span>
</span><span id="line-15"></span><span class="hs-keyword">module</span><span> </span><span class="hs-identifier">Torch.Typed.NN.DataParallel</span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-16"></span><span>
</span><span id="line-17"></span><span class="hs-keyword">import</span><span>           </span><span class="annot"><a href="../file:///nix/store/yi1zp26n2al045qmp9gwpxblhp2c8gs8-ghc-8.8.3-doc/share/doc/ghc/html/libraries/base-4.13.0.0/src"><span class="hs-identifier">Data.Kind</span></a></span><span>
</span><span id="line-18"></span><span class="hs-keyword">import</span><span>           </span><span class="annot"><a href="../file:///nix/store/rl4paa35nh9j6h53mwbr73ss7chbissi-async-2.2.2-doc/share/doc/async-2.2.2/html/src"><span class="hs-identifier">Control.Concurrent.Async</span></a></span><span>
</span><span id="line-19"></span><span class="hs-keyword">import</span><span>           </span><span class="annot"><a href="../file:///nix/store/yi1zp26n2al045qmp9gwpxblhp2c8gs8-ghc-8.8.3-doc/share/doc/ghc/html/libraries/base-4.13.0.0/src"><span class="hs-identifier">GHC.TypeLits</span></a></span><span>
</span><span id="line-20"></span><span class="hs-keyword">import</span><span>           </span><span class="annot"><a href="../file:///nix/store/yi1zp26n2al045qmp9gwpxblhp2c8gs8-ghc-8.8.3-doc/share/doc/ghc/html/libraries/base-4.13.0.0/src"><span class="hs-identifier">System.IO.Unsafe</span></a></span><span>
</span><span id="line-21"></span><span>
</span><span id="line-22"></span><span class="hs-keyword">import</span><span>           </span><span class="annot"><a href="Torch.HList.html"><span class="hs-identifier">Torch.HList</span></a></span><span>
</span><span id="line-23"></span><span class="hs-keyword">import</span><span> </span><span class="hs-keyword">qualified</span><span> </span><span class="annot"><a href="../../../../libtorch-ffi-1.5.0.0/html/src"><span class="hs-identifier">Torch.Internal.Cast</span></a></span><span>                     </span><span class="hs-keyword">as</span><span> </span><span class="annot"><span class="hs-identifier">ATen</span></span><span>
</span><span id="line-24"></span><span class="hs-keyword">import</span><span> </span><span class="hs-keyword">qualified</span><span> </span><span class="annot"><a href="../../../../libtorch-ffi-1.5.0.0/html/src"><span class="hs-identifier">Torch.Internal.Class</span></a></span><span>                    </span><span class="hs-keyword">as</span><span> </span><span class="annot"><span class="hs-identifier">ATen</span></span><span>
</span><span id="line-25"></span><span class="hs-keyword">import</span><span> </span><span class="hs-keyword">qualified</span><span> </span><span class="annot"><a href="Torch.Tensor.html"><span class="hs-identifier">Torch.Tensor</span></a></span><span> </span><span class="hs-keyword">as</span><span> </span><span class="annot"><span class="hs-identifier">D</span></span><span>
</span><span id="line-26"></span><span class="hs-keyword">import</span><span> </span><span class="hs-keyword">qualified</span><span> </span><span class="annot"><a href="Torch.Device.html"><span class="hs-identifier">Torch.Device</span></a></span><span> </span><span class="hs-keyword">as</span><span> </span><span class="annot"><span class="hs-identifier">D</span></span><span>
</span><span id="line-27"></span><span class="hs-keyword">import</span><span> </span><span class="hs-keyword">qualified</span><span> </span><span class="annot"><a href="Torch.DType.html"><span class="hs-identifier">Torch.DType</span></a></span><span> </span><span class="hs-keyword">as</span><span> </span><span class="annot"><span class="hs-identifier">D</span></span><span>
</span><span id="line-28"></span><span class="hs-keyword">import</span><span>           </span><span class="annot"><a href="Torch.Typed.Aux.html"><span class="hs-identifier">Torch.Typed.Aux</span></a></span><span>
</span><span id="line-29"></span><span class="hs-keyword">import</span><span>           </span><span class="annot"><a href="Torch.Typed.Autograd.html"><span class="hs-identifier">Torch.Typed.Autograd</span></a></span><span>
</span><span id="line-30"></span><span class="hs-keyword">import</span><span>           </span><span class="annot"><a href="Torch.Typed.Device.html"><span class="hs-identifier">Torch.Typed.Device</span></a></span><span>
</span><span id="line-31"></span><span class="hs-keyword">import</span><span>           </span><span class="annot"><a href="Torch.Typed.Tensor.html"><span class="hs-identifier">Torch.Typed.Tensor</span></a></span><span>
</span><span id="line-32"></span><span class="hs-keyword">import</span><span>           </span><span class="annot"><a href="Torch.Typed.Parameter.html"><span class="hs-identifier">Torch.Typed.Parameter</span></a></span><span>
</span><span id="line-33"></span><span class="hs-keyword">import</span><span>           </span><span class="annot"><a href="Torch.Typed.Functional.html"><span class="hs-identifier">Torch.Typed.Functional</span></a></span><span>
</span><span id="line-34"></span><span class="hs-keyword">import</span><span>           </span><span class="annot"><a href="Torch.Typed.Factories.html"><span class="hs-identifier">Torch.Typed.Factories</span></a></span><span>
</span><span id="line-35"></span><span class="hs-keyword">import</span><span>           </span><span class="annot"><a href="Torch.Typed.Optim.html"><span class="hs-identifier">Torch.Typed.Optim</span></a></span><span>
</span><span id="line-36"></span><span class="hs-keyword">import</span><span>           </span><span class="annot"><a href="Torch.Typed.NN.html"><span class="hs-identifier">Torch.Typed.NN</span></a></span><span>
</span><span id="line-37"></span><span>
</span><span id="line-38"></span><span class="hs-keyword">data</span><span> </span><span id="ForwardConcurrentlyF"><span class="annot"><a href="Torch.Typed.NN.DataParallel.html#ForwardConcurrentlyF"><span class="hs-identifier hs-var">ForwardConcurrentlyF</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span id="ForwardConcurrentlyF"><span class="annot"><a href="Torch.Typed.NN.DataParallel.html#ForwardConcurrentlyF"><span class="hs-identifier hs-var">ForwardConcurrentlyF</span></a></span></span><span> </span><span class="hs-glyph">|</span><span> </span><span id="ForwardConcurrentlyStochF"><span class="annot"><a href="Torch.Typed.NN.DataParallel.html#ForwardConcurrentlyStochF"><span class="hs-identifier hs-var">ForwardConcurrentlyStochF</span></a></span></span><span>
</span><span id="line-39"></span><span>
</span><span id="line-40"></span><span id="local-6989586621679740426"><span id="local-6989586621679740427"><span id="local-6989586621679740428"><span class="hs-keyword">instance</span><span> </span><span>
</span><span id="line-41"></span><span>  </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="Torch.Typed.NN.html#HasForward"><span class="hs-identifier hs-type">HasForward</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679740428"><span class="hs-identifier hs-type">model</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679740427"><span class="hs-identifier hs-type">input</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679740426"><span class="hs-identifier hs-type">output</span></a></span><span>
</span><span id="line-42"></span><span>  </span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span> </span><span class="annot"><a href="Torch.HList.html#Apply%27"><span class="hs-identifier hs-type">Apply'</span></a></span><span> </span><span class="annot"><a href="Torch.Typed.NN.DataParallel.html#ForwardConcurrentlyF"><span class="hs-identifier hs-type">ForwardConcurrentlyF</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679740428"><span class="hs-identifier hs-type">model</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679740427"><span class="hs-identifier hs-type">input</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="../file:///nix/store/rl4paa35nh9j6h53mwbr73ss7chbissi-async-2.2.2-doc/share/doc/async-2.2.2/html/src"><span class="hs-identifier hs-type">Concurrently</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679740426"><span class="hs-identifier hs-type">output</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-43"></span><span>  </span><span id="local-6989586621679740423"><span class="annot"><span class="annottext">apply' :: ForwardConcurrentlyF -&gt; (model, input) -&gt; Concurrently output
</span><a href="Torch.HList.html#apply%27"><span class="hs-identifier hs-var hs-var hs-var hs-var">apply'</span></a></span></span><span> </span><span class="annot"><a href="Torch.Typed.NN.DataParallel.html#ForwardConcurrentlyF"><span class="hs-identifier hs-type">ForwardConcurrentlyF</span></a></span><span>      </span><span class="hs-special">(</span><span id="local-6989586621679740421"><span class="annot"><span class="annottext">model :: model
</span><a href="#local-6989586621679740421"><span class="hs-identifier hs-var">model</span></a></span></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679740420"><span class="annot"><span class="annottext">input :: input
</span><a href="#local-6989586621679740420"><span class="hs-identifier hs-var">input</span></a></span></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO output -&gt; Concurrently output
forall a. IO a -&gt; Concurrently a
</span><a href="../file:///nix/store/rl4paa35nh9j6h53mwbr73ss7chbissi-async-2.2.2-doc/share/doc/async-2.2.2/html/src"><span class="hs-identifier hs-var">Concurrently</span></a></span><span> </span><span class="annot"><span class="annottext">(IO output -&gt; Concurrently output)
-&gt; (input -&gt; IO output) -&gt; input -&gt; Concurrently output
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><a href="../file:///nix/store/yi1zp26n2al045qmp9gwpxblhp2c8gs8-ghc-8.8.3-doc/share/doc/ghc/html/libraries/base-4.13.0.0/src"><span class="hs-operator hs-var">.</span></a></span><span> </span><span class="annot"><span class="annottext">output -&gt; IO output
forall (f :: * -&gt; *) a. Applicative f =&gt; a -&gt; f a
</span><a href="../file:///nix/store/yi1zp26n2al045qmp9gwpxblhp2c8gs8-ghc-8.8.3-doc/share/doc/ghc/html/libraries/base-4.13.0.0/src"><span class="hs-identifier hs-var">pure</span></a></span><span> </span><span class="annot"><span class="annottext">(output -&gt; IO output) -&gt; (input -&gt; output) -&gt; input -&gt; IO output
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><a href="../file:///nix/store/yi1zp26n2al045qmp9gwpxblhp2c8gs8-ghc-8.8.3-doc/share/doc/ghc/html/libraries/base-4.13.0.0/src"><span class="hs-operator hs-var">.</span></a></span><span> </span><span class="annot"><span class="annottext">model -&gt; input -&gt; output
forall f a b. HasForward f a b =&gt; f -&gt; a -&gt; b
</span><a href="Torch.Typed.NN.html#forward"><span class="hs-identifier hs-var">forward</span></a></span><span> </span><span class="annot"><span class="annottext">model
</span><a href="#local-6989586621679740421"><span class="hs-identifier hs-var">model</span></a></span><span> </span><span class="annot"><span class="annottext">(input -&gt; Concurrently output) -&gt; input -&gt; Concurrently output
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><a href="../file:///nix/store/yi1zp26n2al045qmp9gwpxblhp2c8gs8-ghc-8.8.3-doc/share/doc/ghc/html/libraries/base-4.13.0.0/src"><span class="hs-operator hs-var">$</span></a></span><span> </span><span class="annot"><span class="annottext">input
</span><a href="#local-6989586621679740420"><span class="hs-identifier hs-var">input</span></a></span><span>
</span><span id="line-44"></span><span>  </span><span class="annot"><a href="Torch.HList.html#apply%27"><span class="hs-identifier hs-var">apply'</span></a></span><span> </span><span class="annot"><a href="Torch.Typed.NN.DataParallel.html#ForwardConcurrentlyStochF"><span class="hs-identifier hs-type">ForwardConcurrentlyStochF</span></a></span><span> </span><span class="hs-special">(</span><span id="local-6989586621679740416"><span class="annot"><span class="annottext">model :: model
</span><a href="#local-6989586621679740416"><span class="hs-identifier hs-var">model</span></a></span></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679740415"><span class="annot"><span class="annottext">input :: input
</span><a href="#local-6989586621679740415"><span class="hs-identifier hs-var">input</span></a></span></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO output -&gt; Concurrently output
forall a. IO a -&gt; Concurrently a
</span><a href="../file:///nix/store/rl4paa35nh9j6h53mwbr73ss7chbissi-async-2.2.2-doc/share/doc/async-2.2.2/html/src"><span class="hs-identifier hs-var">Concurrently</span></a></span><span> </span><span class="annot"><span class="annottext">(IO output -&gt; Concurrently output)
-&gt; (input -&gt; IO output) -&gt; input -&gt; Concurrently output
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><a href="../file:///nix/store/yi1zp26n2al045qmp9gwpxblhp2c8gs8-ghc-8.8.3-doc/share/doc/ghc/html/libraries/base-4.13.0.0/src"><span class="hs-operator hs-var">.</span></a></span><span> </span><span class="annot"><span class="annottext">model -&gt; input -&gt; IO output
forall f a b. HasForward f a b =&gt; f -&gt; a -&gt; IO b
</span><a href="Torch.Typed.NN.html#forwardStoch"><span class="hs-identifier hs-var">forwardStoch</span></a></span><span> </span><span class="annot"><span class="annottext">model
</span><a href="#local-6989586621679740416"><span class="hs-identifier hs-var">model</span></a></span><span> </span><span class="annot"><span class="annottext">(input -&gt; Concurrently output) -&gt; input -&gt; Concurrently output
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><a href="../file:///nix/store/yi1zp26n2al045qmp9gwpxblhp2c8gs8-ghc-8.8.3-doc/share/doc/ghc/html/libraries/base-4.13.0.0/src"><span class="hs-operator hs-var">$</span></a></span><span> </span><span class="annot"><span class="annottext">input
</span><a href="#local-6989586621679740415"><span class="hs-identifier hs-var">input</span></a></span></span></span></span><span>
</span><span id="line-45"></span><span>
</span><span id="line-46"></span><span class="hs-comment">-- Run a `model` concurrently on an `input`.</span><span>
</span><span id="line-47"></span><span class="hs-comment">--</span><span>
</span><span id="line-48"></span><span class="hs-comment">-- The `model` is replicated over the supplied `devices'`, and the `input` is scattered</span><span>
</span><span id="line-49"></span><span class="hs-comment">-- over them as well. Then the `forward` function of the replicated `models` is run</span><span>
</span><span id="line-50"></span><span class="hs-comment">-- concurrently on the scattered `inputs`. Finally, the `outputs` are gathered on the</span><span>
</span><span id="line-51"></span><span class="hs-comment">-- target `device'`</span><span>
</span><span id="line-52"></span><span class="hs-comment">--</span><span>
</span><span id="line-53"></span><span class="hs-comment">-- &gt;&gt;&gt; model &lt;- A.sample (LinearSpec @1 @1 @'D.Float @'( 'D.CPU, 0))</span><span>
</span><span id="line-54"></span><span class="hs-comment">-- &gt;&gt;&gt; t = ones @'[2, 1] @'D.Float @'( 'D.CPU, 0)</span><span>
</span><span id="line-55"></span><span class="hs-comment">--</span><span>
</span><span id="line-56"></span><span class="hs-comment">-- &gt;&gt;&gt; :t forward model t</span><span>
</span><span id="line-57"></span><span class="hs-comment">-- forward model t :: IO (Tensor '( 'D.CPU, 0) 'D.Float '[2, 1])</span><span>
</span><span id="line-58"></span><span class="hs-comment">-- &gt;&gt;&gt; forward model t</span><span>
</span><span id="line-59"></span><span class="hs-comment">-- Tensor Float [2,1] [[ 0.2478   ],</span><span>
</span><span id="line-60"></span><span class="hs-comment">--                     [ 0.2478   ]]</span><span>
</span><span id="line-61"></span><span class="hs-comment">--</span><span>
</span><span id="line-62"></span><span class="hs-comment">-- &gt;&gt;&gt; :t forwardConcurrently' @'[ '( 'D.CPU, 0), '( 'D.CUDA, 0)] @'( 'D.CPU, 0) model t</span><span>
</span><span id="line-63"></span><span class="hs-comment">-- forwardConcurrently' @'[ '( 'D.CPU, 0), '( 'D.CUDA, 0)] @'( 'D.CPU, 0) model t</span><span>
</span><span id="line-64"></span><span class="hs-comment">--   :: IO (Tensor '( 'D.CPU, 0) 'D.Float '[2, 1])</span><span>
</span><span id="line-65"></span><span class="hs-comment">-- &gt;&gt;&gt; forwardConcurrently' @'[ '( 'D.CPU, 0), '( 'D.CUDA, 0)] @'( 'D.CPU, 0) model t</span><span>
</span><span id="line-66"></span><span class="hs-comment">-- Tensor Float [2,1] [[ 0.2478   ],</span><span>
</span><span id="line-67"></span><span class="hs-comment">--                     [ 0.2478   ]]</span><span>
</span><span id="line-68"></span><span class="annot"><a href="Torch.Typed.NN.DataParallel.html#forwardConcurrently%27"><span class="hs-identifier hs-type">forwardConcurrently'</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.Typed.NN.DataParallel.html#forwardConcurrentlyStoch%27"><span class="hs-identifier hs-type">forwardConcurrentlyStoch'</span></a></span><span>
</span><span id="line-69"></span><span>  </span><span class="hs-glyph">::</span><span> </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679740411"><span class="annot"><a href="#local-6989586621679740411"><span class="hs-identifier hs-type">devices'</span></a></span></span><span> </span><span id="local-6989586621679740410"><span class="annot"><a href="#local-6989586621679740410"><span class="hs-identifier hs-type">device'</span></a></span></span><span> </span><span id="local-6989586621679740409"><span class="annot"><a href="#local-6989586621679740409"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679740408"><span class="annot"><a href="#local-6989586621679740408"><span class="hs-identifier hs-type">model</span></a></span></span><span> </span><span id="local-6989586621679740407"><span class="annot"><a href="#local-6989586621679740407"><span class="hs-identifier hs-type">input</span></a></span></span><span> </span><span id="local-6989586621679740406"><span class="annot"><a href="#local-6989586621679740406"><span class="hs-identifier hs-type">output</span></a></span></span><span> </span><span id="local-6989586621679740405"><span class="annot"><a href="#local-6989586621679740405"><span class="hs-identifier hs-type">models</span></a></span></span><span> </span><span id="local-6989586621679740404"><span class="annot"><a href="#local-6989586621679740404"><span class="hs-identifier hs-type">inputs</span></a></span></span><span> </span><span id="local-6989586621679740403"><span class="annot"><a href="#local-6989586621679740403"><span class="hs-identifier hs-type">outputs</span></a></span></span><span>
</span><span id="line-70"></span><span>   </span><span class="hs-operator">.</span><span> </span><span class="hs-special">(</span><span> </span><span class="hs-special">'</span><span class="annot"><a href="../file:///nix/store/yi1zp26n2al045qmp9gwpxblhp2c8gs8-ghc-8.8.3-doc/share/doc/ghc/html/libraries/base-4.13.0.0/src"><span class="hs-identifier hs-type">Just</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679740409"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="../file:///nix/store/yi1zp26n2al045qmp9gwpxblhp2c8gs8-ghc-8.8.3-doc/share/doc/ghc/html/libraries/ghc-prim-0.5.3/src"><span class="hs-glyph hs-type">~</span></a></span><span> </span><span class="annot"><a href="Torch.Typed.Device.html#GetDevice"><span class="hs-identifier hs-type">GetDevice</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679740408"><span class="hs-identifier hs-type">model</span></a></span><span>
</span><span id="line-71"></span><span>     </span><span class="hs-special">,</span><span> </span><span class="hs-special">'</span><span class="annot"><a href="../file:///nix/store/yi1zp26n2al045qmp9gwpxblhp2c8gs8-ghc-8.8.3-doc/share/doc/ghc/html/libraries/base-4.13.0.0/src"><span class="hs-identifier hs-type">Just</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679740409"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="../file:///nix/store/yi1zp26n2al045qmp9gwpxblhp2c8gs8-ghc-8.8.3-doc/share/doc/ghc/html/libraries/ghc-prim-0.5.3/src"><span class="hs-glyph hs-type">~</span></a></span><span> </span><span class="annot"><a href="Torch.Typed.Device.html#GetDevice"><span class="hs-identifier hs-type">GetDevice</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679740407"><span class="hs-identifier hs-type">input</span></a></span><span>
</span><span id="line-72"></span><span>     </span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.Typed.Device.html#HasScatter"><span class="hs-identifier hs-type">HasScatter</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679740411"><span class="hs-identifier hs-type">devices'</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679740409"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679740407"><span class="hs-identifier hs-type">input</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679740404"><span class="hs-identifier hs-type">inputs</span></a></span><span>
</span><span id="line-73"></span><span>     </span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.Typed.Device.html#HasReplicate"><span class="hs-identifier hs-type">HasReplicate</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679740411"><span class="hs-identifier hs-type">devices'</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679740409"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679740408"><span class="hs-identifier hs-type">model</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679740405"><span class="hs-identifier hs-type">models</span></a></span><span>
</span><span id="line-74"></span><span>     </span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.HList.html#HZipWithM"><span class="hs-identifier hs-type">HZipWithM</span></a></span><span> </span><span class="annot"><a href="../file:///nix/store/rl4paa35nh9j6h53mwbr73ss7chbissi-async-2.2.2-doc/share/doc/async-2.2.2/html/src"><span class="hs-identifier hs-type">Concurrently</span></a></span><span> </span><span class="annot"><a href="Torch.Typed.NN.DataParallel.html#ForwardConcurrentlyF"><span class="hs-identifier hs-type">ForwardConcurrentlyF</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679740405"><span class="hs-identifier hs-type">models</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679740404"><span class="hs-identifier hs-type">inputs</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679740403"><span class="hs-identifier hs-type">outputs</span></a></span><span>
</span><span id="line-75"></span><span>     </span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.Typed.Device.html#HasGather"><span class="hs-identifier hs-type">HasGather</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679740410"><span class="hs-identifier hs-type">device'</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679740411"><span class="hs-identifier hs-type">devices'</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679740403"><span class="hs-identifier hs-type">outputs</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679740406"><span class="hs-identifier hs-type">output</span></a></span><span>
</span><span id="line-76"></span><span>     </span><span class="hs-special">)</span><span>
</span><span id="line-77"></span><span>  </span><span class="hs-glyph">=&gt;</span><span> </span><span class="annot"><a href="#local-6989586621679740408"><span class="hs-identifier hs-type">model</span></a></span><span>
</span><span id="line-78"></span><span>  </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="#local-6989586621679740407"><span class="hs-identifier hs-type">input</span></a></span><span>
</span><span id="line-79"></span><span>  </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="../file:///nix/store/yi1zp26n2al045qmp9gwpxblhp2c8gs8-ghc-8.8.3-doc/share/doc/ghc/html/libraries/ghc-prim-0.5.3/src"><span class="hs-identifier hs-type">IO</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679740406"><span class="hs-identifier hs-type">output</span></a></span><span>
</span><span id="line-80"></span><span id="forwardConcurrently%27"><span class="annot"><span class="annottext">forwardConcurrently' :: model -&gt; input -&gt; IO output
</span><a href="Torch.Typed.NN.DataParallel.html#forwardConcurrently%27"><span class="hs-identifier hs-var hs-var">forwardConcurrently'</span></a></span></span><span> </span><span id="local-6989586621679740401"><span class="annot"><span class="annottext">model :: model
</span><a href="#local-6989586621679740401"><span class="hs-identifier hs-var">model</span></a></span></span><span> </span><span id="local-6989586621679740400"><span class="annot"><span class="annottext">input :: input
</span><a href="#local-6989586621679740400"><span class="hs-identifier hs-var">input</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="hs-keyword">do</span><span>
</span><span id="line-81"></span><span>  </span><span class="hs-keyword">let</span><span> </span><span id="local-6989586621679740399"><span class="annot"><span class="annottext">models :: HList models
</span><a href="#local-6989586621679740399"><span class="hs-identifier hs-var hs-var">models</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">model -&gt; HList models
forall (devices' :: [(DeviceType, Nat)])
       (device :: (DeviceType, Nat)) f (gs :: [*]).
HasReplicate devices' device f gs =&gt;
f -&gt; HList gs
</span><a href="Torch.Typed.Device.html#replicate"><span class="hs-identifier hs-var">Torch.Typed.Device.replicate</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679740411"><span class="hs-identifier hs-type">devices'</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679740409"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679740408"><span class="hs-identifier hs-type">model</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679740405"><span class="hs-identifier hs-type">models</span></a></span><span> </span><span class="annot"><span class="annottext">model
</span><a href="#local-6989586621679740401"><span class="hs-identifier hs-var">model</span></a></span><span>
</span><span id="line-82"></span><span>      </span><span id="local-6989586621679740397"><span class="annot"><span class="annottext">inputs :: HList inputs
</span><a href="#local-6989586621679740397"><span class="hs-identifier hs-var hs-var">inputs</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">input -&gt; HList inputs
forall k k k (devices' :: k) (device :: k) f (gs :: [k]).
HasScatter devices' device f gs =&gt;
f -&gt; HList gs
</span><a href="Torch.Typed.Device.html#scatter"><span class="hs-identifier hs-var">scatter</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679740411"><span class="hs-identifier hs-type">devices'</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679740409"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679740407"><span class="hs-identifier hs-type">input</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679740404"><span class="hs-identifier hs-type">inputs</span></a></span><span> </span><span class="annot"><span class="annottext">input
</span><a href="#local-6989586621679740400"><span class="hs-identifier hs-var">input</span></a></span><span>
</span><span id="line-83"></span><span>  </span><span id="local-6989586621679740395"><span class="annot"><span class="annottext">HList outputs
</span><a href="#local-6989586621679740395"><span class="hs-identifier hs-var">outputs</span></a></span></span><span> </span><span class="hs-glyph">&lt;-</span><span> </span><span class="annot"><span class="annottext">Concurrently (HList outputs) -&gt; IO (HList outputs)
forall a. Concurrently a -&gt; IO a
</span><a href="../file:///nix/store/rl4paa35nh9j6h53mwbr73ss7chbissi-async-2.2.2-doc/share/doc/async-2.2.2/html/src"><span class="hs-identifier hs-var hs-var">runConcurrently</span></a></span><span> </span><span class="annot"><span class="annottext">(Concurrently (HList outputs) -&gt; IO (HList outputs))
-&gt; Concurrently (HList outputs) -&gt; IO (HList outputs)
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><a href="../file:///nix/store/yi1zp26n2al045qmp9gwpxblhp2c8gs8-ghc-8.8.3-doc/share/doc/ghc/html/libraries/base-4.13.0.0/src"><span class="hs-operator hs-var">$</span></a></span><span> </span><span class="annot"><span class="annottext">HList models -&gt; HList inputs -&gt; Concurrently (HList outputs)
forall k (models :: [k]) (inputs :: [k]) (outputs :: [k]).
HZipWithM
  Concurrently ForwardConcurrentlyF models inputs outputs =&gt;
HList models -&gt; HList inputs -&gt; Concurrently (HList outputs)
</span><a href="Torch.Typed.NN.DataParallel.html#forwardConcurrently"><span class="hs-identifier hs-var">forwardConcurrently</span></a></span><span> </span><span class="annot"><span class="annottext">HList models
</span><a href="#local-6989586621679740399"><span class="hs-identifier hs-var">models</span></a></span><span> </span><span class="annot"><span class="annottext">HList inputs
</span><a href="#local-6989586621679740397"><span class="hs-identifier hs-var">inputs</span></a></span><span>
</span><span id="line-84"></span><span>  </span><span class="hs-keyword">let</span><span> </span><span id="local-6989586621679740392"><span class="annot"><span class="annottext">output :: output
</span><a href="#local-6989586621679740392"><span class="hs-identifier hs-var hs-var">output</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">HList outputs -&gt; output
forall k k k (device' :: k) (devices :: k) (fs :: [k]) g.
HasGather device' devices fs g =&gt;
HList fs -&gt; g
</span><a href="Torch.Typed.Device.html#gather"><span class="hs-identifier hs-var">gather</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679740410"><span class="hs-identifier hs-type">device'</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679740411"><span class="hs-identifier hs-type">devices'</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679740403"><span class="hs-identifier hs-type">outputs</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679740406"><span class="hs-identifier hs-type">output</span></a></span><span> </span><span class="annot"><span class="annottext">HList outputs
</span><a href="#local-6989586621679740395"><span class="hs-identifier hs-var">outputs</span></a></span><span>
</span><span id="line-85"></span><span>  </span><span class="annot"><span class="annottext">output -&gt; IO output
forall (m :: * -&gt; *) a. Monad m =&gt; a -&gt; m a
</span><a href="../file:///nix/store/yi1zp26n2al045qmp9gwpxblhp2c8gs8-ghc-8.8.3-doc/share/doc/ghc/html/libraries/base-4.13.0.0/src"><span class="hs-identifier hs-var">return</span></a></span><span> </span><span class="annot"><span class="annottext">output
</span><a href="#local-6989586621679740392"><span class="hs-identifier hs-var">output</span></a></span><span>
</span><span id="line-86"></span><span id="forwardConcurrentlyStoch%27"><span class="annot"><span class="annottext">forwardConcurrentlyStoch' :: model -&gt; input -&gt; IO output
</span><a href="Torch.Typed.NN.DataParallel.html#forwardConcurrentlyStoch%27"><span class="hs-identifier hs-var hs-var">forwardConcurrentlyStoch'</span></a></span></span><span> </span><span id="local-6989586621679740390"><span class="annot"><span class="annottext">model :: model
</span><a href="#local-6989586621679740390"><span class="hs-identifier hs-var">model</span></a></span></span><span> </span><span id="local-6989586621679740389"><span class="annot"><span class="annottext">input :: input
</span><a href="#local-6989586621679740389"><span class="hs-identifier hs-var">input</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="hs-keyword">do</span><span>
</span><span id="line-87"></span><span>  </span><span class="hs-keyword">let</span><span> </span><span id="local-6989586621679740388"><span class="annot"><span class="annottext">models :: HList models
</span><a href="#local-6989586621679740388"><span class="hs-identifier hs-var hs-var">models</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">model -&gt; HList models
forall (devices' :: [(DeviceType, Nat)])
       (device :: (DeviceType, Nat)) f (gs :: [*]).
HasReplicate devices' device f gs =&gt;
f -&gt; HList gs
</span><a href="Torch.Typed.Device.html#replicate"><span class="hs-identifier hs-var">Torch.Typed.Device.replicate</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679740411"><span class="hs-identifier hs-type">devices'</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679740409"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679740408"><span class="hs-identifier hs-type">model</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679740405"><span class="hs-identifier hs-type">models</span></a></span><span> </span><span class="annot"><span class="annottext">model
</span><a href="#local-6989586621679740390"><span class="hs-identifier hs-var">model</span></a></span><span>
</span><span id="line-88"></span><span>      </span><span id="local-6989586621679740387"><span class="annot"><span class="annottext">inputs :: HList inputs
</span><a href="#local-6989586621679740387"><span class="hs-identifier hs-var hs-var">inputs</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">input -&gt; HList inputs
forall k k k (devices' :: k) (device :: k) f (gs :: [k]).
HasScatter devices' device f gs =&gt;
f -&gt; HList gs
</span><a href="Torch.Typed.Device.html#scatter"><span class="hs-identifier hs-var">scatter</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679740411"><span class="hs-identifier hs-type">devices'</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679740409"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679740407"><span class="hs-identifier hs-type">input</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679740404"><span class="hs-identifier hs-type">inputs</span></a></span><span> </span><span class="annot"><span class="annottext">input
</span><a href="#local-6989586621679740389"><span class="hs-identifier hs-var">input</span></a></span><span>
</span><span id="line-89"></span><span>  </span><span id="local-6989586621679740386"><span class="annot"><span class="annottext">HList outputs
</span><a href="#local-6989586621679740386"><span class="hs-identifier hs-var">outputs</span></a></span></span><span> </span><span class="hs-glyph">&lt;-</span><span> </span><span class="annot"><span class="annottext">Concurrently (HList outputs) -&gt; IO (HList outputs)
forall a. Concurrently a -&gt; IO a
</span><a href="../file:///nix/store/rl4paa35nh9j6h53mwbr73ss7chbissi-async-2.2.2-doc/share/doc/async-2.2.2/html/src"><span class="hs-identifier hs-var hs-var">runConcurrently</span></a></span><span> </span><span class="annot"><span class="annottext">(Concurrently (HList outputs) -&gt; IO (HList outputs))
-&gt; Concurrently (HList outputs) -&gt; IO (HList outputs)
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><a href="../file:///nix/store/yi1zp26n2al045qmp9gwpxblhp2c8gs8-ghc-8.8.3-doc/share/doc/ghc/html/libraries/base-4.13.0.0/src"><span class="hs-operator hs-var">$</span></a></span><span> </span><span class="annot"><span class="annottext">HList models -&gt; HList inputs -&gt; Concurrently (HList outputs)
forall k (models :: [k]) (inputs :: [k]) (outputs :: [k]).
HZipWithM
  Concurrently ForwardConcurrentlyF models inputs outputs =&gt;
HList models -&gt; HList inputs -&gt; Concurrently (HList outputs)
</span><a href="Torch.Typed.NN.DataParallel.html#forwardConcurrentlyStoch"><span class="hs-identifier hs-var">forwardConcurrentlyStoch</span></a></span><span> </span><span class="annot"><span class="annottext">HList models
</span><a href="#local-6989586621679740388"><span class="hs-identifier hs-var">models</span></a></span><span> </span><span class="annot"><span class="annottext">HList inputs
</span><a href="#local-6989586621679740387"><span class="hs-identifier hs-var">inputs</span></a></span><span>
</span><span id="line-90"></span><span>  </span><span class="hs-keyword">let</span><span> </span><span id="local-6989586621679740384"><span class="annot"><span class="annottext">output :: output
</span><a href="#local-6989586621679740384"><span class="hs-identifier hs-var hs-var">output</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">HList outputs -&gt; output
forall k k k (device' :: k) (devices :: k) (fs :: [k]) g.
HasGather device' devices fs g =&gt;
HList fs -&gt; g
</span><a href="Torch.Typed.Device.html#gather"><span class="hs-identifier hs-var">gather</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679740410"><span class="hs-identifier hs-type">device'</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679740411"><span class="hs-identifier hs-type">devices'</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679740403"><span class="hs-identifier hs-type">outputs</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679740406"><span class="hs-identifier hs-type">output</span></a></span><span> </span><span class="annot"><span class="annottext">HList outputs
</span><a href="#local-6989586621679740386"><span class="hs-identifier hs-var">outputs</span></a></span><span>
</span><span id="line-91"></span><span>  </span><span class="annot"><span class="annottext">output -&gt; IO output
forall (m :: * -&gt; *) a. Monad m =&gt; a -&gt; m a
</span><a href="../file:///nix/store/yi1zp26n2al045qmp9gwpxblhp2c8gs8-ghc-8.8.3-doc/share/doc/ghc/html/libraries/base-4.13.0.0/src"><span class="hs-identifier hs-var">return</span></a></span><span> </span><span class="annot"><span class="annottext">output
</span><a href="#local-6989586621679740384"><span class="hs-identifier hs-var">output</span></a></span><span>
</span><span id="line-92"></span><span>
</span><span id="line-93"></span><span class="annot"><a href="Torch.Typed.NN.DataParallel.html#forwardConcurrently"><span class="hs-identifier hs-type">forwardConcurrently</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.Typed.NN.DataParallel.html#forwardConcurrentlyStoch"><span class="hs-identifier hs-type">forwardConcurrentlyStoch</span></a></span><span>
</span><span id="line-94"></span><span>  </span><span class="hs-glyph">::</span><span> </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679740539"><span class="annot"><a href="#local-6989586621679740539"><span class="hs-identifier hs-type">models</span></a></span></span><span> </span><span id="local-6989586621679740538"><span class="annot"><a href="#local-6989586621679740538"><span class="hs-identifier hs-type">inputs</span></a></span></span><span> </span><span id="local-6989586621679740537"><span class="annot"><a href="#local-6989586621679740537"><span class="hs-identifier hs-type">outputs</span></a></span></span><span>
</span><span id="line-95"></span><span>   </span><span class="hs-operator">.</span><span> </span><span class="annot"><a href="Torch.HList.html#HZipWithM"><span class="hs-identifier hs-type">HZipWithM</span></a></span><span> </span><span class="annot"><a href="../file:///nix/store/rl4paa35nh9j6h53mwbr73ss7chbissi-async-2.2.2-doc/share/doc/async-2.2.2/html/src"><span class="hs-identifier hs-type">Concurrently</span></a></span><span> </span><span class="annot"><a href="Torch.Typed.NN.DataParallel.html#ForwardConcurrentlyF"><span class="hs-identifier hs-type">ForwardConcurrentlyF</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679740539"><span class="hs-identifier hs-type">models</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679740538"><span class="hs-identifier hs-type">inputs</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679740537"><span class="hs-identifier hs-type">outputs</span></a></span><span>
</span><span id="line-96"></span><span>  </span><span class="hs-glyph">=&gt;</span><span> </span><span class="annot"><a href="Torch.HList.html#HList"><span class="hs-identifier hs-type">HList</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679740539"><span class="hs-identifier hs-type">models</span></a></span><span>
</span><span id="line-97"></span><span>  </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.HList.html#HList"><span class="hs-identifier hs-type">HList</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679740538"><span class="hs-identifier hs-type">inputs</span></a></span><span>
</span><span id="line-98"></span><span>  </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="../file:///nix/store/rl4paa35nh9j6h53mwbr73ss7chbissi-async-2.2.2-doc/share/doc/async-2.2.2/html/src"><span class="hs-identifier hs-type">Concurrently</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.HList.html#HList"><span class="hs-identifier hs-type">HList</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679740537"><span class="hs-identifier hs-type">outputs</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-99"></span><span id="forwardConcurrently"><span class="annot"><span class="annottext">forwardConcurrently :: HList models -&gt; HList inputs -&gt; Concurrently (HList outputs)
</span><a href="Torch.Typed.NN.DataParallel.html#forwardConcurrently"><span class="hs-identifier hs-var hs-var">forwardConcurrently</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">ForwardConcurrentlyF
-&gt; HList models -&gt; HList inputs -&gt; Concurrently (HList outputs)
forall k (m :: * -&gt; *) f (xs :: [k]) (ys :: [k]) (zs :: [k]).
HZipWithM m f xs ys zs =&gt;
f -&gt; HList xs -&gt; HList ys -&gt; m (HList zs)
</span><a href="Torch.HList.html#hzipWithM"><span class="hs-identifier hs-var">hzipWithM</span></a></span><span> </span><span class="annot"><span class="annottext">ForwardConcurrentlyF
</span><a href="Torch.Typed.NN.DataParallel.html#ForwardConcurrentlyF"><span class="hs-identifier hs-var">ForwardConcurrentlyF</span></a></span><span>
</span><span id="line-100"></span><span id="forwardConcurrentlyStoch"><span class="annot"><span class="annottext">forwardConcurrentlyStoch :: HList models -&gt; HList inputs -&gt; Concurrently (HList outputs)
</span><a href="Torch.Typed.NN.DataParallel.html#forwardConcurrentlyStoch"><span class="hs-identifier hs-var hs-var">forwardConcurrentlyStoch</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">ForwardConcurrentlyF
-&gt; HList models -&gt; HList inputs -&gt; Concurrently (HList outputs)
forall k (m :: * -&gt; *) f (xs :: [k]) (ys :: [k]) (zs :: [k]).
HZipWithM m f xs ys zs =&gt;
f -&gt; HList xs -&gt; HList ys -&gt; m (HList zs)
</span><a href="Torch.HList.html#hzipWithM"><span class="hs-identifier hs-var">hzipWithM</span></a></span><span> </span><span class="annot"><span class="annottext">ForwardConcurrentlyF
</span><a href="Torch.Typed.NN.DataParallel.html#ForwardConcurrentlyStochF"><span class="hs-identifier hs-var">ForwardConcurrentlyStochF</span></a></span><span>
</span><span id="line-101"></span><span>
</span><span id="line-102"></span><span class="hs-keyword">class</span><span> </span><span id="HasGradConcurrently"><span class="annot"><a href="Torch.Typed.NN.DataParallel.html#HasGradConcurrently"><span class="hs-identifier hs-var">HasGradConcurrently</span></a></span></span><span> </span><span id="local-6989586621679740470"><span class="annot"><a href="#local-6989586621679740470"><span class="hs-identifier hs-type">device'</span></a></span></span><span> </span><span id="local-6989586621679740469"><span class="annot"><a href="#local-6989586621679740469"><span class="hs-identifier hs-type">devices</span></a></span></span><span> </span><span id="local-6989586621679740473"><span class="annot"><a href="#local-6989586621679740473"><span class="hs-identifier hs-type">parameters</span></a></span></span><span> </span><span id="local-6989586621679740472"><span class="annot"><a href="#local-6989586621679740472"><span class="hs-identifier hs-type">losses</span></a></span></span><span> </span><span id="local-6989586621679740471"><span class="annot"><a href="#local-6989586621679740471"><span class="hs-identifier hs-type">gradients</span></a></span></span><span> </span><span class="hs-glyph">|</span><span> </span><span class="annot"><a href="#local-6989586621679740470"><span class="hs-identifier hs-type">device'</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679740469"><span class="hs-identifier hs-type">devices</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679740473"><span class="hs-identifier hs-type">parameters</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679740472"><span class="hs-identifier hs-type">losses</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="#local-6989586621679740471"><span class="hs-identifier hs-type">gradients</span></a></span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-103"></span><span>  </span><span id="gradConcurrently"><span class="annot"><a href="Torch.Typed.NN.DataParallel.html#gradConcurrently"><span class="hs-identifier hs-type">gradConcurrently</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.HList.html#HList"><span class="hs-identifier hs-type">HList</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679740473"><span class="hs-identifier hs-type">parameters</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.HList.html#HList"><span class="hs-identifier hs-type">HList</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679740472"><span class="hs-identifier hs-type">losses</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="../file:///nix/store/rl4paa35nh9j6h53mwbr73ss7chbissi-async-2.2.2-doc/share/doc/async-2.2.2/html/src"><span class="hs-identifier hs-type">Concurrently</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.HList.html#HList"><span class="hs-identifier hs-type">HList</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679740471"><span class="hs-identifier hs-type">gradients</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-104"></span><span>
</span><span id="line-105"></span><span class="hs-keyword">data</span><span> </span><span id="GradConcurrentlyF"><span class="annot"><a href="Torch.Typed.NN.DataParallel.html#GradConcurrentlyF"><span class="hs-identifier hs-var">GradConcurrentlyF</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span id="GradConcurrentlyF"><span class="annot"><a href="Torch.Typed.NN.DataParallel.html#GradConcurrentlyF"><span class="hs-identifier hs-var">GradConcurrentlyF</span></a></span></span><span>
</span><span id="line-106"></span><span>
</span><span id="line-107"></span><span id="local-6989586621679740377"><span id="local-6989586621679740378"><span id="local-6989586621679740379"><span id="local-6989586621679740380"><span class="hs-keyword">instance</span><span> </span><span>
</span><span id="line-108"></span><span>  </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="Torch.Typed.Autograd.html#HasGrad"><span class="hs-identifier hs-type">HasGrad</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.HList.html#HList"><span class="hs-identifier hs-type">HList</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679740380"><span class="hs-identifier hs-type">parameters</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.HList.html#HList"><span class="hs-identifier hs-type">HList</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679740379"><span class="hs-identifier hs-type">gradients</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-109"></span><span>  </span><span class="hs-special">,</span><span> </span><span class="annot"><a href="../../../../libtorch-ffi-1.5.0.0/html/src"><span class="hs-identifier hs-type">ATen.Castable</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.HList.html#HList"><span class="hs-identifier hs-type">HList</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679740379"><span class="hs-identifier hs-type">gradients</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">[</span><span class="annot"><a href="Torch.Tensor.html#ATenTensor"><span class="hs-identifier hs-type">D.ATenTensor</span></a></span><span class="hs-special">]</span><span>
</span><span id="line-110"></span><span>  </span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span> </span><span class="annot"><a href="Torch.HList.html#Apply%27"><span class="hs-identifier hs-type">Apply'</span></a></span><span> </span><span class="annot"><a href="Torch.Typed.NN.DataParallel.html#GradConcurrentlyF"><span class="hs-identifier hs-type">GradConcurrentlyF</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.HList.html#HList"><span class="hs-identifier hs-type">HList</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679740380"><span class="hs-identifier hs-type">parameters</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.Typed.Optim.html#Loss"><span class="hs-identifier hs-type">Loss</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679740378"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679740377"><span class="hs-identifier hs-type">dtype</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="../file:///nix/store/rl4paa35nh9j6h53mwbr73ss7chbissi-async-2.2.2-doc/share/doc/async-2.2.2/html/src"><span class="hs-identifier hs-type">Concurrently</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.HList.html#HList"><span class="hs-identifier hs-type">HList</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679740379"><span class="hs-identifier hs-type">gradients</span></a></span><span class="hs-special">)</span><span class="hs-special">)</span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-111"></span><span>  </span><span id="local-6989586621679740375"><span class="annot"><span class="annottext">apply' :: GradConcurrentlyF
-&gt; (HList parameters, Loss device dtype)
-&gt; Concurrently (HList gradients)
</span><a href="#local-6989586621679740375"><span class="hs-identifier hs-var hs-var hs-var hs-var">apply'</span></a></span></span><span> </span><span class="annot"><a href="Torch.Typed.NN.DataParallel.html#GradConcurrentlyF"><span class="hs-identifier hs-type">GradConcurrentlyF</span></a></span><span> </span><span class="hs-special">(</span><span id="local-6989586621679740374"><span class="annot"><span class="annottext">parameters :: HList parameters
</span><a href="#local-6989586621679740374"><span class="hs-identifier hs-var">parameters</span></a></span></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679740373"><span class="annot"><span class="annottext">loss :: Loss device dtype
</span><a href="#local-6989586621679740373"><span class="hs-identifier hs-var">loss</span></a></span></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO (HList gradients) -&gt; Concurrently (HList gradients)
forall a. IO a -&gt; Concurrently a
</span><a href="../file:///nix/store/rl4paa35nh9j6h53mwbr73ss7chbissi-async-2.2.2-doc/share/doc/async-2.2.2/html/src"><span class="hs-identifier hs-var">Concurrently</span></a></span><span> </span><span class="annot"><span class="annottext">(IO (HList gradients) -&gt; Concurrently (HList gradients))
-&gt; (HList parameters -&gt; IO (HList gradients))
-&gt; HList parameters
-&gt; Concurrently (HList gradients)
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><a href="../file:///nix/store/yi1zp26n2al045qmp9gwpxblhp2c8gs8-ghc-8.8.3-doc/share/doc/ghc/html/libraries/base-4.13.0.0/src"><span class="hs-operator hs-var">.</span></a></span><span> </span><span class="annot"><span class="annottext">HList gradients -&gt; IO (HList gradients)
forall (f :: * -&gt; *) a. Applicative f =&gt; a -&gt; f a
</span><a href="../file:///nix/store/yi1zp26n2al045qmp9gwpxblhp2c8gs8-ghc-8.8.3-doc/share/doc/ghc/html/libraries/base-4.13.0.0/src"><span class="hs-identifier hs-var">pure</span></a></span><span>  </span><span class="annot"><span class="annottext">(HList gradients -&gt; IO (HList gradients))
-&gt; (HList parameters -&gt; HList gradients)
-&gt; HList parameters
-&gt; IO (HList gradients)
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><a href="../file:///nix/store/yi1zp26n2al045qmp9gwpxblhp2c8gs8-ghc-8.8.3-doc/share/doc/ghc/html/libraries/base-4.13.0.0/src"><span class="hs-operator hs-var">.</span></a></span><span> </span><span class="annot"><span class="annottext">Loss device dtype -&gt; HList parameters -&gt; HList gradients
forall a b (dtype :: DType) (device :: (DeviceType, Nat)).
HasGrad a b =&gt;
Tensor device dtype '[] -&gt; a -&gt; b
</span><a href="Torch.Typed.Autograd.html#grad"><span class="hs-identifier hs-var">grad</span></a></span><span> </span><span class="annot"><span class="annottext">Loss device dtype
</span><a href="#local-6989586621679740373"><span class="hs-identifier hs-var">loss</span></a></span><span> </span><span class="annot"><span class="annottext">(HList parameters -&gt; Concurrently (HList gradients))
-&gt; HList parameters -&gt; Concurrently (HList gradients)
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><a href="../file:///nix/store/yi1zp26n2al045qmp9gwpxblhp2c8gs8-ghc-8.8.3-doc/share/doc/ghc/html/libraries/base-4.13.0.0/src"><span class="hs-operator hs-var">$</span></a></span><span> </span><span class="annot"><span class="annottext">HList parameters
</span><a href="#local-6989586621679740374"><span class="hs-identifier hs-var">parameters</span></a></span></span></span></span></span><span>
</span><span id="line-112"></span><span>
</span><span id="line-113"></span><span id="local-6989586621679740366"><span id="local-6989586621679740367"><span id="local-6989586621679740368"><span id="local-6989586621679740369"><span id="local-6989586621679740370"><span id="local-6989586621679740371"><span class="hs-keyword">instance</span><span>
</span><span id="line-114"></span><span>  </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="Torch.HList.html#HZipWithM"><span class="hs-identifier hs-type">HZipWithM</span></a></span><span> </span><span class="annot"><a href="../file:///nix/store/rl4paa35nh9j6h53mwbr73ss7chbissi-async-2.2.2-doc/share/doc/async-2.2.2/html/src"><span class="hs-identifier hs-type">Concurrently</span></a></span><span> </span><span class="annot"><a href="Torch.Typed.NN.DataParallel.html#GradConcurrentlyF"><span class="hs-identifier hs-type">GradConcurrentlyF</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679740371"><span class="hs-identifier hs-type">parameters</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679740370"><span class="hs-identifier hs-type">losses</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679740369"><span class="hs-identifier hs-type">gradients'</span></a></span><span>
</span><span id="line-115"></span><span>  </span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.Typed.NN.DataParallel.html#ReduceGradients"><span class="hs-identifier hs-type">ReduceGradients</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679740368"><span class="hs-identifier hs-type">device'</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679740367"><span class="hs-identifier hs-type">devices</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679740369"><span class="hs-identifier hs-type">gradients'</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679740366"><span class="hs-identifier hs-type">gradients</span></a></span><span>
</span><span id="line-116"></span><span>  </span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span> </span><span class="annot"><a href="Torch.Typed.NN.DataParallel.html#HasGradConcurrently"><span class="hs-identifier hs-type">HasGradConcurrently</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679740368"><span class="hs-identifier hs-type">device'</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679740367"><span class="hs-identifier hs-type">devices</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679740371"><span class="hs-identifier hs-type">parameters</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679740370"><span class="hs-identifier hs-type">losses</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679740366"><span class="hs-identifier hs-type">gradients</span></a></span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-117"></span><span>  </span><span id="local-6989586621679740363"><span class="annot"><span class="annottext">gradConcurrently :: HList parameters -&gt; HList losses -&gt; Concurrently (HList gradients)
</span><a href="#local-6989586621679740363"><span class="hs-identifier hs-var hs-var hs-var hs-var">gradConcurrently</span></a></span></span><span> </span><span id="local-6989586621679740362"><span class="annot"><span class="annottext">parameters :: HList parameters
</span><a href="#local-6989586621679740362"><span class="hs-identifier hs-var">parameters</span></a></span></span><span> </span><span id="local-6989586621679740361"><span class="annot"><span class="annottext">losses :: HList losses
</span><a href="#local-6989586621679740361"><span class="hs-identifier hs-var">losses</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span>
</span><span id="line-118"></span><span>    </span><span class="hs-keyword">let</span><span> </span><span id="local-6989586621679740360"><span class="annot"><span class="annottext">gradients :: Concurrently (HList gradients')
</span><a href="#local-6989586621679740360"><span class="hs-identifier hs-var hs-var">gradients</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">GradConcurrentlyF
-&gt; HList parameters
-&gt; HList losses
-&gt; Concurrently (HList gradients')
forall k (m :: * -&gt; *) f (xs :: [k]) (ys :: [k]) (zs :: [k]).
HZipWithM m f xs ys zs =&gt;
f -&gt; HList xs -&gt; HList ys -&gt; m (HList zs)
</span><a href="Torch.HList.html#hzipWithM"><span class="hs-identifier hs-var">hzipWithM</span></a></span><span> </span><span class="annot"><span class="annottext">GradConcurrentlyF
</span><a href="Torch.Typed.NN.DataParallel.html#GradConcurrentlyF"><span class="hs-identifier hs-var">GradConcurrentlyF</span></a></span><span> </span><span class="annot"><span class="annottext">HList parameters
</span><a href="#local-6989586621679740362"><span class="hs-identifier hs-var">parameters</span></a></span><span> </span><span class="annot"><span class="annottext">HList losses
</span><a href="#local-6989586621679740361"><span class="hs-identifier hs-var">losses</span></a></span><span>
</span><span id="line-119"></span><span>    </span><span class="hs-keyword">in</span><span>  </span><span class="annot"><span class="annottext">forall (xxs :: [k]) (ys :: [k]).
ReduceGradients device' devices xxs ys =&gt;
HList xxs -&gt; HList ys
forall k k (device' :: (DeviceType, Nat))
       (devices :: [(DeviceType, Nat)]) (xxs :: [k]) (ys :: [k]).
ReduceGradients device' devices xxs ys =&gt;
HList xxs -&gt; HList ys
</span><a href="Torch.Typed.NN.DataParallel.html#reduceGradients"><span class="hs-identifier hs-var">reduceGradients</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679740368"><span class="hs-identifier hs-type">device'</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679740367"><span class="hs-identifier hs-type">devices</span></a></span><span> </span><span class="annot"><span class="annottext">(HList gradients' -&gt; HList gradients)
-&gt; Concurrently (HList gradients')
-&gt; Concurrently (HList gradients)
forall (f :: * -&gt; *) a b. Functor f =&gt; (a -&gt; b) -&gt; f a -&gt; f b
</span><a href="../file:///nix/store/yi1zp26n2al045qmp9gwpxblhp2c8gs8-ghc-8.8.3-doc/share/doc/ghc/html/libraries/base-4.13.0.0/src"><span class="hs-operator hs-var">&lt;$&gt;</span></a></span><span> </span><span class="annot"><span class="annottext">Concurrently (HList gradients')
</span><a href="#local-6989586621679740360"><span class="hs-identifier hs-var">gradients</span></a></span></span></span></span></span></span></span><span>
</span><span id="line-120"></span><span>
</span><span id="line-121"></span><span class="hs-keyword">class</span><span> </span><span id="ReduceGradients"><span class="annot"><a href="Torch.Typed.NN.DataParallel.html#ReduceGradients"><span class="hs-identifier hs-var">ReduceGradients</span></a></span></span><span> </span><span class="hs-special">(</span><span id="local-6989586621679740464"><span class="annot"><a href="#local-6989586621679740464"><span class="hs-identifier hs-type">device'</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Device.html#DeviceType"><span class="hs-identifier hs-type">D.DeviceType</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="../file:///nix/store/yi1zp26n2al045qmp9gwpxblhp2c8gs8-ghc-8.8.3-doc/share/doc/ghc/html/libraries/ghc-prim-0.5.3/src"><span class="hs-identifier hs-type">Nat</span></a></span><span class="hs-special">)</span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span id="local-6989586621679740463"><span class="annot"><a href="#local-6989586621679740463"><span class="hs-identifier hs-type">devices</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="hs-special">[</span><span class="hs-special">(</span><span class="annot"><a href="Torch.Device.html#DeviceType"><span class="hs-identifier hs-type">D.DeviceType</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="../file:///nix/store/yi1zp26n2al045qmp9gwpxblhp2c8gs8-ghc-8.8.3-doc/share/doc/ghc/html/libraries/ghc-prim-0.5.3/src"><span class="hs-identifier hs-type">Nat</span></a></span><span class="hs-special">)</span><span class="hs-special">]</span><span class="hs-special">)</span><span> </span><span id="local-6989586621679740468"><span class="annot"><a href="#local-6989586621679740468"><span class="hs-identifier hs-type">xxs</span></a></span></span><span> </span><span id="local-6989586621679740467"><span class="annot"><a href="#local-6989586621679740467"><span class="hs-identifier hs-type">ys</span></a></span></span><span> </span><span class="hs-glyph">|</span><span> </span><span class="annot"><a href="#local-6989586621679740464"><span class="hs-identifier hs-type">device'</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679740463"><span class="hs-identifier hs-type">devices</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679740468"><span class="hs-identifier hs-type">xxs</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="#local-6989586621679740467"><span class="hs-identifier hs-type">ys</span></a></span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-122"></span><span>  </span><span id="reduceGradients"><span class="annot"><a href="Torch.Typed.NN.DataParallel.html#reduceGradients"><span class="hs-identifier hs-type">reduceGradients</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.HList.html#HList"><span class="hs-identifier hs-type">HList</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679740468"><span class="hs-identifier hs-type">xxs</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.HList.html#HList"><span class="hs-identifier hs-type">HList</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679740467"><span class="hs-identifier hs-type">ys</span></a></span><span>
</span><span id="line-123"></span><span>
</span><span id="line-124"></span><span id="local-6989586621679740354"><span id="local-6989586621679740355"><span id="local-6989586621679740356"><span id="local-6989586621679740357"><span class="hs-keyword">instance</span><span> </span><span class="hs-pragma">{-# OVERLAPS</span><span> </span><span class="hs-pragma">#-}</span><span>
</span><span id="line-125"></span><span>  </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="Torch.Typed.Device.html#HasToDevice"><span class="hs-identifier hs-type">HasToDevice</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679740357"><span class="hs-identifier hs-type">device'</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679740356"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.HList.html#HList"><span class="hs-identifier hs-type">HList</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679740355"><span class="hs-identifier hs-type">xs</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.HList.html#HList"><span class="hs-identifier hs-type">HList</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679740354"><span class="hs-identifier hs-type">ys</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-126"></span><span>  </span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span> </span><span class="annot"><a href="Torch.Typed.NN.DataParallel.html#ReduceGradients"><span class="hs-identifier hs-type">ReduceGradients</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679740357"><span class="hs-identifier hs-type">device'</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679740356"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-glyph">:</span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="hs-special">]</span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="hs-special">(</span><span class="annot"><a href="Torch.HList.html#HList"><span class="hs-identifier hs-type">HList</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679740355"><span class="hs-identifier hs-type">xs</span></a></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="hs-special">[</span><span class="annot"><a href="../file:///nix/store/yi1zp26n2al045qmp9gwpxblhp2c8gs8-ghc-8.8.3-doc/share/doc/ghc/html/libraries/ghc-prim-0.5.3/src"><span class="hs-identifier hs-type">Type</span></a></span><span class="hs-special">]</span><span class="hs-special">)</span><span class="hs-special">)</span><span> </span><span class="hs-special">'</span><span class="hs-glyph">:</span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="hs-special">]</span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679740354"><span class="hs-identifier hs-type">ys</span></a></span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-127"></span><span>  </span><span id="local-6989586621679740351"><span class="annot"><span class="annottext">reduceGradients :: HList '[HList xs] -&gt; HList ys
</span><a href="#local-6989586621679740351"><span class="hs-identifier hs-var hs-var hs-var hs-var">reduceGradients</span></a></span></span><span> </span><span class="hs-special">(</span><span id="local-6989586621679740350"><span class="annot"><span class="annottext">xs :: HList xs
</span><a href="#local-6989586621679740350"><span class="hs-identifier hs-var">xs</span></a></span></span><span> </span><span class="annot"><a href="Torch.HList.html#%3A."><span class="hs-operator hs-type">:.</span></a></span><span> </span><span class="annot"><a href="Torch.HList.html#HNil"><span class="hs-identifier hs-type">HNil</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">HList xs -&gt; HList ys
forall (device' :: (DeviceType, Nat)) (device :: (DeviceType, Nat))
       f g.
HasToDevice device' device f g =&gt;
f -&gt; g
</span><a href="Torch.Typed.Device.html#toDevice"><span class="hs-identifier hs-var">Torch.Typed.Device.toDevice</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679740357"><span class="hs-identifier hs-type">device'</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679740356"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><span class="annottext">HList xs
</span><a href="#local-6989586621679740350"><span class="hs-identifier hs-var">xs</span></a></span></span></span></span></span><span>
</span><span id="line-128"></span><span>
</span><span id="line-129"></span><span class="hs-keyword">data</span><span> </span><span id="SumF"><span class="annot"><a href="Torch.Typed.NN.DataParallel.html#SumF"><span class="hs-identifier hs-var">SumF</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span id="SumF"><span class="annot"><a href="Torch.Typed.NN.DataParallel.html#SumF"><span class="hs-identifier hs-var">SumF</span></a></span></span><span>
</span><span id="line-130"></span><span>
</span><span id="line-131"></span><span id="local-6989586621679740345"><span class="hs-keyword">instance</span><span> </span><span class="annot"><a href="../file:///nix/store/yi1zp26n2al045qmp9gwpxblhp2c8gs8-ghc-8.8.3-doc/share/doc/ghc/html/libraries/base-4.13.0.0/src"><span class="hs-identifier hs-type">Num</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679740345"><span class="hs-identifier hs-type">y</span></a></span><span> </span><span class="hs-glyph">=&gt;</span><span> </span><span class="annot"><a href="Torch.HList.html#Apply%27"><span class="hs-identifier hs-type">Apply'</span></a></span><span> </span><span class="annot"><a href="Torch.Typed.NN.DataParallel.html#SumF"><span class="hs-identifier hs-type">SumF</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679740345"><span class="hs-identifier hs-type">y</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679740345"><span class="hs-identifier hs-type">y</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679740345"><span class="hs-identifier hs-type">y</span></a></span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-132"></span><span>  </span><span id="local-6989586621679740343"><span class="annot"><span class="annottext">apply' :: SumF -&gt; (y, y) -&gt; y
</span><a href="#local-6989586621679740343"><span class="hs-identifier hs-var hs-var hs-var hs-var">apply'</span></a></span></span><span> </span><span class="hs-identifier">_</span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">(y, y) -&gt; y
forall (t :: * -&gt; *) a. (Foldable t, Num a) =&gt; t a -&gt; a
</span><a href="../file:///nix/store/yi1zp26n2al045qmp9gwpxblhp2c8gs8-ghc-8.8.3-doc/share/doc/ghc/html/libraries/base-4.13.0.0/src"><span class="hs-identifier hs-var">sum</span></a></span></span><span>
</span><span id="line-133"></span><span>
</span><span id="line-134"></span><span id="local-6989586621679740336"><span id="local-6989586621679740337"><span id="local-6989586621679740338"><span id="local-6989586621679740339"><span id="local-6989586621679740340"><span id="local-6989586621679740341"><span class="hs-keyword">instance</span><span>  </span><span class="hs-pragma">{-# OVERLAPPABLE</span><span> </span><span class="hs-pragma">#-}</span><span>
</span><span id="line-135"></span><span>  </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="Torch.Typed.Device.html#HasToDevice"><span class="hs-identifier hs-type">HasToDevice</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679740341"><span class="hs-identifier hs-type">device'</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679740340"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.HList.html#HList"><span class="hs-identifier hs-type">HList</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679740339"><span class="hs-identifier hs-type">xs</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.HList.html#HList"><span class="hs-identifier hs-type">HList</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679740338"><span class="hs-identifier hs-type">ys</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-136"></span><span>  </span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.Typed.NN.DataParallel.html#ReduceGradients"><span class="hs-identifier hs-type">ReduceGradients</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679740341"><span class="hs-identifier hs-type">device'</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679740337"><span class="hs-identifier hs-type">devices</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679740336"><span class="hs-identifier hs-type">xxs</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679740338"><span class="hs-identifier hs-type">ys</span></a></span><span>
</span><span id="line-137"></span><span>  </span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.HList.html#HZipWith"><span class="hs-identifier hs-type">HZipWith</span></a></span><span> </span><span class="annot"><a href="Torch.Typed.NN.DataParallel.html#SumF"><span class="hs-identifier hs-type">SumF</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679740338"><span class="hs-identifier hs-type">ys</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679740338"><span class="hs-identifier hs-type">ys</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679740338"><span class="hs-identifier hs-type">ys</span></a></span><span>
</span><span id="line-138"></span><span>  </span><span class="hs-special">,</span><span> </span><span class="annot"><span class="hs-number">1</span></span><span> </span><span class="annot"><a href="../file:///nix/store/yi1zp26n2al045qmp9gwpxblhp2c8gs8-ghc-8.8.3-doc/share/doc/ghc/html/libraries/base-4.13.0.0/src"><span class="hs-operator hs-type">&lt;=</span></a></span><span> </span><span class="annot"><a href="Torch.HList.html#ListLength"><span class="hs-identifier hs-type">ListLength</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679740336"><span class="hs-identifier hs-type">xxs</span></a></span><span>
</span><span id="line-139"></span><span>  </span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span> </span><span class="annot"><a href="Torch.Typed.NN.DataParallel.html#ReduceGradients"><span class="hs-identifier hs-type">ReduceGradients</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679740341"><span class="hs-identifier hs-type">device'</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679740340"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-glyph">:</span><span> </span><span class="annot"><a href="#local-6989586621679740337"><span class="hs-identifier hs-type">devices</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="hs-special">(</span><span class="annot"><a href="Torch.HList.html#HList"><span class="hs-identifier hs-type">HList</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679740339"><span class="hs-identifier hs-type">xs</span></a></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="hs-special">[</span><span class="annot"><a href="../file:///nix/store/yi1zp26n2al045qmp9gwpxblhp2c8gs8-ghc-8.8.3-doc/share/doc/ghc/html/libraries/ghc-prim-0.5.3/src"><span class="hs-identifier hs-type">Type</span></a></span><span class="hs-special">]</span><span class="hs-special">)</span><span class="hs-special">)</span><span> </span><span class="hs-special">'</span><span class="hs-glyph">:</span><span> </span><span class="annot"><a href="#local-6989586621679740336"><span class="hs-identifier hs-type">xxs</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679740338"><span class="hs-identifier hs-type">ys</span></a></span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-140"></span><span>  </span><span id="local-6989586621679740334"><span class="annot"><span class="annottext">reduceGradients :: HList (HList xs : xxs) -&gt; HList ys
</span><a href="#local-6989586621679740334"><span class="hs-identifier hs-var hs-var hs-var hs-var">reduceGradients</span></a></span></span><span> </span><span class="hs-special">(</span><span id="local-6989586621679740333"><span class="annot"><span class="annottext">xs :: HList xs
</span><a href="#local-6989586621679740333"><span class="hs-identifier hs-var">xs</span></a></span></span><span> </span><span class="annot"><a href="Torch.HList.html#%3A."><span class="hs-operator hs-type">:.</span></a></span><span> </span><span id="local-6989586621679740332"><span class="annot"><span class="annottext">xxs :: HList xxs
</span><a href="#local-6989586621679740332"><span class="hs-identifier hs-var">xxs</span></a></span></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">SumF -&gt; HList ys -&gt; HList ys -&gt; HList ys
forall k f (xs :: [k]) (ys :: [k]) (zs :: [k]).
HZipWith f xs ys zs =&gt;
f -&gt; HList xs -&gt; HList ys -&gt; HList zs
</span><a href="Torch.HList.html#hzipWith"><span class="hs-identifier hs-var">hzipWith</span></a></span><span> </span><span class="annot"><span class="annottext">SumF
</span><a href="Torch.Typed.NN.DataParallel.html#SumF"><span class="hs-identifier hs-var">SumF</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">HList xs -&gt; HList ys
forall (device' :: (DeviceType, Nat)) (device :: (DeviceType, Nat))
       f g.
HasToDevice device' device f g =&gt;
f -&gt; g
</span><a href="Torch.Typed.Device.html#toDevice"><span class="hs-identifier hs-var">Torch.Typed.Device.toDevice</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679740341"><span class="hs-identifier hs-type">device'</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679740340"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><span class="annottext">HList xs
</span><a href="#local-6989586621679740333"><span class="hs-identifier hs-var">xs</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">HList xxs -&gt; HList ys
forall k k (device' :: (DeviceType, Nat))
       (devices :: [(DeviceType, Nat)]) (xxs :: [k]) (ys :: [k]).
ReduceGradients device' devices xxs ys =&gt;
HList xxs -&gt; HList ys
</span><a href="Torch.Typed.NN.DataParallel.html#reduceGradients"><span class="hs-identifier hs-var">reduceGradients</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679740341"><span class="hs-identifier hs-type">device'</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679740337"><span class="hs-identifier hs-type">devices</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679740336"><span class="hs-identifier hs-type">xxs</span></a></span><span> </span><span class="annot"><span class="annottext">HList xxs
</span><a href="#local-6989586621679740332"><span class="hs-identifier hs-var">xxs</span></a></span><span class="hs-special">)</span></span></span></span></span></span></span><span>
</span><span id="line-141"></span></pre></body></html>